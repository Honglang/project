[{"blogurl": "http://www.theusrus.de/blog\n", "blogroll": [], "title": "Statistical Graphics and more"}, {"content": ["I once in a while stop by at the JMP blog, and I was surprised to find tools and techniques implemented in JMP, which I built into Mondrian in the early 2000s. In the post \u201c Visualization of fuel economy vs. performance \u201c, we find a showcase of using multiple smoothers in a scatterplot for\u00a0acceleration versus fuel economy. \n Before discussing the smoothing issues, lets take a look at the dataset. The data can be found at the Consumer Union\u2019s website , and lists basically only 0-60 mph acceleration and fuel efficiency for 168 cars, along of with a classification of the car type. As Mondrian offers the ability to show graphical queries, which pull images directly from the web, I also added a column containing links to images of the cars. Here is an example for the Chevy Volt: \n \n We immediately see two very efficient cars \u2013 compared to the rest of the cars \u2013 which is the Chevy Volt and the Nissan Leaf. As the examples on the JMP blog leave these two cars out, I chose to do the same. Here is what a smoother for all remaining cars looks like. \n \n Unfortunately, the post on the JMP blog does not tell us which smoother they actually use, but if you compare my result with the first scatterplot in the post, you find quite some differences. Not in the general result, which is better acceleration reduces mileage (what a surprise \u2026), but in the detail interpretation. Whereas the smoother on the JMP blog is quite bumpy, the loess smoother suggest an almost linear relationship except for the range between 20 and 30 mpg, which does not change much even when we change the smoothing parameter. \n Finding adequate and comparable smoothing parameters is the challenge when showing smoothers for multiple groups (usually of different sizes). For this example, I chose spline smoothers, which also allow to plot a confidence band around the smoothing estimate. \n The example shows natural smoothing splines with 1 df. As the groups differ in size and support along the x-axis, the degree of smoothing looks quite different and somewhat inhomogeneous; which usually should not be the case. \n Talking to experts in the field, they only shrugged their shoulders when I asked them, how to find compatible smoothing parameters for different sample sizes. \n Btw, the problem was solved on the JMP blog quite elegantly by using linear fits, i.e. no smoothness at all"], "link": "http://www.theusrus.de/blog/fuel-economy-multiple-scatterplot-smoother/", "bloglinks": {}, "links": {"http://www.theusrus.de/blog": 1, "http://www.consumerreports.org/": 1, "http://www.theusRus.de/": 1, "http://blogs.sas.com/": 1}, "blogtitle": "Statistical Graphics and more"}, {"content": ["Programming a VCR was the classical example of failed user interfaces. Given that the only thing that we need to specify for recording a show on a VCR is the starting date and time as well as the running time, it is hard to believe that it is really that hard. \n \n As summer finally seams to be over now, I found myself switching off the automatic water timer, which helped growing tomatoes and zucchinis to unprecedented size and yield. \n Looking at the tool, I was once again surprised, how simple and effective the interface is, which the manufacturer choose to program this watering computer. \n Instead of letting the user wander through menus on a (too) tiny LCD screen, there is only one central dial, which can set \n \n time of day \n starting time \n frequency, and \n duration \n \n For each function, there is a button to confirm the setting, and you are done. A simple color coding tells you which scale belongs to which function/button. \nYou are thus not able to set the watering to 5 times a day for 8 minutes each \u2013 but watering every 6 hours for 10 minutes will dispose the same amount of water. \n I chose a similar approach of limited but explicit choice for selecting bin width and anchor point of histograms in Mondrian . Instead of giving the user the (apparent) freedom of choice, Mondrian prompts the most common values one would choose for data on that scale \u2013 and in the vast majority of all cases the desired bin parameters can be choosen directly from the menu. \n In cases where some odd value needs to be specified, the \u201cValue\u2026\u201d option does the job \u2013 and, btw, doing it interactively is of course even nicer \u2026 \n (For those who have a hard time with the above interface here is further advice )"], "link": "http://www.theusrus.de/blog/less-is-more/", "bloglinks": {}, "links": {"http://www.youtube.com/": 1, "http://www.theusRus.de/": 1}, "blogtitle": "Statistical Graphics and more"}, {"content": ["I read the President\u2019s Corner of the last ASA Newsletter by Bob Rodrigez the other day and had some flashback to times when statistics met Data Mining in the late 90s. Daryl Pregibon \u2013 who happened to be my boss at that time \u2013 put forth a definition of data mining as \u201c statistics at scale and speed \u201c. This may only be one way to look at it, but it shows that there is certainly a strong link to what we did in statistics for a long time, and the essential difference may be more along the technological lines regarding data storage and processing. Bob does phrase exactly the same thing for Big Data 15 years later, when he says \u201c statisticians must be prepared for a different hardware and software infrastructure \u201c. \n Whereas the inventors and promotors of the new buzz word Big Data even create a new profession, called \u201cData Scientist\u201d, the are largely lacking ideas which can describe their conceptual activities (at least ones, which we didn\u2019t use in statistics for decades \u2026). \n Let me try to put Big Data into perspective by contrasting it to statistics and Data Mining: \n \n Whereas statistics and data mining usually deal with fairly well structured data, big data is usually more or less unstructured. Classical statistical procedures were based on (small) planned samples and data mining input was usually derived from (large) transactional sources or remote sensing. Big data goes even further, i.e., collects data at points where we don\u2019t expect someone to be listening, and stores it in immense array of data storage (some people call it \u201cthe cloud\u201d). Be it the location via mobile phones, visited websites via cookies or \u201clikes\u201d, or posts in the so called social web \u2013 someone is recording that data and looks for the next best opportunity to sell it; whether we agree to, or not. \n The marketing aspect is even more important for Big Data than for it was for data mining. Quite similar to the US political campaigns, consulting companies like McKinsey publish papers like \u201c Big data: The next frontier for innovation, competition, and productivity \u201c, which tell us, that we are essentially doomed, if we do not react on the new challenge \u2013 and btw. they are ready to help us for just a few bucks \u2026 \n What is missing though, are the analytical concepts to deal with Big Data \u2013 and to be honest, there is no way around good old statistics. Companies like SAS create high performance tools, that now can connect to Hadoop etc. and will compute good old logistic regression on billions of records in only a few minutes \u2013 the only question is, who would ever feel the need to, or even worse, trusts its results without further diagnostics?"], "link": "http://www.theusrus.de/blog/some-truth-about-big-data/", "bloglinks": {}, "links": {"http://magazine.amstat.org/blog": 1, "http://www.google.de/": 1}, "blogtitle": "Statistical Graphics and more"}, {"content": ["Developing software in academia usually does not lead to commercial products, and if the intention is just this, the academic qualities often fail to reach common standards. Nonetheless, there is always the hope that commercial products might pick up the ideas generated in academic software projects. \n Being involved in many software projects on (interactive) statistical graphics over the course of the last 20 years, one was often disappointed about how little was picked up by the commercial counterpart. All the more I was very surprised to find this post on the JMP-blog: \n  \n which is quite similar, to what can be found in an older post by me back in 2005 \u2013 but here is my current reproduction of the JMP post: \n  \n What was even nicer to read was the phrase \u201c\u2026an analysis of the 2005 Tour is featured in the excellent book by Theus and Urbanek titled\u00a0 Interactive Graphics for Data Analysis .\u201d It seems that the JMP developers once in a while take a look at our book and implement the one or the other feature from the book, which you will also (mostly) find within Mondrian \u2013 can it get any better?"], "link": "http://www.theusrus.de/blog/as-good-as-it-gets/", "bloglinks": {}, "links": {"http://www.interactivegraphics.org": 1, "http://www.theusrus.de/blog": 1, "http://blogs.sas.com/": 2, "http://www.theusRus.de/Blog": 1, "http://www.amazon.com/": 1, "http://www.theusRus.de/": 1}, "blogtitle": "Statistical Graphics and more"}, {"content": ["\u2013 That\u2019s it for this year \u2026 \n After we all recovered from the \u201cshock\u201d that Spanish soccer is still hard to beat (no matter if you are Italian or German \u2026) its time to look into this year\u2019s Tour de France data. \n After the first 4 stages passed, I will start to log the results in the usual ways as in 2005 , 2006 , 2007 , 2008 ,\u00a0 2009 ,\u00a0 2010 \u00a0and 2011 now: \n \n \n \n Stage Results \n cumulative Time \n Ranks \n \n \n  \n  \n  \n \n \n (click on the images to enlarge) \n - each line corresponds to a rider \n- smaller numbers are shorter times, i.e. better ranks \n- all stages are on a common scale, \n- stage-results and cum-times are aligned at the median, which corresponds to the peloton \n \n \n \n \n STAGE 4: still 45 riders very compact, but hey \u2013 a German winner \u2026 \nSTAGE 5: almost no change in the classement \nSTAGE 6: a massive pile up of dozens of riders cuts the leading group by half \nSTAGE 7: not\u00a0CANCELLARA\u2019s day, he gave the jersey to WIGGINS for now \u2026 \nSTAGE 8: RADIOSHACK-NISSAN now the leading team. \nSTAGE 9: again a strong performance of WIGGINS, but the mountains will tell \u2026 \nSTAGE 10: a group of 5 makes the day, but can\u2019t challenge the yellow jersey \nSTAGE 11: quite some shake up in the ranks, but no surprises at the top \nSTAGE 12: team RADIOSHACK with 4 riders in the top 15 \nSTAGE 13: no changes in the top 15 for two stages now \nSTAGE 14: as neither the top 15 nor flop 15 change, its time to look at the drop-outs \nSTAGE 15: the small group of 6 breakaways can\u2019t change the field \nSTAGE 16: VOECKLER\u2019S day, but nobody to stop WIGGINS \nSTAGE 17: The leaders make the day; only 2 stages left \nSTAGE 18: Jan GHYSELINCK\u2019S mysterious reentry of the Tour \u2026 \nSTAGE 19: WIGGINS faster than ever \u2013 how come? \nSTAGE 20: The trace of the winner \u2013 the first British ever. \n For those who want to play with the data . The graphs are created with Mondrian . \n There is a more elaborate analysis of Tour de France (2005) data in the book . \n Of course \u2013 as every year \u2013 a very big thanks to Sergej for updating the script!"], "link": "http://www.theusrus.de/blog/tour-de-france-2012/", "bloglinks": {}, "links": {"http://www.theusrus.de/blog": 7, "http://www.interactivegraphics.org": 1, "http://www.theusrus.de/": 1, "http://www.theusRus.de/Blog": 4}, "blogtitle": "Statistical Graphics and more"}, {"content": ["This one is almost too bad to present, but I could not resist: \n \n The pie chart shows the number of spectators for the past european soccer championships of the last 50 years \u2013 in a pie chart (found on an insert of the \u201c 11Freunde \u201d soccer magazine ). \n Now \u201cthe Good\u201d is too obvious and thus too easy: a simple time series: \n \n Now that looks like a success story. An almost steadily increasing number of spectators bringing in the base cash flow from ticket sales (there are two hick-ups in 1968 / Italy and 1988 / Germany with extremely high number of fans seeing the matches). \n The story behind these number is easy when we look at the number of games played at each of the tournaments: \n \n The system was changed twice in 1980 and 1996 such that far more teams now compete and far more games are played accordingly. \n Looking at the number of spectators per game flattens the time series to an almost constant number of roughly 30,000 to 40,000 spectators per game \u2013 a number which is almost unchanged for the last 16 years: \n \n There are a several other interesting statistics on the insert, but let\u2019s leave with these figures for now. \n Still a long way for the German team to go if they really want to be the champion this time, which I don\u2019t happen to have a good proof for like 2 years ago in the world championship \u2013 although I have something (even worse) in mind \u2026 \n (Sorry for making the graphs in MS Excel, but it was just the fastest \u2026)"], "link": "http://www.theusrus.de/blog/the-good-the-bad-62012-euro-2012-statistics/", "bloglinks": {}, "links": {"http://www.theusrus.de/blog": 1, "http://www.11freunde.de/": 1}, "blogtitle": "Statistical Graphics and more"}, {"content": ["Today is the IPO of Facebook and many of us are asking ourselves what it is, the prospective shareholders are investing in \u2026 The answer is quite simple: \u201cYou\u2019re not the customer, you\u2019re the product\u201d \n Although I am not a friend of circular visualizations, if the whole thing we look at has no repeating nature, Matt MacKeon \u2018s\u00a0visualization of the default privacy settings within Facebook over time\u00a0shows nicely what is going (wr)on(g): \n  \n (click on the image for the interactive version) \n Easy to see how the privacy is gradually taken away from the \u201cdefault\u201d customer. Even those who go to the privacy settings and change the default to more private settings will once in a while be surprised that their settings are back to default, as restructured privacy categories are always set to default even for existing customers. \n Let\u2019s close with a nice example of how the customer <-> product reversal usually ends up:"], "link": "http://www.theusrus.de/blog/facebooks-privacy-erosion-strategy-visualized/", "bloglinks": {}, "links": {"http://mattmckeon.com/": 1, "http://mattmckeon.com": 1, "http://geekisawesome.com/": 1}, "blogtitle": "Statistical Graphics and more"}, {"content": ["In an age where \u201cdata is the new oil\u201d (a controversial claim, worth its own post \u2026) there is data everywhere, i.e., data is collected more and more automatically, be it by smartphones, cameras, or social networks sucking up people\u2019s privacy. Having all this data at hand, opens up the possibility to visualize things we never had a chance to look at before. One (early) example is certainly the \u201c Facebook map \u201c. \n Going back to a quote of John W. Tukey \u2013 who can be seen as the reviving power of statistical graphics, and thus ultimately of visualization in general \u2013 we can learn a bit about the motivation behind graphical data analysis \n \u201c\u2026 paradigm of exploratory data analysis \n a) here is the data \n b) what is it trying to tell us; in particular, which question does it want us to ask? \n c) what seems to be going on? \u201d \n Although there seem to be the \u201cdata first\u201d aspect in both the classical EDA approach and the modern data visualization, we can find a fine distinction regarding the motivation. \n Here are two examples which are dominated by their flashy presentation, but fail to ask the relevant questions and can\u2019t really tell us a story showing what seems to be going on, apart from what we (trivially) knew before. \n  \n This example is taken from the triposo website and shows locations of photos taken with smartphones and logged with the triposo trip advisory application. Whereas this is a cool visualization; what is it trying to tell us? From the comment on the website, we can see how badly the \u201cstory\u201d behind the data fails: \u201c This is probably the clearest example of all: Labor Day celebrations light up Europe and China in a big way. Who doesn\u2019t want to take a picture of a nice 1st of May Parade? \u2026\u201d At least in the last 25 years, it was was hardtop find a single 1st of May Parade in Europe. \n It gets even worse when the visualization actually shows things that are not in the data as in the next example from villevivante . \n  \n Nathan did post this example and finished with \u201c It\u2019s hard to say exactly what you\u2019re seeing here because it does move so fast, and it probably means more if you live in or near Geneva, but speaking to the video itself, you have your highs and lows during the start and end of days. \u201d It is not a particular insight that most of us travel into cities to go to work in the morning and move back out to our home at the end of the day. What is interesting though, is that according to the visualization, people in Geneva do not move along roads, but seem to enter the city like a swarm of bees \u2026 \n To summarize, a good visualization should (at least) fulfill these requirements: \n \n Be clear about what data was used (especially regarding generalization) \n Make sure the visual abstraction does not lead to misinterpretations \n Actually tell a story \n Answer questions where we didn\u2019t know the answer already"], "link": "http://www.theusrus.de/blog/fundamentals-whats-the-story/", "bloglinks": {}, "links": {"http://www.theusrus.de/blog": 1, "http://www.villevivante.ch/": 2, "http://triposo.com/": 2, "http://flowingdata.com/": 1}, "blogtitle": "Statistical Graphics and more"}, {"content": ["Today is the 100th anniversary of the Titanic disaster and it is all over in the media \u2013 ranging from movies to serious reportage. Having worked on visualization of categorical data visualization for a long time, the Titanic data became somewhat like \u201cthe mother of all demo datasets\u201d and may be boring people by now as much as the Iris dataset does for multivariate analyses. \n Nonetheless, there are two issues (which can be found in past posts on this blog), which summarize the most important facts on how the disaster was handled: \n 1. \u201c Women and Children first! \u201c \n (each rectangle shows a combination of Class x Age x Sex) and \nthe proportion of survived passengers via highlighting) \n 2. Travelling 1st Class makes it easier to get into a life boat \u2026 \n \u00a0(Launch sequence of life boats \u2013 woman highlighted) \n The shocking result of this visualization is that the first 6 boats were exclusively used for 1st class passengers (although boat No. 1 was not filled at all), and it took another 4 boats until 3rd class passengers were considered to be saved. Starting with the 15th life boat, chaos spread, and the last three boats went afloat almost empty. \n Looking at the two visualizations, shows clearly what fuels the stories (not only) in the Titanic movies. 2nd class males are among those with the lowest survival rate, indicating a very heroic attitude. The boat filling strategy shows a strong\u00a0social bias, which can only partly be excused by the coincidence of passengers locations and boat locations. \n (Here is the data on the passengers and boats used for the visualization )"], "link": "http://www.theusrus.de/blog/titanic-disaster-visualization-insights-100-years-later/", "bloglinks": {}, "links": {"http://www.theusrus.de/blog": 2, "http://www.theusRus.de/": 1, "http://www.theusRus.de/Blog": 3}, "blogtitle": "Statistical Graphics and more"}, {"content": ["Some weeks ago I was browsing through the categories of TED Talks and was surprised to find an entry on statistics \u2013 which is regraded to be a very boring topic by most people. \n The talk I chose to watch was by Nic Marks \u2013 as I tried to avoid yet another Hans Rosling talk. \n \n \nApart from Marks\u2019 sweeping positive charisma, what struck me most, was the very relevant question, why we choose measures like GDP or NASDAQ to measure our \u201cwellbeing\u201d \u2013 as these KPIs mostly measure how efficient we destroy our (or others) environment or how much we increased the imbalance of wealth within our societies. \n After watching the talk I ended up at the happy planet index site, and found myself flipping through their report . On page 16, I found Figure 2, which kind of blew me away. \n \n I don\u2019t want to get into moral preachings here, but take your time and rethink your life and attitude and try to come up with some explanation and projection of what has changed over the last 45 years \u2013 I am curious to see your comments. \n Sometimes even very simple statistics make you think hard \u2026"], "link": "http://www.theusrus.de/blog/happy-statistics/", "bloglinks": {}, "links": {"http://www.ted.com/": 3, "http://www.happyplanetindex.org/": 2}, "blogtitle": "Statistical Graphics and more"}, {"content": ["On the JMP blog you find a post which uses the same data source I took for my first attempt to visualize the web of the EU debt . I found it hard to really make a point with this data. Looking at the JMP post tells me I wasn\u2019t all too bad. Let\u2019s walk through their visualizations: \n \n The Map \nCertainly necessary for someone in the US \u2013 who knows where Portugal, Spain and Austria are; or was it Australia ..? \nBut seriously, scaling the very irregular shapes of the countries outline has more problems (on the perceptual side) as benefits. \n The Heat Map \nThis graph degrades the information to a binary information of being creditor or not \u2013 be it 1\u20ac or 1,000,000,000\u20ac. The conclusion that Germany and France are in trouble because they lend to many other countries is not convincing as it only reflects their economical power. \n The Tree Map \nAs tree maps are \u201conly\u201d a different representation of a tree, i.e., a hierarchy, why would you visualize a matrix with it? I can\u2019t really \u00a0follow the chain reaction of defaults which is interpreted from this tree map. Looks a bit along the lines \u201cif all you have is a hammer, every problem looks like a nail\u201d. \n \n One thing that is really not well thought about the graphs are the different color schemes between the graphs. \n In the end, I think someone really needs to get \u201cthe right\u201d data and show us \u201cthe right\u201d visualizations such that we understand what\u2019s going on \u2013 but hurry up, Greece might be broke by then \u2026"], "link": "http://www.theusrus.de/blog/eu-debt-crisis-visualizations-no-jmp-foreward/", "bloglinks": {}, "links": {"http://www.theusrus.de/blog": 1, "http://www.co.uk/": 1, "http://blogs.sas.com/": 1}, "blogtitle": "Statistical Graphics and more"}, {"content": ["Looking for a map of the french Departments, I came across this map of the population density of France on Departments level which can be found on Wikipedia \u2013 and you may guess: this is this month\u2019s \u201cThe Bad\u201d. \n \n At first sight there seems to be a contradiction between the apparently continuous color scale (see here for some thoughts on coropleth maps) and the map that does not seem to give any decent insight in the geographical distribution of population density. The answer is twofold. \n 1. The color scale is not continuous but has a break between green and blue (unless you invert the shades of blue) and blue and yellow. What we would expect \u2013 in less saturated colors \u2013 looks like this: \n \n 2. For a map showing a continuous quantity, we usually would not choose so many different saturated colors. \n Let\u2019s approach \u201cThe Good\u201d as I still need to convince you that there might be a better version of the map. In a perfect world, coropleth maps look smooth and \u201ccontinuous\u201d. For the map of France we might want to look at the distance to the capitol Paris, as France is very centralistic. This map uses a monochromatic scale and shows \u201cthe perfect world\u201d \u2026 \n \n As this one is obviously too trivial, we want to look at the population density as in the above plot (2011 census data from wikipedia ). Using a simple linear scale we would end up with this (useless) map, which uses a color scale that ranges from blue (small values) over white (median values) to red (large values): \n \n Except for Paris and three other departments, all regions are unpopulated compared to the capitol. The extremely skewed distribution which is shown in the lower left, explains the dilemma. \n Using the same \u201ctrick\u201d as in the original wiki-map, i.e., cutting off all values above 150 we get a map that is easier to read, but now equalizes all information for areas above 150. \n \n (Note, I used the histogram of log(population Density) for the legend) \n The result is much better now, but there seem to be too many departments put into a single class. \n From the data on the log-scale, we already see what would be most desirable, i.e., a distribution of colors, which is close to a normal distribution. Using a non-continuous transformation of the variable we display, we can map the color-shades to be normal, which ends up in the following map, which I would classify as \u201cThe Good\u201d. \n \n We now get a fairly good feeling of which regions are highly populated, which ones are close to the median (even with a distinction of being above or below average) and also clearly see the extremely unpopulated departments. \n There is a lot more to say about the do\u2019s and don\u2019ts for drawing choropleth maps (which can be found here in Chapter 6). What is even more fun is to play around yourself! Here is the data (unzip and load France.txt with Mondrian) and here is the software \u2013 have fun! \n (Thanks to Antony for providing the map!)"], "link": "http://www.theusrus.de/blog/the-good-the-bad-22012/", "bloglinks": {}, "links": {"http://www.interactivegraphics.org": 1, "http://www.rosuda.org/": 1, "http://www.theusRus.de/Blog": 1, "http://gabrielflor.it/": 1, "http://en.wikipedia.org/": 2, "http://www.theusRus.de/": 1}, "blogtitle": "Statistical Graphics and more"}]
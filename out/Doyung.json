[{"blogurl": "http://shom83.blogspot.com\n", "blogroll": [], "title": "Doyung"}, {"content": ["I was experimenting with Graphlab and Mahout for Matrix Factorization these days. Matrix factorization transform both items and users to the same latent factor space so they can be compared directly. Even though Mahout and Graphlab is great tool for matrix factorization, these are designed for batch process. to get recommendations for new users who rate existing movies in rate matrix, following two steps are necessary. 1) transform user-rating vector to user-latent feature vector. 2) compare all movie-latent feature vectors with 1) and calculate scores.  this demo ask user to rate movies and do 1), 2) step.  most of work is just glue codes from Mahout with Jetty.  check out this and feel free to give me any feedback. Update: added label propagation to find serendipities. since the training data is small enough(1.7 million user, 40 K movies, 19 million edge), just load training data into memory. Todo: I will update with evaluation metric(RMSE, MAP, Precision-Recall) after running batch jobs for this dataset using mahout/Graphlab for ALS, Giraph for label propagation. also, add item-based cf as baseline to compare result"], "link": "http://shom83.blogspot.com/feeds/7907000654463406058/comments/default", "bloglinks": {}, "links": {}, "blogtitle": "Doyung"}, {"content": ["\uac1c\uc778\uc801\uc778 \uad00\uc2ec\uc0ac\uac00 machine learning\uc778\uc9c0\ub77c \ud3c9\uc18c\uc5d0 \uc8fc\ub85c map/reduce\ub97c \uc0ac\uc6a9\ud55c mahout\uc744 \uc774\uc6a9\ud574 \ud544\uc694\ud55c \uc54c\uace0\ub9ac\uc998\ub4e4\uc744 \uc0ac\uc6a9\ud558\uace4 \ud588\ub2e4. \uc694\uc0ac\uc774 \ub9e4\ub2ec\ub9ac\uace0 \uc788\ub294 matrix factorization\ubb38\uc81c\ub97c \ud574\uacb0 \ud558\ub824\uace0 \uc2dc\ub3c4\ud558\ub2e4\uac00 \uc54c\uac8c \ub41c \uc810 \ub4e4\uc744 \uba87\uc790 \uc801\uc5b4\ubcf8\ub2e4.   mahout\uc744 \ub108\ubb34\ub108\ubb34 \uc798 \uc4f0\uace0\ub294 \uc788\uc9c0\ub9cc \uba87\uac00\uc9c0 map/reduce model\uc758 \uadfc\ubcf8\uc801\uc778 \ubb38\uc81c\ub97c \uacc4\uc18d \ub9c8\uc8fc\uce58\uac8c \ub418\ub294\ub370, \uccab \uc9f8\ub85c iterative job\ucc98\ub9ac\uac00 inefficient\ud558\ub2e4\ub294 \uac83\uc774\ub2e4.   Iterative job\uc744 map/reduce\ub85c \uad6c\ud604 \ud560 \ub54c\uc758 \ubb38\uc81c\ub97c \uc880\ub354 \uc790\uc138\ud788 \ub4e4\uc5ec\ub2e4\ubcf4\uba74 \uc544\ub798\uc640 \uac19\ub2e4.       \uc704 \uadf8\ub9bc\uc5d0\uc11c \ub208\uc5ec\uaca8 \ubcfc inefficient \ud55c \uacf3\uc740 \ub450 \uac00\uc9c0 \uc774\ub2e4.  \ud558\ub098\uc758 iteration\ub0b4\uc5d0\uc11c\ub3c4 \ucc98\ub9ac\ud574\uc57c \ud560 \ub370\uc774\ud130\uac00 \ud2b9\uc815 CPU(computing resource)\uc73c\ub85c \ubab0\ub824\uc11c partition\ub420 \uacbd\uc6b0 \ub2e4\ub978 CPU\ub4e4\uc740 \uae30\ub2e4\ub9ac\ub294 lagging\uc774 \ubc1c\uc0dd\ud55c\ub2e4. \uc2e4\uc81c\ub85c \uc0ac\uc6a9\uc790 log graph\ub4e4\uc740 \ub9ce\uc740 \uc218\uc758 edge\ub97c \uac00\uc9c0\ub294 \uba87\uac1c\uc758 vertex\ub4e4\uc744 \uac00\uc9c0\ub294 \uacbd\uc6b0\uac00 \ud754\ud558\uace0, \uc774\ub7f0 vertex\ub4e4\uc774 bottle neck \uc73c\ub85c \uc791\uc6a9\ud55c\ub2e4.  \ub9e4 iteration\ub9c8\ub2e4 \ubc1c\uc0dd\ud558\ub294 barrier\ubd80\ubd84\uc5d0 disk IO\uc640 startup cost\uac00 \uc788\ub2e4. map only job\uc774 # iteration\ub9cc\ud07c hdfs\uc5d0\uc11c input\uc744 \uc77d\uace0, \uacb0\uacfc\ub97c hdfs\uc5d0 \uc4f0\ub294 overhead\uac00 \uc788\ub2e4.  \uc774\ub97c \uadf8\ub9bc\uc73c\ub85c \ud45c\ud604 \ud558\uba74 \uc544\ub798\uc640 \uac19\ub2e4.    \uc774\ub7ec\ud55c iterative\ud55c job\uc744 \ud6a8\uc728\uc801\uc73c\ub85c \ucc98\ub9ac\ud558\uae30 \uc704\ud574 \ub098\uc628 \uac83\ub4e4\uc774 \uad6c\uae00\uc758 pregel\uc774\uace0 \uc774\uc640 \ube44\uc2b7\ud55c framework\ub85c apache Giraph, Hama\uac00 \uc788\ub2e4(\uaf2d iterative job\ub9cc\uc744 \uc704\ud55c\uac74 \uc544\ub2d8, \ub4a4\uc5d0 \uc124\uba85).   \uc774\uc911\uc5d0\uc11c \uc0ac\uc6a9\ud574 \ubcf8 Giraph\ub85c \uac04\ub7b5\ud788 \uc124\uba85\uc744 \ud558\uba74(\uc790\uc138\ud55c \uc124\uba85), map only\uc7a1\uc744 \ud55c\ubc88 submit\ud558\uace0, map only job\uc5d0\uc11c \uc5ec\ub7ec\ubc8c\uc758 worker\uc640 master\ub97c \uc0dd\uc131\ud55c\ub2e4. \uc774 master\ub294 \uac01\uac01\uc758 worker\uc5d0 partition ownership\uc744 \ubd80\uc5ec\ud558\uace0, vertices\ub97c partitioning\ud55c\ub2e4.  \uac01\uac01\uc758 worker\ub294 \uc790\uc2e0\uc5d0\uac8c \uc18d\ud55c vertices\ub4e4\uc5d0\ub300\ud574 compute\ub97c \ud558\uace0 barrier\uc5d0\uc11c sync\ud55c\ub2e4(iteration\ud69f\uc218\ub9cc\ud07c \ubc18\ubcf5).  map/reduce\uc640 \ub2ec\ub9ac hadoop\uc758 startup penalty\ub97c \ud55c\ubc88\uc73c\ub85c \uc904\uc774\uace0, \uac01\uac01\uc758 superstep(iteration)\uc758 \uacb0\uacfc\ub4e4\uc744 hdfs\uac00\uc544\ub2cc memory\uc5d0 \ub4e4\uace0 \uc788\uc5b4 \ub2e4\uc74c superstep\uc5d0\uc11c \ud6e8\uc52c \ube60\ub978 access\uac00 \uac00\ub2a5\ud558\ub2e4.     \ub458\uc9f8\ub85c interdependent computation(graph-parallel algorithm)\uc740 not map-reducible\ud558\ub2e4.  \uc870\uae08\ub354 \uc77c\ubc18\ud654 \ud558\uc790\uba74 \ub9ce\uc740 \uc218\uc758 machine learning algorithm\ub4e4\uc740 \ub2e4\uc74c\uacfc \uac19\uc740 property\ub97c \uac16\ub294\ub2e4.   \ud604\uc7ac vertex X3\uc758 computing\uc744 \uc704\ud574\uc11c X3\uc758 neighbor\ub4e4\uc758 value\ub4e4\uc774 \ud544\uc694\ud55c \uacbd\uc6b0\uac00 \ub9ce\uc740\ub370 \uc774\ub294 mapper\ub07c\ub9ac \ud1b5\uc2e0\uc774 \ubd88\uac00\ub2a5\ud55c map/reduce model\uc5d0\uc11c\ub294 \ucc98\ub9ac \ud558\uae30 \ud798\ub4e4\ub2e4. label propagation algorithm(graph-parallel algorithm)\uc744 \uc608\ub85c \uadf8 \uc77c\ubc18\uc801\uc778 \ud2b9\uc131\uc744 \ubcf4\uc790.    \uc2e4\uc81c\ub85c belief propagation\uac19\uc740 algorithm\uc740 mahout\uc758 DistributedRowMatrix\ub97c \uc774\uc6a9\ud558\uc5ec matrix\ub85c \ubc14\uafd4\uc11c \uc0dd\uac01\ud558\uba74 \uad6c\ud604 \uc790\uccb4\ub294 \uc27d\uac8c \ud560 \uc218 \uc788\ub2e4. \ud558\uc9c0\ub9cc matrix\ud615\ud0dc\ub85c \uc0dd\uac01\ud558\ub294 \uac8c intuitive\ud558\uc9c0\ub3c4 \uc54a\uace0, \uc704\uc5d0\uc11c \ub9d0\ud55c \uccab\ubc88\uc9f8 \uc774\uc720\uc5d0 \uc758\ud574\uc11c\ub3c4 map/reduce\ub9d0\uace0 \ub2e4\ub978 computing model\uc744 \ucc3e\uac8c \ub41c\ub2e4.   \uc5ec\uae30\uc11c \uc774 \ud3ec\uc2a4\ud2b8\uc758 \uc8fc\uc778\uacf5\uc778 Graphlab\uc774 \ub4f1\uc7a5\ud558\uac8c \ub41c\ub2e4.      \uc704\uc5d0\uc11c\uc640 \uac19\uc774 machine learning algorithm\uc744 data-parallel\uacfc graph-parallel\ub85c \uad6c\ubd84 \ud588\uc744 \ub54c Graphlab\uc740 Graph-parallel algorithm\uc5d0 \ud2b9\ud654\ub41c framework\uc774\ub2e4.  \uc0b4\uc9dd \uc911\uac04 \uc815\ub9ac\ub97c \ud558\uc790\uba74, map/reduce\uac00 key, value pair\uc5d0 map/reduce\ub77c\ub294 computation\uc744 \uc815\uc758 \ud558\ub294 framework\uc600\ub2e4\uba74 Graphlab\uc740 graph\uc0c1\uc758 vertex node\uc5d0 gatter, apply, scatter \ub77c\ub294 computation\uc744 \uc815\uc758 \ud558\ub294 framework\uc774\ub2e4.  \uc774 framework\uc5d0\uc11c\ub294 \uac01\uac01\uc758 vertex\ub294 \uc0ac\uc6a9\uc790\uac00 \uc815\uc758 \ud55c vertex-program\uc744 \ud1b5\ud574 \ud544\uc694\ud55c computing\uc744 \ud558\ub294\ub370 \uc774\ub54c neighbor vertex\ub4e4\uc758 \uc0c1\ud0dc\uac12 \ubfd0\ub9cc\uc544\ub2c8\ub77c \ub2e4\ub978 vertex\uc758 \uc0c1\ud0dc \uac12\ub4e4\ub3c4 mpi\ub97c \ud1b5\ud574 \uc5bb\uc5b4 \uc624\ub294 api\uac00 \uc81c\uacf5 \ub41c\ub2e4.   \ub2e4\ub978 \ub9d0\ub85c \uc704\uc5d0\uc11c \ub9d0\ud55c sparse data dependencies\ub294 graph\ub97c \ud1b5\ud574, local updates\ub294 vertex-program\ub97c \ud1b5\ud574 \ub9cc\uc871\ub41c\ub2e4.    \uc774\ub294 \uc0ac\uc2e4 \uc704\uc5d0\uc11c \uc5b8\uae09\ud55c Pregel(Giraph, Hama)\uacfc \uac70\uc758 \ud761\uc0ac\ud558\ub2e4. \ucc28\uc774\uc810\uc774\ub77c\uba74 pregel\uc740 \uac01\uac01\uc758 vertex-program\uc774 message\ub97c \ud1b5\ud574 interact\ud558\uace0, Graphlab\uc740 \uac01\uac01\uc758 program\uc774 dependencies\uac00 \uc788\ub294 \uc11c\ub85c\uc758 state\ub97c access\ud560 \uc218 \uc788\ub2e4\ub294 \uc810\uc774\ub2e4. \ubb34\uc2a8 \uc18c\ub9ac\uc778\uac00? \uc544\ub798\ub97c \ubcf4\uc790.       \uc5ec\uae30\uc11c \uac00\uc7a5 \uc911\uc694\ud55c \uc810\uc740 asynchronously \uc774\ub2e4. \uc704\uc5d0\uc11c \uc124\uba85 \ud588\ub358 BSP model\uc640\uc758 \uac00\uc7a5 \ud070 \ucc28\uc774\uc810\uc740 \ubc14\ub85c \uc774 asynchronous\ud55c execution\uc774\ub2e4. Graphlab\uc740 \uc774\ub7f0 asynchronous update\ub97c scheduling\ud558\uba74\uc11c consistency\ub97c \ubcf4\uc7a5\ud574 \uc8fc\ub294\ub370, \uc774\ub97c \uc704\ud574 \uc544\ub798\uc640 \uac19\uc774 scope rule\uc774\ub77c\ub294 \uac1c\ub150\uc744 \uac00\uc9c4\ub2e4.              \uacb0\ub860\uc801\uc73c\ub85c vertex consisitency\uac00 \uac00\uc7a5 parallel\ud558\uace0, full consistency\uac00 \uac00\uc7a5 non-parallel\ud558\ub2e4. \uc54c\uace0\ub9ac\uc998 \ubcc4\ub85c \uc5b4\ub5a4 scope rule\uc774 \ud544\uc694\ud55c\uc9c0 \uc815\uc758\ud558\uba74 framework\uc774 race condition\uacfc deadlock\uc774 \ubc1c\uc0dd\ud558\uc9c0 \uc54a\ub3c4\ub85d \ubcf4\uc7a5\ud574\uc900\ub2e4.   version1(shared memory)\uc5d0\uc11c\ub294 \ub370\uc774\ud130\uac00 \ucee4\uc9c0\uba74 memory\ub3c4 \ucee4\uc838\uc57c \ud588\uc5c8\uc9c0\ub9cc, version 2\ubd80\ud130\ub294 distributed version\uc73c\ub85c \uc774\ub7f0 \uc81c\uc57d\uc774 \uc5c6\uc5b4\uc84c\uace0, HDFS\ub97c input/output\uc73c\ub85c\ub3c4 \uc0ac\uc6a9\ud560 \uc218 \uc788\uac8c \ub418\uc5c8\ub2e4. \ub610 \ub9e4\uc6b0 \ub2e4\uc591\ud55c algorithm\ub4e4\uc744 toolkit\uc73c\ub85c \uc81c\uacf5\ud558\uace0 \uc788\uc5b4\uc11c \ub2f9\uc7a5 \uc0ac\uc6a9\ud574 \ubcfc \uc218 \uc788\ub2e4\ub294 \uc7a5\uc810\ub3c4 \uc788\ub2e4.   \uc790\uc138\ud55c \ub0b4\uc6a9\uc740 http://graphlab.org/ \uc5d0\uc11c \uaf2d \uc0b4\ud3b4\ubcf4\uae38 \ubc14\ub780\ub2e4.  http://videolectures.net/nipsworkshops2010_guestrin_kml/ \ub294 SELECT lab\uc5d0\uc11c NIPS2010\uc5d0 \ubc1c\ud45c\ud55c video\uc774\ub2e4.   reference:  http://graphlab.org/   TODO:  Graphlab\uacfc mahout\uc744 benchmark \ud574\ubcf8 \uacb0\uacfc \uc815\ub9ac MPI + Graphlab setup tutorial Giraph \uc790\uc138\ud55c \uc124\uba85 \ud398\uc774\uc9c0 \uc815\ub9ac"], "link": "http://shom83.blogspot.com/feeds/1461231851096162526/comments/default", "bloglinks": {}, "links": {"http://3.blogspot.com/": 3, "http://graphlab.org/": 2, "http://1.blogspot.com/": 2, "http://videolectures.net/": 1, "http://4.blogspot.com/": 5, "http://2.blogspot.com/": 3}, "blogtitle": "Doyung"}, {"content": ["I found this interesting problem from interview street. problem was to maintain running median from stream of numbers. more formally, following is full problem from interview street . The median of M numbers is defined as the middle number after sorting them in order, if M is odd or the average number of the middle 2 numbers (again after sorting) if M is even. You have an empty number list at first. Then you can add or remove some number from the list. For each add or remove operation, output the median of numbers in the list.  Example : For a set of m = 5 numbers, { 9, 2, 8, 4, 1 } the median is the third number in sorted set { 1, 2, 4, 8, 9 } which is 4. Similarly for set of m = 4, { 5, 2, 10, 4 }, the median is the average of second and the third element in the sorted set { 2, 4, 5, 10 } which is (4+5)/2 = 4.5  Constraints:  0 < n <= 100,000    1. naive If n is small enough, problem is simple. each insert/delete sort entire elements this require n * nlogn(n operation x cost for sorting).    2. using two multiset   Thing is only few elements are affected when insert/delete operation happen. solution using two multiset s1, s2.    invariant  1) s1 is supposed to maintain 0 ~ n/2th order statistic. 2) s2 is supposed to maintain n/2 ~ nth order statistic. 3) s1.size() and s2.size() only differ at most 1.  to hold invariant 1, 2 we compare x(current value to insert or delete) with maximum of s1 and minimum of s2 to decide where to put x.  to hold invariant 3 we need re-balance step this can be done in constant time by 1) moving minimum of s2 to s1 2) moving maximum of s1 to s   Solution once 3 invariant is meet, then calculating median as problem description is trivial.  1) s1.size == s2.size(s1.size + s2.size is even), then return (maximum of s1 + minimum of s2) / 2.0 one tip we should take care of integer overflow when we average two value(32bit integer) since adding two 32bit integer can cause integer overflow. 2) otherwise if s1.size > s2.size, return maximum of s1. s1.size < s2.size, return minimum of s2.  finally checking if we can delete x is trivial, since multiset provide find method in O(logN) complexity.  just good enough pass testcases.  3. using skip list  I was wondering what about more generic cases. few google search gives me link to skip list. for this problem, we exactly need indexable skip list since we keep need to extract median as input comes. obviously this problem can be solved by indexable skip list. here is my simple implementation.  TODO want to take a look at how redis use skip list and understand why skip list is better than self-balance-tree in distributed environment.    check out code here"], "link": "http://shom83.blogspot.com/feeds/4486818226146072543/comments/default", "bloglinks": {}, "links": {"http://www.interviewstreet.com/": 1, "https://github.com/": 1, "http://www.blogger.com/": 1}, "blogtitle": "Doyung"}, {"content": ["Alternating-Least-Squares with Weighted-lambda-Regularization(ALS-WR) Purpose ALS-WR \ub294 model-based \ubc29\uc2dd\uc73c\ub85c \uc6d0\ub798 matrix R\uc744 iterate\ud558\uba74\uc11c U, M \ub450\uac1c\uc758 matrix\ub85c factorize\ud55c\ub2e4. R = (user, item, rate)\ud615\uc2dd\uc758 matrix\ub85c U X I\uc758 \uc0ac\uc774\uc988\ub97c \uac00\uc9c4\ub2e4. \uc6d0\ub798\ub294 R\uc548\uc5d0 \ub300\ubd80\ubd84\uc758 R(i, j)\ub294 \ub2e4 \ube44\uc5b4 \uc788\ub2e4. Collaborative Filtering\uc758 \ubaa9\uc801\uc740 \uc774 \ube44\uc5b4 \uc788\ub294 R(i,j)\ub4e4\uc744 \uc5b4\ud14b\uac8c \uc608\uce21 \ud560 \uac70 \uc778\uac00\uc774\ub2e4. Background CF\ub294 \ud06c\uac8c 3\uac00\uc9c0\ub85c \ub098\ub25c\ub2e4.  \ubc29\uc2dd \uc7a5\uc810 \ub2e8\uc810 memory-based \uacb0\uacfc\uc774\ud574 \uc26c\uc6c0, \uad6c\ud604 \uc26c\uc6c0, centent frer \uc0ac\ub78c\uc774 \ub9e4\uae30\ub294 rating\uc5d0 \uc11e\uc778 noise\uc5d0 \ub300\ucc98 \ubbf8\ud761, spare\ud55c data\uc5d0\uc120 performance down, new user/new item\uc5d0 no result, not very scalable. model-based rate\uc790\uccb4\ubcf4\ub2e4\ub294 training set\uc758 pattern\uc774\uc6a9, sparse data\uc5d0 \ube44\uad50\uc801 \uac15\ud568, \uc9c1\uad00\uc801 \uacb0\uacfc\uc774\ud574 model building\uc5d0 \ube44\uc6a9 \ud07c, scalability \uc640 performance\uac04\uc758 trade off, reduction model\ub54c\ubb38\uc5d0 \uc6d0\ub798 useful data can be lost hybrid memory-based + model-based \ube44\uc6a9\ud07c  Introduction \ucc38\uace0:\uac1c\ub150\uc774\ud574   \ub17c\ubb38  \uc2dc\uc791\ud558\uae30 \uc804\uc5d0 matrix factorization\uc5d0 \ub300\ud55c \uc124\uba85(?\uc815\ud655\ud788\ub294 svd\uac1c\ub150\uc124\uba85)\uc73c\ub85c \ub9c1\ud06c\ub97c \ub2ec\uc544 \ub193\uc558\ub2e4. ALS-WR\ub294 model-based\ubc29\uc2dd\uc73c\ub85c\uc368 \uc6d0\ub798 rating matrix R(user x item)\uc744 least squared error \ub97c \ucd5c\uc18c\ub85c \ud558\ub294 U(user x hidden feature), M(item x hidden feature)\ub85c factorize\ud558\ub294 \uc54c\uace0\ub9ac\uc998\uc774\ub2e4. \ub9d0\uc740 \uac70\ucc3d\ud55c\ub370, \uacb0\uad6d \uc5b4\ub5a4 cost function F(U, M) = square error part + regularization part \uc744 \ucd5c\uc18c\ub85c \ud558\ub294 U, M\uc744 \ucc3e\ub294 \ubb38\uc81c\uc774\ub2e4. \uc790\uc138\ud55c \uc2dd\uc740 \ub17c\ubb38\uc744 \ucc38\uc870 \ud558\uace0, \uc774\ud574\ud55c \ub300\ub85c\ub9cc \uc758\uacac\uc744 \ucd94\uac00\ud558\uaca0\ub2e4. \uc55e\uc5d0 square error part\ub294 (\uc2e4\uc81c rate R(i, j) - \uc608\uce21 rate R^(i, j))\ub97c error\ub77c\uace0 \uc815\uc758\ud558\uace0, \uc774 error^2\ub4e4\uc758 \ud569\uc744 \uc758\ubbf8\ud55c\ub2e4. Regularization\uc740 machine learning \ubd84\uc57c\uc5d0\uc11c \uc790\uc8fc \uc0ac\uc6a9 \ub418\ub294 \uc6a9\uc5b4\ub85c\uc368, model\uc774 overfit\ud558\ub294 \uac83\uc744 \ubc29\uc9c0\ud558\ub294\ub370 \ub3c4\uc6c0\uc744 \uc8fc\ub294 \ubc29\uc2dd\uc774\ub2e4. overfit\uc774 \ubaa8\ub0d0  \uc704\uc758 \uc2dd\uc5d0\uc11c \uc804\uccb4 cost\ub294 \uac01\uac01\uc758 data\ub4e4\uacfc \uc608\uce21 \uace1\uc120 y = ax + b\uc640\uc758 \uac70\ub9ac\ub4e4\uc758 \uc81c\uacf1\uc758 \ud569\uc774\ub2e4. \uadf8\ub7fc \uc704\uc758 optimization problem\uc5d0\uc11c cost \ub97c \ucd5c\uc18c\ud654 \ud558\ub824\uba74 1\ucc28\uc2dd\uc774 \uc544\ub2cc y = ax^50 + bx^49.... \uc2dd\uc758 \ub192\uc740 \ucc28\uc6d0\uc2dd(\uace1\uc120\uc774 \ub420\uac83\uc774\ub2e4?) \uc744 \uc0ac\uc6a9\ud558\uba74 \ub420\uac83\uc774\ub2e4. \ubb38\uc81c\ub294 \uad49\uc7a5\ud788 \ubcf5\uc7a1\ud55c \uc2dd\uc744 \uc368\uc11c training set\uc5d0\uc11c\uc758 cost\ub97c \ucd5c\uc18c\ub85c \ub9cc\ub4e4\uc5b4 \ubd10\uc57c training set\uc744 \uc798 \ub300\ubcc0 \ud560 \uc218 \uc788\uc9c0\ub294 \uc54a\ub2e4. training set\uc744 \uc798 \ub300\ubcc0 \ud558\ub294 \uc2dd\uc744 \ucc3e\uc544\uc57c test set\uc5d0\uc11c\ub3c4 \uc798 \uc791\ub3d9\ud558\ub294\ub370, training\uc5d0 \ud2b9\ud654\ub41c \ub192\uc740 \ucc28\uc6d0\uc2dd\uc740 \ubcf4\ud1b5 test set\uc5d0\uc11c\ub294 \ub192\uc740 error\ub97c \ubcf4\uc778\ub2e4. \uc774\ub97c \uc774 \ub192\uc740 \ucc28\uc218\uc758 \uc2dd\uc740 overfit\ub418\uc5c8\ub2e4\uace0 \ud55c\ub2e4. \ub2e4\uc2dc \ub9d0\ud574 cost\ub97c \ucd5c\uc18c\ub85c \ud558\ub294 U, M\uc744 \ucc3e\ub294\uac83\uc774 \ubb38\uc81c\uc774\uace0, \uc774\ub54c overfit\uc744 \ubc29\uc9c0\ud558\uae30 \uc704\ud574 regularization part\ub97c \ucd94\uac00 \ud55c \uac83\uc774\ub2e4. algorithm(\uc544\uc8fc\uac04\ub7b5) ALS-WR\ub294 M\uc744 \uace0\uc815\ud558\uace0, U\ub97c optimize\ud558\uace0, U\ub97c \uace0\uc815\ud558\uace0 M\uc744 optimize\ud558\ub294 \uc77c\uc744 \ud55c \ubc88\uc758 iteration\uc73c\ub85c \ud55c\ub2e4. \ucc98\uc74c M\uc740 \ud3c9\uade0 rating\ub4e4\uc5d0\uc11c \uc791\uc740 random number\ub9cc\ud07c\uc758 \ucc28\uc774\uac00 \ub098\ub294 \uc784\uc758\uc758 rate\ub85c initialize\ub418\uace0 iteration\uc744 \uac70\uce58\uba74\uc11c M\uacfc U\ub97c optimize\ud55c\ub2e4. Recommendation \uacb0\uad6d \ucd5c\uc885\uc801\uc73c\ub85c R^(i, j)\ub97c \uc5b4\ud14b\uac8c \uc608\uce21 \ud558\ub290\ub0d0\ub294 \ub2e4\uc74c\uacfc \uac19\ub2e4. ALS-WR\ub97c \ud1b5\ud574\uc11c R => U, M\uc73c\ub85c factorize\ub41c\ub2e4. \ub2e4\ub978\ub9d0\ub85c U\ub294 user\ub97c hidden feature space\ub85c, M\uc740 item\uc744 hidden feature space\ub85c project\ud558\uc5ec hidden feature space\uc5d0\uc11c\uc758 similarity\ub97c \uce21\uc815\ud558\uc5ec user\uc758 item\uc5d0 \uc608\uc0c1 R^(i, j)\ub97c \uacc4\uc0b0 \ud558\uac8c \ub41c\ub2e4. R' = U x transpose(M)\uc774 \ub41c\ub2e4. Test mahout-0.6-snapshot\uc744 \uc774\uc6a9\ud558\uc5ec test \ud574\ubcf4\uc558\ub2e4. Cluster\ub294 8 core, 16G\uc11c\ubc84 10\ub300   Iteration # Hidden Feature # RMSE Running time 20 30 0.9167081037790646 2 hour"], "link": "http://shom83.blogspot.com/feeds/5645567893844386853/comments/default", "bloglinks": {}, "links": {"http://www.hp.com/": 1, "http://www.igvita.com/": 1, "http://shom83.blogspot.com/": 6}, "blogtitle": "Doyung"}]
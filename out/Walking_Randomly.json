[{"blogurl": "http://www.walkingrandomly.com\n", "blogroll": [], "title": "Walking Randomly"}, {"content": ["Of Mathematica and memory \n A Mathematica user recently contacted me to report a suspected memory leak, wondering if it was a known issue before escalating it any further.\u00a0 At the beginning of his Mathematica notebook he had the following command \n Clear[Evaluate[Context[] <> \"*\"]] \n This command clears all the definitions for symbols in the current context and so the user expected it to release all used memory back to the system. However, every time he re-evaluated his notebook, the amount of memory used by Mathematica increased. If he did this enough times, Mathematica used all available memory. \n Looks like a memory leak, smells like a memory leak but it isn\u2019t! \n What\u2019s happening? \n The culprit is the fact that Mathematica stores an evaluation history.\u00a0\u00a0 This allows you to recall the output of the 10th evaluation (say) with the command \n %10 \n As my colleague ran and re-ran his notebook, over and over again, this history grew without bound eating up all of his memory and causing what looked like a memory leak. \n Limiting the size of the history \n The way to fix this issue is simply to limit the length of the output history.\u00a0 Personally, I rarely need more than the most recently evaluated output so I suggested that we limit it to one. \n $HistoryLength = 1; \n This fixed the problem for him. No matter how many times he re-ran his notebook, the memory usage remained roughly constant.\u00a0 However, we observed (in windows at least) that if the Mathematica session was using vast amounts of memory due to history, executing the above command did not release it.\u00a0 So, you can use this trick to prevent the history from eating all of your memory but it doesn\u2019t appear to fix things after the event\u2026to do that requires a little more work .\u00a0 The easiest way, however, is to kill the kernel and start again. \n Links \n \n Memory Management in Mathematica \n \n Mathematica Session History \n ClearSystemCache[] \u2013 The system cache is another area of Mathematica that can use up some memory."], "link": "http://www.walkingrandomly.com/?p=4655", "bloglinks": {}, "links": {"http://reference.wolfram.com/": 4}, "blogtitle": "Walking Randomly"}, {"content": ["MATLAB Mobile has been around for Apple devices for a while now but Android users have had to make do with third party alternatives such as MATLAB Commander and MLConnect .\u00a0 All that has now changed with the release of MATLAB Mobile for Android . \n MATLAB Mobile is NOT MATLAB running on your phone \n While MATLAB Mobile is a very nice and interesting product, there is one thing you should get clear in your mind\u2013 this is not a full version of MATLAB on your phone or Tablet.\u00a0 MATLAB Mobile is essentially a thin client that connects to an instance of MATLAB running on your desktop or The Mathworks Cloud.\u00a0 In other words, it doesn\u2019t work at all if you don\u2019t have a network connection or a licensed copy of MATLAB. \n What if you do want to run MATLAB code directly on your phone? \n While it is unlikely that we\u2019ll see a full version of MATLAB compiled for Android devices any time soon, Android toting MATLABers have a couple of other options available to them in addition to MATLAB Mobile. \n \n Octave for Android Octave is a free, open source alternative to MATLAB that can run many .m file scripts and functions.\u00a0 Corbin Champion has ported it to Android and although it is still a work in progress, it works very well. \n Mathmatiz \u2013 Small and light, this free app understands a subset of the MATLAB language and can do basic plotting. \n Addi \u2013 Much smaller and less capable than Octave for Android, this is Corbin Champion\u2019s earlier attempt at bringing a free MATLAB clone to Android.\u00a0 It is based on the Java library, JMathLib ."], "link": "http://www.walkingrandomly.com/?p=4652", "bloglinks": {}, "links": {"http://www.jmathlib.de/": 1, "http://www.co.uk/": 1, "http://www.gnu.org/": 1, "https://play.google.com/": 7}, "blogtitle": "Walking Randomly"}, {"content": ["Simulink from The Mathworks is widely used in various disciplines.\u00a0 I was recently asked to come up with a list of alternative products, both free and commercial. \n Here are some alternatives that I know of: \n \n MapleSim \u2013 A commercial Simuink replacement from the makers of the computer algebra system, Maple \n OpenModelica -An open-source Modelica-based modeling and simulation environment intended for industrial and academic usage \n Wolfram SystemModeler \u2013 Very new commercial product from the makers of Mathematica.\u00a0 Click here for Wolfram\u2019s take on why their product is the best. \n xcos \u2013 This free Simulink alternative comes with Scilab. \n \n I plan to keep this list updated and, eventually, include more details.\u00a0 Comments, suggestions and links to comparison articles are very welcome.\u00a0 If you have taught a course using one of these alternatives and have experiences to share, please let me know.\u00a0 Similarly for anyone who was switched (or attempted to switch) their research from Simulink.\u00a0 Either comment to this post or contact me directly. \n I\u2019ve nothing against Simulink but would like to get a handle on what else is out there."], "link": "http://www.walkingrandomly.com/?p=4379", "bloglinks": {}, "links": {"http://www.walkingrandomly.com/": 1, "http://www.scilab.org/": 1, "https://www.openmodelica.org/": 1, "http://www.co.uk/": 1, "http://www.maplesoft.com/": 1, "http://www.wolfram.com/": 2}, "blogtitle": "Walking Randomly"}, {"content": ["There are many ways to benchmark an Android device but the one I have always been most interested in is the Linpack for android benchmark by GreeneComputing.\u00a0 The Linpack benchmarks have been used for many years by supercomputer builders to compare computational muscle and they form the basis of the Top 500 list of supercomputers. \n Linpack measures how quickly a machine can solve a dense n by n  system of linear equations which is a common task in scientific and engineering applications.\u00a0 The results of the benchmark are measured in flops which stands for floating point operations per second.\u00a0 A typical desktop PC might acheive around 50 gigaflops (50 billion flops) whereas the most powerful PCs on Earth are measured in terms of petaflops ( Quadrillions of flops) with the current champion weighing in at 16 petaflops, that\u2019s 16,000,000,000,000,000 floating point operations per second\u2013which is a lot! \n Acording to the Android Linpack benchmark, my Samsung Galaxy S2 is capable of 85 megaflops which is pretty powerful compared to supercomputers of bygone eras but rather weedy by today\u2019s standards.\u00a0 It turns out, however, that the Linpack for Android app is under-reporting what your phone is really capable of.\u00a0 As the authors say \u2018This test is more a reflection of the state of the Android Dalvik Virtual Machine than of the floating point performance of the underlying processor.\u2019\u00a0\u00a0 It\u2019s a nice way of comparing the speed of two phones, or different firmwares on the same phone, but does not measure the true performance potential of your device.Put another way, it\u2019s like measuring how hard you can punch while wearing huge, soft boxing gloves. \n Rahul Garg, a PhD. student at McGill University, thought that it was high time to take the gloves off! \n rgbench \u2013 a true high performance benchmark for android devices \n Rahul has written a new benchmark app called RgbenchMM that aims to more accurately reflect the power of modern Android devices.\u00a0 It performs a different calculation to Linpack in that it meaures the speed of matrix-matrix multiplication , another common operation in sicentific computing. \n The benchmark was written using the NDK (Native Development Kit) which means that it runs directly on the device rather than on the Java Virtual Machine, thus avoiding Java overheads.\u00a0 Furthermore, Rahul has used HPC tricks such as tiling and loop unrolling to squeeze out the very last drop of performance from your phone\u2019s processor . The code tests about 50 different variations and the performance of the best version found for your device is then displayed. \n When I ran the app on my Samsung Galaxy S2 I noted that it takes rather longer than Linpack for Android to execute \u2013 several minutes in fact \u2013 which is probably due to the large number of variations its trying out to see which is the best.\u00a0 I received the following results \n \n 1 thread: 389 Mflops \n 2 threads: 960 Mflops \n 4 threads: 867.0 Mflops \n \n Since my phone has a dual core processor, I expected performance to be best for 2 threads and that\u2019s exactly what I got. Almost a Gigaflop on a mobile phone is not bad going at all! For comparison, I get around 85 Mflops on Linpack for Android.\u00a0 Give it a try and see how your device compares. \n \n Links \n \n RgbenchMM on GooglePlay \n Prelim Analysis of RgbenchMM \u2013 Some of the in-depth details of the benchmark, written by the app\u2019s author. \n Supercomputers vs mobile phones"], "link": "http://www.walkingrandomly.com/?p=3079", "bloglinks": {}, "links": {"http://codedivine.org/": 1, "http://www.walkingrandomly.com/": 2, "http://developer.android.com/": 1, "http://www.techhive.com/": 1, "https://play.google.com/": 3, "http://arstechnica.com/": 1, "http://en.wikipedia.org/": 7}, "blogtitle": "Walking Randomly"}, {"content": ["I felt like playing with Julia and MATLAB this Sunday morning.\u00a0 I found some code that prices European Options in MATLAB using Monte Carlo simulations over at computeraidedfinance.com and thought that I\u2019d port this over to Julia.\u00a0 Here\u2019s the original MATLAB code \n function V = bench_CPU_European(numPaths)\n%Simple European\nsteps = 250;\nr = (0.05);\nsigma = (0.4);\nT = (1);\ndt = T/(steps);\nK = (100);\n\nS = 100 * ones(numPaths,1);\n\nfor i=1:steps\n rnd = randn(numPaths,1);\n S = S .* exp((r-0.5*sigma.^2)*dt + sigma*sqrt(dt)*rnd);\nend\nV = mean( exp(-r*T)*max(K-S,0) ) \n I ran this a couple of times to see what results I should be getting and how long it would take for 1 million paths: \n tic;bench_CPU_European(1000000);toc\nV =\n 13.1596\nElapsed time is 6.035635 seconds.\n>> tic;bench_CPU_European(1000000);toc\nV =\n 13.1258\nElapsed time is 5.924104 seconds.\n>> tic;bench_CPU_European(1000000);toc\nV =\n 13.1479\nElapsed time is 5.936475 seconds. \n The result varies because this is a stochastic process but we can see that it should be around 13.1 or so and takes around 6 seconds on my laptop. Since it\u2019s Sunday morning, I am feeling lazy and have no intention of considering if this code is optimal or not right now. I\u2019m just going to copy and paste it into a julia file and hack at the syntax until it becomes valid Julia code. The following seems to work \n function bench_CPU_European(numPaths)\n\nsteps = 250\nr = 0.05\nsigma = .4;\nT = 1;\ndt = T/(steps)\nK = 100;\n\nS = 100 * ones(numPaths,1);\n\nfor i=1:steps\n rnd = randn(numPaths,1)\n S = S .* exp((r-0.5*sigma.^2)*dt + sigma*sqrt(dt)*rnd)\nend\nV = mean( exp(-r*T)*max(K-S,0) )\nend \n I ran this on Julia and got the following \n julia> tic();bench_CPU_European(1000000);toc()\nelapsed time: 36.259000062942505 seconds\n36.259000062942505\n\njulia> bench_CPU_European(1000000)\n13.114855104505445 \n The Julia code appears to be valid, it gives the correct result of 13.1 ish but at 36.25 seconds is around 6 times slower than the MATLAB version.\u00a0 The dog needs walking so I\u2019m going to think about this another time but comments are welcome. \n Update (9pm 7th October 2012): \u00a0\u00a0 I\u2019ve just tried this Julia code on the Linux partition of the same laptop and 1 million paths took 14 seconds or so: \n tic();bench_CPU_European(1000000);toc()\nelapsed time: 14.146281957626343 seconds \n I built this version of Julia from source and so it\u2019s at the current bleeding edge (version 0.0.0+98589672.r65a1 Commit 65a1f3dedc (2012-10-07 06:40:18). The code is still slower than the MATLAB version but better than the older Windows build \n Update: 13th October 2012 \n Over on the Julia mailing list , someone posted a faster version of this simulation in Julia \n function bench_eu(numPaths)\n steps = 250\n r = 0.05\n sigma = .4;\n T = 1;\n dt = T/(steps)\n K = 100;\n\n S = 100 * ones(numPaths,1);\n\n t1 = (r-0.5*sigma.^2)*dt\n t2 = sigma*sqrt(dt)\n for i=1:steps\n  for j=1:numPaths\n   S[j] .*= exp(t1 + t2*randn())\n  end\n end\n\n V = mean( exp(-r*T)*max(K-S,0) )\nend \n On the Linux partition of my test machine, this got through 1000000 paths in 8.53 seconds, very close to the MATLAB speed: \n julia> tic();bench_eu(1000000);toc()\nelapsed time: 8.534484148025513 seconds \n It seems that, when using Julia, one needs to unlearn everything you\u2019ve ever learned about vectorisation in MATLAB. \n Update: 28th October 2012 \n Members of the Julia team have been improving the performance of the randn() function used in the above code (see here and here for details).\u00a0 Using the de-vectorised code above, execution time for 1 million paths in Julia is now down to 7.2 seconds on my machine on Linux.\u00a0 Still slower than the MATLAB 2012a implementation but it\u2019s getting there.\u00a0 This was using Julia version \u00a00.0.0+100403134.r0999 Commit 099936aec6 (2012-10-28 05:24:40) \n tic();bench_eu(1000000);toc()\nelapsed time: 7.223690032958984 seconds\n7.223690032958984 \n \n Laptop model: Dell XPS L702X \n CPU: Intel Core i7-2630QM @2Ghz software overclockable to 2.9Ghz. 4 physical cores but total 8 virtual cores due to Hyperthreading. \n RAM: 8 Gb \n OS: Windows 7 Home Premium 64 bit and Ubuntu 12.04 \n MATLAB: 2012a \n Julia: Original windows version was Version 0.0.0+94063912.r17f5, Commit 17f50ea4e0 (2012-08-15 22:30:58).\u00a0 Several versions used on Linux since, see text for details."], "link": "http://www.walkingrandomly.com/?p=4619", "bloglinks": {}, "links": {"https://github.com/": 1, "http://www.notebookcheck.net/": 1, "https://groups.google.com/": 2, "http://en.wikipedia.org/": 1, "http://computeraidedfinance.com/": 1, "http://www.co.uk/": 1, "http://julialang.org/": 1}, "blogtitle": "Walking Randomly"}, {"content": ["Welcome to the latest edition of A Month of Math Software where I take a look at all that is shiny and new in the computational mathematics world.\u00a0 This one\u2019s slightly late and so it not only covers all of September but also the first 3 days in October.\u00a0 If you have any math software news that you\u2019d like to share with the world, drop me a line and tell me all about it.\u00a0 Enjoy! \n MATLAB gets a Ribbon (sorry\u2026Toolstrip) \n A new version of MATLAB has been released and it has had some major cosmetic surgery.\u00a0 The Mathworks insist on calling the new look in 2012b a Toolstrip but everyone else will call it a Ribbon .\u00a0 Although they\u2019ve been around for many years, ribbon based interfaces hit the big time when Microsoft used them for Office 2007..a decision that many , many , many , many , many , many , many people hated.\u00a0 I hate them too and now I have to contend with one in MATLAB\u2026and so do you because there is no way to switch back to the old interface.\u00a0 The best you can do is minimise the thing and pretend it doesn\u2019t exist.\u00a0 Unhappy users abound (check out the user comments at http://blogs.mathworks.com/loren/2012/09/12/the-matlab-r2012b-desktop-part-1-introduction-to-the-toolstrip/ for example).\u00a0 There have been a lot of other changes too which I\u2019ll discuss in an upcoming review. \n Do you use MATLAB? How do you feel about this new look? \n \n Numerical Javascript! \n \n Numeric , a comprehensive free numerical library for Javascript, has seen a minor update to version 1.2.3.\u00a0 The new release includes a much faster algorithm for linear programming . \n \n Free and open source general purpose mathematics \n \n \n Scilab , arguably the best open source MATLAB clone available, has seen a major upgrade to version 5.4.\u00a0 Go to http://www.scilab.org/products/scilab/download/5.4.0/whatsnew for the new goodness. \n \n  \n \n On 8th September, Sage version 5.3 was released.\u00a0 Sage is an extremely powerful general purpose mathematics package based on Python and dozens of other open source projects.\u00a0 The Sage development team like to say that instead of\u00a0 re-inventing the wheel they built a car!\u00a0 Mighty fine one too if you ask me.\u00a0 What\u2019s new in Sage 5.3 \n Ren\u00e9 Grothmann has updated his very nice, free Euler Math Toolbox.\u00a0 At the time of writing its at version 18.8 but the updates come thick and fast.\u00a0 The latest changes are always at http://euler.rene-grothmann.de/Programs/XX%20-%20Changes.html \n \n The theory of numbers \n \n Pari version 2.5.3 has been released. Pari is a free \u2018computer algebra system designed for fast computations in number theory\u2019 \n Magma version 2.18-10 was released in September.\u00a0 Magma is a commercial system for algebra, number theory, algebraic geometry and algebraic combinatorics. \n \n Numerical Libraries \n \n The Intel Math Kernel Library (MKL) is now at version 11.0.\u00a0 The MKL is a highly optimised numerical library for Intel platforms that covers subjects such as linear algebra, fast fourier transforms and random numbers.\u00a0 Find out what\u2019s new at http://software.intel.com/en-us/articles/whats-new-in-intel-mkl/ \n LAPACK, the standard library for linear algebra on which libraries such as MKL and ACML are based, has been updated to version 3.4.2 .\u00a0 There is no new functionality, this is a bug-fix release \n The Numerical Algorithms Group (NAG) have released a major update to their commercial C library.\u00a0 Mark 23 of the library includes lots of new stuff (345 new functions) such as a version of the Mersenne Twister random number generator with skip-ahead, additional functions for multidimensional integrals, a new suite of functions for solving boundary-value problems by an implementation of the Chebyshev pseudospectral method and loads more.\u00a0 The press release is at\u00a0 http://www.nag.co.uk/numeric/CL/newatmark23 and the juicy detail is at http://www.nag.co.uk/numeric/CL/nagdoc_cl23/html/genint/news.html \n \n Python \n \n After the publication of the last Month of Math Software I learned about the death of John Hunter, author of matplotlib , due to complications arising from cancer treatment.\u00a0 A tribute has been written by Fernando Perez.\u00a0 My heart goes out to his family and friends. \n After 8 months work, version 0.11 of SciPy is now available.\u00a0 Go to http://docs.scipy.org/doc/scipy/reference/release.0.11.0.html for the good stuff which includes improvements to the optimisation routines and new routines for dense and sparse matrices among others. \n A new major release of pandas is available. Pandas provides easy-to-use data structures and data analysis tools for Python.\u00a0 See what\u2019s new in 0.9.0 at http://pandas.pydata.org/pandas-docs/dev/whatsnew.html \n \n Bits of this and that \n \n IDL version has been bumped to version 8.2.1.\u00a0 http://idldatapoint.com/2012/10/03/idl-8-2-1-released/ has the details. \n Gnumeric version 1.11.6 \u2013 A free spreadsheet program \n \n And finally\u2026. \n I am a big fan of the xkcd webcomic and so a recent question on the Mathematica StackExchange site instantly caught my eye.\u00a0 Xkcd often publishes hand drawn graphs that look like this: \n \n The question asked\u2026How could one produce graphs that look like this using Mathematica?\u00a0 It didn\u2019t take long before the community came up with some code that automatically produces plots like this \n \n I am definitely going to use style in my next presentation!\u00a0 Not to be out-done, others have since done similar work in R , MATLAB and Latex ."], "link": "http://www.walkingrandomly.com/?p=4596", "bloglinks": {}, "links": {"http://betanews.com/": 1, "http://stackoverflow.com/": 2, "http://blogs.mathworks.com/": 2, "http://matplotlib.org/": 1, "http://www.sagemath.org/": 2, "http://docs.scipy.org/": 1, "http://mathematica.stackexchange.com/": 3, "http://www.co.uk/": 2, "http://it-tactics.co.uk/": 1, "http://euler.rene-grothmann.de/": 1, "http://projects.gnome.org/": 1, "http://www.exceluser.com/": 1, "http://www.smittypro.com/Blog": 1, "http://tex.stackexchange.com/": 1, "http://negativevacuum.wordpress.com/": 1, "http://magma.edu.au/": 1, "http://www.scilab.org/": 3, "http://answers.microsoft.com/": 1, "http://www.scipy.org/": 1, "http://pandas.pydata.org/": 2, "http://software.intel.com/": 1, "http://mail.scipy.org/": 1, "http://www.netlib.org/": 1, "http://www.cbsnews.com/": 1, "http://www.walkingrandomly.com/": 2, "http://pari.u-bordeaux.fr/": 2, "http://numericjs.com/": 2, "http://xkcd.com/": 2, "http://en.wikipedia.org/": 1, "http://idldatapoint.com/": 1}, "blogtitle": "Walking Randomly"}, {"content": ["Pop quiz: What does the following line of MATLAB code do? \n rand('state',10) \n If you said \u2018It changes the seed of the random number generator to 10\u2032 you get half a point. \n \u2018Only half a point!?\u2019 I hear you say accusingly \u2018but it says so in my book [for example, 1-3], why not a full point?\u2019 \n You only get a full point if you\u2019d said something like \u2018It changes the seed of the random number generator to 10 and it also changes the random number generator from the high quality, default Mersenne Twister generator to a lower quality legacy random number generator. \u2018 \n OK, how about this one? \n rand('seed',10) \n This behaves in a very similar manner\u2013 it changes both the seed and the type of the underlying generator. However, the random number generator it switches to this time is an even older one that was introduced as far back as MATLAB version 4.\u00a0 It is not very good at all by modern standards! \n A closer look \n Open up a fresh copy of a recent version of MATLAB and ask it about the random number generator it\u2019s using \n >> RandStream.getGlobalStream\nans =\nmt19937ar random stream (current global stream)\n    Seed: 0\n NormalTransform: Ziggurat \n mt1993ar refers to a particular variant of the Mersenne Twister algorithm \u2013 an industry strength random number generator that\u2019s used in many software packages and simulations.\u00a0 It\u2019s been the default generator in MATLAB since 2007a.\u00a0 Change the seed using the modern (since 2011a), recommended syntax and ask again: \n >> rng(10)\n>> RandStream.getGlobalStream\nans =\nmt19937ar random stream (current global stream)\n    Seed: 10\n NormalTransform: Ziggurat \n This is behaving exactly as you\u2019d expect, you ask it to change the seed and it changes the seed\u2026nothing more, nothing less. Now, let\u2019s use the older syntax \n >> rand('state',10)\n>> RandStream.getGlobalStream\nans =\nlegacy random stream (current global stream)\n RAND algorithm: V5 (Subtract-with-Borrow), RANDN algorithm: V5 (Ziggurat) \n The random number generator has completely changed!\u00a0\u00a0 We are no longer using the Mersenne Twister algorithm, we are now using a \u2018subtract with borrow\u2019 [see reference 4 for implementation details] generator which has been shown to have several undesirable issues [5-7]. \n Let\u2019s do it again but this time using the even older \u2018seed\u2019 version: \n >> rand('seed',10)\n>> RandStream.getGlobalStream\nans =\nlegacy random stream (current global stream)\n RAND algorithm: V4 (Congruential), RANDN algorithm: V5 (Ziggurat) \n Now, this random number generator is ancient by computing standards.\u00a0 It also has a relatively tiny period of only 2 billion or so.\u00a0 For details see [4] \n Why this matters \n Now, all of this is well documented so you may wonder why I am making such a big issue out of it.\u00a0 Here are my reasons \n \n I often get sent MATLAB code for the purposes of code-review and optimisation.\u00a0 I see the old seeding syntax a LOT and the program\u2019s authors are often blissfully unaware of the consequnces. \n The old syntax looks like all it should do is change the seed.\u00a0 It doesn\u2019t!\u00a0 Before 2007a, however, it did! \n The old syntax is written in dozens of books because it was once the default, correct syntax to use. \n Many users don\u2019t read the relevent section of the MATLAB documentation because they have no idea that there is a potential issue.\u00a0 They read a book or tutorial..it says to use rand(\u2018state\u2019,10) so they do. \n MATLAB doesn\u2019t use the old generators by default any more because they are not very good [4-7]! \n Using these old generators may adversely affect the quality of your simulation. \n \n The bottom line \n Don\u2019t do either of these to change the seed of the default generator to 10: \n rand('state',10)\nrand('seed',10) \n Do this instead: \n rng(10) \n Only if you completely understand and accept the consequences of the older syntax should you use it. \n References \n 1. \u2018MATLAB \u2013 A practical introduction to programming and problem solving\u2019, 2009,Stormy Attaway \n 2. MATLAB Guide (Second Edition), 2005, Desmond Higham and Nicholas Higham \n 3. Essential MATLAB for Engineers and Scientists (Fourth Edition), 2009, Hahn and Valentine \n 4. Numerical Computing with MATLAB, 2004, Cleve Moler ( available online ) \n 5.\u00a0 Why does the random number generator in MATLAB fail a particular test of randomness? The Mathworks, retreived 26th September 2012 \n 6. A strong nonrandom pattern in Matlab default random number generator , 2006, Petr Savicky, retreived 26th September 2012 \n 7.\u00a0 Learning Random Numbers: A Matlab Anomaly, 2008, Petr Savicky and Marko Robnik-\u0160ikonja, Applied Artificial Intelligence, Vol22 issue 3, pp 254-265 \n Other posts on random numbers in MATLAB \n \n Parallel Random Numbers in MATLAB #1 \u2013 An introduction to random numbers and seeding in MATLAB \n Probability of overlapping subsequences (How likely is it to get overlapping random sequences using two different seeds for the Mersenne Twister algorithm)"], "link": "http://www.walkingrandomly.com/?p=2945", "bloglinks": {}, "links": {"http://www.walkingrandomly.com/": 2, "http://www.co.uk/": 4, "http://en.wikipedia.org/": 1, "http://www2.cas.cz/": 1}, "blogtitle": "Walking Randomly"}, {"content": ["One of my favourite investment news sites is The Motley Fool which frequently run articles such as 10 Shares Trading Near 52 week lows and 15 Shares Trading Near 52 week Highs .\u00a0 The idea behind such filtering is to seek out shares that have done particularly badly (or well) over the last year and then subject them to further analysis in order to find opportunities.\u00a0 Thanks to Mathematica\u2019s FinancialData command, it is rather easy to generate these lists yourself whenever you like. \n 15 Shares Trading Near 52 Week Highs \n The original article selected the 15 largest cap shares from the FTSE All Share Index that were trading within 3% of their 52 week high at the time of publication.\u00a0 Let\u2019s see how to do that using Mathematica. \n The following code returns the tickers of all shares from the FTSE All Share Index that are trading within 3% of their 52 week high. \n percentage = 3;\nall52weekHighs =\n Select[FinancialData[\"^FTAS\", \"Members\"],\n Abs[FinancialData[#, \"FractionalChangeHigh52Week\"]] < (percentage/100.) &]; \n The variable all52weekHighs contains a list of stock tickers (e.g. LLOY.L) that meet our criteria.\u00a0 The next thing to do is to find the market cap of each one: \n all52WeekHighsWithCaps =\n Map[{#, FinancialData[#, \"MarketCap\"]} &, all52weekHighs]; \n This works fine for most shares. LloydsTSB for example returns {\u201cLLOY.L\u201d, 2.7746*10^10} at the time of writing but the MarketCap query fails for some tickers. For example, the Market Cap for HSL.L is not available and we get {\u201cHSL.L\u201d, Missing[\"NotAvailable\"]}.\u00a0 Let\u2019s discard these by insisting that we only consider stocks that have a numeric market cap. \n Goodall52WeekHighsWithCaps =\n Select[all52WeekHighsWithCaps, NumberQ[#[[2]]] &]; \n We sort the list according to MarketCap: \n sorted = Sort[Goodall52WeekHighsWithCaps, #1[[2]] > #2[[2]] &]; \n Let\u2019s prettify the list a little by iterating over all tickers and replacing the ticker with the associated stock name. Also, let\u2019s divide the market cap by 1 million to make it more readable \n finallist =\n Map[{FinancialData[#[[1]], \"Name\"], #[[2]]/1000000} &, sorted]; \n Now, you may be wondering why I haven\u2019t been showing you the output of these commands. This is simply because even this final list is rather large at 118 entries at the time of writing \n Length[finallist]\n\n118 \n The original article only considered the top 15 sorted by Market Cap so let\u2019s show those. Market Caps are given in millions. \n top15 = finallist[[1;;15]]//Grid\n\nHSBC Holdings PLC\u00a0\u00a0 \u00a094159.\nNational Grid\u00a0\u00a0 \u00a024432.\nPrudential PLC\u00a0\u00a0 \u00a021775.\nCentrica PLC\u00a0\u00a0 \u00a017193.\nRolls Royce Group\u00a0\u00a0 \u00a016363.\nWPP Plc\u00a0\u00a0 \u00a010743.\nExperian PLC\u00a0\u00a0 \u00a010197.\nOld Mutual PLC\u00a0\u00a0 \u00a08400.\nLegal & General Group PLC\u00a0\u00a0 \u00a08036.\nWolseley PLC\u00a0\u00a0 \u00a07955.\nStandard Life\u00a0\u00a0 \u00a06662.\nJ Sainsbury plc\u00a0\u00a0 \u00a06401.\nAggreko PLC\u00a0\u00a0 \u00a06391.\nLand Securities Group PLC\u00a0\u00a0 \u00a06180.\nBritish Land Co PLC\u00a0\u00a0 \u00a04859. \n and we are done."], "link": "http://www.walkingrandomly.com/?p=4571", "bloglinks": {}, "links": {"http://reference.wolfram.com/": 1, "http://www.co.uk/": 4}, "blogtitle": "Walking Randomly"}, {"content": ["Welcome to the 90th edition of the Carnival of Mathematics and the first one hosted by me since I handed over the administrative reigns to the good people of aperiodical .\u00a0 The CoM is a great way to read about and promote mathematical blogging and has been running for over 5 years.\u00a0 Hosted on a different blog each month, it covers the entire mathematical spectrum from simple mucking around with numbers right up to cutting edge research. \n Writers can submit their own posts for inclusion in a carnival if they like and anyone can submit any mathy post that they\u2019ve found interesting\u2013 ideally, something written over the last month or so to keep it fresh. \n If you want to keep up with the CoM, head over to its twitter feed or the dedicated page at aperiodical . \n Trivia \n Carnival tradition dictates that I post some trivia about this month\u2019s edition number.\u00a0 Here\u2019s what I came up with for 90: \n \n 90 is the only number that is the sum of its digits plus the squares of its digits (via NumberGossip ) \n 90 is a Harshad number in base 10.\u00a0 It is also a Perrin Number , a pronic number , a unitary perfect number and a semi perfect number . \n 90 is the smallest number that has six representations as a sum of four positive squares (via Wolfram Alpha ) \n \n Neat Stuff \n \n Matthew Handy explains how researchers at MIT used geometric series to solve an economic problem in Zeno\u2019s Facebook Page . \n Carnival regular, Pat Ballew tells us about a nice connection between numeric frieze patterns and triangulating polygons . \n Ethan Brown, a thirteen-year-old \u201cMathemagician\u201d and the author of the blog coolmathstuff.com brings us Probability, The Number e, and Magic all in one \n \n Computation \n \n The Numerical Algorithms Group (NAG) discusses Linear Quantile Regression , a new feature in the latest version of their software. \n Samir Kahn has been Modelling Flow Intertia in Three Couple Liquid Tanks using Maple. \n Cleve Moler, inventor of MATLAB, has written two posts on Conway\u2019s Game of Life ( part 1 , part 2 ) \n \n Puzzles and Games \n \n \n Shecky R brings us Mind Wrenching \u2013 A self-referential logic puzzle that will give your brain cells a workout. \n Brent Yorgey has been visualizing winning strategies for \u201cnim-like\u201d games and says \u2018This is a post about visualizing winning strategies for certain games where players take turns removing counters from two piles.\u00a0 The games make for fun games to actually play, and analyzing them can get quite interesting!\u2019 \n \n Funnies \n \n The xkcd comic shows how pointless the phrase \u2018We are the fastest growing [whatever]\u2018 is \n Mark Dominus offers a koan on the Consistency of the Peano Axioms . \n \n Art and Mathematics \n \n \n Egan Chernoff sent in Alternative Base Representation saying \u2018I look forward to your critiques of my latest piece\u2019 \n Gianluigi Filippelli gives us Poincar\u00e9, Einstein and Picasso: children of time and says \u2018Following an article by Arthur I. Miller on the Guardian, I try to tell the possible connections between cubism, mathematics and relativity.\u2019 \n Gianluigi continues his cultural theme with a look at some mathematical poems recently published in Nature in The day of mathematical poetry . \n \n Books \n \n Shiva Kintali has reviewed a couple of books \u2013 Matching Theory by Laszlo Lovasz and Elements of Automata Theory by Jacques Sakarovitch . \n \n Tricks and Tactics \n \n John D Cook gives us Binomial Coefficient Trick \n \n Topology \n \n Mark Dominus of The Universe of Discourse gives us three posts this month: A two parter on topology and set theory (Click here for part 1 and here for part 2 ). \n \n Teaching \n \n Dan McQuillan gives us On Trigonometric Nostalgia and says \u2018This is a post about fostering a problem-solving mentality in a world where we do not even understand how our own tools work. It superimposes our nostalgia for the world we used to know with our innate curiosity, which still exists. Basic trigonometry is still fun and still relevant. Indeed, one can always ask questions and calculate!\u2019 \n Frederick Koh takes on the dot product in Understanding MATTERS (7) saying \u2018T his dot product concept involving parallel vector planes is rather fundamental, yet a handful of my students are unable to figure out how things exactly work. Hence I have decided to pen this detailed explanation in the hope that it will benefit not just my charges, but other math learners as well.\u2019 \n Augustus Van Dusen has written the first in an upcoming series of posts that will prove properties of logarthmic and exponential functions. Augustus says \u2018This particular post will focus on the properties of logarithmic functions of real variables. Students in advanced placement calculus in high school and beginning college students who are not math majors are the intended audience.\u2019 \n \n \n Comment \n \n Peter Rowlett asks does mathematics have a culture of historical inaccuracy ? \n Mike Thayer submitted his article Tired of playing defense saying \u2018These are my thoughts on the Andrew Hacker NY Times article from July, and the Roger Schank Washington Post article from earlier this week.It is my defense of teaching algebra\u2026\u2019 \n Egan Chernoff submits Bill, you had me at \u201carithmetic\u201d and asks \u2018how do other people feel about the phrase \u201clet\u2019s do the math.\u201d \u2018 \n \n Not the only game in town \n The Carnival of Mathematics isn\u2019t the only mathematical blog carnival that\u2019s doing the tour.\u00a0 There\u2019s also the fantastic monthly Math Teachers at Play . \n End \n That\u2019s it for the 90th Edition.\u00a0 Past editions written by me include 80 , 76 , 74 and 73 among others.\u00a0 For future editions keep an eye on @carnivalofmath and aperiodical.com \n \n You can follow WalkingRandomly via RSS , Twitter , Facebook and Google+"], "link": "http://www.walkingrandomly.com/?p=4558", "bloglinks": {}, "links": {"http://oeis.org/": 2, "http://blogs.mathworks.com/": 2, "http://www.wolframalpha.com/": 1, "http://matthewmadduxeducation.com/": 2, "http://travels.aperiodical.com/": 1, "http://mathlesstraveled.com/": 1, "http://pballew.co.uk/": 1, "https://plus.google.com/": 1, "http://www.numbergossip.com/": 1, "http://www.whitegroupmaths.com/": 1, "http://math-frolic.co.uk/": 1, "http://blog.plover.com/": 3, "http://kintali.wordpress.com/": 2, "http://coolmathstuff123.co.uk/": 1, "http://www.norwich.edu/": 1, "http://blog.nag.com/": 1, "http://docmadhattan.fieldofscience.com/": 2, "http://www.mapleprimes.com/": 1, "http://hyperbolicguitars.co.uk/": 1, "https://twitter.com/": 3, "http://www.johndcook.com/blog": 1, "http://www.walkingrandomly.com/": 4, "http://aperiodical.com/": 4, "http://letsplaymath.net/": 1, "http://thinkingmachineblog.wordpress.com/": 1, "http://xkcd.com/": 1, "http://www.dotmaths.com/blog": 1, "http://en.wikipedia.org/": 3, "http://www.facebook.com/": 1}, "blogtitle": "Walking Randomly"}, {"content": ["I\u2019m hosting the 90th Carnival of Mathematics very soon .\u00a0 If you have written (or read) a mathematics blog article over the last month and want to give it more attention, why not make a submission ? The deadline for submissions is 10th September."], "link": "http://www.walkingrandomly.com/?p=4556", "bloglinks": {}, "links": {"http://aperiodical.com/": 1, "https://docs.google.com/": 1}, "blogtitle": "Walking Randomly"}, {"content": ["Welcome to the August edition of A Month of Math Software\u2013 a regular series of articles where I share what\u2019s shiny and new in the world of mathematical software. \u00a0If you like what you see and want more, take a browse through the archives . \u00a0If you have some news that you think should go into next month\u2019s edition, contact me to tell me all about it so I can tell the world. \n This edition includes lots of new releases, blog posts and news about mathematics on mobile devices\u2026enjoy! \n Mobile Mathematics \n August was a very big month for mobile mathematical applications with the following releases \n \n Full LaTeX on iPad with on device compilation and .dvi viewer \n Maxima \u00a0on Android \u2013 Maxima is a free computer algebra system with a long pedigree \n Octave on Android \u2013 Octave is basically a free version of MATLAB. \u00a0The author of this package is Corbin Champion who also wrote Addi (a simplified MATLAB clone based on JMathLib ). \u00a0Corbin tried to get funding via kickstarter (see my article on this \u2013 here ) to allow him to dedicate himself full time to this port but, sadly, was\u00a0unsuccessful. \u00a0Thankfully, Corbin has managed to do some development on the project anyway and has released this package as a starter for 10. \u00a0Its lacking a lot of stuff but is a fantastic start! \n The Geogebra team have started a kickstarter project that aims to bring Geigebra to iPad . \u00a0Why not head over there and pledge some support? \n \n General purpose mathematics \n \n Maxima , a free computer algebra system (CAS) for Windows, Linux and Mac OSX, has been updated to version 5.28 . \u00a0Back in 2010, a guest writer wrote a Maxima tutorial here at WalkingRandomly \u2013 Maxima Tutorial \u2013 plotting direction fields for 1st order ODEs \n Mathics is a free, lightweight alternative to Mathematica and has recently been updated to version 0.5 . \n Pari/GP is another free computer algebra system that was updated to 2.5.2 in August (The website says august but the changelog says June I\u2019ve only just noticed the update so its going in August\u2019s edition) \u2014 \u00a0 Pari focuses on number theory but can be used for many other kinds of computation. \n The free Euler Math Toolbox has been updated many times throughout August and is now at version 18.4. \u00a0See the Changelog for what\u2019s new . \n \n Do numerical computing using\u2026.Javascript! \n \n The Numeric Javascript library has been updated to version 1.2.2. The main new feature is linear programming\u2013 the function is numeric.solveLP() \n \n Mathematical software libraries \n \n The AMD Core Math Libray (ACML) has been updated to version 5.2.0 . \n Version 2.4.6 of PLASMA (Parallel Linear Algebra for Scalable Multi-core Architectures)\u00a0has been released. \u00a0See what\u2019s new at http://icl.cs.utk.edu/plasma/news/news.html?id=299 \n A new minor version of ARPACK-NG (3.1.2) has been released. \u00a0See http://forge.scilab.org/index.php/p/arpack-ng/source/tree/master/CHANGES for the newness. \u00a0ARPACK is a collection of Fortran77 subroutines designed to solve large scale eigenvalue problems \n \n GPU Programming \n GPU stands for Graphical Processing Unit but these days you can get a GPU to do a lot more than just graphics. \u00a0You could think of them as essentially massively parallel math \u00a0co-processors that can make light work of certain operations. \n \n Jacket is a commercial GPU Processing add-on for MATLAB. \u00a0In recent blog posts, the Jacket developers discuss SAR Image Formation Algorithms on the GPU and Option Pricing . \n CULA is a set of commercial GPU-accelerated linear algebra libraries. \u00a0 CULA-Dense is, as you might expect, for dense matrices and is now at version 15. \u00a0 \u00a0 CULA-Sparse is at version S3. \u00a0I can\u2019t find a what\u2019s new document but the main change seems to be the addition of support for NVIDIA\u2019s Kepler architecture . \u00a0The CULA library can be called from C, C++, Fortran, MATLAB, and Python and is free for individual academic use . \n GPULib is a commercial software library enabling GPU-accelerated calculations for IDL . \u00a0In a recent blog post, one of GPULib\u2019s developers has been experimenting with OpenCL support . \n \n Statistics \n \n R Commander , a basic GUI for the free R programming language , has been updated to version 1.9.x \n IBM\u2019s SPSS has been updated to version 21. \u00a0Some new features are discussed at http://www-01.ibm.com/software/analytics/spss/products/statistics/features.html \n VSN International have released version 15.1 of their bio-statistics package, Genstat . \u00a0The list of new stuff is at http://www.vsni.co.uk/software/genstat/15th-edition-new-features \n \n Academic codes and applications \n \n Version 3.0 of the SCIP Optimization Suite has been released. According to the website , \u2018SCIP is currently one of the fastest non-commercial mixed     integer programming (MIP) solvers . It is also a framework for     constraint integer programming and     branch-cut-and-price\u2019. Here are the all important Release Notes and Changelog . \n Templates for First-Order Conic Solvers (TFOCS, pronounced\u00a0 tee-fox ) is a software package that provides a set of templates, or building blocks, that can be used to construct efficient, customized solvers for a variety of models.\u00a0 The latest version, 1.1a, was released back in February but I have only recently learned of it and so am including it in this month\u2019s edition.\u00a0 A set of demos and wiki for this software is available. \n Version 1.0 of Blaze has been released.\u00a0 Blaze is an open-source, high-performance C++ math library for dense and sparse arithmetic.\u00a0 There is a getting started tutorial and a set of benchmarks ."], "link": "http://www.walkingrandomly.com/?p=4460", "bloglinks": {}, "links": {"http://www.jmathlib.de/": 1, "http://www-01.ibm.com/": 1, "http://socserv.mcmaster.ca/": 1, "http://www.r-project.org/": 1, "http://gpulib.co.uk/": 1, "http://www.culatools.com/": 3, "http://www.numericjs.com/": 1, "http://code.google.com/": 3, "https://sites.google.com/": 1, "http://www.co.uk/": 2, "https://play.google.com/": 1, "http://euler.rene-grothmann.de/": 2, "http://scip.zib.de/": 3, "http://www.mathics.org/": 1, "http://www.txcorp.com/": 1, "https://groups.google.com/": 1, "http://www.nvidia.com/": 1, "http://www.geogebra.org/": 1, "http://developer.amd.com/": 2, "http://ugcs.caltech.edu/": 1, "http://www.kickstarter.com/": 1, "http://maxima.sourceforge.net/": 1, "http://www.utexas.edu/": 1, "http://www.exelisvis.com/": 1, "http://forge.scilab.org/": 2, "http://blog.accelereyes.com/blog": 2, "http://www.walkingrandomly.com/": 6, "http://icl.utk.edu/": 2, "http://tfocs.stanford.edu/": 3, "http://pari.u-bordeaux.fr/": 2}, "blogtitle": "Walking Randomly"}, {"content": ["While on the train to work I came across a very interesting blog entry.\u00a0 Full LaTeX support (on device compilation and .dvi viewer) is now available on iPad courtesy of TeX Writer By FastIntelligence .\u00a0 Here is the blog post telling us the good news http://litchie.com/blog/?p=406 \n At the time of writing, the blog is down ( Update: working again), possibly because of the click storm that my twitter announcement caused..especially after it was picked up by @TeXtip .\u00a0 So, here is the iTunes link http://itunes.apple.com/us/app/tex-writer/id552717222?mt=8 \n I haven\u2019t tried this yet but it looks VERY interesting.\u00a0 If you get a chance to try it out, feel free to let me know how you get on in the comments section. \n Update 1: This version of TeX writer(1.1) cannot output to .pdf.\u00a0 Only .dvi output is supported at the moment. \n \n You can follow WalkingRandomly via RSS , Twitter , Facebook and Google+"], "link": "http://www.walkingrandomly.com/?p=4547", "bloglinks": {}, "links": {"https://plus.google.com/": 1, "https://twitter.com/": 3, "http://www.facebook.com/": 1, "http://itunes.apple.com/": 1, "http://t.co/": 2}, "blogtitle": "Walking Randomly"}, {"content": ["Let\u2019s use Mathematica to to discover the longest English words where the letters are in alphabetical order.\u00a0 The following command will give all such words \n DictionaryLookup[x__ /; Characters[x] == Sort[Characters[x]]] \n I\u2019m not going to show all of the output because there are 562 of them (including single letter words such as \u2018I\u2019 and \u2018a\u2019) as we can see by doing \n Length[\n DictionaryLookup[x__ /; Characters[x] == Sort[Characters[x]]]\n]\n\n562 \n The longest of these words has seven characters: \n Max[Map[StringLength,\n DictionaryLookup[x__ /; Characters[x] == Sort[Characters[x]]]]]\n\n7 \n It turns out that only one such word has the maximum 7 characters \n DictionaryLookup[x__ /; Characters[x] == Sort[Characters[x]] && StringLength[x] == 7]\n\n{\"billowy\"} \n There are 34 such words that contain 6 characters \n DictionaryLookup[\n x__ /; Characters[x] == Sort[Characters[x]] && StringLength[x] == 6]\n\n{\"abbess\", \"Abbott\", \"abhors\", \"accent\", \"accept\", \"access\", \\\n\"accost\", \"adders\", \"almost\", \"begins\", \"bellow\", \"Bellow\", \"bijoux\", \\\n\"billow\", \"biopsy\", \"bloops\", \"cellos\", \"chills\", \"chilly\", \"chimps\", \\\n\"chinos\", \"chintz\", \"chippy\", \"chivvy\", \"choosy\", \"choppy\", \"Deimos\", \\\n\"effort\", \"floors\", \"floppy\", \"flossy\", \"gloppy\", \"glossy\", \"knotty\"} \n If you insist on all letters being different, there are 9: \n DictionaryLookup[\n x__ /; Characters[x] == Sort[Characters[x]] && StringLength[x] == 6 &&\n Length[Union[Characters[x]]] == Length[Characters[x]]]\n\n{\"abhors\", \"almost\", \"begins\", \"bijoux\", \"biopsy\", \"chimps\", \\\n\"chinos\", \"chintz\", \"Deimos\"} \n How about where all the letters are in reverse alphabetical order with no repeats ? The longest such words have 7 characters \n Max[\n Map[StringLength,\n DictionaryLookup[\n x__ /; Characters[x] == Reverse[Sort[Characters[x]]]]]]\n\n7 \n Here they are \n DictionaryLookup[\n x__ /; Characters[x] == Reverse[Sort[Characters[x]]] &&\n StringLength[x] == 7 &&\n Length[Union[Characters[x]]] == Length[Characters[x]]]\n\n{\"sponged\", \"wronged\"} \n \n You can follow WalkingRandomly via RSS , Twitter , Facebook and Google+"], "link": "http://www.walkingrandomly.com/?p=4529", "bloglinks": {}, "links": {"https://twitter.com/": 1, "https://plus.google.com/": 1, "http://www.wolfram.com/": 1, "http://www.facebook.com/": 1}, "blogtitle": "Walking Randomly"}, {"content": ["I\u2019ve been playing with AVX vectorisation on Sandy Bridge CPUs off and on for a while now and thought that I\u2019d write up a little of what I\u2019ve discovered.\u00a0 The basic idea of vectorisation is that each core in a modern CPU can operate on multiple values (i.e. a vector) simultaneously per instruction cycle. \n Sandy bridge (and the newer Ivy Bridge ) processors have 256bit wide vector units which means that each CORE can perform certain operations on up to eight 32-bit floats or four 64-bit doubles per clock cycle .\u00a0 So, on a quad core you have 4 vector units (one per core) and could operate on up to 16 doubles or 32 floats per clock cycle. \n This all sounds great so how does a programmer actually make use of this neat hardware trick?\u00a0 There are many routes:- \n Intrinsics \n At the \u2018close to the metal\u2019 level you code for these vector units using instructions called AVX intrinsics.\u00a0 This is relatively difficult and leads to none-portable code if you are not careful. \n \n Introduction to Intel Advanced Vector Extensions \u2013 includes some example C++ programs using AVX intinsics \n Benefits of Intel AVX for small matrices \u2013 More code examples along with speed comparisons. \n \n Auto-vectorisation in compilers \n Since working with intrinsics is such hard work, why not let the compiler take the strain? Many modern compilers can automatically vectorize your C, C++ or Fortran code including gcc, PGI and Intel. Sometimes all you need to do is add an extra switch at compile time and reap the speed benefits. In truth, vectorization isn\u2019t always automatic and the programmer needs to give the compiler some assistance but it is a lot easier than hand-coding intrinsics. \n \n A Guide to Auto-vectorization with Intel C++ Compilers \u2013 Exactly what it says.\u00a0 In my experience, the intel compilers do auto-vectorisation better than other compilers. \n Auto-vectorisation in gcc 4.7 \u2013 A superb article showing how auto-vectorisation works in practice when using gcc 4.7.\u00a0 Lots of C code examples along with the emitted assembler and a good discussion of the hints you may need to give to the compiler to get maximum performance. \n Auto-vectorisation in gcc \u2013 The project page for auto-vectorisation in gcc \n Optimizing Application Performance on x64 Processor-based Systems with PGI Compilers and Tools \u2013 Includes discussion and example of auto-vectorisation using the PGI compiler \n Jim Radigan: Inside Auto-Vectorization, 1 of n \u2013 A video by a Microsoft engineer working on Visual Studio 2012.\u00a0 A superb introduction to what vectorisation is along with speed-up demonstrations and discussion on how the auto-vectoriser will work in Visual Studio 2012. \n Auto Vectorizer in Visual Studio 2012 \u2013 A series of blog articles about vectorization in Visual Studio 2012. \n \n Intel SPMD Program Compiler (ispc) \n There is a midway point between automagic vectorisation and having to use intrinsics. Intel have a free compiler called ispc ( http://ispc.github.com/ ) that allows you to write compute kernels in a modified subset of C. These kernels are then compiled to make use of vectorised instruction sets. Programming using ispc feels a little like using OpenCL or CUDA. I figured out how to hook it up to MATLAB a few months ago and developed a version of the Square Root functio n that is almost twice as fast as MATLAB\u2019s own version for sandy bridge i7 processors. \n \n http://ispc.github.com/ \u2013 The website for ispc \n http://ispc.github.com/perf.html \u2013 Some performance metrics.\u00a0 In some cases combining vectorisation and parallelisation can increase single precision throughput by more than a factor of 32 on a quad-core machine! \n ispc: A SPMD Compiler For  High-Performance CPU Programming , Illinois-Intel Parallelism  Center Distinguished Speaker Series (UIUC), March 15,  2012. ( talk  video \u2013requires Windows Media Player.) This link was taken from Matt Pharr\u2019s website (The author of ispc). \n \n Vectorised Libraries \n Vendors of numerical libraries are steadily applying vectorisation techniques in order to maximise performance.\u00a0 If the execution speed of your application depends upon these library functions, you may get a significant speed boost simply by updating to the latest version of the library and recompiling with the relevant compiler flags. \n \n Intel AVX optimization in Intel Math Kernel Library (MKL) \u2013 See what\u2019s been vectorised in version 10.3 of the MKL \n Intel Integrated Performance Primitives (IPP) Functions Optimized for AVX \u2013 The IPP library includes many basic algorithms used in image and signal processing \n \n CUDA for x86 \n Another route to vectorised code is to make use of the PGI Compiler\u2019s support for x86 CUDA.\u00a0 What you do is take CUDA kernels written for NVIDIA GPUs and use the PGI Compiler to compile these kernels for x86 processors.\u00a0 The resulting executables take advantage of vectorisation.\u00a0 In essence, the vector units of the CPU are acting like CUDA cores\u2013which they sort of are anyway! \n The PGI compilers also have technology which they call PGI Unified binary which allows you to use NVIDIA GPUs when present or default to using multi-core x86 if no GPU is present. \n \n PGI CUDA-x86 \u2013 PGI\u2019s main page for their CUDA on x86 technologies \n \n OpenCL for x86 processors \n Yet another route to vectorisation would be to use Intel\u2019s OpenCL implementation which takes OpenCL kernels and compiles them down to take advantage of vector units ( http://software.intel.com/en-us/blogs/2011/09/26/autovectorization-in-intel-opencl-sdk-15/ ).\u00a0 The AMD OpenCL implementation may also do this but I haven\u2019t tried it and haven\u2019t had chance to research it yet. \n WalkingRandomly posts \n I\u2019ve written a couple of blog posts that made use of this technology. \n \n Using Intel\u2019s SPMD Compiler (ispc) with MATLAB on Linux \n Using the Portland PGI Compiler for MATLAB mex files in Windows \n \n Miscellaneous resources \n There is other stuff out there but the above covers everything that I have used so far.\u00a0 I\u2019ll finish by saying that everyone interested in vectorisation should check out this website \u2026It\u2019s the bible! \n Research Articles on SSE/AVX vectorisation \n \n I found the following research articles useful/interesting.\u00a0 I\u2019ll add to this list over time as I dig out other articles. \n \n An efficient vectorization of linked-cell particle simulations \n Accelerating cellular automata simulations using AVX and CUDA"], "link": "http://www.walkingrandomly.com/?p=3378", "bloglinks": {}, "links": {"http://www.pharr.org/": 2, "http://arxiv.org/": 1, "http://www.pgroup.com/": 3, "http://agner.org/": 1, "http://gcc.gnu.org/": 1, "http://www.walkingrandomly.com/": 3, "http://ispc.github.com/": 3, "http://blogs.msdn.com/": 1, "http://locklessinc.com/": 1, "http://dl.acm.org/": 1, "http://media.illinois.edu/": 1, "http://en.wikipedia.org/": 3, "http://software.intel.com/": 6}, "blogtitle": "Walking Randomly"}, {"content": ["Someone recently asked me if WalkingRandomly.com had a facebook page.\u00a0 Since it wasn\u2019t much effort to create one, I have now done so.\u00a0 I have no idea if this will be of any use to anyone but\u00a0a first stab at it is at http://www.facebook.com/Walkingrandomly \u00a0 \n Now I have to decide what to do with it. Does anyone have any thoughts on a blog such as this having its own facebook profile?\u00a0 Is it a good idea?\u00a0 Will anyone make use of it or is it just pointless?"], "link": "http://www.walkingrandomly.com/?p=4476", "bloglinks": {}, "links": {"http://www.facebook.com/": 1}, "blogtitle": "Walking Randomly"}]
[{"blogurl": "http://rtutorialseries.blogspot.com\n", "blogroll": [], "title": "R Tutorial Series"}, {"content": ["Centering variables and creating z-scores are two common data analysis activities. While they are relatively simple to calculate by hand, R makes these operations extremely easy thanks to the scale() function. \n Tutorial Files Before we begin, you may want to download the dataset (.csv) used in this tutorial. Be sure to right-click and save the file to your R working directory. \n The Scale() Function The scale() function makes use of the following arguments. \n x: a numeric object \n center: if TRUE, the objects' column means are subtracted from the values in those columns (ignoring NAs); if FALSE, centering is not performed \n scale: if TRUE, the centered column values are divided by the column's standard deviation (when center is also TRUE; otherwise, the root mean square is used); if FALSE, scaling is not performed \n Centering Variables Normally, to center a variable, you would subtract the mean of all data points from each individual data point. With scale() , this can be accomplished in one simple call. \n > #center variable A using the scale() function \n > scale(A, center = TRUE, scale = FALSE) \n You can verify these results by making the calculation by hand, as demonstrated in the following screenshot. \n  \n Centering a variable with the scale() function and by hand Generating Z-Scores Normally, to create z-scores (standardized scores) from a variable, you would subtract the mean of all data points from each individual data point, then divide those points by the standard deviation of all points. Again, this can be accomplished in one call using scale() . \n > #generate z-scores for variable A using the scale() function \n > scale(A, center = TRUE, scale = TRUE) \n Again, the following screenshot demonstrates equivalence between the function results and hand calculation. \n  \n Generating z-scores from a variable by hand and using the scale() function Complete Scale() Example To see a complete example of how scale() can be used to center variables and generate z-scores in R, please download the scale() example (.txt) file. \n References The official scale function manual page is available from: http://stat.ethz.ch/R-manual/R-patched/library/base/html/scale.html"], "link": "http://feedproxy.google.com/~r/RTutorialSeries/~3/2rk7_AY2ZQI/r-tutorial-series-centering-variables.html", "bloglinks": {}, "links": {"http://4.blogspot.com/": 1, "http://2.blogspot.com/": 1, "http://dl.dropbox.com/": 2}, "blogtitle": "R Tutorial Series"}, {"content": ["Unfortunately, due to the vexing complexities of academic style guides and the limitations of associated software packages, citing a non-standard name, such as Cher, Prince, or R Development Core Team can be problematic. Thankfully, I have discovered a simple trick in Word and EndNote that allows for the accurate automatic formatting of R citations. Note that this method was developed using Word 2011 and EndNote X4 for Mac. I am unaware of the differences between operating systems and software versions, but it is anticipated that this method will work for almost anyone. \n \n\nThe Intuitive, But Nonworking Way \nIf you were going to create your R record in EndNote, you would probably enter something like what is pictured below. In the name field, it makes sense to just type in R Development Core Team. \n \n \n \n \n \nHowever, this is where things take an untimely turn. EndNote will try to interpret that peculiar name as a series of first, last, and middle names, which leads to inaccurate citations. \n \n \n \n \n \n \n \n\nThe Unintiuitive, But Working Way \nThis is where we basically need to trick EndNote into interpreting our R citation the proper way. All we have to do is add a comma after R Development Core Team in the name field. \n \n \n \n \n \nThis tells EndNote that R Core Development Team is a complete last name of an author that has no first name. Hence, EndNote uses what it has (a last name with no first name) in generating its citations. \n \n \n \n \n \n \nNote: The official citation for R can be found by issuing the citation() command in the R console."], "link": "http://feedproxy.google.com/~r/RTutorialSeries/~3/wUym6DTaAIk/r-tutorial-series-citing-r-with-endnote.html", "bloglinks": {}, "links": {"http://4.blogspot.com/": 4}, "blogtitle": "R Tutorial Series"}, {"content": ["Exploratory factor analysis (EFA) is a common technique in the social sciences for explaining the variance between several measured variables as a smaller set of latent variables. EFA is often used to consolidate survey data by revealing the groupings (factors) that underly individual questions. This will be the context for demonstration in this tutorial. \n Tutorial Files Before we begin, you may want to download the dataset (.csv) used in this tutorial. Be sure to right-click and save the file to your R working directory. This dataset contains a hypothetical sample of 300 responses on 6 items from a survey of college students' favorite subject matter. The items range in value from 1 to 5, which represent a scale from Strongly Dislike to Strongly Like. Our 6 items asked students to rate their liking of different college subject matter areas, including biology (BIO), geology (GEO), chemistry (CHEM), algebra (ALG), calculus (CALC), and statistics (STAT). This is where our tutorial ends, because all students rated all of these content areas as Strongly Dislike, thereby rendering insufficient variance for conducting EFA (just kidding). \n Beginning Steps To begin, we need to read our datasets into R and store their contents in variables. \n > #read the dataset into R variable using the read.csv(file) function \n > data <- read.csv(\"dataset_EFA.csv\") \n   \n First 10 rows of the dataset Psych Package Next, we need to install and load the psych package, which I prefer to use when conducting EFA. In this tutorial, we will make use of the package's fa() function. \n > #install the package \n > install.packages(\"psych\") \n > #load the package \n > library(psych) \n Number of Factors For this tutorial, we will assume that the appropriate number of factors has already been determined to be 2, such as through eigenvalues, scree tests, and a priori considerations. Most often, you will want to test solutions above and below the determined amount to ensure the optimal number of factors was selected. \n Factor Solution To derive the factor solution, we will use the fa() function from the psych package, which receives the following primary arguments. \n r: the correlation matrix \n nfactors: number of factors to be extracted (default = 1) \n rotate: one of several matrix rotation methods, such as \"varimax\" or \"oblimin\" \n fm: one of several factoring methods, such as \"pa\" (principal axis) or \"ml\" (maximum likelihood) \n Note that several rotation and factoring methods are available when conducting EFA. Rotation methods can be described as orthogonal , which do not allow the resulting factors to be correlated, and oblique , which do allow the resulting factors to be correlated. Factoring methods can be described as common , which are used when the goal is to better describe data, and component , which are used when the goal is to reduce the amount of data. The fa() function is used for common factoring. For component analysis, see princomp() . The best methods will vary by circumstance and it is therefore recommended that you seek professional council in determining the optimal parameters for your future EFAs. \nIn this tutorial, we will use oblique rotation ( rotate = \"oblimin\" ), which recognizes that there is likely to be some correlation between students' latent subject matter preference factors in the real world. We will use principal axis factoring ( fm = \"pa\" ), because we are most interested in identifying the underlying constructs in the data. \n > #calculate the correlation matrix \n > corMat <- cor(data) \n > #display the correlation matrix \n > corMat \n   \n The correlation matrix > #use fa() to conduct an oblique principal-axis exploratory factor analysis \n > #save the solution to an R variable \n > solution <- fa(r = corMat, nfactors = 2, rotate = \"oblimin\", fm = \"pa\") \n > #display the solution output \n > solution \n   \n Complete solution output \nBy looking at our factor loadings, we can begin to assess our factor solution. We can see that BIO, GEO, and CHEM all have high factor loadings around 0.8 on the first factor (PA1). Therefore, we might call this factor Science and consider it representative of a student's interest in science subject matter. Similarly, ALG, CALC, and STAT load highly on the second factor (PA2), which we might call Math . Note that STAT has a much lower loading on PA2 than ALG or CALC and that it has a slight loading on factor PA1. This suggests that statistics is less related to the concept of Math than algebra and calculus. Just below the loadings table, we can see that each factor accounted for around 30% of the variance in responses, leading to a factor solution that accounted for 66% of the total variance in students' subject matter preference. Lastly, notice that our factors are correlated at 0.21 and recall that our choice of oblique rotation allowed for the recognition of this relationship. \nOf course, there are many other considerations to be made in developing and assessing an EFA that will not be presented here. The intent with this tutorial was simply to demonstrate the basic execution of EFA in R. For a detailed and digestible overview of EFA, I recommend the Factor Analysis chapter of Multivariate Data Analysis by Hair, Black, Babin, and Anderson. \n Complete EFA Example To see a complete example of how EFA data can be organized using the psych package in R, please download the EFA example (.txt) file. For the code used in this tutorial, download the EFA Example (.R) file. \n References Revelle, W. (2011). psych: Procedures for Personality and Psychological Research. http://personality-project.org/r/psych.manual.pdf"], "link": "http://feedproxy.google.com/~r/RTutorialSeries/~3/LLM3lnuMWzQ/r-tutorial-series-exploratory-factor.html", "bloglinks": {}, "links": {"http://4.blogspot.com/": 1, "http://3.blogspot.com/": 2, "http://dl.dropbox.com/": 3}, "blogtitle": "R Tutorial Series"}, {"content": ["The R Programming wikibook is an open source community project that \"aims to create a cross-disciplinary practical guide to the R programming language.\" It was launched in June 2011 and is seeking content and contributors. The full call for the R Programming wikibook can be found on Tal Galili's blog . The R Programming wikibook itself is available at http://en.wikibooks.org/wiki/R_Programming . I am writing to raise awareness for the R Programming wikibook and to formally offer content from the R Tutorial Series by John M. Quick for use under a Creative Commons Attribution-ShareAlike 3.0 Unported License . This means that articles from the R Tutorial Series may be included in and modified for the R Programming wikibook, so long as proper attribution is given and the resulting content is made available under an equivalent license. A complete list of contributing blogs can be found on the R Programming wikibook's Sources page . I hope that the R Programming wikibook will thrive and grow to support a large community of R users, including readers of the R Tutorial Series."], "link": "http://feedproxy.google.com/~r/RTutorialSeries/~3/JVjrzr_Rk5E/r-programming-wikibook.html", "bloglinks": {}, "links": {"http://www.r-statistics.com/": 1, "http://en.wikibooks.org/": 3, "http://creativecommons.org/": 1, "http://www.johnmquick.com/": 1}, "blogtitle": "R Tutorial Series"}, {"content": ["Having wrapped up a recent flurry of R ANOVA articles (and exhausted my knowledge of the subject), I decided to take a look at the R Tutorial Series' Google Analytics data from the past few months. \nSince I posted the Two-Way Omnibus ANOVA article on January 17, we have had about 150 visits per day and over 19,000 total page views. The original introduction to R posts are still the most popular ones here, although a few from the regression and ANOVA series are also represented in the most viewed. \nI also wanted to share a funny observation about the patterns of visits to the R Tutorial Series. The following graph portrays our daily viewership over the past few months. \n \n \n \n \n \nThe valleys on the chart correspond to the weekends (evidently when no one wants to read about statistical computing). The initial peaks are Mondays, which happen to be when I most often make new posts. Typically, a slightly higher peak comes on Tuesday, followed by a gradual decline back into the weekend valley. Thus, our visits to the R Tutorial Series end up creating a nice little wave pattern throughout the year. The good news with these numbers is that people are reading the R Tutorial Series and (hopefully) learning to use R and apply it to their daily work, which is the blog's ultimate purpose. I also appreciate all of the comments, questions, and tips that have been posted by readers. Your feedback really helps to improve the tutorials. \n \nUpcoming Plans \nAs mentioned, I have concluded my planned coverage of ANOVA in R. Thus, we have reached a sort of break period, much like the one that followed last year's spurt of regression tutorials. I do plan to keep writing R tutorials, but for the time being, they may arrive in less predictable intervals and cover a wider variety of content. As always, I welcome contact regarding guest posts, especially on statistical and R content that I have not covered or am not yet familiar with."], "link": "http://feedproxy.google.com/~r/RTutorialSeries/~3/xbytgM5u2mk/r-tutorial-series-2011-anova-article.html", "bloglinks": {}, "links": {"http://3.blogspot.com/": 1}, "blogtitle": "R Tutorial Series"}, {"content": ["As demonstrated in the preceding ANOVA tutorials, data organization is central to conducting ANOVA in R. In standard ANOVA, we used the tapply() function to generate a table for a single summary function. In repeated measures ANOVA, we used separate datasets for our omnibus ANOVA and follow-up comparisons. This tutorial will demonstrate how the reshape package can be used to simplify the ANOVA data organization process in R. \n Tutorial Files Before we begin, you may want to download the between group and repeated measures datasets (.csv) used in this tutorial. Be sure to right-click and save the files to your R working directory. The between groups dataset contains a hypothetical sample of 30 cases separated into three groups (a, b, and c). The repeated measures dataset contains a hypothetical sample of 10 cases across three measurements (a, b, and c). In both cases, the values are represented on a scale that ranges from 1 to 5. \n Beginning Steps To begin, we need to read our datasets into R and store their contents in variables. \n > #read the datasets into R variables using the read.csv(file) function \n > dataBetween <- read.csv(\"dataset_ANOVA_reshape_1.csv\") \n > dataRepeated <- read.csv(\"dataset_ANOVA_reshape_2.csv\") \n Reshape Package Next, we need to install and load the reshape package. In this tutorial, we will make use of the package's cast() and melt() functions. \n > #install the package \n > install.packages(\"reshape\") \n > #load the package \n > library(reshape) \n Using cast() to Derive ANOVA Descriptives The cast() function can be used to easily derive summary statistics for a between groups ANOVA dataset. The cast() function receives the following primary arguments. \n data: the dataset \n formula: in our case, a one-sided formula indicating the grouping variable \n fun.aggregate: a function or vector of functions for deriving summary statistics, such as mean, var, or sd \n > #display the raw between groups data \n > dataBetween \n   \n The raw between groups data > #cast the between groups data using cast(data, formula, fun.aggregate) to get the group means \n > cast(dataBetween, formula = ~group, fun.aggregate = mean) \n   \n The casted data with means \nNote that the fun.aggregate argument can also receive a vector of summary statistics functions. This will yield all of the requested descriptives via a single cast() function. \n > #cast the between groups data using cast(data, formula, fun.aggregate) to get the group means, variances, and standard deviations \n > cast(dataBetween, formula = ~group, fun.aggregate = c(mean, var, sd)) \n   \n The casted data with descriptives Using melt() to Prepare Repeated Measures Data for Pairwise Comparisons The melt() function can be used to morph a repeated measures ANOVA dataset prior to conducting pairwise comparisons. The melt() function receives the following primary arguments. \n data: the dataset \n id.vars: the id variable or a vector of values that can be used as ids \n measure.vars: a vector containing the variables to be melted \n variable_name: the name of the column containing the melted variables \n > #display the repeated measures data \n > dataRepeated \n   \n The raw repeated measures data > #melt the repeated measures data using melt(data, id.vars, measure.vars, variable_name) to organize it for pairwise comparisons \n > melt(dataRepeated, id.vars = \"case\", measure.vars = c(\"valueA\", \"valueB\", \"valueC\"), variable_name = \"abcValues\") \n   \n The melted repeated measures data \nNote that the data are now prepared to be used in the pairwise.t.test() function. See the One-Way ANOVA with Pairwise Comparisons tutorial for details on using the pairwise.t.test() function. \n Complete ANOVA Reshape Example To see a complete example of how ANOVA data can be organized using the reshape package in R, please download the ANOVA reshape example (.txt) file."], "link": "http://feedproxy.google.com/~r/RTutorialSeries/~3/uBwUngF18-k/r-tutorial-series-applying-reshape.html", "bloglinks": {}, "links": {"http://2.blogspot.com/": 1, "http://3.blogspot.com/": 2, "http://1.blogspot.com/": 2, "http://dl.dropbox.com/": 3, "http://rtutorialseries.blogspot.com/": 1}, "blogtitle": "R Tutorial Series"}, {"content": ["When we have a statistically significant effect in ANOVA and an independent variable of more than two levels, we typically want to make follow-up comparisons. There are numerous methods for making pairwise comparisons and this tutorial will demonstrate how to execute several different techniques in R. \n Tutorial Files Before we begin, you may want to download the sample data (.csv) used in this tutorial. Be sure to right-click and save the file to your R working directory. This dataset contains a hypothetical sample of 30 participants who are divided into three stress reduction treatment groups (mental, physical, and medical). The values are represented on a scale that ranges from 1 to 5. This dataset can be conceptualized as a comparison between three stress treatment programs, one using mental methods, one using physical training, and one using medication. The values represent how effective the treatment programs were at reducing participant's stress levels, with higher numbers indicating higher effectiveness. \n Beginning Steps To begin, we need to read our dataset into R and store its contents in a variable. \n > #read the dataset into an R variable using the read.csv(file) function \n > dataPairwiseComparisons <- read.csv(\"dataset_ANOVA_OneWayComparisons.csv\") \n > #display the data \n > dataPairwiseComparisons \n   \n The first ten rows of our dataset Omnibus ANOVA For the purposes of this tutorial, we will assume that the omnibus ANOVA has already been conducted and that the main effect for treatment was statistically significant. For details on this process, see the One-Way ANOVA with Pairwise Comparisons tutorial, which uses the same dataset. \n Means Let's also look at the means of our treatment groups. Here, we will use the tapply() function, along with the following arguments, to generate a table of means. \n X: the data \n INDEX: a list() of factor variables \n FUN: the function to be applied \n > #use tapply(X, INDEX, FUN) to generate a table displaying each treatment group mean \n > tapply(X = dataPairwiseComparisons$StressReduction, INDEX = list(dataPairwiseComparisons$Treatment), FUN = mean) \n   \n The treatment group means Pairwise Comparisons We will cover five major techniques for controlling Type I error when making pairwise comparisons. These methods are no adjustment, Bonferroni's adjustment, Holm's adjustment, Fisher's LSD, and Tukey's HSD. All of these techniques will be demonstrated on our sample dataset, although the decision as to which to use in a given situation is left up to the reader. \n pairwise.t.test() Our first three methods will make use of the pairwise.t.test() function, which has the following major arguments. \n x: the dependent variable \n g: the independent variable \n p.adj: the p-value adjustment method used to control for the family-wise Type I error rate across the comparisons; one of \"none\", \"bonferroni\", \"holm\", \"hochberg\", \"hommel\", \"BH\", or \"BY\" \n No Adjustment Using p.adj = \"none\" in the pairwise.t.test() function makes no correction for the Type I error rate across the pairwise tests. This technique can be useful for employing methods that are not already built into R functions, such as the Shaffer/Modified Shaffer, which use different alpha level divisors based on the number of levels composing the independent variable. The console results will contain no adjustment, but the researcher can manually consider the statistical significance of the p-values under his or her desired alpha level. \n > #use pairwise.t.test(x, g, p.adj) to test the pairwise comparisons between the treatment group means \n > #no adjustment \n > pairwise.t.test(dataPairwiseComparisons$StressReduction, dataPairwiseComparisons$Treatment, p.adj = \"none\") \n   \n Pairwise comparisons of treatment group means with no adjustment \nWith no adjustment, the mental-medical and physical-medical comparisons are statistically significant, whereas the mental-physical comparison is not. This suggests that both the mental and physical treatments are superior to the medical treatment, but that there is insufficient statistical support to distinguish between the mental and physical treatments. \n Bonferroni Adjustment The Bonferroni adjustment simply divides the Type I error rate (.05) by the number of tests (in this case, three). Hence, this method is often considered overly conservative. The Bonferroni adjustment can be made using p.adj = \"bonferroni\" in the pairwise.t.test() function. \n > #Bonferroni adjustment \n > pairwise.t.test(dataPairwiseComparisons$StressReduction, dataPairwiseComparisons$Treatment, p.adj = \"bonferroni\") \n   \n Pairwise comparisons of treatment group means using Bonferroni adjustment \nUsing the Bonferroni adjustment, only the mental-medical comparison is statistically significant. This suggests that the mental treatment is superior to the medical treatment, but that there is insufficient statistical support to distinguish between the mental and physical treatments and the physical and medical treatments. Notice that these results are more conservative than with no adjustment. \n Holm Adjustment The Holm adjustment sequentially compares the lowest p-value with a Type I error rate that is reduced for each consecutive test. In our case, this means that our first p-value is tested at the .05/3 level (.017), second at the .05/2 level (.025), and third at the .05/1 level (.05). This method is generally considered superior to the Bonferroni adjustment and can be employed using p.adj = \"holm\" in the pairwise.t.test() function. \n > #Holm adjustment \n > pairwise.t.test(dataPairwiseComparisons$StressReduction, dataPairwiseComparisons$Treatment, p.adj = \"holm\") \n   \n Pairwise comparisons of treatment group means using Holm adjustment \nUsing the Holm procedure, our results are practically (but not mathematically) identical to using no adjustment. \n LSD Method The Fisher Least Significant Difference (LSD) method essentially does not correct for the Type I error rate for multiple comparisons and is generally not recommended relative to other options. However, should the need arise to employ this method, one should seek out the LSD.test() function in the agricolae package, which has the following major arguments. \n y: the dependent variable \n trt: the independent variable \n DFerror: the degrees of freedom error \n MSerror: the mean squared error \n Note that the DFerror and MSerror can be found in the omnibus ANOVA table. \n > #load the agricolae package (install first, if necessary) \n > library(agricolae) \n #LSD method \n #use LSD.test(y, trt, DFerror, MSerror) to test the pairwise comparisons between the treatment group means \n > LSD.test(dataPairwiseComparisons$StressReduction, dataPairwiseComparisons$Treatment, 30.5, 1.13) \n   \n Pairwise comparisons of treatment group means using LSD method \nUsing the LSD method, our results are practically (but not mathematically) identical to using no adjustment or the Holm procedure. \n HSD Method The Tukey Honest Significant Difference (HSD) method controls for the Type I error rate across multiple comparisons and is generally considered an acceptable technique. This method can be executed using the TukeyHSD(x) function, where x is a linear model object created using the aov(formula, data) function. Note that in this application, the aov(formula, data) function is identical to the lm(formula, data) that we are already familiar with from linear regression . \n > #HSD method \n > #use TukeyHSD(x), in tandem with aov(formula, data), to test the pairwise comparisons between the treatment group means \n TukeyHSD(aov(StressReduction ~ Treatment, dataPairwiseComparisons)) \n   \n Pairwise comparisons of treatment group means using HSD method \nUsing the HSD method, our results are practically (but not mathematically) identical to using the Bonferroni, Holm, or LSD methods. \n Complete Pairwise Comparisons Example To see a complete example of how various pairwise comparison techniques can be applied in R, please download the ANOVA pairwise comparisons example (.txt) file."], "link": "http://feedproxy.google.com/~r/RTutorialSeries/~3/A9gRXiQp8zo/r-tutorial-series-anova-pairwise.html", "bloglinks": {}, "links": {"http://3.blogspot.com/": 1, "http://dl.dropbox.com/": 2, "http://1.blogspot.com/": 2, "http://rtutorialseries.blogspot.com/": 2, "http://4.blogspot.com/": 3, "http://2.blogspot.com/": 1}, "blogtitle": "R Tutorial Series"}, {"content": ["When the sample sizes within the levels of our independent variables are not equal, we have to handle our ANOVA differently than in the typical two-way case. This tutorial will demonstrate how to conduct a two-way ANOVA in R when the sample sizes within each level of the independent variables are not the same. \n Tutorial Files Before we begin, you may want to download the sample data (.csv) used in this tutorial. Be sure to right-click and save the file to your R working directory. This dataset contains a hypothetical sample of 30 students who were exposed to one of two learning environments (offline or online) and one of two methods of instruction (classroom or tutor), then tested on a math assessment. Possible math scores range from 0 to 100 and indicate how well each student performed on the math assessment. Each student participated in either an offline or online learning environment and received either classroom instruction (i.e. one to many) or instruction from a personal tutor (i.e. one to one). \n Beginning Steps To begin, we need to read our dataset into R and store its contents in a variable. \n > #read the dataset into an R variable using the read.csv(file) function \n > dataTwoWayUnequalSample <- read.csv(\"dataset_ANOVA_TwoWayUnequalSample.csv\") \n > #display the data \n > dataTwoWayUnequalSample \n   \n The first ten rows of our dataset Unequal Sample Sizes In our study, 16 students participated in the online environment, whereas only 14 participated in the offline environment. Further, 20 students received classroom instruction, whereas only 10 received personal tutor instruction. As such, we should take action to compensate for the unequal sample sizes in order to retain the validity of our analysis. Generally, this comes down to examining the correlation between the factors and the causes of the unequal sample sizes en route to choosing whether to use weighted or unweighted means - a decision which can drastically impact the results of an ANOVA. This tutorial will demonstrate how to conduct ANOVA using both weighted and unweighted means. Thus, the ultimate decision as to the use of weighted or unweighted means is left up to each individual and his or her specific circumstances. \n Weighted Means First, let's suppose that we decided to go with weighted means, which take into account the correlation between our factors that results from having treatment groups with different sample sizes. A weighted mean is calculated by simply adding up all of the values and dividing by the total number of values. Consequently, we can easily derive the weighted means for each treatment group using our subset(data, condition) and mean(data) functions. \n > #use subset(data, condition) to create subsets for each treatment group \n > #offline subset \n > offlineData <- subset(dataTwoWayUnequalSample, dataTwoWayUnequalSample$environment == \"offline\") \n > #online subset \n > onlineData <- subset(dataTwoWayUnequalSample, dataTwoWayUnequalSample$environment == \"online\") \n > #classroom subset \n > classroomData <- subset(dataTwoWayUnequalSample, dataTwoWayUnequalSample$instruction == \"classroom\") \n > #tutor subset \n > tutorData <- subset(dataTwoWayUnequalSample, dataTwoWayUnequalSample$instruction == \"tutor\") \n > #use mean(data) to calculate the weighted means for each treatment group \n > #offline weighted mean \n > mean(offlineData$math) \n > #online weighted mean \n > mean(onlineData$math) \n > #classroom weighted mean \n > mean(classroomData$math) \n > #tutor weighted mean \n > mean(tutorData$math) \n   \n The weighted means for the environment and instruction conditions ANOVA using Type I Sums of Squares When applying weighted means, it is suggested that we use Type I sums of squares (SS) in our ANOVA. Type I happens to be the default SS used in our standard anova(object) function, which will be used to execute our analysis. Note that in the case of two-way ANOVA, the ordering of our independent variables matters when using weighted means. Therefore, we must run our ANOVA two times, once with each independent variable taking the lead. However, the interaction effect is not affected by the ordering of the independent variables. \n > #use anova(object) to execute the Type I SS ANOVAs \n > #environment ANOVA \n > anova(lm(math ~ environment * instruction, dataTwoWayUnequalSample)) \n > #instruction ANOVA \n > anova(lm(math ~ instruction * environment, dataTwoWayUnequalSample)) \n   \n The Type I SS ANOVA results. Note the differences in main effects based on the ordering of the independent variables. \nThese results indicate statistically insignificant main effects for both the environment and instruction variables, as well as the interaction between them. \n Unweighted Means Now let's turn to using unweighted means, which essentially ignore the correlation between the independent variables that arise from unequal sample sizes. An unweighted mean is calculated by taking the average of the individual group means. Thus, we can derive our unweighted means by summing the means of each level of our independent variables and dividing by the total number of levels. For instance, to find the unweighted mean for environment, we will add the means for our offline and online groups, then divide by two. \n > #use mean(data) and subset(data, condition) to calculate the unweighted means for each treatment group \n > #offline unweighted mean = (classroom offline mean + tutor offline mean) / 2 \n (mean(subset(offlineData$math, offlineData$instruction == \"classroom\")) + mean(subset(offlineData$math, offlineData$instruction == \"tutor\"))) / 2 \n > #online unweighted mean = (classroom online mean + tutor online mean) / 2 \n > (mean(subset(onlineData$math, onlineData$instruction == \"classroom\")) + mean(subset(onlineData$math, onlineData$instruction == \"tutor\"))) / 2 \n > #classroom unweighted mean = (offline classroom mean + online classroom mean) / 2 \n > (mean(subset(classroomData$math, classroomData$environment == \"offline\")) + mean(subset(classroomData$math, classroomData$environment == \"online\"))) / 2 \n > #tutor unweighted mean = (offline tutor mean + online tutor mean) / 2 \n > (mean(subset(tutorData$math, tutorData$environment == \"offline\")) + mean(subset(tutorData$math, tutorData$environment == \"online\"))) / 2 \n   \n The unweighted means for the environment and instruction conditions ANOVA using Type III Sums of Squares When applying unweighted means, it is suggested that we use Type III sums of squares (SS) in our ANOVA. Type III SS can be set using the type argument in the Anova(mod, type) function, which is a member of the car package. \n > #load the car package (install first, if necessary) \n > library(car) \n > #use the Anova(mod, type) function to conduct the Type III SS ANOVA \n > Anova(lm(math ~ environment * instruction, dataTwoWayUnequalSample), type = \"3\") \n   \n The Type III SS ANOVA results. \nOnce again, our ANOVA results indicate statistically insignificant main effects for both the environment and instruction variables, as well as the interaction between them. However, it is worth noting that both the means and p-values are different when using unweighted means and Type III SS compared to weighted means and Type I SS. In certain cases, this difference can be quite pronounced and lead to entirely different outcomes between the two methods. Hence, choosing the appropriate means and SS for a given analysis is a matter that should be approached with conscious consideration. \n Pairwise Comparisons Note that since our independent variables contain only two levels, there is no need to conduct follow-up comparisons. However, should you reach this point with a statistically significant independent variable of more than three levels, you could conduct pairwise comparisons in the same manner as demonstrated in the Two-Way ANOVA with Comparisons tutorial. \n Complete Two-Way ANOVA with Unequal Sample Sizes Example To see a complete example of how two-way ANOVA with unequal sample sizes can be conducted in R, please download the two-way ANOVA with unequal sample sizes example (.txt) file."], "link": "http://feedproxy.google.com/~r/RTutorialSeries/~3/cXv3FZ8N2S4/r-tutorial-series-two-way-anova-with_28.html", "bloglinks": {}, "links": {"http://2.blogspot.com/": 2, "http://3.blogspot.com/": 3, "http://rtutorialseries.blogspot.com/": 1, "http://dl.dropbox.com/": 2}, "blogtitle": "R Tutorial Series"}, {"content": ["Repeated measures data require a different analysis procedure than our typical two-way ANOVA and subsequently follow a different R process. This tutorial will demonstrate how to conduct two-way repeated measures ANOVA in R using the Anova() function from the car package. \nNote that the two-way repeated measures ANOVA process can be very complex to organize and execute in R. Although it has been distilled into just a few small steps in this guide, it is recommended that you fully and precisely complete the example before experimenting with your own data. As you will see, organization of the raw data is critical to successfully conducting a two-way repeated measures ANOVA using the demonstrated technique. \n Tutorial Files Before we begin, you may want to download the sample data (.csv) and sample idata frame (.csv) used in this tutorial. Be sure to right-click and save the files to your R working directory. This dataset contains a hypothetical sample of 30 participants whose interest in school and interest in work was measured at three different ages (10, 15, and 20). The interest values are represented on a scale that ranges from 1 to 5 and indicate how interested each participant was in a given topic at each given age. \n Data Setup Notice that our data are arranged differently for a repeated measures ANOVA. In a typical two-way ANOVA, we would place all of the values of our independent variable in a single column and identify their respective levels with a second column, as demonstrated in this sample two-way dataset . In a two-way repeated measures ANOVA, we instead combine each independent variable with its time interval, thus yielding columns for each pairing. Hence, rather than having one vertical column for school interest and one for work interest, with a second column for age, we have six separate columns for interest, three for school interest and three for work interest at each age level. The following graphic is intended to help demonstrate this organization method. \n  \n Treat time as if it were an independent variable. Then combine each independent variable with each level of time and arrange the columns horizontally. Beginning Steps To begin, we need to read our dataset into R and store its contents in a variable. \n > #read the dataset into an R variable using the read.csv(file) function \n > dataTwoWayRepeatedMeasures <- read.csv(\"dataset_ANOVA_TwoWayRepeatedMeasures.csv\") \n > #display the data \n > #notice the atypical column arrangement for repeated measures data \n > dataTwoWayRepeatedMeasures \n   \n The first ten rows of our dataset idata Frame Another item that we need to import for this analysis is our idata frame. This object will be used in our Anova() function to define the structure of our analysis. \n > #read the idata frame into an R variable \n > idataTwoWayRepeatedMeasures <- read.csv(\"idata_ANOVA_TwoWayRepeatedMeasures.csv\") \n > #display the idata frame \n > #notice the text values and correspondence between our idata rows and the columns in our dataset \n > idataTwoWayRepeatedMeasures \n   \n The idata frame \nNote that it is critical that your idata frame take the demonstrated form for this technique to work. I experimented with several alternative, perhaps more intuitive, layouts without success. It is particularly important to notice that both columns of the idata frame contain text values (not numerical ones - hence the repeated prefixing of Age to the values in every row of the Age column). Additionally, if you read the rows of the idata frame horizontally, you will see that they correspond precisely to the columns of our dataset. The following graphic is intended to help demonstrate this organization method. \n  \n \n Use only text values in your idata frame. Ensure that the rows of your idata frame correspond to the columns in your dataset. Linear Model Prior to executing our analysis, we must follow two steps to formulate our linear model to be used in the Anova() function. \n Step 1: Bind the Columns > #use cbind() to bind the columns of the original dataset \n > interestBind <- cbind(dataTwoWayRepeatedMeasures$schoolAge10, dataTwoWayRepeatedMeasures$schoolAge15, dataTwoWayRepeatedMeasures$schoolAge20, dataTwoWayRepeatedMeasures$workAge10, dataTwoWayRepeatedMeasures$workAge15, dataTwoWayRepeatedMeasures$workAge20) \n Step 2: Define the Model > #use lm() to generate a linear model using the bound columns from step 1 \n > interestModel <- lm(interestBind ~ 1) \n Anova(mod, idata, idesign) Function Typically, researchers will choose one of several techniques for analyzing repeated measures data, such as an epsilon-correction method, like Huynh-Feldt or Greenhouse-Geisser, or a multivariate method, like Wilks' Lambda or Hotelling's Trace. Conveniently, having already prepared our data, we can employ a single Anova(mod, idata, idesign) function from the car package to yield all of the relevant repeated measures results. This allows us simplicity in that only a single function is required, regardless of the technique that we wish to employ. Thus, witnessing our outcomes becomes as simple as locating the desired method in the cleanly printed results. \nOur Anova(mod, idata, idesign) function will be composed of three arguments. First, mod will contain our linear model. Second, idata will contain our data frame. Third, idesign will contain a multiplication of the row headings from our idata frame (in other words, our independent variables), preceded by a tilde (~). Thus, our final function takes on the following form. \n > #load the car package (install first, if necessary) \n library(car) \n > #compose the Anova(mod, idata, idesign) function \n > analysis <- Anova(interestModel, idata = idataTwoWayRepeatedMeasures, idesign = ~Interest * Age) \n Results Summary Finally, we can use the summary(object) function to visualize the results of our repeated measures ANOVA. \n > #use summary(object) to visualize the results of the repeated measures ANOVA \n > summary(analysis) \n   \n Relevant segment of repeated measures ANOVA results \nSupposing that we are interested in the Wilks' Lambda method, we can see that there is a statistically significant interaction effect between interest in school and interest in work across the age groups ( p < .001). This suggests that we should further examine our data at the level of simple main effects. For more information investigating on simple main effects, see the Two-Way ANOVA with Interactions and Simple Main Effects tutorial. Of course, in this case of repeated measures ANOVA, another way to break the data down would be to run two one-way repeated measures ANOVAs , one for each of the independent variables. In either instance, pairwise comparisons can be conducted to determine the significance of the differences between the levels of any significant effects. \n Complete Two-Way Repeated Measures ANOVA Example To see a complete example of how two-way repeated measures ANOVA can be conducted in R, please download the two-way repeated measures ANOVA example (.txt) file. \n References Moore, Colleen. (n.d.). 610 R9 -- Two-way Repeated-measures Anova. Retrieved January 21, 2011 from http://psych.wisc.edu/moore/Rpdf/610-R9_Within2way.pdf"], "link": "http://feedproxy.google.com/~r/RTutorialSeries/~3/UfCLWHf_3dM/r-tutorial-series-two-way-repeated.html", "bloglinks": {}, "links": {"http://4.blogspot.com/": 3, "http://www.dailyi.org/blog": 1, "http://2.blogspot.com/": 2, "http://dl.dropbox.com/": 3, "http://rtutorialseries.blogspot.com/": 3}, "blogtitle": "R Tutorial Series"}, {"content": ["Book Information Mittal, H. (2011). R graphs cookbook . Birmingham, UK: Packt Publishing Ltd. Audience The book's stated audience is anyone who is familiar with the basics of R, as well as expert users who are looking for a graphical reference. However, it is my opinion that the book is better suited for advanced users who are already somewhat familiar with R graphics and are very comfortable with programming in R. Content To begin, the first chapter of R Graphs Cookbook rapidly introduces all of the major graphic types covered in the book. Next, in Chapter two, readers are acquainted with various arguments and modification functions that are used throughout the book to customize and enhance visuals. Subsequently, individual chapters focus on specific topics in R graphics, such as: scatterplots, line and time series charts, bar, dot, and pie charts, histograms, box plots, heat and contour maps, geographical maps, and exporting and annotating graphics. Analysis I will start with some general impressions, before moving into chapter by chapter analyses. First, I feel that the book needs both more and larger screenshots. Often times, recipes are without any visuals and most of the time only one is present, whereas one per major graphical modification is expected. Furthermore, the screenshots are too small. These are critical items to neglect in a book that explicitly deals with visuals. Fortunately, full-size, full-color images are provided with the downloadable code for the book. Second, I feel that the topics presented in the book are glanced over with far too little explanation. This is the main reason that I feel it is not suited for those who are not already well versed in R programming. Moreover, R Graphs Cookbook frequently refers the reader to help documentation or to other books on R, which can be frustrating. I personally feel that a book should be largely self-contained, at least when discussing topics within its scope. Third, I believe that the book could be better organized for use as a fast reference guide and that it generally could be better structured to present information. For example, rather than tables are a clearer way to present head to head comparisons between objects, and lists are better for describing several function arguments. On the other hand, I do like the book's code formatting, which displays one argument per line. While this could confuse novice users into thinking that each argument is a separate line of executable code, most readers should find this a welcomed organization style for often lengthy graphics functions. I also enjoyed how the see also sections at the end of each recipe let me know whether more recipes would build on a given topic. Continuing, chapter one felt like a whirlwind of information that charged forward with a lack of purpose, organization, and explanation. Chapter two was much better, offering several nice recipes that were fast and easy to digest, with just enough information provided. Chapter three takes an in-depth look at scatterplots and provides a number of useful recipes, such as how to group data, label points, generate error bars, and create graphical correlation matrices. Similarly, chapter four provides a solid collection of recipes for time series and line charts. In contrast, chapters five through seven cover a disappointingly sparse amount of material related to their respective topics. Unfortunately, they do not stretch far beyond what is covered in the two graphics-focused chapters of Statistical Analysis with R , which is a guide for newcomers and early beginners. From an advanced reference like R Graphs Cookbook , I expected broader coverage. For instance, very few external packages are presented in this book, with the author choosing to focus on built-in graphics functions almost exclusively. An introduction to external options, such as ggplot2 , would be warmly welcomed. Chapters eight and nine relate a few of the lesser covered topics in R, including heat, contour, and geographical maps. These chapters will likely be informative and valuable for readers interested in these graphical applications. Lastly, chapter ten deals with the presentation and exportation of graphics. While I wish a deeper exploration was made, there are some useful tips in is chapter. Namely, the use of the expression() function to annotate graphics is well covered. Brief Summary Title: R Graphs Cookbook Author: Hrishi Mittal Where To Find: Packt Publishing \n Audience: those who are comfortable programming in R, able to mix, match, apply, and extend recipes for their own purposes, and looking to learn more about R's built-in graphical capabilities. Content: a loosely associated collection of recipes for applying R's built-in graphics functions to create the most common types of charts, graphs, plots, and maps. Analysis: although it could have better visuals, structure, and coverage, it is likely that almost any reader will be able to take away valuable techniques from this book Arbitrary Rating: 6/10 Recommendation: take a look at the table of contents and count the number of recipes that would both be useful to you and that you do not already know how to accomplish to get an idea of how much you will take away from this book; also read the free sample chapter Disclaimer: I received a review copy of this book"], "link": "http://feedproxy.google.com/~r/RTutorialSeries/~3/P6dBs19xt74/book-review-r-graphs-cookbook.html", "bloglinks": {}, "links": {"https://www.packtpub.com/": 1, "http://link.packtpub.com/": 2, "http://www.prettygraph.com/": 1}, "blogtitle": "R Tutorial Series"}, {"content": ["Repeated measures data require a different analysis procedure than our typical one-way ANOVA and subsequently follow a different R process. This tutorial will demonstrate how to conduct one-way repeated measures ANOVA in R using the Anova(mod, idata, idesign) function from the car package. \n Tutorial Files Before we begin, you may want to download the sample data (.csv) used in this tutorial. Be sure to right-click and save the file to your R working directory. This dataset contains a hypothetical sample of 30 participants whose interest in voting was measured at three different ages (10, 15, and 20). The interest values are represented on a scale that ranges from 1 to 5 and indicate how interested each participant was in voting at each given age. \n Data Setup Notice that our data are arranged differently for a repeated measures ANOVA. In a typical one-way ANOVA, we would place all of the values of our independent variable in a single column and identify their respective levels with a second column, as demonstrated in this sample one-way dataset . In a repeated measures ANOVA, we instead treat each level of our independent variable as if it were a variable, thus placing them side by side as columns. Hence, rather than having one vertical column for voting interest, with a second column for age, we have three separate columns for voting interest, one for each age level. \n Beginning Steps To begin, we need to read our dataset into R and store its contents in a variable. \n > #read the dataset into an R variable using the read.csv(file) function \n > dataOneWayRepeatedMeasures <- read.csv(\"dataset_ANOVA_OneWayRepeatedMeasures.csv\") \n > #display the data \n > #notice the atypical column arrangement for repeated measures data \n > dataOneWayRepeatedMeasures \n   \n The first ten rows of our dataset Preparing the Repeated Measures Factor Prior to executing our analysis, we must follow a small series of steps in order to prepare our repeated measures factor. \n Step 1: Define the Levels > #use c() to create a vector containing the number of levels within the repeated measures factor \n > #create a vector numbering the levels for our three voting interest age groups \n > ageLevels <- c(1, 2, 3) \n Step 2: Define the Factor > #use as.factor() to create a factor using the level vector from step 1 \n > #convert the age levels into a factor \n > ageFactor <- as.factor(ageLevels) \n Step 3: Define the Frame > #use data.frame() to create a data frame using the factor from step 2 \n > #convert the age factor into a data frame \n > ageFrame <- data.frame(ageFactor) \n Step 4: Bind the Columns > #use cbind() to bind the levels of the factor from the original dataset \n > #bind the age columns \n > ageBind <- cbind(dataOneWayRepeatedMeasures$Interest10, dataOneWayRepeatedMeasures$Interest15, dataOneWayRepeatedMeasures$Interest20) \n Step 5: Define the Model > #use lm() to generate a linear model using the bound factor levels from step 4 \n > #generate a linear model using the bound age levels \n > ageModel <- lm(ageBind ~ 1) \n Employing the Anova(mod, idata, idesign) Function Typically, researchers will choose one of several techniques for analyzing repeated measures data, such as an epsilon-correction method, like Huynh-Feldt or Greenhouse-Geisser, or a multivariate method, like Wilks' Lambda or Hotelling's Trace. Conveniently, having already prepared our data, we can employ a single Anova(mod, idata, idesign) function from the car package to yield all of the relevant repeated measures results. This allows us simplicity in that only a single function is required, regardless of the technique that we wish to employ. Thus, witnessing our outcomes becomes as simple as locating the desired method in the cleanly printed results. \nOur Anova(mod, idata, idesign) function will be composed of three arguments. First, mod will contain our linear model from Step 5 in the preceding section. Second, idata will contain our data frame from Step 3. Third, idesign will contain our factor from Step 2, preceded by a tilde (~). Thus, our final function takes on the following form. \n > #load the car package (install first, if necessary) \n library(car) \n > #compose the Anova(mod, idata, idesign) function \n > analysis <- Anova(ageModel, idata = ageFrame, idesign = ~ageFactor) \n Visualizing the Results Finally, we can use the summary(object) function to visualize the results of our repeated measures ANOVA. \n > #use summary(object) to visualize the results of the repeated measures ANOVA \n > summary(analysis) \n   \n Relevant segment of repeated measures ANOVA results \nSupposing that we are interested in the Wilks' Lambda method, we can see that the differences in the means for voting interest at ages 10, 15, and 20 are statistically significant ( p < .001). \n Pairwise Comparisons Note that we could conduct follow-up comparisons on our age factor to determine which age level means are significantly different from one another. For this purpose, it is recommended that the data be rearranged into the standard ANOVA format that we have used throughout our other tutorials. Subsequently, we could conduct pairwise comparisons in the same manner as demonstrated in the One-Way ANOVA with Comparisons tutorial. \n Complete One-Way Repeated Measures ANOVA Example To see a complete example of how one-way repeated measures ANOVA can be conducted in R, please download the one-way repeated measures ANOVA example (.txt) file."], "link": "http://feedproxy.google.com/~r/RTutorialSeries/~3/mcD7wZHho0s/r-tutorial-series-one-way-repeated.html", "bloglinks": {}, "links": {"http://www.dailyi.org/blog": 1, "http://3.blogspot.com/": 1, "http://2.blogspot.com/": 1, "http://dl.dropbox.com/": 2, "http://rtutorialseries.blogspot.com/": 1}, "blogtitle": "R Tutorial Series"}, {"content": ["When an interaction is present in a two-way ANOVA, we typically choose to ignore the main effects and elect to investigate the simple main effects when making pairwise comparisons. This tutorial will demonstrate how to conduct pairwise comparisons when an interaction is present in a two-way ANOVA. \n Tutorial Files Before we begin, you may want to download the sample data (.csv) used in this tutorial. Be sure to right-click and save the file to your R working directory. This dataset contains a hypothetical sample of 60 participants who are divided into three stress reduction treatment groups (mental, physical, and medical) and two gender groups (male and female). The stress reduction values are represented on a scale that ranges from 1 to 5. This dataset can be conceptualized as a comparison between three stress treatment programs, one using mental methods, one using physical training, and one using medication across genders. The values represent how effective the treatment programs were at reducing participant's stress levels, with higher numbers indicating higher effectiveness. \n Beginning Steps To begin, we need to read our dataset into R and store its contents in a variable. \n > #read the dataset into an R variable using the read.csv(file) function \n > dataTwoWayInteraction <- read.csv(\"dataset_ANOVA_TwoWayInteraction.csv\") \n > #display the data \n > dataTwoWayInteraction \n   \n The first ten rows of our dataset. Omnibus Test Let's run a general omnibus test to assess the main effects and interactions present in the dataset. \n > #use anova(object) to test the omnibus hypothesis \n > #Are main effects or interaction effects present in the independent variables? \n > anova(lm(StressReduction ~ Treatment * Gender, dataTwoWayInteraction)) \n   \n The omnibus ANOVA test Divide the Data The significant omnibus interaction suggests that we should ignore the main effects and instead investigate the simple main effects for our independent variables. To do so, we need to divide our dataset along each level of our treatment variable. We can create subsets of our dataset using the subset(data, condition) function, where data is the original dataset and condition contains the parameters defining the subset. \n > #use subset(data, condition) to divide the original dataset \n > #medical subset \n > dataMedical <- subset(dataTwoWayInteraction, Treatment == \"medical\") \n > #mental subset \n > dataMental <- subset(dataTwoWayInteraction, Treatment == \"mental\") \n > #physical subset \n > dataPhysical <- subset(dataTwoWayInteraction, Treatment == \"physical\") \n Group ANOVAs With datasets representing each of our treatment groups, we can now run an ANOVA for each that investigates the impact of gender. You may notice that this is effectively running three one-way ANOVAs with gender being the independent variable. Therefore, we should control for Type I error by dividing our typical .05 alpha level by three (.017). \n > #run ANOVA on the treatment subsets to investigate the impacts of gender within each \n > #medical \n > anova(lm(StressReduction ~ Gender, dataMedical)) \n > #mental \n > anova(lm(StressReduction ~ Gender, dataMental)) \n > #physical \n > anova(lm(StressReduction ~ Gender, dataPhysical)) \n   \n The gender within treatment group ANOVA tests \nAt an alpha level of .017, the gender effect within the mental ( p = .014) and physical ( p < .001) groups was statistically significant. In the mental condition, the means are 3 for males and 4 for females. In the physical condition, the means are 4 for males and 2 for females. These results suggest that the mental treatment is more effective in reducing stress for females than males, while the physical treatment is more effective for males than females. Further, there is insufficient statistical support for a gender difference in the medical treatment. \n Pairwise Comparisons Note that since our gender variable contains only two levels, there is no need to conduct follow-up comparisons. However, should you reach this point with an independent variable of more than three levels, you could conduct pairwise comparisons in the same manner as demonstrated in the Two-Way ANOVA with Comparisons tutorial. In this case, remember to carry through your reduced Type I error rate from the preceding ANOVA tests. \n Complete Two-Way ANOVA with Interactions Example To see a complete example of how two-way ANOVA simple main effects can be explored in R, please download the two-way ANOVA interaction example (.txt) file."], "link": "http://feedproxy.google.com/~r/RTutorialSeries/~3/4mFG0DBmpz8/r-tutorial-series-two-way-anova-with.html", "bloglinks": {}, "links": {"http://4.blogspot.com/": 2, "http://2.blogspot.com/": 1, "http://rtutorialseries.blogspot.com/": 1, "http://dl.dropbox.com/": 2}, "blogtitle": "R Tutorial Series"}, {"content": ["Reviews of my Statistical Analysis with R book have started to emerge online and I am writing today to share them with potential readers and recommenders. \n \nReviews \nThe following is a list of online reviews for Statistical Analysis with R . If you have written a review of the book and would like it to be featured in this post, please contact me . \n \n A review from Slashdot.org \n A review from the Stubborn Mule blog \n A review from the Nor Talk Too Wise blog \n A review from Robin Wilson's blog \n A review from Daniel Lemire's blog \n \nIn summarizing the reviews, a few points are very clear about Statistical Analysis with R . \n \n It is for beginners: The book was written for people who have little to no experience with R, statistical software, and programming. It makes no assumptions of prior experience along these lines and starts right from the beginning. If you are new to R and want to learn how to apply it to your work, then this book is for you. If you are already an intermediate or experienced user, perhaps you might recommend it to people you know who are just becoming familiar with R. \n It is a learning tool, not a reference: The book is structured with the intent that it is experienced as a holistic learning experience. The chapters build on one another and progressively delve deeper into R. It is not a dictionary-style reference that one might pull out, flip to an entry, and get a brief answer on a single item. Again, this has implications for the audience. Beginners are more likely to enjoy this approach, whereas experienced users may be interested in more of a reference-style book. \n It has a story: Woven into the book's learning structure is a storyline based on the Three Kingdoms period of ancient Chinese history. For many, this will be a motivating and engaging way to learn. For others, the story may not inspire the same level of interest. If you would like to get a taste of the story, and the book in general, it is recommended that you read the free sample chapter . \n \n \n \n \n \n \n \n \nNew Release: R Graph Cookbook \nPackt Publishing recently released a second book on R, the R Graph Cookbook by Hrishi Mittal. This reference-style guide covers an array of R graphical applications and is geared towards users who are already familiar with the basics of R. A sample chapter is available. I will be reviewing this book in the near future and posting my thoughts here on the R Tutorial Series blog. [Update: read my review of R Graph Cookbook ]"], "link": "http://feedproxy.google.com/~r/RTutorialSeries/~3/yk82bhVkC9A/r-tutorial-series-statistical-analysis.html", "bloglinks": {}, "links": {"http://slashdot.org/": 1, "http://nortalktoowise.com/": 1, "http://blog.rtwilson.com/": 1, "http://rtutorialseries.blogspot.com/": 1, "https://www.packtpub.com/": 2, "http://lemire.me/blog": 1, "http://www.stubbornmule.net/": 1, "http://4.blogspot.com/": 1, "http://www.emailmeform.com/": 1, "http://link.packtpub.com/": 2}, "blogtitle": "R Tutorial Series"}, {"content": ["By extending our one-way ANOVA procedure, we can test the pairwise comparisons between the levels of several independent variables. This tutorial will demonstrate how to conduct pairwise comparisons in a two-way ANOVA. \n Tutorial Files Before we begin, you may want to download the sample data (.csv) used in this tutorial. Be sure to right-click and save the file to your R working directory. This dataset contains a hypothetical sample of 27 participants who are divided into three stress reduction treatment groups (mental, physical, and medical) and three age groups (young, mid, and old). The stress reduction values are represented on a scale that ranges from 0 to 10. This dataset can be conceptualized as a comparison between three stress treatment programs, one using mental methods, one using physical training, and one using medication, across three age groups. The stress reduction values represent how effective the treatment programs were at reducing participant's stress levels, with higher numbers indicating higher effectiveness. Note that the numbers in this dataset are not very realistic and are simply used to make this example possible. \n Beginning Steps To begin, we need to read our dataset into R and store its contents in a variable. \n > #read the dataset into an R variable using the read.csv(file) function \n > dataTwoWayComparisons <- read.csv(\"dataset_ANOVA_TwoWayComparisons.csv\") \n > #display the data \n > dataTwoWayComparisons \n   \n The first ten rows of our dataset. Omnibus Test Let's run a general omnibus test to assess the main effects and interactions present in the dataset. \n > #use anova(object) to test the omnibus hypothesis \n > #Are main effects or interaction effects present in the independent variables? \n > anova(lm(StressReduction ~ Treatment * Age, dataTwoWayComparisons)) \n   \n The omnibus ANOVA test Pairwise Comparisons Since the omnibus test was significant for both variables and no interaction effect was present, we can proceed to testing the main effect pairwise comparisons. To accomplish this, we will apply our pairwise.t.test() function to each of our independent variables. For more details on the pairwise.t.test() function, see the One-Way ANOVA with Pairwise Comparisons tutorial. \n > #use pairwise.t.test(x, g, p.adj) to test the pairwise comparisons between the treatment group means \n > #What significant differences are present amongst the treatment means? \n > pairwise.t.test(dataTwoWayComparisons$StressReduction, dataTwoWayComparisons$Treatment, p.adj = \"none\") \n > #use pairwise.t.test(x, g, p.adj) to test the pairwise comparisons between the age group means \n > #What significant differences are present amongst the age group means? \n > pairwise.t.test(dataTwoWayComparisons$StressReduction, dataTwoWayComparisons$Age, p.adj = \"none\") \n   \n Pairwise comparisons of treatment group means \n  \n Pairwise comparisons of age group means \nNote that the desired p-adjustment method will vary by researcher, study, etc. Here, we will assume an alpha level of .05 for all tests, effectively making no adjustment for the family-wise Type I error rate. \nThese results indicate that there are are no statistically significant pairwise differences between the treatment groups and that all of the comparisons between age groups are statistically significant. The age group means are 8 for young, 5 for mid, and 2 for old. Consequently, we are inclined to conclude that, regardless of treatment, young patients are going to be most responsive, followed by middle aged patients, followed by older ones. However, there is insufficient support to differentiate between the effectiveness of the treatment methods themselves. \n Complete Two-Way ANOVA with Pairwise Comparisons Example To see a complete example of how two-way ANOVA pairwise comparisons can be conducted in R, please download the two-way ANOVA comparisons example (.txt) file."], "link": "http://feedproxy.google.com/~r/RTutorialSeries/~3/3OFmHX3fOLE/r-tutorial-series-two-way-anova-with.html", "bloglinks": {}, "links": {"http://2.blogspot.com/": 2, "http://3.blogspot.com/": 1, "http://rtutorialseries.blogspot.com/": 1, "http://dl.dropbox.com/": 2, "http://1.blogspot.com/": 1}, "blogtitle": "R Tutorial Series"}, {"content": ["When we have more than two groups in a one-way ANOVA, we typically want to statistically assess the differences between each group. Whereas a one-way omnibus ANOVA assesses whether a significant difference exists at all amongst the groups, pairwise comparisons can be used to determine which group differences are statistically significant. \n Tutorial Files Before we begin, you may want to download the sample data (.csv) used in this tutorial. Be sure to right-click and save the file to your R working directory. This dataset contains a hypothetical sample of 30 participants who are divided into three stress reduction treatment groups (mental, physical, and medical). The values are represented on a scale that ranges from 1 to 5. This dataset can be conceptualized as a comparison between three stress treatment programs, one using mental methods, one using physical training, and one using medication. The values represent how effective the treatment programs were at reducing participant's stress levels, with higher numbers indicating higher effectiveness. \n Beginning Steps To begin, we need to read our dataset into R and store its contents in a variable. \n > #read the dataset into an R variable using the read.csv(file) function \n > dataOneWayComparisons <- read.csv(\"dataset_ANOVA_OneWayComparisons.csv\") \n > #display the data \n > dataOneWayComparisons \n   \n The first ten rows of our dataset. Omnibus Test One way to begin an ANOVA is to run a general omnibus test. The advantage to starting here is that if the omnibus test comes up insignificant, you can stop your analysis and deem all pairwise comparisons insignificant. If the omnibus test is significant, you should continue with pairwise comparisons. \n > #use anova(object) to test the omnibus hypothesis \n > #Is there a significant difference amongst the treatment means? \n > anova(lm(StressReduction ~ Treatment, dataOneWayComparisons)) \n  The omnibus ANOVA test Pairwise Comparisons Since the omnibus test was significant, we are safe to continue with our pairwise comparisons. To make pairwise comparisons between the treatment groups, we will use the pairwise.t.test() function, which has the following major arguments. \n x: the dependent variable \n g: the independent variable \n p.adj: the p-value adjustment method used to control for the family-wise Type I error rate across the comparisons; one of \"none\", \"bonferroni\", \"holm\", \"hochberg\", \"hommel\", \"BH\", or \"BY\" \n The pairwise.t.test() function can be implemented as follows. \n > #use pairwise.t.test(x, g, p.adj) to test the pairwise comparisons between the treatment group means \n > #What significant differences are present amongst the treatment means? \n > pairwise.t.test(dataOneWayComparisons$StressReduction, dataOneWayComparisons$Treatment, p.adj = \"none\") \n   \n Pairwise comparisons of treatment group means \nNote that the desired p-adjustment method will vary by researcher, study, etc. Here, we will assume an alpha level of .05 for all tests, effectively making no adjustment for the family-wise Type I error rate. \nThese results indicate that there is a statistically significant difference between the mental and medical ( p = .004) and physical and medical ( p = 0.045), but not the mental and physical ( p = 0.302) treatments. The treatment means are 3.5 for mental, 3 for physical, and 2 for medical. Subsequently, we are inclined to conclude based on this study that the mental and physical treatments lead to greater stress reduction than the medical method, but that there is insufficient statistical support to determine that either the mental or physical treatment method is superior. \n Complete One-Way ANOVA with Pairwise Comparisons Example To see a complete example of how one-way ANOVA pairwise comparisons can be conducted in R, please download the one-way ANOVA comparisons example (.txt) file. \n References R Documentation (n.d.). Adjust P-values for Multiple Comparisons. Retrieved January 16, 2011 from http://stat.ethz.ch/R-manual/R-devel/library/stats/html/p.adjust.html"], "link": "http://feedproxy.google.com/~r/RTutorialSeries/~3/BEs5KoabVm0/r-tutorial-series-one-way-anova-with.html", "bloglinks": {}, "links": {"http://4.blogspot.com/": 1, "http://2.blogspot.com/": 1, "http://rtutorialseries.blogspot.com/": 1, "http://dl.dropbox.com/": 2, "http://1.blogspot.com/": 1}, "blogtitle": "R Tutorial Series"}, {"content": ["As with the one-way case, testing the omnibus hypothesis via two-way ANOVA is simple process in R. This tutorial will explore how R can be used to perform a two-way ANOVA to test the difference between two (or more) group means. \n Tutorial Files Before we begin, you may want to download the sample data (.csv) used in this tutorial. Be sure to right-click and save the file to your R working directory. This dataset contains a hypothetical sample of 60 participants who are divided by gender (male and female) and treatment group (control and treatment). The values represent a scale that ranges from 1 to 5. For instance, this dataset could be conceptualized as a comparison between two professional training programs, where the control group participated the company's longstanding program and the treatment group participated in an experimental program. The values could represent the attitudes of employees towards the training programs on a scale from 1 (poor) to 5 (excellent). \n Beginning Steps To begin, we need to read our dataset into R and store its contents in a variable. \n > #read the two-way ANOVA dataset into an R variable using the read.csv(file) function \n > dataTwoWay <- read.csv(\"dataset_ANOVA_TwoWay.csv\") \n > #display the data \n > dataTwoWay \n   \n The first ten rows of our two-way ANOVA dataset. Two-Way ANOVA Now that our data are ready, we can conduct a two-way omnibus ANOVA test using the anova(object) function. Note that the only step necessary to add a second independent variable into our ANOVA model is to incorporate it into our lm(model, dataset) function using the * operator. Whereas our one-way model was lm(Values ~ Group) , our two-way model becomes lm(Values ~ Group * Gender) . As you can see from the results below, adding a second independent variable in this manner also gives us information about the interaction between our variables. \n > #use anova(object) to test the omnibus hypothesis in two-way ANOVA \n > #Are the differences between the group means for treatment and gender statistically significant? \n > #Is there a statistically significant interaction between treatment and gender? \n > anova(lm(Values ~ Group * Gender, dataTwoWay)) \n   \n Our two-way ANOVA table. \nThe output of our ANOVA test indicates that the difference between our treatment group means is statistically significant ( p < .001) and that the difference between genders is not ( p = .585). However, in light of the statistically significant interaction between treatment group and gender ( p = .032), we would generally elect to forgo these main effects. Subsequently, a series of follow-up procedures could be carried out to examine the simple main effects for treatment group and gender. \n Two-Way Multiple Group ANOVA Conducting a two-way omnibus ANOVA with multiple groups is identical to the demonstrated two-group test. The only difference is that the values in your dataset would be associated with more than two groups. Subsequently, the omnibus hypothesis would test for mean differences across all of the groups. The anova(object) function and its contained lm(formula, data) function would remain the same. \n Complete Two-Way Omnibus ANOVA Example To see a complete example of how a two-way omnibus ANOVA can be conducted in R, please download the two-way ANOVA example (.txt) file."], "link": "http://feedproxy.google.com/~r/RTutorialSeries/~3/1xJ77SbSQx8/r-tutorial-series-two-way-omnibus-anova.html", "bloglinks": {}, "links": {"http://3.blogspot.com/": 1, "http://rtutorialseries.blogspot.com/": 1, "http://dl.dropbox.com/": 2, "http://1.blogspot.com/": 1}, "blogtitle": "R Tutorial Series"}, {"content": ["In the final days of October, my beginner's guide to R was released. The book's official title is Statistical Analysis with R and it can be found on the Packt Publishing website. \nThe primary focus of Statistical Analysis with R is helping new users become accustomed to R and empowering them to apply R to suit their own needs. No prior experience with R, statistical software packages, or programming is necessary to learn from this book. It is written for a broad audience and should be well received by businesspeople, IT professionals, researchers, and students alike. Statistical Analysis with R takes readers on a journey from their first installation and launch of R, to analyzing and assessing data, to communicating and visualizing results. This guide is an excellent way to rapidly become an experienced R user and learn the skills that you need to apply R to your work. \n \n \n \n \n \n \n\nSamples \nA sample chapter from Statistical Analysis with R is available from the Packt website. This chapter, the book's eight, introduces the graphical capabilities of R, such as generating, customizing, and exporting various plots, charts, and graphs. You can download the sample chapter and its accompanying R files for free. If you like this chapter and are interested in learning more about R's graphical capabilities, you should know that chapter 9 demonstrates in depth how you can build and customize your own R visualizations. \nThe publisher has also posted a few brief samples from the book, which can be accessed via the following links. These samples are taken from chapters 7 and 8 of Statistical Analysis with R . Respectively, they cover the common process behind all R analyses and introduce the graphical capabilities of R. \n \n Organizing and Communicating R Analyses \n R Graphics Part 1 \n R Graphics Part 2 \n \n \n\nFeedback \nIf you decide to read Statistical Analysis with R , please feel free to provide me with your feedback. It would be great to know what you learned from the book, how future guides could be improved, and your overall experience with R."], "link": "http://feedproxy.google.com/~r/RTutorialSeries/~3/GoRNSxe4EUU/r-beginners-guide-book-update.html", "bloglinks": {}, "links": {"https://www.packtpub.com/": 2, "http://3.blogspot.com/": 1, "http://link.packtpub.com/": 1, "http://www.packtpub.com/": 3}, "blogtitle": "R Tutorial Series"}, {"content": ["Testing the omnibus hypothesis via one-way ANOVA is simple process in R. This tutorial will explore how R can be used to perform a one-way ANOVA to test the difference between two (or more) group means. \n Tutorial Files Before we begin, you may want to download the sample data (.csv) used in this tutorial. Be sure to right-click and save the file to your R working directory. This dataset contains a hypothetical sample of 60 participants, who are divided into two groups (control and treatment) of 30. The values represent a scale that ranges from 1 to 5. For instance, this dataset could be conceptualized as a comparison between two professional training programs, where the control group participated the company's longstanding program and the treatment group participated in an experimental program. The values could represent the attitudes of employees towards the training programs on a scale from 1 (poor) to 5 (excellent). \n Beginning Steps To begin, we need to read our dataset into R and store its contents in a variable. \n > #read the one-way ANOVA dataset into an R variable using the read.csv(file) function \n > dataOneWay <- read.csv(\"dataset_ANOVA_OneWay.csv\") \n > #display the data \n > dataOneWay \n   \n The first ten rows of our one-way ANOVA dataset. One-Way ANOVA Now that our data are ready, we can conduct a one-way omnibus ANOVA test using the anova(object) function. \n > #use anova(object) to test the omnibus hypothesis in one-way ANOVA \n > #is the difference between the group means statistically significant? \n > anova(lm(Values ~ Group, dataOneWay)) \n   \n Our one-way ANOVA table. \nThe output of our ANOVA test indicates that the difference between our group means is statistically significant ( p < .001). Conceptually, this suggests that employee attitudes towards the experimental training program were significantly higher than their attitudes towards the preexisting program. \n Note that the object argument in our anova(object) function contained a linear model generated by the lm(formula, data) function. This is the same type of model that is used when conducting linear regression in R. A more detailed explanation of the lm(formula, data) function and examples of its use are available in my Simple Linear Regression article. One-Way Multiple Group ANOVA Conducting a one-way omnibus ANOVA with multiple groups is identical to the demonstrated two-group test. The only difference is that the values in your dataset would be associated with more than two groups. Subsequently, the omnibus hypothesis would test for mean differences across all of the groups. The anova(object) function and its contained lm(formula, data) function would remain the same. \n Complete One-Way Omnibus ANOVA Example To see a complete example of how a one-way omnibus ANOVA can be conducted in R, please download the one-way ANOVA example (.txt) file."], "link": "http://feedproxy.google.com/~r/RTutorialSeries/~3/US3kr0tJJp4/r-tutorial-series-one-way-omnibus-anova.html", "bloglinks": {}, "links": {"http://4.blogspot.com/": 1, "http://1.blogspot.com/": 1, "http://dl.dropbox.com/": 2, "http://rtutorialseries.blogspot.com/": 1}, "blogtitle": "R Tutorial Series"}, {"content": ["Update: Statistical Analysis with R is now available! I recently submitted the final drafts of all chapters of my R Beginner's Guide book, which is to be published through Packt. The official publishing timeline is set to December 2010, although the book may release ahead of schedule if all continues to go well. Below is an updated list of the major topics covered in the R Beginner's Guide. Over the course of this book, you will acquire the knowledge and skills necessary to: Conduct organized data analyses in R Communicate data analyses conducted in R Generate, customize, and export detailed charts, plots, and graphs Build your own custom data visualizations Program in the R language Create your own custom functions Extend the functionality of R via external packages Manage the R workspace and console Import external data into R Manipulate data using variables Execute a wide array of multi-argument and variable-argument functions Develop and employ predictive regression models Assess the practical and statistical significance of predictions Understand R, its benefits, and how to use it to maximize the impact of your data analyses"], "link": "http://feedproxy.google.com/~r/RTutorialSeries/~3/TgXtmZB7MxA/r-beginners-guide-book-update-1012010.html", "bloglinks": {}, "links": {"http://rtutorialseries.blogspot.com/": 1}, "blogtitle": "R Tutorial Series"}, {"content": ["There are times that labeling a plot's data points can be very useful, such as when conveying information in certain visuals or looking for patterns in our data. Fortunately, labeling the individual data points on a plot is a relatively simple process in R. In this tutorial, we will use the Calibrate package's textxy function to label the points on a scatterplot. \n Tutorial Files Before we begin, you may want to download the sample data (.csv) used in this tutorial. Be sure to right-click and save the file to your R working directory. This dataset contains information used to estimate undergraduate enrollment at the University of New Mexico (Office of Institutional Research, 1990). Note that this tutorial assumes that this data has already been read into R and saved into a variable named enrollmentData . \n Plot To begin, we need to create a scatterplot using the plot(x,y) function. With our example data, we will plot the year on the x axis and the unemployment rate on the y axis. \n > #generate a plot using the plot(x,y) function \n > #plot year on the x axis and unemployment rate on the y axis \n > plot(enrollmentData$YEAR, enrollmentData$UNEM) \n   \n For a more detailed description of plotting data in R, see the article on scatterplots . \n Textxy Within the calibrate package, the textxy() function can be used to label a plot's data points. The textxy() function accepts the following arugments (\"Label points in a plot,\" n.d.). \n Required\n x: the x values of the plot's points \n y: the y values of the plot's points \n labs: the labels to be associated with the plot's points \n Optional\n cx: used to resize the label font \n dcol: used to set the label color; defaults to black \n m: sets the origin of the plot; defaults to (0,0) \n Here, we will use textxy() to add labels for the enrollment at the University of New Mexico to each of our plot's data points. \n > #if necessary, install the calibrate package \n > #install.packages(\"calibrate\") \n > #load the calibrate package \n > library(calibrate) \n > #use the textxy() function to add labels to the preexisting plot's points \n > #add labels for the total enrollment \n > textxy(enrollmentData$YEAR, enrollmentData$UNEM, enrollmentData$ROLL) \n   \n In this case, adding labels to our data points helps us to better assess the relationships in our dataset. \n Complete Data Point Labeling Example To see a complete example of how a plot's data points can be labeled in R, please download the Data Point Labeling (.txt) file. \n References Label points in a plot. (n.d.). Retrieved September 19, 2010 from http://rss.acs.unt.edu/Rdoc/library/calibrate/html/textxy.html \nOffice of Institutional Research (1990). Enrollment Forecast [Data File]. Retrieved November 22, 2009 from http://lib.stat.cmu.edu/DASL/Datafiles/enrolldat.html"], "link": "http://feedproxy.google.com/~r/RTutorialSeries/~3/QjNHdDrfhwM/r-tutorial-series-labeling-data-points.html", "bloglinks": {}, "links": {"http://4.blogspot.com/": 1, "http://2.blogspot.com/": 1, "http://rtutorialseries.blogspot.com/": 1, "http://dl.dropbox.com/": 2}, "blogtitle": "R Tutorial Series"}, {"content": ["Update: Statistical Analysis with R is now available! I am excited to announce that I have submitted the entire first draft of my R Beginner's Guide book, which is to be published through Packt. The tenth and final chapter was submitted a full month ahead of schedule. The printed book could become available in as little as three to four months. Below is a list of the major topics covered in the R Beginner's Guide. Understanding what R is, its benefits, and why to use it Downloading, installing, and running R Dissecting the anatomy of R Programming in R Handling external data Using variables Managing the R workspace and console Using multi-argument and variable-argument functions Creating predictive data models Assessing practical vs. statistical significance Regression modeling Creating custom functions Assessing the viability of predictions Organizing and communicating data analyses Generating, customizing, and exporting graphics Building custom visualizations Extending R via packages Taking advantage of electronic learning resources"], "link": "http://feedproxy.google.com/~r/RTutorialSeries/~3/g5OUOIRXqT0/r-beginners-guide-book-update-7192010.html", "bloglinks": {}, "links": {"http://rtutorialseries.blogspot.com/": 1}, "blogtitle": "R Tutorial Series"}, {"content": ["Update: Statistical Analysis with R is now available! I am writing to update you on the progress of my R Beginner's Guide book, which is to be published through Packt. I have really gotten to work over the past couple months and have recently completed the first draft of the first half of the book. Right now, I am operating a few weeks ahead of our planned schedule, which calls for the first draft of all ten chapters by mid-August. To give you an idea of its content, the book focuses on most of the topics covered in this blog as well as many more, such as data visualization, custom functions, and online resources. The topics are covered in great depth and numerous opportunities for practice and exploration are offered. The book's theme centers around the Three Kingdoms period of ancient China. The reader takes on the role of the lead strategist for the Shu kingdom at a pivotal point in history. Throughout the book, the reader uses R to help devise a course of action for the Shu forces. I will continue to make steady progress on this book over the summer months. I am also excited to be able to share more R tutorials and knowledge in the near future through this project."], "link": "http://feedproxy.google.com/~r/RTutorialSeries/~3/Xj3-w3tJENU/r-beginners-guide-book-update-4282010.html", "bloglinks": {}, "links": {"http://rtutorialseries.blogspot.com/": 1}, "blogtitle": "R Tutorial Series"}, {"content": ["1/1/2011 Update: Tal Galili wrote an article that revisits the first year of R-Bloggers and this post was listed as one of the top 14. Therefore, I decided to make a small update to each section. I start by describing the initial series of tutorials that I wrote. A few more have been added since and even more planned in the upcoming year. As always, an up to date listing of my articles can be found on the R Tutorial Series blog . New posts will also continue to be offered through the R Bloggers network. Since October 2009, I have written 13 articles [many more now, of course] for the R Tutorial Series blog. The first two introduce new users to R. The remaining 11 cover a wide range of topics related to multiple regression and correlation. This collection of tutorials represents my most recent training in statistics. Thus, for the time being, I will not be contributing new articles as frequently as I have over the past few months. However, I will undoubtedly encounter future projects that require new statistical methods and partake in more statistics courses, both of which will provide additional tutorial material. Below is a categorized list of the articles currently offered in the R Tutorial Series. Introduction to R Part 1 \n Part 2 \n Descriptive Statistics Summary and Descriptive Statistics \n Data Visualization Scatterplots \n Correlation Zero-Order Correlations \n Regression Simple Linear Regression \n Multiple Linear Regression \n Regression Assumptions \n Regression with Interaction Variables \n Regression with Categorical Variables \n Polynomial Regression \n Hierarchical Linear Regression \n I also have two additional R-related items to update you on. The first is the R Bloggers website and the second is my R Beginner's Guide. 1/1/2011 Update: I originally reported that 50 blogs composed the R Bloggers network. Now that number has risen to over 140. I hope that R Bloggers continues to thrive and contribute to the R community. R Tutorial Series on R Bloggers R Bloggers (http://www.r-bloggers.com) is a website that aggregates over 50 different blogs that focus on R. It is an excellent resource for keeping up to date on the many uses of R and for learning about the wide range of work being conducted in R. I recommend using R Bloggers for these purposes. The R Tutorial Series was invited to participate in the R Bloggers collection and is now available to R Bloggers' readers. R Beginner's Guide 11/1/2010 Update: Statistical Analysis with R is now available! Lastly, I want to let you know that I am working on a beginner's guide for R. It is primarily focused towards introducing R to information technology, business, and data analyst professionals. The book will be offered through PACKT Publishing (http://www.packtpub.com) and should be available within the next year. If you have enjoyed the R Tutorial Series, then you may be interested in looking for the guide once it is completed. In the meantime, keep reading the R Tutorial Series and R Bloggers and I will keep you updated on the book's major milestones."], "link": "http://feedproxy.google.com/~r/RTutorialSeries/~3/59iGaXEXk9c/r-tutorial-series-r-beginners-guide-and.html", "bloglinks": {}, "links": {"http://www.r-statistics.com/": 1, "http://link.packtpub.com/": 1, "http://rtutorialseries.blogspot.com/": 14, "http://www.r-bloggers.com/": 3}, "blogtitle": "R Tutorial Series"}, {"content": ["Often times, a scatterplot reveals a pattern that seems not so linear. Polynomial regression can be used to explore a predictor at different levels of curvilinearity. This tutorial will demonstrate how polynomial regression can be used in a hierarchical fashion to best represent a dataset in R. \n Tutorial Files Before we begin, you may want to download the sample data (.csv) used in this tutorial. Be sure to right-click and save the file to your R working directory. Note that all code samples in this tutorial assume that this data has already been read into an R variable and has been attached. This dataset contains hypothetical student data that uses practice exam scores to predict final exam scores. \n Scatterplot  \n The preceding scatterplot demonstrates that these data may not be linear. Notably, no one scored lower than 50 on the practice exam and at approximately the 85 and above practice mark, final exam scores taper off. These suggest that the data is curvilinear. Furthermore, since exam scores range between 0 to 100, it is not possible to observe nor appropriate to predict that an individual with a 150 practice score would have a certain final exam score. \n Creating The Higher Order Variables A two step process, identical to the one used to create interaction variables , can be followed to create higher order variables in R. First, the variables must be centered to mitigate multicollinearity. Second, the predictor must be multiplied by itself a certain number of times to create each higher order variable. In this tutorial, we will explore the a linear, quadratic, and cubic model. Therefore, the predictor will need to be squared to create the quadratic model and cubed to create the cubic model. \n Step 1: Centering To center a variable, simply subtract its mean from each data point and save the result into a new R variable, as demonstrated below. \n > #center the independent variable \n > FinalC <- Final - mean(Final) \n > #center the predictor \n > PracticeC <- Practice - mean(Practice) \n Step 2: Multiplication Once the input variable has been centered, the higher order terms can be created. Since a higher order variable is formed by the product of a predictor with itself, we can simply multiply our centered term from step one and save the result into a new R variable, as demonstrated below. \n > #create the quadratic variable \n > PracticeC2 <- PracticeC * PracticeC \n > #create the cubic variable \n > PracticeC3 <- PracticeC * PracticeC * PracticeC \n Creating The Models Now we have all of the pieces necessary to assemble our linear and curvilinear models. \n > #create the models using lm(FORMULA, DATAVAR) \n > #linear model \n > linearModel <- lm(FinalC ~ PracticeC, datavar) \n > #quadratic model \n > quadraticModel <- lm(FinalC ~ PracticeC + PracticeC2, datavar) \n > #cubic model \n > cubicModel <- lm(FinalC ~ PracticeC + PracticeC2 + PracticeC3, datavar) \n Evaluating The Models As is the case in other forms of regression, it can be helpful to summarize and compare our potential models using the summary(MODEL) and anova(MODEL1, MODEL2,\u2026 MODELi) functions. \n > #display summary information about the models \n > summary(linearModel) \n > summary(quadraticModel) \n > summary(cubicModel) \n #compare the models using ANOVA \n anova(linearModel, quadraticModel, cubicModel) \n The model summaries and ANOVA comparison chart are displayed below. \n  \n At this point we can compare the models. In this case, the quadratic and cubic terms are not statistically significant themselves nor are their models statistically significant beyond the linear model. However, in a real research study, there would be other practical considerations to make before deciding on a final model. \n More On Interactions, Polynomials, and HLR Certainly, much more can be done with these topics than I have covered in my tutorials. What I have provided is a basic discussion with guided examples. The regression topics covered in these tutorials can be mixed and matched to create exceedingly complex models. For example, multiple interactions and higher order variables could be contained in a single model. The good news is that more complex models can be created using the same techniques covered here. The basic principles remain the same. \n Complete Polynomial Regression Example To see a complete example of how polynomial regression models can be created in R, please download the polynomial regression example (.txt) file."], "link": "http://feedproxy.google.com/~r/RTutorialSeries/~3/zhQ3mwvkjuM/r-tutorial-series-basic-polynomial.html", "bloglinks": {}, "links": {"http://3.blogspot.com/": 1, "http://1.blogspot.com/": 1, "http://dl.dropbox.com/": 2, "http://rtutorialseries.blogspot.com/": 2}, "blogtitle": "R Tutorial Series"}, {"content": ["Categorical predictors can be incorporated into regression analysis, provided that they are properly prepared and interpreted. This tutorial will explore how categorical variables can be handled in R. \n Tutorial Files Before we begin, you may want to download the sample data (.csv) used in this tutorial. Be sure to right-click and save the file to your R working directory. Note that all code samples in this tutorial assume that this data has already been read into an R variable and has been attached. This dataset contains variables for the following information related to NFL quarterback and team salaries in 1991. \n TEAM: Name of team \n QB: Starting quarterback salary in thousands of dollars \n TOTAL: team salary in thousands of dollars \n CONF: conference (NFC or AFC) \n In this dataset, the CONF variable is categorical. It can take on one of two values, either NFC or AFC. Suppose for the purposes of this tutorial that our research question is \"how well do quarterback salary and conference predict total team salary?\" The model that we use to answer this question will need to incorporate the categorical predictor for conference. \n Dummy Coding To be able to perform regression with a categorical variable, it must first be coded. Here, I will use the as.numeric(VAR) function, where VAR is the categorical variable, to dummy code the CONF predictor. As a result, CONF will represent NFC as 1 and AFC as 0. The sample code below demonstrates this process. \n > #represent a categorical variable numerically using as.numeric(VAR) \n > #dummy code the CONF variable into NFC = 1 and AFC = 0 \n > dCONF <- as.numeric(CONF) - 1 \n Note that the -1 that comes after the as.numeric(CONF) function causes the variables to read 1 and 0 rather than 2 and 1, which is the default behavior. \n Interpretation Visual One useful way to visualize the relationship between a categorical and continuous variable is through a box plot. When dealing with categorical variables, R automatically creates such a graph via the plot() function (see Scatterplots ). The CONF variable is graphically compared to TOTAL in the following sample code. \n > #use the plot() function to create a box plot \n > #what does the relationship between conference and team salary look like? \n > plot(CONF, TOTAL, main=\"Team Salary by Conference\", xlab=\"Conference\", ylab=\"Salary ($1,000s)\") \n The resulting box plot is show below. \n  \n From a box plot, we can derive many useful insights, such as the minimum, maximum, and median values. Our box plot of total team salary on conference suggests that, compared to AFC teams, NFC teams have slightly higher salaries on average and the range of these salaries is larger. \n  \n Routine Analysis Once a categorical variable has been quantified, it can be used in routine analyses, such as descriptive statistics and correlations. The following code depicts a few examples. \n > #what are the mean and standard deviation of conference? \n > mean(dCONF) \n > [1] 0.5 \n > sd(dCONF) \n > [1] 0.5091751 \n > #this makes sense\u2026 there are an even number of teams in both conferences and they are coded as either 0 or 1! \n > #what is the correlation between total team salary and conference? \n > cor(dCONF, TOTAL) \n > [1]0.007019319 \n The correlation between total team salary and conference indicates that there is little to no linear relationship between the variables. \n Linear Regression Let's return to our original question of how well quarterback salary and conference predict team salary. With the categorical predictor quantified, we can create a regression model for this relationship, as demonstrated below. \n > #create a linear model using lm(FORMULA, DATAVAR) \n > #predict team salary using quarterback salary and conference \n linearModel <- lm(TOTAL ~ QB + dCONF, datavar) \n #generate model summary \n summary(linearModel) \n The model summary is pictured below. \n  \n Considering both the counterintuitive and statistically insignificant results of this model, our analysis of the conference variable would likely end or change directions at this point. However, there is one more interpretation method that is worth mentioning for future reference. \n Split Model With a dummy coded predictor, a regression model can be split into two halves by substituting in the possible values for the categorical variable. For example, we can think of our model as a regression of total salary on quarterback salary for two states of the world - teams in the AFC and teams in the NFC. These derivative models are covered in the following sample code. \n > #input the categorical values to split the linear model into two representations \n > #the original model: TOTAL = 19099 + 2.5 * QB - 103 * dCONF \n > #substitute 0 for dCONF to derive the AFC model: TOTAL = 19099 + 2.5 * QB \n > #substitute 1 for dCONF to derive the NFC model: TOTAL = 18996 + 2.5 * QB \n #what is the predicted salary for a team with a quarterback salary of $2,000,000 in the AFC and NFC conferences? \n #AFC prediction \n 19099 + 2.5 * 2000 \n [1] 24099 \n #NFC prediction \n 18996 + 2.5 * 2000 \n [1] 23996 \n Based only on what we have modeled, we can further infer that conference was not a significant predictor of total team salaries in the NFL in 1991. The difference between the team salaries based on conference is less than one-half of one percent on average! Of course, only using quarterback salary and conference to predict an NFL team's overall salary is neglecting quite a few potentially significant predictors. Nonetheless, split model interpretation is a useful way to break down the perspectives captured by a categorical regression model. \n More On Categorical Predictors Certainly, much more can be done with categorical variables than the basic dummy coding that was demonstrated here. Individuals whose work requires a deeper inspection into the procedures of categorical regression are encouraged to seek additional resources (and to consider writing a guest tutorial for this series). \n Complete Categorical Regression Example To see a complete example of how a categorical regression model can be created in R, please download the categorical regression example (.txt) file. \n References The Associated Press. (1991). Q-back and team salaries [Data File]. Retrieved December 14, 2009 from http://lib.stat.cmu.edu/DASL/Datafiles/qbacksalarydat.html"], "link": "http://feedproxy.google.com/~r/RTutorialSeries/~3/ACaZRs_OEYI/r-tutorial-series-regression-with.html", "bloglinks": {}, "links": {"http://2.blogspot.com/": 1, "http://3.blogspot.com/": 2, "http://rtutorialseries.blogspot.com/": 1, "http://dl.dropbox.com/": 2}, "blogtitle": "R Tutorial Series"}]
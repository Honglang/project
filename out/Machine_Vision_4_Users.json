[{"blogurl": "http://machinevision4users.blogspot.com\n", "blogroll": [], "title": "Machine Vision 4 Users"}, {"content": ["How do you determine if a lens costing $800 is better than one costing a quarter the price? Well asides from thinking, as I do with wine, it must be better if they can command a premium for it, the answer is to do a side-by-side comparison. \u201c But Brian,\u201d I hear you moaning, \u201cI only want to buy one lens, not two, one of which I will not need.\u201d  Well fortunately, Edmund Optics has already done some benchmarking for you. \u201c Better Optics = Better System Performance \u201d describes how they compared their lens with one from a competitor. Surprisingly enough, the Edmunds lens came out on top, but that\u2019s not important right now.  What is important is how they conducted the comparison. It was a simple test that you could do yourself. Yes, you will need two lenses, but if you ask nicely your supplier will let you have them \u201con evaluation.\u201d They may ask that you share the results with them. That\u2019s something I have no problem with: mutual back-scratching is mutually beneficial.  So read the Edmunds article and learn why their lenses are so good how to evaluate lenses for yourself."], "link": "http://machinevision4users.blogspot.com/feeds/2238974095516784799/comments/default", "bloglinks": {}, "links": {"http://www.edmundoptics.com/": 1}, "blogtitle": "Machine Vision 4 Users"}, {"content": ["The Intel Atom processor is a neat little device. It\u2019s miserly in its use of electricity, so in laptops and netbooks it gives great battery life. It also generates relatively little heat, which makes it good for fanless applications. I\u2019ve seen some camera companies use it in their smart cameras too, but I have to question the wisdom of doing so.  I\u2019ve nothing against the little processor that could \u2013 in fact I have one in the netbook I\u2019m typing this on \u2013 but they\u2019re not really up to high-speed image processing.  So you\u2019ll understand my surprise in learning that Dalsa \u2013 sorry, Teledyne Dalsa \u2013 have launched a vision PC built around the little fellow. The box I\u2019m referring to is the  GEVA-300 . Now I try to avoid being negative, but really Dalsa, an Atom-based machine? And it\u2019s intended for multiple cameras. Why not just step up to an i5? Was the whole point just to have a fanless offering?  And to that point, if you spend just a couple of minutes on the Dalsa site you\u2019ll see they offer such a device, the GEVA-1000. It\u2019s not clear what processor it actually employs, but I\u2019m figuring that the bigger model number means more horsepower under the hood. I don\u2019t know what the price difference is either, but I\u2019ll wager anyone who buys the 300 will later wish they\u2019d stepped up to the 1000."], "link": "http://machinevision4users.blogspot.com/feeds/3724903602167764793/comments/default", "bloglinks": {}, "links": {"http://www.teledynedalsa.com/": 1}, "blogtitle": "Machine Vision 4 Users"}, {"content": ["If you haven't already heard, Cognex reported solid numbers for the third quarter of 2012. Revenue (sales) was flat compared to the same period in 2011, while income (profit) was down just 1%. Comparing the first nine months, 2012 is looking a little better than '11, although we must remember that every year seems to be a good year for Cognex.  R&D expenditure, (the number I use as an indicator of new products in the pipeline,) has been pretty flat all year, suggesting the pace is being maintained but not accelerated. I guess when you're number one, all you have to do is stay ahead of the competition.  One point that I keep returning to is the amount of cash Cognex keeps in the bank. Right now they're sitting on $416m, up from $357m at the end of last year. That's right, nearly half a billion dollars in the bank!  If I worked at Cognex, (and I am available!) I'd be looking for a way to make that pot of gold work a little harder. We've seen some consolidation in the machine vision business of late. I can't help thinking that if the people in Natick don't put that money to use, (R&D or acquisitions,) someone is going to do it for them.  Time will tell."], "link": "http://machinevision4users.blogspot.com/feeds/2531679302846182963/comments/default", "bloglinks": {}, "links": {"http://cgnx.shareholder.com/": 1}, "blogtitle": "Machine Vision 4 Users"}, {"content": ["Machine vision pros know it\u2019s not always necessary to use a color camera for a color application. Often all that\u2019s needed is to either match the wavelength of the illumination source to the target. Like colors lighten, so a red light will make a red target appear white(ish) to the camera. An alternative is to put a filter over the lens, so that only light of the target wavelength is allowed through.  But what if you need to look at several targets in several different wavelengths?  What you need then is a liquid crystal tunable filter. A product like  VariSpec might do what you want, and something similar is available from  Inno-Spec . And if you want to understand just how they might be used, I suggest you read \u201c Tell-Tale Color Changes: Camera Can Find Age of a Bruise \u201d on the BioPhotonics website, October 2012.  This fascinating article describes some important color imaging work going on in the medical field. I\u2019m not going to steal their page views by telling you about it: click the link and read for yourself.  And last, if you want to understand more about how a liquid crystal tunable lens actually works, take a look at \u201c Liquid Crystal Tunable Filters \u201d on the Olympus Microscopy Resource Center site."], "link": "http://machinevision4users.blogspot.com/feeds/2920067628007447778/comments/default", "bloglinks": {}, "links": {"http://www.spectralcameras.com/": 1, "http://www.photonics.com/": 1, "http://www.olympusmicro.com/": 1, "http://www.eoc-inc.com/": 1}, "blogtitle": "Machine Vision 4 Users"}, {"content": ["At the risk of offending some manufacturers, not all machine vision lights are terribly robust. I find they often lack sturdy mounting points or heat sinks, and seem rather fragile. That\u2019s when, when I saw the  Prox Spot Lights from Smart Vision Lights I said, \u201cGosh, isn\u2019t that a good idea.\u201d  My favorites are the SA30 Series which come in a 30mm housing and have an adjustable spot size, thanks to a sliding outer barrel. There\u2019s no need for a dedicated external power supply \u2013 just feed them 24V \u2013 and it\u2019s even possible to vary the light output.  I\u2019d suggest setting them up at 80%, so if their output drops off over a year or two there\u2019s some space to crank \u2018em up a bit. Assuming you know what intensity you actually need. ;-)"], "link": "http://machinevision4users.blogspot.com/feeds/778361586118562002/comments/default", "bloglinks": {}, "links": {"http://www.smartvisionlights.com/": 1}, "blogtitle": "Machine Vision 4 Users"}, {"content": ["Anything has to be better than turning the focus ring first one way, then the other while trying to watch an image on a monitor. It\u2019s even worse when, as in a system I worked on recently, the monitor is not viewable when working at the camera. And don\u2019t get me started on the tribulations of linescan camera focusing!  All of which is why, since 2009 I\u2019ve been getting excited about the potential of liquid lenses. (\u201c The end of focus problems \u201d June 14 th , 2009.) Cognex and  Microscan have offered liquid lenses on select products for a few years, but there\u2019s been nothing I could buy to add to a camera, until now.  Just in time for Vision 2012 optics specialists Qioptiq have announced their flo.x lens \u201cwith liquid lens focusing.\u201d This sounds exactly what I\u2019ve been waiting for, albeit with a couple of drawbacks. First, it\u2019s made for an M12 mount, rather than C-mount. And second, the focal length is a rather wide angle 3.35mm.  No, it\u2019s not exactly what I\u2019ve been waiting for, but the very fact that it exists gives me hope. Who knows, perhaps I\u2019ll be sent a plane ticket to Stuttgart so I can attend Vision 2013 for the unveiling of the C-mount liquid lens!  By-the-way, if you\u2019re looking on the Qiotiq website for details of the flo.x, - well I couldn\u2019t find anything, although they do have some great  machine vision lenses ."], "link": "http://machinevision4users.blogspot.com/feeds/6138560399339141563/comments/default", "bloglinks": {}, "links": {"http://machinevision4users.blogspot.com/": 2, "http://www.qioptiq.com/": 1}, "blogtitle": "Machine Vision 4 Users"}, {"content": ["US-based stock market investors will understand that by \u201cfoolish\u201d I\u2019m referring to that excellent source of financial advice, The Motley Fool. And the Fool recently took a look at our friends from Natick. Or more accurately, they took a look at how Cognex manages its cash flow. \u201c Cognex: Making Bucks More Quickly \u201d (fool.com, October 12 th , 2012,) discusses what is, to me at any rate, a different way to assess cash flow management. To understand how the \u201cCash Conversion Cycle\u201d is calculated and what it means you\u2019ll need to read the Fool article. I will however tell you the bottom line: they believe Cognex is doing a pretty good job of managing its cashflows.  Third quarter results come out in just a few days, so we\u2019ll be able to see for ourselves if that trend is continued."], "link": "http://machinevision4users.blogspot.com/feeds/1588699825182515681/comments/default", "bloglinks": {}, "links": {"http://www.fool.com/": 1}, "blogtitle": "Machine Vision 4 Users"}, {"content": ["Ah yes, lighting. The bane of our machine vision lives. One of the challenges we face is that what works for item A on our conveyor may not work so well for item B, even though they come off the same machines and travel down the same conveyor. So when designing a system we spend hours \u2026 make that days \u2026 trying to find an optimal solution.  How about just using different lights? When space allows, this can be an effective solution, but sometimes it\u2019s not possible. In desperation I have even resorted to placing a mask over regions of my lights, thus Mask A for item A and so on.  But wouldn\u2019t it be easier to have control over each LED?  The  RL28Q and  RL16Q from Oregon-based Orled (ORegon\u2013LED?) go some way towards this illumination nirvana. These ring lights provide independent control over four quadrants, so you can chose to cast a shadow in a particular direction, for example. (Something that might help with detecting topographical defects, for example.  Now my impression is that these lights are really intended for use with microscopes, where a person viewing would switch quadrant as necessary. But I\u2019m pretty sure that, with a little ingenuity, segment-switching could be automated for a machine vision application.  And that might make lighting just a tiddly bit easier."], "link": "http://machinevision4users.blogspot.com/feeds/1321480975531879480/comments/default", "bloglinks": {}, "links": {"http://www.orled.com/": 2}, "blogtitle": "Machine Vision 4 Users"}, {"content": ["Back on October 7 th I started to talk about the challenge of inspecting objects that vary in appearance. This was in reference to meat (\u201c The intelligent bacon slicer \u201d) but even stamped, cast, molded and machined parts have a habit of changing.  Now the normal, random, short-term variation you should take in to account when the system is first designed. But how about the unexpected shift that takes place when Purchasing switch you to a different coating supplier? Chances are, no one thinks to tell you there\u2019s a change coming; you\u2019re only the machine vision engineer after all. So the first you know is when you get a phone call to tell you all the parts are failing inspection.  First off, your troubleshooting skills are put to the test. This is where some initial setup images are so useful. Pull them out and compare them with the latest images. If you can run your software offline \u2013 in emulator mode perhaps \u2013 so much the better. That way you should see what\u2019s gone wrong. But what do you do?  Personally, I like to rant at those who made the change \u2013 \u201cthrowing my toys out the pram,\u201d my co-worker calls it \u2013 but then it\u2019s time to make some changes.  Don\u2019t tweak the lens. Once you start altering hardware you\u2019ll never get it back to the original settings. And be careful about changing thresholds because what will you do when Purchasing switch back to the old supplier?  I suggest you create a new configuration \u2013 call it \u201cProduct 999-dark\u201d and have the original be \u201cProduct 999-light\u201d. Then, if you\u2019re really clever, you\u2019ll find some way for the system to determine which of these is in front of the camera and auto-select the right file.  This approach won\u2019t get you out of every hole, but if it did what would I right about next? But I hope it stops from digging yourself in deeper.  As always, your comments are welcomed."], "link": "http://machinevision4users.blogspot.com/feeds/8325851069046327292/comments/default", "bloglinks": {}, "links": {"http://machinevision4users.blogspot.com/": 1}, "blogtitle": "Machine Vision 4 Users"}, {"content": ["Headlines last month reported a slowdown in the North American machine vision business. (\u201c Local, Global Machine Vision Markets Slow \u201d ControlDesign, September 10 th 2012.) This sounds grim, so let\u2019s take a look at the report.  First, it\u2019s just the rate of growth that\u2019s slowing. Back in the heady, rebound days of 2011 growth was up at 10%; through to 2016 IMS Research are projecting 7 \u2013 8%. That\u2019s pretty darned good growth. Name me another industry that can look forward to that.  Second, and this is where it gets really interesting, the same article says the AIA reported machine vision sales dropped 2% in the first quarter of 2012, yet in the same breath said software sales were up 26%, lighting up 11%, frame grabbers up 7% and smart cameras up by 4%. That sounds like pretty robust business for the components folks, so who\u2019s down?  It has to be the builders of inspection machines, doesn\u2019t it? Fewer turnkey systems and more people doing it themselves. At least, that\u2019s my interpretation. Do you have a different one?  And one last complaint, while I\u2019m in a moaning mood: There\u2019s been a tendency in recent years, started I believe by the Wall Street Journal, to follow every announcement of positive news with a \u201cBut\u201d and this Control Design article is no different: \u201c\u2026 vision revenues grew more than 10% \u2026 But\u2026\u201d  Am I the only one tired of the negative spinmeisters? The machine vision industry is looking pretty healthy. Let\u2019s celebrate that."], "link": "http://machinevision4users.blogspot.com/feeds/7975437825793781161/comments/default", "bloglinks": {}, "links": {"http://www.controldesign.com/": 1}, "blogtitle": "Machine Vision 4 Users"}, {"content": ["Employment prospects in machine vision are pretty good: the industry is growing and our skills are in demand. But even if you use  LinkedIn ,  Indeed and  Dice , which I think are some of the best places to search, the odds of landing an interview seem slim. \u201c Why can't good engineers get good jobs? \u201d on the EE Times website October 10 th , 2012, discusses this problem. It\u2019s a good article, so I\u2019m not going to regurgitate it here, just click the link. I would say though, read the comments and then adapt your job search accordingly."], "link": "http://machinevision4users.blogspot.com/feeds/419024711930195967/comments/default", "bloglinks": {}, "links": {"http://www.indeed.com/": 1, "http://www.linkedin.com/": 1, "http://www.dice.com/": 1, "http://eetimes.com/": 1}, "blogtitle": "Machine Vision 4 Users"}, {"content": ["Attentive readers may have noticed an addition to my Friends list over on the right. \u201cDoctor of Vision\u201d is my link, (they appear in alphabetical order, so Vision Doctor would have had lower placement,) to a new site targeted at those looking for  machine vision information .  That might sound like what I'm doing, but as you can tell from the screen shot below, the site Lars Fermum has put together is in a completely different league to my humble blog.   Whether you're new to machine vision, or just looking to improve your knowledge, the Vision Doctor site is an absolute treasure trove of info. Lars has articles on all the main topics \u2013 lighting, optics, cameras \u2013 plus, in the  Service area, a number of useful calculators.  Check it out."], "link": "http://machinevision4users.blogspot.com/feeds/5530621873784358190/comments/default", "bloglinks": {}, "links": {"http://www.co.uk/": 2, "http://1.blogspot.com/": 1}, "blogtitle": "Machine Vision 4 Users"}, {"content": ["Time is short, so I shall very quickly point you at an interesting  3D application . This is on the website of Netherlands vision company, Ellips. Ellips specialize in fruit and vegetable sorting, and you may have clicked through to them from the article I linked to in my last post, \u201cWhere the volume is.\u201d Clearly though, they also dabble in 3D, and as the pictures show, it looks very interesting."], "link": "http://machinevision4users.blogspot.com/feeds/4676098446540602598/comments/default", "bloglinks": {}, "links": {"http://www.ellips.nl/": 1}, "blogtitle": "Machine Vision 4 Users"}, {"content": ["Everyone in machine vision wants volume. It\u2019s where the money is, but so few applications are more than one or two-offs. Food inspection, as detailed in \u201c Machine Vision Helps Food Processors Cut OverheadCosts ,\u201d on the Vision Online website (October 9 th , 2012,) is a notable exception.  Everyone eats food, which is probably why there are so many inspection opportunities. Few though match the application writer Winn Hardin described thus, \u201cThe machine builder typically sells 50 sorting machines per year, requiring 400 machine vision camera solutions.\u201d  Mr. Hardin doesn\u2019t name the particular builder, although you could do the same as me and Google the type of application."], "link": "http://machinevision4users.blogspot.com/feeds/8529814847921474143/comments/default", "bloglinks": {}, "links": {"http://visiononline.org/": 1}, "blogtitle": "Machine Vision 4 Users"}, {"content": ["The love-fest that is Vision 2012 is less than a month away and already vendors are giving us sneak-peeks at their latest and greatest. Some of the most intriguing come from camera-maker AVT who, besides some ho-hum range extensions, have an entirely new product, the Mako.  As I write this, the Mako page on the AVT website doesn\u2019t have any content, so instead I will direct you their  press release . Now this camera looks much like the reliable old Guppy, but whereas that was a FireWire camera, this will be offered with both GigE and USB3 interfaces.  I see that as highly significant. In fact I\u2019d go so far as to say it means FireWire is on its death-bed, at least in the machine vision world. Some years back AVT saw how the wind was blowing when they snapped up Prosilica, thereby gaining a GigE product line up, and now they\u2019re backing the new USB standard. I\u2019d say that means the future is GigE and USB3, for everything except really large sensor formats and very high data rates.  Just out of curiosity, does anyone think we\u2019ll see a linescan USB3 camera before the year end?"], "link": "http://machinevision4users.blogspot.com/feeds/2629898265454604889/comments/default", "bloglinks": {}, "links": {"http://www.alliedvisiontec.com/": 1}, "blogtitle": "Machine Vision 4 Users"}, {"content": ["In the automotive world Sales and Marketing types like to talk to about cross-shopping. The three series BMW is often cross-shopped with the Audi A4, the VW Beetle with the Mini. In other words, consumers are smart enough to check out competitive products before plunking down their hard-earned.  So here's my question: how often do you cross-shop vision systems?  I'll bet the answer is \u201cpractically never.\u201d I'll bet that when you need a smart camera you call your friendly local electrical bits-and-bobs distributor and ask what he can offer. If he carries Cognex, that's what you'll get. If he works with Omron, or Panasonic, well guess what you'll be using.  Is this a smart way to buy machine vision? I don't think so.  I'm shopping for a new car right now. I figured out my needs, (interior space, good gas mileage, good warranty,) and my budget, and now I'm compiling a spreadsheet where I can compare the models that meet my constraints. The final decision will still involve some subjective criteria \u2013 how it looks, how it feels \u2013 but I'm comfortable with that because I know I'll be working from a base of quantifiable data and will be making an informed decision.  I think we should buy vision systems the same way. There are a lot of vendors out there with products that differ but all have strengths and weaknesses. So before you buy a Matrox Iris, a Banner PresencePlus P4, or a Cognex InSight, figure out your needs and see which fits best. That way you won't be buying a Maserati when what you need is a minivan."], "link": "http://machinevision4users.blogspot.com/feeds/7157246041090898945/comments/default", "bloglinks": {}, "links": {}, "blogtitle": "Machine Vision 4 Users"}, {"content": ["A good camera mount is hard to find, so when I saw an interesting design in a recent movie from  Allied Vision Technology  I had to pause and rewind a few times. Eventually I grabbed this screen shot.   This shows a couple of AVT cameras on mounts that both act as heat sinks and provide two axes of rotation. I guess you could count a third translational axis too.  I like the look of these, although I have to wonder how you\u2019d get a camera back to its original position if it got knocked. Perhaps some kind of scale could be added?  If my plea for a camera mounting standard, (\u201c  We need a new camera mounting system  \u201d,) ever gains any traction perhaps it would look something like these.  And for any of you interested in viewing the entire movie, here it is in all its glory."], "link": "http://machinevision4users.blogspot.com/feeds/8261669409599525973/comments/default", "bloglinks": {}, "links": {"http://4.blogspot.com/": 1, "http://machinevision4users.blogspot.com/": 1, "http://www.alliedvisiontec.com/": 1}, "blogtitle": "Machine Vision 4 Users"}, {"content": ["If you visit the machine vision section of Keyence\u2019s website, ( www.keyence.com ,) you\u2019ll see they\u2019re talking about the wonderful new CVX series of vision sensors. With features like a \u201cjudgment algorithm,\u201d and \u201ccolor learning,\u201d it sounds pretty slick. The pictures show what looks like a low-end smart camera slash high-end vision sensor that you just point at the objects to be inspected as they shuffle by.  But then disappointment struck. I asked a co-worker to get some more info \u2013 download the brochure, find out about pricing and so on \u2013 and that\u2019s when trouble struck. Apparently Keyence aren\u2019t ready to share that kind of info.  I understand it takes time to get all the marketing materials together, but surely they can be coordinated? And here\u2019s something I\u2019ve said before but I think it bears repeating: please don\u2019t tell me you\u2019ve got a great new product until you\u2019re actually ready to sell it to me. Just telling me what\u2019s coming soon causes me to, at best, delay a purchase, and at worst, go to one of your competitors.  So please, Keyence and every other vendor in our industry, don\u2019t be coy about your new products. Talk about them openly, have all the info, and be willing to ship, or shut up until you are."], "link": "http://machinevision4users.blogspot.com/feeds/4568362982615081072/comments/default", "bloglinks": {}, "links": {"http://www.keyence.com/": 1}, "blogtitle": "Machine Vision 4 Users"}, {"content": ["There\u2019s nothing like the smell of bacon frying in the pan, unless you\u2019re a vegetarian I suppose, but when you buy a pound, or a kilo, how do you know what you\u2019re getting?  Well the butcher, or more likely the packaging machine, weighs it. But there lies a problem. The retailer wants to give you exactly a pound of bacon, and no more. But as bacon comes in slices he has to add in that extra rasher so as to make the minimum weight.  This giveaway is a problem, but machine vision has come to the rescue.  Stemmer Imaging announced recently that they\u2019ve been working with slicing equipment maker Marel on an  automated grading system . The issue here is that bacon is sliced to a thickness, but the weight of a slice can vary depending on the ratio of meat to fat. So the \u201csmart\u201d slicer looks at the end face of the slab of bacon and determines how much meat and how much fat. From here it can determine the optimum thickness to ensure the final pack weighs exactly the declared weight, and no more.  Clever, eh?  Sadly, there\u2019s little information about the  IBS2000 Vision Bacon Slicer on the Marel website, but I did find a write-up on, of all places, the ITS International website. They\u2019re the people who cover intelligent transportation systems, (another big vision market,) and if you scroll to the bottom of \u201c Machine vision - cameras for intelligent traffic management ,\u201d (October 2011,) you\u2019ll find a sidebar piece about the bacon slicer.  But the story doesn\u2019t end there. While Googling bacon and vision, up popped a link to a University of Nebraska-Lincoln report for the National Pork Board. Published in 2000, \u201c Quality Lean Growth Modeling-Bacon Quality Assessment ,\u201d (it\u2019s a pdf,) includes a section titled, \u201cCHAPTER 3- MACHINE VISION ANALYSIS OF BACON\u201d.  What I found fascinating is that this addresses the same issue: how to objectively determine ratios of fat and meat. I hope the folks at Stemmer read the report because it goes in to much detail about how the appearance of the meat can vary.  Variation in the object being inspected is of course a big challenge for the development of automated inspection systems. So big in fact that I think I\u2019ll return to it very soon. Until then, how\u2019s that bacon sandwich looking?"], "link": "http://machinevision4users.blogspot.com/feeds/8931648197172471554/comments/default", "bloglinks": {}, "links": {"http://www.marel.com/": 1, "http://www.pork.org/": 1, "http://www.co.uk/": 1, "http://www.itsinternational.com/": 1}, "blogtitle": "Machine Vision 4 Users"}, {"content": ["Picking a camera is hard work. There\u2019s resolution and lens format, sensor type and frame rate, and then there\u2019s the interface standard, in terms of both speed and range. Now if you\u2019re able to put the PC close to the camera pretty much any interface \u2013 GigE, FireWire, USB, or CameraLink - will span the distance, but there are many applications where the two are, of necessity, separated.  As a rough guide, if you have more than 3m between them you should give some thought to the most appropriate standard. Sometimes though this limits your choice of camera, but never fear, Andy Wilson is here.  No, Andy\u2019s not going to stretch your cables, but he does have some advice on how to make them reach further. \u201c Clearing Up Choices for Cabling and Connectors ,\u201d (Vision Systems Design, September 1 st , 2012, points out that most of the standard interfaces now have some kind of extender technology. If this is something you might need to deal with, I suggest you click the link above and save Andy\u2019s article in your Favorites."], "link": "http://machinevision4users.blogspot.com/feeds/5417084988649022302/comments/default", "bloglinks": {}, "links": {"http://www.vision-systems.com/": 1}, "blogtitle": "Machine Vision 4 Users"}, {"content": ["Perhaps you stumbled across this site because you need to learn about machine vision. If so, allow me to point you at some quality  video material . This comes from Microscan, who sell cameras, lights, and software. In short, they\u2019re positioning themselves as something of a one-stop-shop for vision.  Needless to say, though I shall say it anyway, their videos are a little biased towards the use of Microscan products, but I\u2019ve found them a pretty good start point. They won\u2019t get you through the AIA\u2019s  Certification but they\u2019ll put you on the right road.  Take a look and come back to me with questions."], "link": "http://machinevision4users.blogspot.com/feeds/3423894481657075417/comments/default", "bloglinks": {}, "links": {"http://www.microscan.com/": 1, "http://www.visiononline.org/": 1}, "blogtitle": "Machine Vision 4 Users"}, {"content": ["It\u2019s the rare vision system that never needs any loving. It shouldn\u2019t be that way, but factories are rough places for electronics, and that\u2019s before all those nightshift tweakers get their fingers in the system. So inevitably, long-suffering vision engineer gets called to fix a system that isn\u2019t working.  Now definitions of \u201cnot working\u201d vary. It might mean that everything is being rejected, or that the system won\u2019t power-up, or something in between, so said vision engineer needs some good troubleshooting skills.  This is something I\u2019ve tried to address over my years of blogging, and now I\u2019ve come across an article on the Assembly website, (\u201c Machine Vision: Troubleshooting Vision Systems ,\u201d December 22 nd , 2010,) that seems to repeat many of my suggestions.  One of those interesting of the points made concerned camera mounting. To quote writer John Sprovieri, quoting Mark Sippel of Balluff\u201cA standard 3/4\"-inch screw mount is fine for attaching a camera to a tripod, but it\u2019s ridiculous for industrial applications.\u201d  Does that call to mind my recent post, \u201c We need a new camera mountingsystem \u201d?"], "link": "http://machinevision4users.blogspot.com/feeds/2922040371898794236/comments/default", "bloglinks": {}, "links": {"http://www.assemblymag.com/": 1, "http://machinevision4users.blogspot.com/": 1}, "blogtitle": "Machine Vision 4 Users"}, {"content": ["Is your webcam spying on you? According to this  story  on the BBC, it could be. But more to the point, could you use that camera for something useful?  Start-up Flutter thinks so. They\u2019ve developed software that will use your PC\u2019s webcam as an alternative to the mouse. The idea is that it will recognize your gestures and respond appropriately. (See \u201c  How Flutter wants to become the eye of the machine  ,\u201d posted on the Gigaom website, September 24 th , 2012.)  I understand some will ask, \u201cHas it become too hard to use a mouse?\u201d But I think there are some serious applications.  On the domestic front, I often leave Pandora playing on a laptop. That\u2019s all well and good until it decides to ask if I\u2019m still listening. Wouldn\u2019t it be cool if I could just give it a thumbs-up from the comfort of my couch, rather than getting up to walk across the room?  Then there are the work applications. The factory floor is a tough place for a mouse and keyboard. Yes, touch screens are possible but they cost two limbs at least and still may not do all I want. Imagine just being able to start and stop by pointing.  And one last question for you. Is this machine vision or computer vision?"], "link": "http://machinevision4users.blogspot.com/feeds/2476618149605637671/comments/default", "bloglinks": {}, "links": {"http://gigaom.com/": 1, "http://www.bbc.com/": 1}, "blogtitle": "Machine Vision 4 Users"}, {"content": ["Point Grey sent me an email \u2013 you probably got it too \u2013 saying that the latest additions to their Flea series are priced at $995.  I haven\u2019t purchased a machine camera for a while, but that strikes me as a competitive price for a 2.8Mp GigeE unit with a Sony CCD sensor. Time was I used to calculate the price per megapixel \u2013 call it the Grey Index \u2013 and just last year I was paying $500 per Mp. This camera, the  FL3-GE-28S4C or S4M if you want the monochrome version, works out at $335 per Mp.  Cameras keep getting cheaper."], "link": "http://machinevision4users.blogspot.com/feeds/613970930951447536/comments/default", "bloglinks": {}, "links": {"http://www.ptgreystore.com/": 1}, "blogtitle": "Machine Vision 4 Users"}, {"content": ["Say \u201csmart camera\u201d and most machine vision people will respond \u201cCognex\u201d. My guess is that only one in fifty would go \u201cMatrox\u201d and that\u2019s a pity because Matrox has a very viable smart camera product.  Going by the name of Iris, and more recently  Iris GT , it\u2019s a capable product that runs a software product they call \u201cDesign Assistant\u201d or DA for short. Now I\u2019ve played with DA and I found it good, but not so good that I was filled with a burning desire to use it for every application.  But I hear there\u2019s a pretty significant upgrade coming to Iris and DA. Things like more memory in the cameras, (always a good move,) upgrading the camera OS, and a host of new and improved tools for DA. You\u2019ll need to wait for the official announcement from Matrox to learn what these are, but it\u2019s my understanding that a filmstrip image replay function, like that on the  Cognex Checker , is on the way.  Improvements are good, even if it is a bit of a pain-in-the-ass to switch over, but I\u2019m still not sure this will convert me to the DA cause. But maybe I should download the evaluation version and give it a go."], "link": "http://machinevision4users.blogspot.com/feeds/200362514777757931/comments/default", "bloglinks": {}, "links": {"http://www.matrox.com/": 1, "http://www.cognex.com/": 1}, "blogtitle": "Machine Vision 4 Users"}]
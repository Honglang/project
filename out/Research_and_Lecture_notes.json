[{"blogurl": "http://fabricebaudoin.wordpress.com\n", "blogroll": [], "title": "Research and Lecture notes"}, {"content": ["More generally, by using the same methods as in the previous Lecture, we can introduce iterated derivatives. If , we set \n . \nWe may then consider as a square integrable random process indexed by and valued in . By using the integration by parts formula, it is possible to prove, as we did it in the previous Lecture, that for any , the operator is closable on . We denote by the domain of in , it is the closure of the class of cylindric random variables with respect to the norm \n , \nand \n \nWe have the following key result which makes Malliavin calculus so useful when one wants to study the existence of densities for random variables. \n Theorem. ( P. Malliavin ) Let be a measurable random vector such that: \n \n For every , ; \n The matrix \n \n is invertible.\n \n Then has a density with respect to the Lebesgue measure. If moreover, for every , \n \nthen this density is . \n \n The matrix is often called the Malliavin matrix of the random vector . \n This theorem relies on the following lemma of Fourier analysis for which we shall use the following notation: If is a smooth function then for , we denote \n \n Lemma. Let be a probability measure on such that for every smooth and compactly supported function , \n \nwhere , , . Then is absolutely continuous with respect to the Lebesgue measure with a smooth density. \n Proof. The idea is to show that we may assume that is compactly supported and then use Fourier transforms techniques. Let , and . Let be a smooth function on such that on the ball and outside the ball . Let be the measure on that has a density with respect to . It is easily seen, by induction and integrating by parts that for every smooth and compactly supported function , \n \nwhere , , . Now, if we can prove that under the above assumption has a smooth density, then we will able to conclude that has a smooth density because and are arbitrary. Let \n \nbe the Fourier transform of the measure . The assumption implies that is rapidly decreasing (apply the inequality with ). We conclude that has a smooth density with respect to the Lebesgue measure and that this density is given by the inverse Fourier transform formula: \n \n We may now turn to the proof of the Theorem. \n The proof relies on the integration by parts formula for the Malliavin derivative. Let be a smooth and compactly supported function on . Since , we easily deduce that and that \n \nTherefore we obtain \n \nWe conclude that \n \nAs a consequence, we obtain \n \n \n \n \nBy using inductively this integration by parts formula, it is seen that for every , , there exists an integrable random variable such that, \n \n Filed under: Stochastic Calculus lectures"], "link": "http://fabricebaudoin.wordpress.com/2012/10/29/lecture-33-the-malliavin-matrix-and-existence-of-densities/", "bloglinks": {}, "links": {"http://www.ams.org/": 1, "http://feeds.wordpress.com/": 1, "http://fabricebaudoin.wordpress.com/": 1}, "blogtitle": "Research and Lecture notes"}, {"content": ["The next Lectures will be devoted to the study of the problem of the existence of a density for solutions of stochastic differential equations. The basic tool to study such questions is the so-called Malliavin calculus. \n Let us consider a filtered probability space on which is defined a Brownian motion . We assume that is the usual completion of the natural filtration of . \n A measurable real valued random variable is said to be cylindric if it can be written \n \nwhere and is a function such that and all its partial derivatives have polynomial growth. The set of cylindric random variables is denoted by . It is easy to see that is dense in for every . \n The Malliavin derivative of is the valued stochastic process given by \n \nWe can see as an (unbounded) operator from the space into the Banach space \n \nOur first task will be to prove that is closable. This will be a consequence of the following fundamental integration by parts formula which is interesting in itself. \n Proposition. (Integration by parts formula) Let and be a progressively measurable such that . We have \n \n \n Proof. \nLet \n \nLet us now fix and denote \n \nFrom Girsanov\u2019s theorem , we have \n \nNow, on one hand we compute \n \n , \nand on the other hand, we obtain \n \n \n Proposition. Let . As a densely defined operator from into , is closable. \n Proof. Let be a sequence in that converges in to and such that converges in to . We want to prove that . Let be a function in . Let us first assume . We have \n \nand \n \nAs a consequence, we obtain \n \nSince is arbitrary, we conclude . Let us now assume . Let be a smooth and compactly supported function and let . We have \n \nAs a consequence, we get \n \nand thus \n \nOn the other hand, we have \n \nWe conclude \n \n The closure of in shall still be denoted by . Its domain is the closure of with respect to the norm \n \nFor , we can consider the adjoint operator of . This is a densely defined operator with which is characterized by the duality formula \n \nFrom the integration by parts formula and Burkholder-Davis-Gundy inequalities , it is clear that the domain of in contains the set of progressively measurable processes such that and in that case, The operator can thus be thought as an extension of the It\u014d\u2019s integral. It is often called the Skohorod integral. \n Exercise. (Clark-Ocone formula) \nShow that for , \n \n Filed under: Stochastic Calculus lectures"], "link": "http://fabricebaudoin.wordpress.com/2012/10/25/lecture-32-the-malliavin-derivative/", "bloglinks": {}, "links": {"http://feeds.wordpress.com/": 1, "http://en.wikipedia.org/": 2, "http://fabricebaudoin.wordpress.com/": 3}, "blogtitle": "Research and Lecture notes"}, {"content": ["Filed under: Stochastic Calculus lectures"], "link": "http://fabricebaudoin.wordpress.com/2012/10/25/then-a-miracle-occurs/", "bloglinks": {}, "links": {"http://feeds.wordpress.com/": 1, "http://fabricebaudoin.wordpress.com/": 2}, "blogtitle": "Research and Lecture notes"}, {"content": ["As usual, let be a filtered probability space which satisfies the usual conditions. It is often useful to use the language of Stratonovitch \u2018s integration to study stochastic differential equations because the It\u014d\u2019s formula takes a much nicer form. If , , is an -adapted real valued local martingale and if is an -adapted continuous semimartingale satisfying , then by definition the Stratonovitch integral of with respect to is defined as \n \nwhere: \n \n is the It\u014d integral of against ; \n is the quadratic covariation at time between and . \n \n By using Stratonovitch integral instead of It\u014d\u2019s, the It\u014d formula reduces to the classical change of variable formula. \n Theorem. Let be a - dimensional continuous semimartingale. Let now be a function. We have \n \n \n Let be a non empty open set. A smooth vector field on is simply a smooth map \n \nThe vector field defines a differential operator acting on smooth functions as follows: \n \nWe note that is a derivation, that is a map on , linear over , satisfying for , \nAn interesting result is that, conversely, any derivation on is a vector field. \n Let now be a -dimensional Brownian motion and consider  vector fields , , . By using the language of vector fields and Stratonovitch integrals, the fundamental theorem for the existence and the uniqueness of solutions for stochastic differential equations is the following: \n Theorem. Assume that are bounded vector fields with bounded derivatives up to order 2. Let . On , there exists a unique continuous and adapted process such that for , \n \nwith the convention that . \n Thanks to It\u014d\u2019s formula the corresponding It\u014d\u2019s formulation is \n \nwhere for , is the vector field given by \n \nIf is a function, from It\u014d\u2019s formula, we have for , \n \nand the process \n \nis a local martingale where is the second order differential operator \n \n Filed under: Stochastic Calculus lectures"], "link": "http://fabricebaudoin.wordpress.com/2012/10/24/lecture-30-stratonovitch-stochastic-differential-equations/", "bloglinks": {}, "links": {"http://feeds.wordpress.com/": 1, "http://en.wikipedia.org/": 1, "http://fabricebaudoin.wordpress.com/": 1}, "blogtitle": "Research and Lecture notes"}, {"content": ["In the previous section, we have seen that if is the solution of a stochastic differential equation \n \nthen is a Markov process, that is for every , \n \nwhere . It is remarkable that this property still holds when is now any finite stopping time. This property is called the strong Markov property. \nThe key lemma is the following: \n Lemma. Let be a standard Brownian motion and let be a finite stopping time. The process, is a standard Brownian motion independent from . \n Proof. Let be a finite stopping time of the filtration . We first assume bounded. Let us consider the process Let , . Applying Doob\u2019s stopping theorem to the martingale with the stopping times and , yields: \n \nTherefore \n \nThe increments of are therefore independent and stationary. The conclusion then easily follows. If is not bounded almost surely, then we can consider the stopping time and from the previous result the finite dimensional distributions do not depend on and are the same as a Brownian motion. We can then let to conclude \n Theorem. For every , is a strong Markov process with semigroup : For every Borel function with polynomial growth, every , and every finite stopping time , \n \n \n Proof. The proof is identical to the proof of the usual Markov property with the additional ingredient given by the previous proposition \n The strong Markov property for solutions of stochastic differential equations is useful to solve boundary value problems in partial differential equations theory. Let be a bounded closed set in . For , we denote . If is bounded Borel function such that , we define \n . \nThe proof of the following theorem is let to the reader. \n Theorem. Let be a bounded Borel function and assume that the function is . Then is the unique solution of the Dirirchlet boundary value problem \n \nin , with the initial condition \n \nand the boundary condition \n \n \n Filed under: Stochastic Calculus lectures"], "link": "http://fabricebaudoin.wordpress.com/2012/10/22/lecture-29-the-strong-markov-property-for-solutions-of-stochastic-differential-equations/", "bloglinks": {}, "links": {"http://feeds.wordpress.com/": 1, "http://fabricebaudoin.wordpress.com/": 1}, "blogtitle": "Research and Lecture notes"}, {"content": ["It is now time to give some applications of the theory of stochastic differential equations to parabolic second order partial differential equations. In particular we are going to prove that solutions of such equations can represented by using solutions of stochastic differential equations. This representation formula is called the Feynman - Kac formula. \nAs usual, we consider a filtered probability space  which satisfies the usual conditions and on which is defined a -dimensional Brownian motion . Again, we consider two functions and and we assume that there exists such that \n \nLet be the second order differential operator \n \nwhere . \n As we know, there exists a bicontinuous process such that for , \n \nMoreover, as it has been stressed before, for every , and \n \nAs a consequence, if is a Borel function with polynomial growth, we can consider the function \n \n Theorem. For every , is a Markov process with semigroup . More precisely, for every Borel function with polynomial growth and every , \n \n \n Proof. The key point, here, is to observe that solutions are actually adapted to the natural filtration of the Brownian motion . More precisely, there exists on the space of continuous functions a predictable functional such that for : \n \nIndeed, let us first work on where is small enough. In that case, as seen previously, the process is the unique fixed point of the application defined by \n \n Alternatively, one can interpret this by observing that is the limit of the sequence of processes inductively defined by \n \nIt is easily checked that for each there is a predictable functional such that \n \nwhich proves the above claim when is small enough. To get the existence of for any , we can proceed \n With this hands, we can now prove the Markov property. Let . For , we have \n \n \nConsequently, from uniqueness of solutions, \n \nWe deduce that for a Borel function with polynomial growth, \n \nbecause is a Brownian motion independent of  \n Theorem Let be a Borel function with polynomial growth and assume that the function \n \nis , that is once differentiable with respect to and twice differentiable with respect to . Then solves the Cauchy problem \n \nin , with the initial condition . \n Proof. Let and consider the function . According the previous theorem, we have \n \nAs a consequence, the process is a martingale. But from Ito\u2019s formula the bounded variation part of is which is therefore 0. We conclude \n \n Exercise Show that if is a function such that and have polynomial growth, then the function is . Here, we denote by the Hessian matrix of . \n Theorem. Let be a Borel function with polynomial growth. Let be a solution of the Cauchy problem \n \n with the initial condition . \nIf there exists a locally integrable function and , such that for every and , \n \nthen . \n \n Proof. Let and, as before, consider the function . As a consequence of Ito\u2019s formula, we have \n \nwhere is a local martingale with quadratic variation . The conditions on and $u$ imply that this quadratic variation is integrable. As a consequence, is a martingale and thus  \n The previous results may be extended to study parabolic equations with potential as well. More precisely, let be a bounded function. If is a Borel function with polynomial growth, we define \n . \nThe same proofs as before will give the following theorems. \n Theorem. For every and every Borel function with polynomial growth and every , \n \n \n Theorem. Let be a Borel function with polynomial growth and assume that the function \n \nis , that is once differentiable with respect to and twice differentiable with respect to . Then solves the Cauchy problem \n \nin , with the initial condition \n . \n \n Theorem. Let be a Borel function with polynomial growth. Let be a solution of the Cauchy problem \n \n with the initial condition . If there exists a locally integrable function and , such that for every and , \n , \nthen . \n \n Filed under: Stochastic Calculus lectures"], "link": "http://fabricebaudoin.wordpress.com/2012/10/18/lecture-28-the-feynman-kac-formula/", "bloglinks": {}, "links": {"http://feeds.wordpress.com/": 1, "http://en.wikipedia.org/": 2, "http://fabricebaudoin.wordpress.com/": 1}, "blogtitle": "Research and Lecture notes"}, {"content": ["In this lecture, we study the regularity of the solution of a stochastic differential equation with respect to its initial condition. The key tool is a multimensional parameter extension of the Kolmogorov continuity theorem whose proof is almost identical to the one-dimensional case. \n Theorem. Let be a -dimensional stochastic process such that there exist positive constants such that for every \n \nThere exists a modification of the process such that for every there exists a finite random variable such that for every \n \n \n As above, we consider two functions and and we assume that there exists such that \n \nAs we already know, for every , there exists a continuous and adapted process such that for , \n \n Proposition. Let . For every , there exists a constant such that for every and , \n . \nAs a consequence, there exists a modification of the process such that for , , \n \nand such that is continuous for almost every . \n Proof. As before, we can find such that \n , ; \nand ), . \n We fix and . Let \n \nBy using the inequality , we obtain \n \nWe now have \n \nand from Burkholder-Davis-Gundy inequality \n \n \n \nAs a conclusion we obtain \n \n Gronwall\u2019s inequality yields then \n \nwhere is a continuous function. \n We have for , \n , \nand \n \n \n \nThe conclusion then easily follows by combining the two previous estimates \n In the sequel, of course, we shall always work with this bicontinuous version of the solution. \n Definition. The continuous process of continuous maps is called the stochastic flow associated to the equation. \n If the maps and are moreover , then the stochastic flow is itself differentiable and the equation for the derivative can be obtained by formally differentiating the equation with respect to its initial condition. We willl admit this result without proof: \n Theorem. Let us assume that and are Lipschitz functions, then for every , the flow associated to the equation is a flow of differentiable maps. Moreover, the first variation process which is defined as the Jacobian matrix  is the unique solution of the matrix stochastic differential equation: \n \n \n Filed under: Stochastic Calculus lectures"], "link": "http://fabricebaudoin.wordpress.com/2012/10/16/lecture-27-stochastic-differential-equations-regularity-of-the-flow/", "bloglinks": {}, "links": {"http://feeds.wordpress.com/": 1, "http://en.wikipedia.org/": 1, "http://fabricebaudoin.wordpress.com/": 3}, "blogtitle": "Research and Lecture notes"}, {"content": ["We now turn to the theory of stochastic differential equations. Stochastic differential equations are the differential equations corresponding to the theory of the stochastic integration. \n As usual, we consider a filtered probability space  which satisfies the usual conditions and on which is defined a -dimensional Brownian motion . Let , and be functions. \n Theorem. Let us assume that there exists such that \n \nThen, for every , there exists a unique continuous and adapted process such that for \n \nMoreover, for every , \n \n \n Proof. \nLet us first observe that from our assumptions, there exists such that \n \n , ; \n ), . \n \n The idea is to apply a fixed point theorem in a convenient Banach space. \nFor , let us consider the space of continuous and adapted processes such that \n . \nWe endow that space with the norm \n \nIt is easily seen that is a Banach space. \n Step one: We first prove that if a continuous and adapted process is a solution of the equation then, for every , . \n Let us fix and consider for the stopping times For , \n \nTherefore, by using the inequality , we get \n \nThus, we have \n \n \nBy using our assumptions, we first estimate \n \nBy using our assumptions and Doob\u2019s inequality , we now estimate \n \nTherefore, from the inequality , we get \n \n \nWe may now apply Gronwall\u2019s lemma to the function and deduce \n \nwhere is a constant that does not depend on . Fatou\u2019s lemma implies by passing to the limit when that \n \nWe conclude, as expected, that \nMore generally, by using the same arguments we can observe that if a continuous and adapted process satisfies \n \nwith , then . \n Step 2: We now show existence and uniqueness of solutions for the equation on a time interval where is small enough. \n Let us consider the application that sends a continuous and adapted process to the process By using successively the inequalities , Cauchy-Schwarz inequality and Doob\u2019s inequality, we get . Moreover, arguing the same way as above, we can prove \nTherefore, if is small enough is a Lipschitz map whose Lipshitz constant is strictly less than 1. Consequently, it has a unique fixed point. This fixed point is, of course the unique solution of the equation on the time interval . Here again, we can observe that the same reasoning applies if is replaced by a random variable that satisfies . \n Step 3. \nIn order to get a solution of the equation on , we may apply the previous step to get a solution on intervals , where is small enough and . This will provide a solution of the equation on . This solution is unique, from the uniqueness on each interval \n \n Definition: An equation like in the previous theorem is called a stochastic differential equation. \n Exercise: (Ornstein-Uhlenbeck process) Let . We consider the following stochastic differential equation, \n \n \n Show that it admits a unique solution that is given by \n \n Show that is Gaussian process. Compute its mean and covariance function. \n Show that if then, when , converges in distribution toward a Gaussian distribution. \n \n \n Exercise. (Brownian bridge) We consider for the following stochastic differential equation \n \n \n Show that \n \nis the unique solution. \n Deduce that is Gaussian process. Compute its mean and covariance function. \n Show that in , when , .\n \n \n Exercise. Let and . We consider the following stochastic differential equation, \n \nShow that \n \nis the unique solution. \n The next proposition shows that solutions of stochastic differential equations are intrinsically related to a second order differential operator. This connection will later be investigated in more details. \n Proposition. Let be the solution of a stochastic differential equation \n \nwhere and are Borel functions. Let now be a function. The process \n \nis a local martingale, where is the second order differential operator \n \nand . \n Filed under: Stochastic Calculus lectures"], "link": "http://fabricebaudoin.wordpress.com/2012/10/09/lecture-26-stochastic-differential-equations-existence-and-uniqueness-of-solutions/", "bloglinks": {}, "links": {"http://feeds.wordpress.com/": 1, "http://fabricebaudoin.wordpress.com/": 2}, "blogtitle": "Research and Lecture notes"}, {"content": ["In this section, we describe a theorem which has far reaching consequences in mathematical finance: The Girsanov theorem. It describes the impact of a probability change on stochastic calculus. \n Let be a filtered probability space. We assume that is the usual completion of the filtration of a Brownian motion . Let be a probability measure on which is equivalent to . We denote by the density of with respect to . \n Theorem (Girsanov theorem) There exists a progressively measurable process such that for every , and Moreover, the process is a Brownian motion on the filtered probability space . As a consequence, a continuous and adapted process is a -semimartingale if and only if it is a -semimartingale. \n Proof. Since and are equivalent on , there are of course also equivalent on for every . The density of with respect to is given by . As a consequence, the process is a positive martingale. From It\u014d\u2019s representation theorem, we therefore deduce that there exists a progressively measurable process such that Let now . We have then, \n \nBy using It\u014d\u2019s formula to the process , we see that it implies \n \nWe now want to prove that the process is a -Brownian motion. It is clear the -quadratic variation of this process is . From the Levy\u2019s characterization result, we therefore just need to prove that it is a local martingale. For this, we are going to prove that that the process \n \nis a -local martingale. Indeed, from the integration by parts formula, it is immediate that \n \nSince is the density of with respect to , it is then easy to deduce that is a -local martingale and thus a Brownian motion \n Exercise. Let be a filtered probability space that satisfies the usual conditions. As before, let be a probability measure on which is equivalent to . We denote by the density of with respect to and . Let be a local martingale. Show that the process \n \nis a local martingale. As a consequence, a continuous and adapted process is a -semimartingale if and only if it is a -semimartingale. \n Exercise Let be a Brownian motion. We denote by the Wiener measure, by the coordinate process and by its natural filtration. \n \n Let and be the distribution of the process . Show that for every , and that \n \n \n Is it true that  \n For , we denote Compute the density function of (You may use the previous question).\n \n More generally, let  be a measurable function such that for every , . We denote by the distribution of the process . Show that for every , \n \nand that \n \n \n \n \n Let be a filtered probability space that satisfies the usual conditions and let be a Brownian motion on it. Let now be a progressively measurable process such that for every , . We denote \n \nAs a consequence of It\u014d's formula, it is clear that  is a local martingale. In general is not a martingale, but the following two lemmas provide simple sufficient conditions that it is. \n Lemma. If for every , then is a uniformly integrable martingale. \n Proof. The process is a non negative local martingale and thus a super martingale \n Lemma. (Novikov\u2019s condition) If , then is a uniformly integrable martingale. \n Proof. We denote . As a consequence of , the random variable has moments of all order. So from Burkholder-Davis-Gundy inequalities, has moments of all orders, which implies that is a uniformly integrable martingale. We have then \n \nThe Cauchy-Schwarz inequality implies then that . \nWe deduce from the Doob's convergence theorem that the process is a uniformly integrable submartingale. Let now . We have \n \nHolder's inequality shows then that \n \n \n \n \nIf we can prove that , then by letting in the above inequality, we would get \n \nand thus . \n Let such that . Consider and so that . Using \n \nand then Holder's inequality, shows that there is a constant (depending only on ) such that for any stopping time \n \nBy the Doob's maximal inequality, it implies that the local martingale is actually a true martingale. This implies and the desired conclusion \n We now assume that is a uniformly integrable martingale. In that case, it is easy to see that on the -field , there is a unique probability measure equivalent to such that for every , The same argument as before shows then that with respect to , the process \n is a Brownian motion. \n Filed under: Stochastic Calculus lectures"], "link": "http://fabricebaudoin.wordpress.com/2012/10/02/lecture-25-girsanov-theore/", "bloglinks": {}, "links": {"http://feeds.wordpress.com/": 1, "http://en.wikipedia.org/": 1, "http://fabricebaudoin.wordpress.com/": 1}, "blogtitle": "Research and Lecture notes"}, {"content": ["In this section, we study some of the most important martingale inequalities: The Burkholder - Davis - Gundy inequalities. Interestingly, the range of application of these inequalities is very large and they play an important role in harmonic analysis and the study of singular integrals (see for instance the nice survey by my colleague Pr. Ba\u00f1uelos ). These inequalities admit several proofs. We present here a proof using It\u014d\u2019s formula and an interesting domination inequality which is due to Lenglart. For an alternative proof, you may refer to the original approach by Burkholder-Davis-Gundy. \n We admit without proof, the following domination inequality which is is due to Lenglart. \n Proposition. (Lenglart) Let be a positive adapted right-continuous process and be an increasing process. Assume that for every bounded stopping time , . Then, for every , \n We shall use this lemma to prove the following \n Theorem. (Burkholder-Davis-Gundy inequalities) Let and be a continuous local martingale such that . For every , there exist universal constants and , independent of and  such that \n \n \n Proof. By stopping it is enough to prove the result for bounded . Let . From It\u014d\u2019s formula we have \n \n \nAs a consequence of the Doob\u2019s stopping theorem, we get that for every bounded stopping time , \n \nFrom the Lenglart\u2019s domination inequality, we deduce then that for every , \n \nWe now bound \n \n \n \nAs a consequence, we obtain: \n \nLetting yields the claimed result, that is \n \nWe proceed now to the proof of the left hand side inequality. We have, \n \nTherefore, we get \n \nBy using the previous argument, we now have \n \n \n \nAs a conclusion, we obtained \n \nThis is an inequality of the form , which easily implies \n , thanks to the inequality , with a conveniently chosen  \n Filed under: Stochastic Calculus lectures"], "link": "http://fabricebaudoin.wordpress.com/2012/09/28/lecture-24-burkholder-davis-gundy-inequalities/", "bloglinks": {}, "links": {"http://feeds.wordpress.com/": 1, "http://www.rutgers.edu/": 1, "http://www.purdue.edu/": 2, "http://arxiv.org/": 1, "http://en.wikipedia.org/": 1, "http://fabricebaudoin.wordpress.com/": 1, "http://projecteuclid.org/": 1}, "blogtitle": "Research and Lecture notes"}]
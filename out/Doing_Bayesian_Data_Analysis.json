[{"blogurl": "http://doingbayesiandataanalysis.blogspot.com\n", "blogroll": [], "title": "Doing Bayesian Data Analysis"}, {"content": ["In a thread elsewhere, a reader of Bayesian estimation supersedes the t test commented: \"Doesn't Abelson's paradox preclude the establishment of guidelines for a sufficiently small effect size?\" In this post I briefly review Abelson's paradox and demonstrate how hierarchical Bayesian data analysis is actually applied to real baseball data of the type that Abelson used to illustrate his paradox. Bayesian estimation provides rich estimates of the abilities of players and their differences. There is no paradox. First, a cursory review of Abelson's paradox. It was described in a brief article: Abelson, R. P. (1985). A variance explanation paradox: When a little is a lot. Psychological Bulletin, 97(1), 129-133. Abelson considered the batting averages of major league baseball players. A batting average is simply the ratio of number of hits to number of at-bats. In the 2012 season, players each had about 550 opportunities at bat, and typically got about 150 hits, for a typical batting average of about 0.27. Across 143 different players, the batting averages ranged from about 0.19 to 0.34. (Data from ESPN .) Abelson was concerned with whether that variation across players was large compared to the variation within players; in other words, he wanted to know the magnitude of the proportion of variance accounted for by player ability. He came up with a mathematical approximation and argued that for typical data the magnitude of the proportion of variance accounted for is about 0.003. The \"paradox\" is that such a small number conflicts with sports fans' intuition that player ability should account for a lot more of the variance of hits. Abelson discussed the meaning of his calculation and how it differs from the everyday intuition of the sports fan, saying that his statistic refers to the predictability of a single at-bat. But I can't say I fully understand what Abelson was going for, and the Bayesian analysis of real data (shown below) seems clear and unparadoxical to me. What does any of that have to do with Bayesian data analysis? Presumably the reader who commented about Abelson's paradox was thinking about the approach to null values that I and others have advocated, whereby a null value for a parameter is deemed accepted for practical purposes if its 95% highest density interval (HDI) falls entirely within a region of practical equivalence (ROPE) around the null value. Perhaps the reader was concerned that no ROPE can be established because even tiny values, like Abelson's 0.003, can correspond to intuitively large effects. Perhaps the best rebuttal is simply to demonstrate how to do a Bayesian analysis of batting averages, including a ROPE. The analysis uses a hierarchical model that simultaneously estimates individual player abilites and the overall average ability of major league players. The model comes directly from Chapter 9 of Doing Bayesian Data Analysis. (For an example of applying the same model to meta-analysis of ESP data, see this post . That post also includes a hierarchical diagram of the model.) In the model, the i-th player has an underlying probability of getting a hit, denoted theta[i]. The value of theta[i] is estimated from observing the number of hits y[i] and at-bats N[i] for each player. Importantly, the model assumes that the theta[i] come from a higher-level distribution that describes the individual differences among major league players. There is an overall central tendency, mu, for the batting average of major league players, and a \"tightness\" of clustering around that central tendency, denoted kappa. (For details, please see Ch. 9 of DBDA.) The hierarchical structure of the model provides shrinkage in the estimates of the individual abilities. Essentially, each player's data inform the estimate of theta[i] for that player, but also inform the group-level parameters mu and kappa, which in turn influence the estimated values of theta[.] for other players. Thus, if many players all have batting averages right around .27, the group-level distribution is estimated to be very \"tight,\" which pulls in (shrinks) outlying individuals toward the group average. This is intuitively reasonable: If you have information that player after player has an average around .27, you should use that information to inform your estimate of the next player. When making decisions about differences in estimated abilities, what sort of ROPE is meaningful? There is no single correct answer because it depends on practical consequences. But suppose we say that a difference of 10 hits, in a season of 550 at bats, has practical significance. The ratio 10/550 is just under 0.02, so let's establish a ROPE as -0.02 to +0.02. Our decision rule for assessing differences between players is now this: The difference in abilities between players is deemed to be credibly and practically different from zero if the 95% HDI on the estimated difference falls completely outside a ROPE from -0.20 to +0.02. The difference in abilities is deemed to be practically equivalent to zero if the 95% HDI on the estimated difference falls completely inside the ROPE. Here are some results from the analysis. First, consider the players with the highest and lowest batting average during the 2012 regular season:  The right panel shows that their abilities (in terms of estimated probability of getting a hit at bat) are credibly different, and the posterior distribution reveals in detail the relative credibility of the whole range of candidate differences. The graphs also plot the observed batting average (y[i]/N[i]) as small red +'s on the abscissa. Notice that the estimated theta values show clear shrinkage toward the group average. Thus, although Buster Posey had a batting average of 0.336, the estimate of the underlying probability of getting a hit is shrunken toward the major league average, with a mean estimate of 0.313. Similarly, although Carlos Pena had a batting average of 0.197, the estimate of the underlying probability of getting a hit is shrunken toward the central tendency of the group, with a mean estimate of 0.225. Despite the shrinkage, the difference (right panel) is still credibly non-zero. Here are the results for the two players in the middle of the pack:  The right panel shows that the estimated difference in their underlying probabilities of getting a hit is nearly zero. 52% of the posterior distribution falls within the ROPE. Thus, we do not have enough precision in the estimate of the differences to declare that their abilities are equal for practical purposes, where \"practical\" is defined in terms of this choice of ROPE. Thus, Bayesian analysis provides rich and meaningful inferences about the sort of data that Abelson was interested in. I don't see any \"paradox\" that needs to be overcome. The Bayesian analysis never even brought up the issue of \"proportion of variance accounted for\" as Abelson did. Because the Bayesian analysis directly estimates all the parameters of interest, and provides a complete posterior distribution for their credibilities, Abelson's paradoxical statistic never even arose. Appendix: The complete program. Data are from ESPN, linked in text above.  rm(list = ls()) graphics.off() fileNameRoot=\"MajorLeagueBaseballBattingJAGS\" if ( .Platform$OS.type != \"windows\" ) { windows <- function( ... ) X11( ... ) }      # In the style of: require(rjags)   # Kruschke, J. K. (2011). Doing Bayesian Data Analysis:      # A Tutorial with R and BUGS. Academic Press / Elsevier. #------------------------------------------------------------------------------ # THE MODEL. # Specify the model in JAGS language, but save it as a string in R: modelString = \" model {  # Likelihood:  for ( i in 1:nPlayers ) {   y[i] ~ dbin( theta[i] , N[i] )  }  # Prior:  for ( i in 1:nPlayers ) {   theta[i] ~ dbeta( a , b )  }  a <- mu * kappa  b <- ( 1.0 - mu ) * kappa  mu ~ dbeta( 1,1 )  kappa ~ dgamma( 1.393 , 0.0393 ) # mode=10, sd=30 } # ... JAGS model specification ends. \" # close quote to end modelString # Write the modelString to a file, using R commands: writeLines(modelString,con=\"model.txt\") #------------------------------------------------------------------------------ # THE DATA. dataFrame = read.csv( file=\"MajorLeagueBaseballBattingStats2012.csv\" ) y = dataFrame$H # hits for each player N = dataFrame$AB # at bats for each player nPlayers = length(y) dataList = list(  y = y ,  N = N ,  nPlayers = nPlayers ) #------------------------------------------------------------------------------ # INTIALIZE THE CHAIN. # Let JAGS do it randomly... #------------------------------------------------------------------------------ # RUN THE CHAINS. parameters = c( \"mu\" , \"kappa\" , \"theta\" ) # The parameter(s) to be monitored. adaptSteps = 1000    # Number of steps to \"tune\" the samplers. burnInSteps = 1000   # Number of steps to \"burn-in\" the samplers. nChains = 3     # Number of chains to run. numSavedSteps=100000   # Total number of steps in chains to save. thinSteps=1     # Number of steps to \"thin\" (1=keep every step). nIter = ceiling( ( numSavedSteps * thinSteps ) / nChains ) # Steps per chain. # Create, initialize, and adapt the model: jagsModel = jags.model( \"model.txt\" , data=dataList , # inits=initsList ,       n.chains=nChains , n.adapt=adaptSteps ) # Burn-in: cat( \"Burning in the MCMC chain...\\n\" ) update( jagsModel , n.iter=burnInSteps ) # The saved MCMC chain: cat( \"Sampling final MCMC chain...\\n\" ) codaSamples = coda.samples( jagsModel , variable.names=parameters ,        n.iter=nIter , thin=thinSteps ) # resulting codaSamples object has these indices: # codaSamples[[ chainIdx ]][ stepIdx , paramIdx ] #------------------------------------------------------------------------------ # EXAMINE THE RESULTS. checkConvergence = FALSE if ( checkConvergence ) { autocorr.plot( codaSamples , ask=T ) } # Convert coda-object codaSamples to matrix object for easier handling. # But note that this concatenates the different chains into one long chain. # Result is mcmcChain[ stepIdx , paramIdx ] mcmcChain = as.matrix( codaSamples ) # Extract the posterior sample from JAGS for easier reference: mu = mcmcChain[,\"mu\"] kappa = mcmcChain[,\"kappa\"] # BRugs gets sample from JAGS theta = matrix( 0 , nrow=nPlayers , ncol=nChains*nIter ) for ( i in 1:nPlayers ) {  nodeName = paste( \"theta[\" , i , \"]\" , sep=\"\" )  theta[i,] = mcmcChain[,nodeName] } # Make a graph using R commands: source(\"plotPost.R\") windows(width=7,height=2.5) layout( matrix( 1:2 , nrow=1 , byrow=TRUE ) ) #par(mar=c(2.95,2.95,1.0,0),mgp=c(1.35,0.35,0),oma=c( 0.1, 0.1, 0.1, 0.1) ) plotPost( mu , xlab=\"mu\" , main=\"Group Mean\" ) plotPost( kappa , xlab=\"kappa\" , main=\"Group Certainty\" ) savePlot( file=paste(fileNameRoot,\"MuKappa\",sep=\"\") , type=\"jpg\" ) plotPlayerDiff = function( idx1 , idx2 , diffRope=c(-0.02,0.02) , savePlotFile=FALSE ) { windows(width=7,height=2.5) layout( matrix( 1:3 , nrow=1 , byrow=TRUE ) ) #par(mar=c(2.95,2.95,1.0,0),mgp=c(1.35,0.35,0),oma=c( 0.1, 0.1, 0.1, 0.1) ) plotPost( theta[idx1,] , xlab=paste(\"theta\",idx1) , main=dataFrame$PLAYER[idx1] ) points( dataFrame$AVG[idx1] , 0 , pch=\"+\" , col=\"red\" , cex=1.5 ) plotPost( theta[idx2,] , xlab=paste(\"theta\",idx2) , main=dataFrame$PLAYER[idx2] ) points( dataFrame$AVG[idx2] , 0 , pch=\"+\" , col=\"red\" , cex=1.5) plotPost( theta[idx1,] - theta[idx2,] ,    xlab=paste(\"theta\",idx1,\"-\",\"theta\",idx2) , main=\"Difference\" ,    compVal=0.0 , ROPE=diffRope ) points( dataFrame$AVG[idx1]-dataFrame$AVG[idx2] , 0 , pch=\"+\" , col=\"red\" , cex=1.5) if ( savePlotFile ) {  savePlot( file=paste(fileNameRoot,\"Theta\",idx1,\"Theta\",idx2,sep=\"\") , type=\"jpg\" ) } } plotPlayerDiff(1,nPlayers,savePlotFile=TRUE) plotPlayerDiff( round(nPlayers/2)-1 , round(nPlayers/2) ,savePlotFile=TRUE)"], "link": "http://doingbayesiandataanalysis.blogspot.com/feeds/6025224247091507399/comments/default", "bloglinks": {}, "links": {"http://2.blogspot.com/": 1, "http://doingbayesiandataanalysis.blogspot.com/": 1, "http://www.indiana.edu/": 1, "http://1.blogspot.com/": 1, "http://espn.go.com/": 1}, "blogtitle": "Doing Bayesian Data Analysis"}, {"content": ["This post shows how to estimate trend coefficients when there is an auto-regressive AR(1) process on the deviation from the trend. The specific example uses a sinusoidal trend to describe daily temperatures across many years, but the programming method in JAGS/BUGS can be easily adapted to other trends. The example extends a previous post about average daily temperatures modeled as sinusoidal variation around a linear trend. The substantive goal was to estimate the slope of the linear component, to determine whether there is a credible non-zero increase in temperatures over the years. In that post, the discussion mentioned lack of independence across days in the deviation from the trend, and with this post the dependence is described by a simple auto-regressive AR(1) model. Here is the model specification with the essential conceptual components highlighted in yellow: model {  trend[1] <- beta0 + beta1 * x[1] + amp * cos( ( x[1] - thresh ) / wl )  for( i in 2 : Ndata ) {  y[i] ~ dt( mu[i] , tau , nu )  mu[i] <- trend[i] + ar1 * ( y[i-1] - trend[i-1] )   trend[i] <- beta0 + beta1 * x[i] + amp * cos( ( x[i] - thresh ) / wl )  }  ar1 ~ dunif(-1.1,1.1) # or dunif(-0.01,0.01)  beta0 ~ dnorm( 0 , 1.0E-12 )  beta1 ~ dnorm( 0 , 1.0E-12 )  tau ~ dgamma( 0.001 , 0.001 )  amp ~ dunif(0,50)  thresh ~ dunif(-183,183)  nu <- nuMinusOne + 1  nuMinusOne ~ dexp(1/29) } The trend is modeled as a linear component plus a sinusoidal component: trend[i] <- beta0 + beta1 * x[i] + amp * cos( ( x[i] - thresh ) / wl ) The slope on the linear component is beta1 . The predicted value of y at time i, denoted mu[i], is the trend at time i plus a proportion of the deviation from the trend on the previous time step: mu[i] <- trend[i] + ar1 * ( y[i-1] - trend[i-1] ) Notice that if ar1 is zero, then the model reduces to simply mu[i] = trend[i] . Here is the posterior when ar1 is restricted to being essentially zero, by setting its prior to ar1 ~ dunif(-0.01,0.01) :  The parameter estimates are basically identical to those in the previous post (as they should be!). In particular, the linear trend component is credibly greater than zero. When ar1 is freely estimated, by setting its prior to ar1 ~ dunif(-1.1,1.1) , then the posterior looks like this:  Notice that the AR(1) coefficient is quite large positive, which makes sense for consecutive daily temperatures (if it's hotter than the sinusoid would predict on one day, it'll probably be hotter than the sinusoid would predict on the next day too). Notice that the estimate of the standard deviation of the noise is now smaller than before, which again makes sense because the AR(1) process is accounting for deviation from the trend which used to be accounted for only by the noise. Importantly, notice that estimates of the other trend parameters are now less certain. In particular, the linear trend component, while having the nearly the same mean in the posterior, has a much wider 95% HDI, which now includes zero."], "link": "http://doingbayesiandataanalysis.blogspot.com/feeds/2030976434807621981/comments/default", "bloglinks": {}, "links": {"http://4.blogspot.com/": 1, "http://1.blogspot.com/": 1, "http://doingbayesiandataanalysis.blogspot.com/": 1}, "blogtitle": "Doing Bayesian Data Analysis"}, {"content": ["Workshop on doing Bayesian data analysis at Indiana University's Workshop in Methods, Friday Oct. 5, 2:00pm. See details here . A list of some previous workshops is here ."], "link": "http://doingbayesiandataanalysis.blogspot.com/feeds/6952770358258047049/comments/default", "bloglinks": {}, "links": {"http://1.blogspot.com/": 1, "http://www.indiana.edu/": 2}, "blogtitle": "Doing Bayesian Data Analysis"}, {"content": ["As mentioned in several previous posts, I strongly recommend using JAGS instead of BUGS, and I have converted all the BUGS programs to JAGS versions. Here I provide guidelines for how to make the conversion in case you want to convert your own programs.  For a concrete example, I will use the programs BernTwoBugs.R and BernTwoJags.R. I\u2019ll proceed section by section through the programs.  The header:   BUGS + BRugs version:  library(BRugs)  JAGS + rjags version:  require(rjags)  Instead of \u201crequire\u201d it could say \u201clibrary\u201d. Also in the JAGS + rjags version I added a way for the graphics to work on non-Windows machines. This is just R, so it can work with BUGS too:  if ( .Platform$OS.type != \"windows\" ) {   windows <- function( ... ) X11( ... )  }   The model specification:   BUGS + BRugs version:  modelstring = \" # BUGS model specification begins here... model {   # Likelihood. Each flip is Bernoulli.   for ( i in 1 : N1 ) { y1[i] ~ dbern( theta1 ) }   for ( i in 1 : N2 ) { y2[i] ~ dbern( theta2 ) }   # Prior. Independent beta distributions.   theta1 ~ dbeta( 3 , 3 )   theta2 ~ dbeta( 3 , 3 ) } # ... end BUGS model specification \" # close quote for modelstring # Write model to a file: .temp = file(\"model.txt\",\"w\") ; writeLines(modelstring,con=.temp) ; close(.temp)  # Load model file into BRugs and check its syntax: modelCheck( \"model.txt\" )  JAGS + rjags version:  modelString = \" # JAGS model specification begins here... model {   # Likelihood. Each flip is Bernoulli.   for ( i in 1 : N1 ) { y1[i] ~ dbern( theta1 ) }   for ( i in 1 : N2 ) { y2[i] ~ dbern( theta2 ) }   # Prior. Independent beta distributions.   theta1 ~ dbeta( 3 , 3 )   theta2 ~ dbeta( 3 , 3 ) } # ... end JAGS model specification \" # close quote for modelstring # Write the modelString to a file, using R commands: writeLines(modelString,con=\"model.txt\")  Notice that the model specification is the same in JAGS as in BUGS. Also, in both cases the modelString gets written to a file called \u201cmodel.txt\u201d. The JAGS + rjags version uses a streamlined version of writeLines that would also work in the BUGS program, as it is just an R command. The only difference is in how the specification gets communicated to BUGS or JAGS: BRugs uses the modelCheck command, but there is no analogous command in rjags.  The data:   BUGS + BRugs version:  # Specify the data in a form that is compatible with BRugs model, as a list: datalist = list(   N1 = 7 ,   y1 = c( 1,1,1,1,1,0,0 ) ,   N2 = 7 ,   y2 = c( 1,1,0,0,0,0,0 ) ) # Get the data into BRugs: modelData( bugsData( datalist ) )  JAGS + rjags version:  # Specify the data in a form that is compatible with JAGS model, as a list: dataList = list(   N1 = 7 ,   y1 = c( 1,1,1,1,1,0,0 ) ,   N2 = 7 ,   y2 = c( 1,1,0,0,0,0,0 ) )  The specification of the data is the same in JAGS as in BUGS. The only difference is in how the specification gets communicated to BUGS or JAGS.: BRugs uses the modelData command, but there is no analogous command in rjags.  Initialize the chains:   BUGS + BRugs version:  modelCompile() modelGenInits()  JAGS + rjags version:  # Can be done automatically in jags.model() by commenting out inits argument. # Otherwise could be established as: # initsList = list( theta1 = sum(dataList$y1)/length(dataList$y1) ,  #      theta2 = sum(dataList$y2)/length(dataList$y2) )  The BUGS version has to compile the model (using the BRugs modelCompile command) and then generate initial values (using the BRugs modelGenInits command). The JAGS version does not need any explicit initialization at this point, as the commented code explains.   Run the chains:   BUGS + BRugs version:  samplesSet( c( \"theta1\" , \"theta2\" ) ) # Keep a record of sampled \"theta\" values chainlength = 10000      # Arbitrary length of chain to generate. modelUpdate( chainlength )    # Actually generate the chain.  JAGS + rjags version:  parameters = c( \"theta1\" , \"theta2\" )  # The parameter(s) to be monitored. adaptSteps = 500    # Number of steps to \"tune\" the samplers. burnInSteps = 1000    # Number of steps to \"burn-in\" the samplers. nChains = 3      # Number of chains to run. numSavedSteps=50000    # Total number of steps in chains to save. thinSteps=1      # Number of steps to \"thin\" (1=keep every step). nIter = ceiling( ( numSavedSteps * thinSteps ) / nChains ) # Steps per chain. # Create, initialize, and adapt the model: jagsModel = jags.model( \"model.txt\" , data=dataList , # inits=initsList ,        n.chains=nChains , n.adapt=adaptSteps ) # Burn-in: cat( \"Burning in the MCMC chain...\\n\" ) update( jagsModel , n.iter=burnInSteps ) # The saved MCMC chain: cat( \"Sampling final MCMC chain...\\n\" ) codaSamples = coda.samples( jagsModel , variable.names=parameters ,         n.iter=nIter , thin=thinSteps ) # resulting codaSamples object has these indices:  #  codaSamples[[ chainIdx ]][ stepIdx , paramIdx ]  Roughly the equivalent of BRugs modelCompile is rjags jags.model. For burning in, the rough equivalent of BRugs modelUpdate before samplesSet is rjags update. Notice that the BUGS version here did no burning in. For the final chain, the rough equivalent of BRugs modelUpdate is rjags coda.samples. Notice that rjags specifies the parameters to be stored with the variable.names argument in the coda.samples command, whereas BRugs specifies the parameters in its samplesSet command.  Examine the results:   BUGS + BRugs version:  theta1Sample = samplesSample( \"theta1\" ) # Put sampled values in a vector. theta2Sample = samplesSample( \"theta2\" ) # Put sampled values in a vector.  # Plot the trajectory of the last 500 sampled values. \u2026  JAGS + rjags version:  # Convert coda-object codaSamples to matrix object for easier handling. # But note that this concatenates the different chains into one long chain. # Result is mcmcChain[ stepIdx , paramIdx ] mcmcChain = as.matrix( codaSamples )  theta1Sample = mcmcChain[,\"theta1\"] # Put sampled values in a vector. theta2Sample = mcmcChain[,\"theta2\"] # Put sampled values in a vector.  # Plot the trajectory of the last 500 sampled values. \u2026  Once the chain is put into variables in R, they can be plotted the same way.  One big difference not shown above is how the chains can be examined for autocorrelation and convergence. My homegrown plotChains function uses BRugs commands and will not work with the JAGS output. Instead, JAGS+rjags returns the chain as a coda-package object, named codaSamples above. There are many useful functions in the coda package for displaying the chains, not shown above. For example, summary( codaSamples ), plot( codaSamples ), and autocorr.plot( codaSamples )."], "link": "http://doingbayesiandataanalysis.blogspot.com/feeds/9045385434912545482/comments/default", "bloglinks": {}, "links": {}, "blogtitle": "Doing Bayesian Data Analysis"}, {"content": ["Perception apparently employs prior knowledge that illumination comes from above, and that the surface itself has constant color. Here's a new article, in press. I'm a bit reluctant about it because it got zero feedback and is unchanged from the initial submission, but, damn the torpedos ..., fools rush in ..., and all that sort of thing. Abstract: Bayesian inference is conditional on the space of models assumed by the analyst. The posterior distribution indicates only which of the available parameter values are less bad than the others, without indicating whether the best available parameter values really fit the data well. A posterior predictive check is important to assess whether the posterior predictions of the least bad parameters are discrepant from the actual data in systematic ways. Gelman and Shalizi (2012a) assert that the posterior predictive check, whether done qualitatively or quantitatively, is non-Bayesian. I suggest that the qualitative posterior predictive check might be Bayesian, and the quantitative posterior predictive check should be Bayesian. In particular, I show that the \u201cBayesian p value,\u201d from which an analyst attempts to reject a model without recourse to an alternative model, is ambiguous and inconclusive. Instead, the posterior predictive check, whether qualitative or quantitative, should be consummated with Bayesian estimation of an expanded model. The conclusion agrees with Gelman and Shalizi (2012a) regarding the importance of the posterior predictive check for breaking out of an initially assumed space of models. Philosophically, the conclusion allows the liberation to be completely Bayesian instead of relying on a non-Bayesian deus ex machina. Practically, the conclusion cautions against use of the Bayesian p value in favor of direct model expansion and Bayesian evaluation. Kruschke, J. K. (in press). Posterior predictive check can and should be Bayesian: Comment on Gelman and Shalizi (2012a). British Journal of Mathematical and Statistical Psychology . Get the full manuscript here ."], "link": "http://doingbayesiandataanalysis.blogspot.com/feeds/5115374879592708715/comments/default", "bloglinks": {}, "links": {"http://3.blogspot.com/": 1, "http://www.indiana.edu/": 1}, "blogtitle": "Doing Bayesian Data Analysis"}, {"content": ["The in-press article, Bayesian estimation supersedes the t test , focuses on the two-group case. Various readers have wanted a one-group version, which is now available. It is in the zip file with the two-group programs. Here is an example of the code for using the program:   # Specify the data y = c(101,100,102,104,102,97,105,105,98,101,100,123,105,103,100,95,102,106,  109,102,82,102,100,102,102,101,102,102,103,103,97,97,103,101,97,104,  96,103,124,101,101,100,101,101,104,100,101) # Run the Bayesian analysis: source(\"BEST1G.R\") mcmcChain = BEST1Gmcmc( y ) # Display the results: BEST1Gplot( y , mcmcChain , compValm=100 , ROPEeff=c(-0.1,0.1) , pairsPlot=TRUE )  The function BEST1Gplot returns detailed numerical summaries of the posterior distribution (not shown here), and it also produces graphical output like this:"], "link": "http://doingbayesiandataanalysis.blogspot.com/feeds/1689758464377126577/comments/default", "bloglinks": {}, "links": {"http://2.blogspot.com/": 1, "http://www.indiana.edu/": 1, "http://1.blogspot.com/": 1}, "blogtitle": "Doing Bayesian Data Analysis"}, {"content": ["Workshop on doing Bayesian data analysis at Michigan State University, East Lansing, September 14-15. See details and registration info here . A list of some previous workshops is here ."], "link": "http://doingbayesiandataanalysis.blogspot.com/feeds/3096673058055673350/comments/default", "bloglinks": {}, "links": {"http://4.blogspot.com/": 1, "http://www.indiana.edu/": 2}, "blogtitle": "Doing Bayesian Data Analysis"}, {"content": ["In a previous post I showed that it's more intuitive to think of a gamma distribution in terms of its mode and standard deviation (sd) than its mean and sd because the gamma distribution is typically skewed. But I did not show how to estimate the mode and sd in the context of a working JAGS/BUGS program, which I do here. Suppose we have some data, y, that we wish to describe with a gamma distribution. (This requires that all the y values are non-negative, of course.) The dgamma function in JAGS/BUGS and R is parameterized by shape and rate parameters, not by mean, mode, or sd. Therefore we must reparameterize the shape and rate into equivalent mean, mode or sd. If we want to reparameterize by the mean of the gamma distribution, a JAGS/BUGS model statement could look like this:  model {  for ( i in 1:N ) {   y[i] ~ dgamma( sh , ra )  }  # parameterized by mean (m) and standard deviation (sd)  sh <- pow(m,2) / pow(sd,2)  ra <-  m / pow(sd,2)  m ~ dunif(0,100)  sd ~ dunif(0,100)  } If we want to reparameterize by the mode of the gamma distribution, a JAGS/BUGS model statement could look like this:  model {  for ( i in 1:N ) {   y[i] ~ dgamma( sh , ra )  }  # parameterized by mode (m) and standard deviation (sd):  sh <- 1 + m * ra  ra <- ( m + sqrt( m^2 + 4*sd^2 ) ) / ( 2 * sd^2 )  m ~ dunif(0,100)  sd ~ dunif(0,100)  } In both model statements, the m parameter is given a dunif(0,100) prior, which implies that the priors in the two models are not equivalent because the mean is not the same as the mode. With vague priors the difference may be inconsequential for the posterior, but it is an important conceptual distinction. In fact, the whole point of reparameterizing is to make the prior more intuitive to specify! It's more intuitive, for most of us, to put a meaningful prior on the mode and sd than on the shape and rate. Here are the results for the two models:   The left panels show the data (which are the same for both models) with a smattering of posterior predicted gamma distributions superimposed. The upper row shows the estimates for the model parameterized by the mean and sd, while the lower row shows the estimates for the model parameterized by mode and sd. You can see that the estimated mean (about 8.08) is larger than the estimated mode (about 7.01), but the estimated sd is essentially the same in the two models. Appendix: Full program listed here, merely FYI. graphics.off() rm(list=ls(all=TRUE)) fileNameRoot=\"GammaModeJags\" # for constructing output filenames if ( .Platform$OS.type != \"windows\" ) {  windows <- function( ... ) X11( ... ) } require(rjags)   # Kruschke, J. K. (2011). Doing Bayesian Data Analysis:       # A Tutorial with R and BUGS. Academic Press / Elsevier. #------------------------------------------------------------------------------ # THE MODEL. mType = c(\"Mean\",\"Mode\")[1] if ( mType == \"Mean\" ) {  modelstring = \"  model {  for ( i in 1:N ) {   y[i] ~ dgamma( sh , ra )  }  # parameterized by mean (m) and standard deviation (sd)  sh <- pow(m,2) / pow(sd,2)  ra <-  m / pow(sd,2)  m ~ dunif(0,100)  sd ~ dunif(0,100)  }  \" # close quote for modelstring }  if ( mType == \"Mode\" ) {  modelstring = \"  model {  for ( i in 1:N ) {   y[i] ~ dgamma( sh , ra )  }  # parameterized by mode (m) and standard deviation (sd):  sh <- 1 + m * ra  ra <- ( m + sqrt( m^2 + 4*sd^2 ) ) / ( 2 * sd^2 )  m ~ dunif(0,100)  sd ~ dunif(0,100)  }  \" # close quote for modelstring }  # Write model to a file, and send to BUGS: writeLines(modelstring,con=\"model.txt\") #------------------------------------------------------------------------------ # THE DATA. # Load the data: N = 87 ; m=8 ; sd=3 set.seed(47401) y = rgamma( N , shape=m^2/sd^2 , rate=m/sd^2 )  # Specify the data as a list: dataList = list( y = y , N = N ) #------------------------------------------------------------------------------ # INTIALIZE THE CHAINS. initsList = list( m = mean(y) , sd = sd(y) ) #------------------------------------------------------------------------------ # RUN THE CHAINS parameters = c( \"m\" , \"sd\" )  adaptSteps = 1000    # Number of steps to \"tune\" the samplers. burnInSteps = 1000   # Number of steps to \"burn-in\" the samplers. nChains = 3     # Number of chains to run. numSavedSteps=50000   # Total number of steps in chains to save. thinSteps=1     # Number of steps to \"thin\" (1=keep every step). nPerChain = ceiling( ( numSavedSteps * thinSteps ) / nChains ) # Steps per chain. # Create, initialize, and adapt the model: jagsModel = jags.model( \"model.txt\" , data=dataList , inits=initsList ,       n.chains=nChains , n.adapt=adaptSteps ) # Burn-in: cat( \"Burning in the MCMC chain...\\n\" ) update( jagsModel , n.iter=burnInSteps ) # The saved MCMC chain: cat( \"Sampling final MCMC chain...\\n\" ) codaSamples = coda.samples( jagsModel , variable.names=parameters ,        n.iter=nPerChain , thin=thinSteps ) # resulting codaSamples object has these indices: # codaSamples[[ chainIdx ]][ stepIdx , paramIdx ] #------------------------------------------------------------------------------ # EXAMINE THE RESULTS checkConvergence = F if ( checkConvergence ) {  windows()  autocorr.plot( codaSamples , ask=F ) } # Convert coda-object codaSamples to matrix object for easier handling. # But note that this concatenates the different chains into one long chain. # Result is mcmcChain[ stepIdx , paramIdx ] mcmcChain = as.matrix( codaSamples ) chainLength = NROW(mcmcChain) source(\"plotPost.R\") windows(width=10,height=3) layout( matrix(1:3,nrow=1) ) # Data with superimposed posterior predictive gamma's: hist( y , xlab=\"y\" , ylim=c(0,0.15) , main=\"Data\" , col=\"grey\" , prob=TRUE ) xComb=seq(min(y),max(y),length=501) nPPC = 15 for ( idx in round(seq(1,chainLength,length=nPPC)) ) {  if ( mType==\"Mean\" ) {  m = mcmcChain[idx,\"m\"]  sd = mcmcChain[idx,\"sd\"]  sh = m^2 / sd^2  ra = m / sd^2  }  if ( mType==\"Mode\" ) {  m = mcmcChain[idx,\"m\"]  sd = mcmcChain[idx,\"sd\"]  ra = ( m + sqrt( m^2 + 4*sd^2 ) ) / ( 2 * sd^2 )  sh = 1 + m * ra  }  lines( xComb , dgamma( xComb , sh , ra ) , col=\"skyblue\" , lwd=2 ) } # Posterior estimates of parameters: par( mar=c(3,1,2.5,0) , mgp=c(2,0.7,0) ) plotPost( mcmcChain[,\"m\"] , xlab=mType , main=\"Posterior Est.\" , showMode=T ) plotPost( mcmcChain[,\"sd\"] , xlab=\"sd\" , main=\"Posterior Est.\" , showMode=T ) savePlot(file=paste(fileNameRoot,mType,sep=\"\"),type=\"jpg\")"], "link": "http://doingbayesiandataanalysis.blogspot.com/feeds/3676551354329642685/comments/default", "bloglinks": {}, "links": {"http://2.blogspot.com/": 1, "http://3.blogspot.com/": 1, "http://doingbayesiandataanalysis.blogspot.com/": 1}, "blogtitle": "Doing Bayesian Data Analysis"}, {"content": ["I was asked by a reader how I created Figure 7.2 of the book, reproduced at right, which shows the progression of discrete position probabilities at each step in a simple Metropolis algorithm. I couldn't find the original program, so I made a new one, reported here, with an additional example that illustrates a bimodal target distribution. The main point is mentioned in the middle of p. 128: \"At every time step, we multiply the current position probability vector w by the transition probability matrix T to get the position probabilities for the next time step. We keep multiplying by T over and over again to derive the long-run position probabilities. This process is exactly what generated the graphs in Figure 7.2.\" The code consists of two main parts. First, build the transition matrix. Second, specify an initial position vector and repeatedly multiply by the transition matrix. Here is the code:  # For Figure 7.2, p. 123 of Doing Bayesian Data Analysis. fileNameRoot = \"DBDAfigure7pt2\" # Specify the target probability distribution. pTargetName = \"Linear\" # for filename of saved graph nSlots = 7 pTarget = 1:nSlots pTarget = pTarget/sum(pTarget) # Uncomment following lines for different example #pTargetName = \"Bimodal\" # for filename of saved graph #pTarget = c(1,2,2,1,3,3,1) #nSlots = length(pTarget) #pTarget = pTarget/sum(pTarget) # Construct the matrix of proposal probabilities. # Row is from position, column is to position. proposalMatrix = matrix( 0 , nrow=nSlots , ncol=nSlots ) for ( fromIdx in 1:nSlots ) {  for ( toIdx in 1:nSlots ) {  if ( toIdx == fromIdx-1 ) { proposalMatrix[fromIdx,toIdx] = 0.5 }  if ( toIdx == fromIdx+1 ) { proposalMatrix[fromIdx,toIdx] = 0.5 }  } } # Construct the matrix of acceptance probabilities. # Row is from position, column is to position. acceptMatrix = matrix( 0 , nrow=nSlots , ncol=nSlots ) for ( fromIdx in 1:nSlots ) {  for ( toIdx in 1:nSlots ) {  acceptMatrix[fromIdx,toIdx] = min( pTarget[toIdx]/pTarget[fromIdx] , 1 )  } } # Compute the matrix of overall move probabilities: moveMatrix = proposalMatrix * acceptMatrix # Compute the transition matrix, including the probability of staying in place: transitionMatrix = moveMatrix for ( diagIdx in 1:nSlots ) {  transitionMatrix[diagIdx,diagIdx] = 1.0 - sum(moveMatrix[diagIdx,]) } show( transitionMatrix ) # Specify starting position vector: positionVec = rep(0,nSlots) positionVec[round(nSlots/2)] = 1.0 # Loop through time steps and display position probabilities: windows(height=7,width=7) # change to x11 for non-WindowsOS layout( matrix(1:16,nrow=4) ) par( mar = c( 2.8 , 2.8 , 1.0 , 0.5 ) , mgp = c( 1.4 , 0.5 , 0 ) ) for ( timeIdx in 1:15 ) {  # Display position probability:  plot( 1:nSlots , positionVec , xlab=\"Position\" , ylab=\"Probability\" ,   type=\"h\" , lwd=5 , col=\"skyblue\" )  text( 1 , max(positionVec) , bquote(t==.(timeIdx)) , adj=c(0,1) )  # Update next position probability:  positionVec = positionVec %*% transitionMatrix } # Plot target distribution plot( 1:nSlots , pTarget , xlab=\"Position\" , ylab=\"Probability\" ,   type=\"h\" , lwd=5 , col=\"skyblue\" ) text( 1 , max(positionVec) , bquote(target) , adj=c(0,1) ) savePlot( filename=paste(fileNameRoot,pTargetName,sep=\"\") , type=\"jpg\" )  For the linearly increasing target distribution, the transition matrix looks like this:  [,1]  [,2]  [,3] [,4]  [,5]  [,6]  [,7] [1,] 0.50 0.5000000 0.0000000 0.000 0.0000000 0.00000000 0.0000000 [2,] 0.25 0.2500000 0.5000000 0.000 0.0000000 0.00000000 0.0000000 [3,] 0.00 0.3333333 0.1666667 0.500 0.0000000 0.00000000 0.0000000 [4,] 0.00 0.0000000 0.3750000 0.125 0.5000000 0.00000000 0.0000000 [5,] 0.00 0.0000000 0.0000000 0.400 0.1000000 0.50000000 0.0000000 [6,] 0.00 0.0000000 0.0000000 0.000 0.4166667 0.08333333 0.5000000 [7,] 0.00 0.0000000 0.0000000 0.000 0.0000000 0.42857143 0.5714286 The row is the \"from\" position and the column is the \"to\" position. For example, the probability of moving from position 4 to position 3 is 0.375. The resulting graph looks like this:  If you uncomment the lines that specify a bimodal target, the resulting graph looks like this:"], "link": "http://doingbayesiandataanalysis.blogspot.com/feeds/4457973812893892728/comments/default", "bloglinks": {}, "links": {"http://4.blogspot.com/": 1, "http://2.blogspot.com/": 1, "http://3.blogspot.com/": 1}, "blogtitle": "Doing Bayesian Data Analysis"}, {"content": ["The plotPost() function, which plots histograms of MCMC chains annotated with HDI and other info, was changed a few weeks ago. plotPost() now returns summary information about the chain instead of summary information about the histogram. A reader caught a conflict this caused in the program BernMetropolisTemplate.R , which has now been changed to accommodate the new plotPost() . The new programs can be found at the usual site: http://www.indiana.edu/~kruschke/DoingBayesianDataAnalysis/Programs/?M=D .The zip file with all the programs has also been updated. Please let me know right away if you find other programs that have conflicts with the new plotPost() . Greatly appreciated!"], "link": "http://doingbayesiandataanalysis.blogspot.com/feeds/6100786295351158189/comments/default", "bloglinks": {}, "links": {"http://1.blogspot.com/": 1, "http://www.indiana.edu/": 1}, "blogtitle": "Doing Bayesian Data Analysis"}, {"content": ["Consider two groups of data on a metric scale, for which we want to conduct a t test. To compute the p value of t , we need to determine its sampling distribution, which is the relative probability of all possible values of t that would be obtained from the null hypothesis if the data-collection procedure were repeated ad infinitum. Therefore ---as many statisticians have pointed out--- the sampling distribution of t depends on the stopping intention assumed by the analyst, because the stopping intention influences the relative probabilities of data sets from the null hypothesis. The conventional assumption is that data collection stopped when the sample size, N, reached a threshold. Under this conventional assumption, every imaginary sample from the null hypothesis has the same sample size, N. However, many researchers collect data until a threshold duration instead of a threshold N. There is nothing wrong with the stopping intention of threshold duration instead of threshold sample size, because the data are completely insulated from the researcher's stopping intention: The n th datum collected is uninfluenced by how many other data have been collected previously or are intended to be collected later. But the space of imaginary data that could arise from the null hypothesis does depend on the intention to stop at threshold duration, because the sample size is a random value across imaginary repetitions of the study. I have pointed this out and given examples in various articles and presentations (especially here but also here ), but many people ask about the mechanics behind the examples. This blog post shows a few simple examples. Imagine generating random data from the null hypothesis, for a fixed duration. Data appear randomly through time. Thus, for a given duration, there is a certain probability that N=4, that N=5, that N=6, and so on. For any fixed N, the sampling probability of t is given by the conventional t density. To derive the t distribution for sampling for a fixed duration, we simply add the t distributions for each possible N, weighted by the probability of getting N. That's easy to do mechanically in a computer program. All we have to do is specify p(N) for each N. As a concrete example, suppose we have data with N=8 in each of two groups. We might have gotten those data when intending to stop at N=8 in each group, that is, N=16 altogether. Then the probability of N looks like the left panel below, with a \"spike\" at N=16, and the probability of getting extreme t values from the null hypothesis is shown in the right panel below, with the critical value as in the conventional tables:  But what if the data collection involved posting a sign-up sheet for a fixed duration, so that the number of volunteers is a random value, and, moreover, the actual data is collected in a room that seats a maximum of 16 people. Then the probability distribution across sample sizes might look like the left panel below, with the resulting t distribution on the right:  Notice in the right panel (above) that the sampling distribution of t has a heavier tail and larger critical value to achieve p <.05 And what if data collection involved posting a sign-up sheet for a fixed duration, but the data-collection session is not run unless at least 16 people sign up? Then the probability distribution across sample sizes might look like the left panel below, with the resulting t distribution on the right:  Notice in the right panel (above) that the sampling distribution of t has a lighter tail and smaller critical value to achieve p <.05 Here's the problem: Suppose we are given some data, with N=16 and t obs =2.14. What is the p value? It depends on the stopping intention assumed by analyst, even though the stopping intention has no influence on the values in the data. Here's the R program for generating the plots above: # TsamplingUntilThresholdDuration.R graphics.off() rm(list=ls(all=TRUE)) fileNameRoot = \"TsamplingUntilThresholdDuration\" # Specify the probability of getting each candidate sample size N during the # fixed duration: # Nprob is relative probability of getting each N, from 0 to length(Nprob)-1: NprobSelection = c(\"LowSkew\",\"Spike\",\"HighSkew\")[1] # type 1, 2, or 3 inside [] if ( NprobSelection==\"LowSkew\" ) {  Nprob = c(0,0,0,0,0,1,2,3,4,5,6,7,8,9,10,11,12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)  Nprob = Nprob^0.1 } if ( NprobSelection==\"Spike\" ) {  Nprob = c(0,0,0,0,0,0,0,0,0,0,0,0,0,0, 0, 0,12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0) } if ( NprobSelection==\"HighSkew\" ) {  Nprob = c(0,0,0,0,0,0,0,0,0,0,0,0,0,0, 0, 0,12,11,10, 9, 8, 7, 6, 5, 4, 3, 2, 1)  Nprob = Nprob^0.1 } Nposs = 0:(length(Nprob)-1) # vector of N values for components of Nprob # Outlaw getting less than 4 total (2 per group): Nprob[1:4]=0 Nprob = Nprob/sum(Nprob) # normalize so it's a true probability distribution # Prepare plotting parameters: windows(width=10,height=5) layout( matrix(1:2,ncol=2) ) cexLab = 2.25 cexMain = 1.75 cexAxis = 1.5 cexText = 2.25 marPar = c(4,5,3,1) mgpPar = c(2.5,0.5,0) par(mar=marPar,mgp=mgpPar) # Plot the probability of each N: plot( Nposs , Nprob , type=\"h\" , lwd=3 ,   xlab=\"N total\" , ylab=\"p(N)\" ,   main=bquote(\"Probability of N in Fixed Duration\"*\"\") ,   cex.lab=cexLab , cex.main = cexMain , cex.axis=cexAxis ) text( 0 , max(Nprob) , paste(\"mode =\",Nposs[which.max(Nprob)]) , adj=c(0,1) ,   cex=cexText ) # Compute cumulative t distribution: tObs = seq(1.75,2.75,length=2001) # vector of observed t values for x axis. pAnyTgtTobs = rep(0,length(tObs)) # prob any null t greater than observed t. for ( n in 4:length(Nposs) ) { # start at 4 because df=(n-2) and Nposs[4] is 3.  pAnyTgtTobs = pAnyTgtTobs + Nprob[n] * 2 * ( 1 - pt( tObs , df=(n-2) ) ) } critVal = min( tObs[ pAnyTgtTobs <= .05 ] ) # Plot the cumulative t distribution: #windows(width=7,height=7) yLim = c(0,0.12) textHt = 0.065 plot( tObs , pAnyTgtTobs , ylim=yLim ,   xlab=bquote(t[obs]) ,   ylab=bquote(\"p( \"*abs( t[null] )*\" > \"*abs( t[obs] )*\" )\") ,   cex.lab=cexLab , cex.main = cexMain , cex.axis=cexAxis ,   main=bquote( \"Fixed Duration, modal total N=\"* .(Nposs[which.max(Nprob)]) ) ,   type=\"l\" , lwd=2 ) abline( h = 0.05 , lty=\"dashed\" ) text( 0 , 0.05 , \"p=.05\" , adj=c(0.25,-0.3) ) arrows( critVal , 0.05 , critVal , 0 , length=.1 , lwd=2.0 ) text( critVal , textHt ,   bquote( t[crit] == .(signif(critVal,3)) ) , adj=c(.25,0) , cex=cexText ) plotFileName = paste(fileNameRoot,sep=\"\") savePlot(paste(plotFileName,NprobSelection,sep=\"\"),type=\"eps\") savePlot(paste(plotFileName,NprobSelection,sep=\"\"),type=\"jpg\")"], "link": "http://doingbayesiandataanalysis.blogspot.com/feeds/6049212185922183435/comments/default", "bloglinks": {}, "links": {"http://2.blogspot.com/": 2, "http://www.indiana.edu/": 2, "http://1.blogspot.com/": 1}, "blogtitle": "Doing Bayesian Data Analysis"}, {"content": ["As an illustration of how straight forward it is in JAGS/BUGS to fit non-linear trends to data, I estimated the parameters of a sinusoid-plus-linear trend when fit to average daily temperatures. The temperatures are for Madison, Wisconsin, in honor of my Bayesian analysis workshop there next week . Conclusion: Both the approaching workshop and the linear trend in the temperatures indicate that it's getting warmer in Wisconsin! Here (below) are the data (obtained from the University of Dayton Average Daily Temperature Archive ) with a smattering of credible regression curves superimposed on the data. There are 20 curves, each using different parameter combinations from 20 widely-separated steps in the MCMC chain.   The panels at the bottom of the figure show the marginal posterior distributions of the parameters. In particular, the linear trend parameter is credibly non-zero, and suggests that on average over the last 17 years, the average daily temperature has increased by 0.059 degrees Fahrenheit per year (i.e., about 0.59 degrees per decade). Details: Here is the JAGS model statement: model {  for( i in 1 : Ndata ) {   y[i] ~ dt( mu[i] , tau , nu )   mu[i] <- beta0 + beta1 * x[i] + amp * cos( ( x[i] - thresh ) / wl )  }  beta0 ~ dnorm( 0 , 1.0E-12 )  beta1 ~ dnorm( 0 , 1.0E-12 )  tau ~ dgamma( 0.001 , 0.001 )  amp ~ dunif(0,50)  thresh ~ dunif(-183,183)   nu <- nuMinusOne + 1  nuMinusOne ~ dexp(1/29) } The predicted value, mu, is a linear trend, beta0 + beta1 * x[i] , plus a sinusoidal deviation, amp * cos( ( x[i] - thresh ) / wl ) . Notice that the data are assumed to be distributed as a t distribution, not as a normal distribution, around the predicted value mu. The heavy tails of a t distribution accommodate outliers. The df parameter of the t distribution, nu, is estimated from the data. (I put an exponential prior on nu; you can read more about \"robust estimation\" in this article .) In this version of the model, I assumed a fixed wavelength of 365.24219 days per cycle. That's a \"tropical year\". Hence the wl parameter in the model was set at 365.24219/(2*pi) to convert to radians. In other versions I estimated wl and it came out to be very close to the duration of a tropical year. Quibbles: Maybe the linear trend is an artifact because of the arbitrary alignment of start and stop dates on the cycle. Two reasons to doubt this explanation. First, the sinusoidal component is supposed to \"soak up\" variance due to the cycle, thereby reducing influence of end points of the data. Second, as a check, I constructed an artificial data set that had zero linear trend, and examined the estimated linear coefficient. To do this, I took the 2003 data and concatenated that cycle to itself 17 times. Therefore the artificial data had the same sort of alignment issues as real data. The resulting estimate of the linear trend had zero very near its mode. The sinusoid doesn't seem to capture the actual shape of the temperature cycle very accurately. The extremes in the actual temperatures seem to go beyond the peaks in the sinusoidal curve. The tails of the t distribution accommodate the high extremes in summer and the low extremes in winter, but the temperatures are not symmetrically distributed around mu throughout the year. If anyone can tell me a better model of annual temperature trends (that's also easy to write in JAGS for demo purposes), please let me know. The data violate the assumption of independence in the model. The model assumes that, on each day, the temperature is a random draw from a t distribution centered on mu, with no influence from the temperature of the previous day. Clearly this is wrong as a description of real temperatures. Does this mean the model is utterly useless and uninterpretable? Maybe not. We can think of the likelihood function, which multiplies together the t-distribution densities of all the data points, merely as a measure of fit rather than as a generative model of data. The estimated parameters tell us about the descriptive fit, not about the process that generated the data. Maybe. UPDATED WITH AUTO-REGRESSIVE AR(1) TERM HERE !"], "link": "http://doingbayesiandataanalysis.blogspot.com/feeds/2567532668410609986/comments/default", "bloglinks": {}, "links": {"http://2.blogspot.com/": 1, "http://academic.udayton.edu/": 1, "http://www.indiana.edu/": 2, "http://doingbayesiandataanalysis.blogspot.com/": 1}, "blogtitle": "Doing Bayesian Data Analysis"}, {"content": ["Instructors seek examples of using the book, Doing Bayesian Data Analysis, as part of a course. A cursory web search yielded these few listed below, but there must be others. For example, my own course web page did not show up in the search, nor did another course from which a published review of the book arose. Please let me know of other courses that use the book, and I will update this list in a subsequent post.  Applied Bayesian Modeling for the Social Sciences , Dave Armstrong Bayesian Methods , Nick Beauchamp  Statistical & Cognitive Modeling for Formal Semantics , Adrian Brasoveanu  Introduction to Bayesian Analysis , Brad Carlin  Doing Bayesian Data Analysis , John Kruschke Applied Bayesian Statistics , Marco Steenbergen Statistics VI , Tuerlinckx and Vanpaemel (from which this book review arose) Bayesian Data Analysis , Uppsala University Topics in  Quantitative Psychology: Bayesian Data Analysis (no web page), Caren Rotello, U. of Massachusetts"], "link": "http://doingbayesiandataanalysis.blogspot.com/feeds/3329143885045090172/comments/default", "bloglinks": {}, "links": {"http://www.democraticwriting.com/": 1, "http://onderwijsaanbod.kuleuven.be/": 2, "http://www.ethz.ch/": 1, "http://people.ucsc.edu/": 1, "http://doingbayesiandataanalysis.blogspot.com/": 2, "https://pantherfile.uwm.edu/": 1, "http://www.uu.se/": 1, "http://www.indiana.edu/": 2, "http://www.umn.edu/": 1}, "blogtitle": "Doing Bayesian Data Analysis"}, {"content": ["Workshop at the University of Wisconsin at Madison, July 11-13. Three full days of doing Bayesian data analysis. See details and registration info here . A list of some previous workshops is here ."], "link": "http://doingbayesiandataanalysis.blogspot.com/feeds/2968254122275469976/comments/default", "bloglinks": {}, "links": {"http://4.blogspot.com/": 1, "http://www.indiana.edu/": 2}, "blogtitle": "Doing Bayesian Data Analysis"}, {"content": ["Until today, I limited distribution of the solutions manual to instructors and other appropriate professionals. Understandably, this disappointed many people. It was only a matter of time before the solutions would be made publicly available, and now is a good time for the release because it is between major academic sessions for most schools in the northern hemisphere. The solutions manual is a 187 page document composed by the author. It is available from this link . Please note that the solutions are based on the original BUGS programs, but the recommended recent versions of the programs are in JAGS."], "link": "http://doingbayesiandataanalysis.blogspot.com/feeds/3116275003408318057/comments/default", "bloglinks": {}, "links": {"http://4.blogspot.com/": 1, "http://www.indiana.edu/": 1}, "blogtitle": "Doing Bayesian Data Analysis"}, {"content": ["In this post I show a simple illustration of a mixture of normal distributions. For the examples, we assume we have metric values that we suppose are generated by a mixture of two different normal distributions, which I'll call clusters. We don't know which datum came from each cluster. Our goal is to estimate the probability that each score came from each of the two clusters, and the means and SD of the normal distributions that describe the clusters. The model specification (for JAGS): The assumes that the clusters have the same standard deviation, but different means. model {  # Likelihood:  for( i in 1 : N ) {   y[i] ~ dnorm( mu[i] , tau )   mu[i] <- muOfClust[ clust[i] ]   clust[i] ~ dcat( pClust[1:Nclust] )  }  # Prior:  tau ~ dgamma( 0.01 , 0.01 )  for ( clustIdx in 1: Nclust ) {   muOfClust[clustIdx] ~ dnorm( 0 , 1.0E-10 )  }  pClust[1:Nclust] ~ ddirch( onesRepNclust ) }  The data specification: # Generate random data from known parameter values: set.seed(47405) trueM1 = 100 N1 = 200 trueM2 = 145 # 145 for first example below; 130 for second example N2 = 200 trueSD = 15 effsz = abs( trueM2 - trueM1 ) / trueSD y1 = rnorm( N1 ) y1 = (y1-mean(y1))/sd(y1) * trueSD + trueM1 y2 = rnorm( N2 ) y2 = (y2-mean(y2))/sd(y2) * trueSD + trueM2 y = c( y1 , y2 ) N = length(y)  # Must have at least one data point with fixed assignment  # to each cluster, otherwise some clusters will end up empty: Nclust = 2 clust = rep(NA,N)  clust[which.min(y)]=1 # smallest value assigned to cluster 1  clust[which.max(y)]=2 # highest value assigned to cluster 2  dataList = list(  y = y ,  N = N ,  Nclust = Nclust ,  clust = clust ,  onesRepNclust = rep(1,Nclust) ) Results when mean of cluster 2 is 3 standard deviations away from mean of cluster 1: The posterior recovers the generating values fairly well.    Upper panel: Data with underlying normal generators. Lower panel: For each datum, the posterior probability that it is assigned to cluster 2.    Marginal posterior on cluster means and SD.    Pairs plot of cluster means and SD.  Results when mean of cluster 2 is 2 standard deviations away from mean of cluster 1: There is lots of uncertainty. See captions for discussion.    Lower panel: Notice that the lowest and highest data values have fixed cluster assignments, but all the other data values have posterior probabilities of cluster assignment noticeably far from 0 or 1.    Notice the bimodal distribution of sigma (SD).    Notice in the in the right column that when sigma is small, around 15, then the cluster means are near their true generating values. But when sigma is large, then the cluster means get close together. Essentially, there is a bimodal posterior: Either there are two clusters, with smaller sigma and distinct means, or there is one cluster, with larger sigma and both cluster means set near the mean of the one cluster."], "link": "http://doingbayesiandataanalysis.blogspot.com/feeds/9099941696574804195/comments/default", "bloglinks": {}, "links": {"http://4.blogspot.com/": 1, "http://2.blogspot.com/": 1, "http://3.blogspot.com/": 4}, "blogtitle": "Doing Bayesian Data Analysis"}, {"content": ["In this post, I describe how it is easier to intuit the beta distribution in terms of its mode than its mean. This is especially handy when specifying a prior beta distribution. (In a previous post , I explained how it is easier to intuit the gamma distribution in terms of its mode instead of its mean.) A problem with using the mean to describe a distribution is that for skewed distributions, the mean may be far from the mode, but the mode may be what we intuitively want as the \"descriptive handle\" on the distribution, and therefore the mean is not a good surrogate for the description of central tendency. Especially when we are specifying a prior distribution, we may want to express our intuition in terms of the mode of the prior instead of the mean. For a beta distribution with shape parameters a and b, the mode is (a-1)/(a+b-2). Suppose we have a desired mode, and we want to determine the corresponding shape parameters. Here's the solution. First, we express the \"certainty\" of the estimate in terms of the equivalent prior sample size, k=a+b, with k\u22652. The certainty must be at least 2 because it essentially assumes that the prior contains at least one \"head\" and one \"tail,\" which is to say that we know each outcome is at least possible. Then a little algebra reveals: a = mode * (k-2) + 1 b = (1-mode) * (k-2) + 1 Here are a few examples:     The book expressed beta distributions in terms of mean and certainty instead of mode and certainty; cf. Eqn. 5.5, p. 83, where m denoted the mean and n denoted the certainty instead of k used here."], "link": "http://doingbayesiandataanalysis.blogspot.com/feeds/1981158748768549514/comments/default", "bloglinks": {}, "links": {"http://4.blogspot.com/": 1, "http://2.blogspot.com/": 1, "http://1.blogspot.com/": 1, "http://doingbayesiandataanalysis.blogspot.com/": 1}, "blogtitle": "Doing Bayesian Data Analysis"}, {"content": ["New version of May 27, 2012: Bayesian estimation for two groups provides complete distributions of credible values for the effect size, group means and their difference, standard deviations and their difference, and the normality of the data. The method handles outliers. The decision rule can accept the null value (unlike traditional t tests) when certainty in the estimate is high (unlike Bayesian model comparison using Bayes factors). The method also yields precise estimates of statistical power for various research goals. The software and programs are free, and run on Macintosh, Linux, and Windows platforms. See this linked page for the latest paper and the software . Search tag: BEST (for Bayesian estimation) (This is the second revision of a the first version announced at a previous post .)"], "link": "http://doingbayesiandataanalysis.blogspot.com/feeds/8199794560111583602/comments/default", "bloglinks": {}, "links": {"http://4.blogspot.com/": 1, "http://www.indiana.edu/": 1, "http://doingbayesiandataanalysis.blogspot.com/": 1}, "blogtitle": "Doing Bayesian Data Analysis"}, {"content": ["A previous post reported an analysis of a \"split plot\" design, in which one factor is between subjects and a second factor is within subjects. That program has now been revised, and the advantage of Bayesian analysis over NHST has been confirmed. My heartfelt thanks to Wolf Vanpaemel for pointing out an error in one of the contrast analyses in the originally posted program. I have now corrected the error and expanded the program to handle the intended contrast. Subsequent discussion with Wolf also prompted me to think harder about whether the model I specified really matched the model used by NHST analyses, and whether the apparent advantage of the Bayesian analysis (reported in the previous post) really made sense. They do, as I explain below. I also revised other aspects of the program to incorporate the improvements in the most recent forms of the other ANOVA-type programs, as reported at this previous post . (By the way, you may recall that Wolf and co-author Francis Tuerlinckx wrote a review of the book .) A reminder of the split plot design: Consider an example provided by Maxwell & Delaney (2004, Designing Experiments and Analyzing Data: A Model Comparison Perspective , 2nd Edition, Erlbaum; Ch. 12). (As I've mentioned elsewhere, if you must learn NHST, their book is a great resource.) A perceptual psychologist is studying response times for identifying letters flashed on a screen. The letters can be rotated off of vertical by zero degrees, four degrees, or eight degrees. Every subject responds many times to letters at each of the three angles. The experimenter (for unknown reasons) analyzes only the median response time of each subject at each angle. Thus, each subject contributes only one datum at each level of angle (factor B) . There are two types of subjects: \"young\" and \"old.\" Age of subject is factor A. The structure of the data is shown below. Y is the median response time, in milliseconds. There are 10 subjects per Age group.      Y  Subj  Angle  Age   450  1  B1(Zero)  A1(Young)   510  1  B2(Four)  A1(Young)   630  1  B3(Eight)  A1(Young)   390  2  B1(Zero)  A1(Young)   480  2  B2(Four)  A1(Young)   540  2  B3(Eight)  A1(Young)   ...  ...  ...  ...   510  10  B1(Zero)  A1(Young)   540  10  B2(Four)  A1(Young)   660  10  B3(Eight)  A1(Young)   420  11  B1(Zero)  A2(Old)   570  11  B2(Four)  A2(Old)   690  11  B3(Eight)  A2(Old)   600  12  B1(Zero)  A2(Old)   720  12  B2(Four)  A2(Old)   810  12  B3(Eight)  A2(Old)   ...  ...  ...  ...   510  20  B1(Zero)  A2(Old)   690  20  B2(Four)  A2(Old)   810  20  B3(Eight)  A2(Old)  (More info appears at the original post .) An advantage of Bayesian analysis: The original post showed that the main effect of age, that is, the between-subject factor, was credibly non-zero, which agreed with the result from NHST, which had a p value a little under .05. The estimated magnitude of difference between Old and Young closely matched the marginal means in the data. But the 95% HDI on the difference was very precise compared with the NHST confidence interval. In other words, the Bayesian analysis was much more powerful. The diference was dramatic, so I expressed some doubt in the original post. But I am now convinced that the difference is real and correct. Essentially, the Bayesian analysis estimates all the parameters simultaneously, and creates a single, fixed posterior distribution over multi-dimensional parameter space. We then examine the posterior from difference perspectives, such as, for example, collapsing across all dimensions except Old minus Young, or collapsing across all dimensions except Four degrees minus Zero degrees. We do not \"re-scale\" the posterior for different perspectives on the parameters. In NHST, on the other hand, different tests can have different error terms in their F ratios, which means that different comparisons are scaled differently. In particular, the F ratio for Old versus Young uses a different error term (i.e., denominator) than the F ratio for Four degrees versus Zero degrees, and it turns out that the former error term is larger than the latter error term, hence the former test is not as powerful, relatively speaking. Bayes is better! The models in the Bayesian analysis and in classical ANOVA: In classical ANOVA, the model analyzes the data variance into five components plus residual noise. (See Maxwell & Delaney, Ch. 12, cited above.) The five components are: (1) the (between-subect) main effect, A, (2) the (within-subject) main effect, B, (3) the main effect of subject within levels of A, S/A, (4) the interaction AxB, and (5) the interaction of B with subjects within levels of A, BxS/A. It turns out that the five components actually use up all the variance, so there is zero residual noise remaining. Another way of thinking about it is that the BxS/A interaction term cannot be identified separately from the noise , because there is only one measurement per cell of the design. (That is also why the BxS/A term is used as the error term for some of the F ratios.) Therefore the model I've used in the Bayesian analysis does not include a BxS/A term: for ( i in 1:Ntotal ) {  y[i] ~ dnorm( mu[i] , tau )  mu[i] <- base + a[aLvl[i]] + s[sLvl[i]] + b[bLvl[i]] + axb[aLvl[i],bLvl[i]]  # The model has no BxS term because that would leave zero noise variance. } The model remains unchanged from the original program; the news here is explicitly explaining it.  The corrected contrast analysis: The original post included a few different contrast analyses. One was programmed incorrectly, because I mistakenly put it in the section for interaction contrasts, instead of creating a new section for so-called \"simple\" contrasts. While correcting the code, I also re-expressed the contrasts in the more meaningful new format reported at this previous post . Thus, instead of just a matrix of numerical contrast coefficients without clear meaning, the new code uses logical referencing with the level names, like this: simpleContrastList = list(  A1B1vA2B1 = ( outer(aLvlNames==\"A2(Old)\",bLvlNames==\"B1(Zero)\")     - outer(aLvlNames==\"A1(Young)\",bLvlNames==\"B1(Zero)\") ) ) That code simply means to compute the difference of \"A2(Old),B1(Zero)\" and \"A1(Young),B1(Zero)\", that is, the difference of Old and Young at Zero degrees angle. If you haven't previously tried programming a contrast, that code might still look mysterious, but once you get the hang of it, it's more meaningful and resistant to inadvertent re-ordering of levels than the old format: simpleContrastList = list(  A1B1vA2B1 = matrix( c(1,0,0,-1,0,0) , nrow=2 , byrow=TRUE ) ) While that old form is shorter, it is less meaningful because it does not show the names of the levels being referred to, and it is easily broken if the levels get re-ordered by different operating system conventions for alphabetizing. One more change: The computation of the simple contrast, at the end of the program, relies on a new section of code. Other revisions in the program: I also changed the prior specification in the model, as explained at this previous post . For example, here is the prior on the main effect of A: for ( j in 1:NaLvl ) { a[j] ~ dnorm( 0.0 , aTau ) } aTau <- 1 / pow( aSD , 2 ) aSD ~ dgamma(1.221,0.003683) # mode=60,sd=300. Change for scale of data! The estimate of the standard deviation of the A effect, aSD , has a gamma prior that has a mode at 60 with declining density toward zero, instead of a \"generic\" uniform or folded-t or gamma that has notable mass near zero. Thanks again to Wolf for finding the error in the contrast analysis and spurring the revisions! Get the revised program here and the data file here ."], "link": "http://doingbayesiandataanalysis.blogspot.com/feeds/3467745414817549583/comments/default", "bloglinks": {}, "links": {"http://ppw.kuleuven.be/": 2, "http://3.blogspot.com/": 1, "http://www.indiana.edu/": 2, "http://doingbayesiandataanalysis.blogspot.com/": 6}, "blogtitle": "Doing Bayesian Data Analysis"}, {"content": ["I'll be doing a week-long workshop at the Inter-university Consortium for Political and Social Research (ICPSR), at the University of Michigan, Ann Arbor, June 11-15. Details are here .  A list of future and past workshops can be found here ."], "link": "http://doingbayesiandataanalysis.blogspot.com/feeds/6501007891981247313/comments/default", "bloglinks": {}, "links": {"http://1.blogspot.com/": 1, "http://www.indiana.edu/": 2}, "blogtitle": "Doing Bayesian Data Analysis"}, {"content": ["In this post I contrast conventions for illustrating hierarchical models. On the one hand, there is the traditional convention as used, for example, by DoodleBUGS. On the other hand, there is the style used in Doing Bayesian Data Analysis (DBDA). I explain the advantages of the style in DBDA. Consider a generic model for Bayesian linear regression. The graphical model diagram in DBDA looks like this:   Graphical diagram in Doing Bayesian Data Analysis . A corresponding graphical model diagram in DoodleBUGS looks something like this:   Graphical diagram from DoodleBUGS . The DoodleBUGS diagrams are much like conventional graphical diagrams used in computer science and statistics. Which diagram is better for explaining the model? For me, it's the diagrams in DBDA .  The diagrams in DBDA show at a glance what the distribution is for each variable. By contrast, the diagrams in DoodleBUGS do not show the distributions at all. Instead, you have to cross reference the equations, shown elsewhere. The diagrams in DBDA show which parameters \"live together\" in the same distribution. For example, \u03bc i and \u03c4 are seen to be the mean and precision of the same normal distribution. By contrast, the diagrams in DoodleBUGS do not show which distributions the parameters \"live in\". For example, we do not know from the diagram whether \u03bc i and \u03c4 are in the same distribution or not. To find out, you have to look the equations, shown elsewhere. There are other explanatory advantages of the format in DBDA. In particular, the icons of the distributions show directly whether a variable is discrete or continuous, and its range. For example, the icon of the gamma distribution shows that the variable is continuous and has a lower bound. The icon of the Bernoulli distribution (not illustrated here, but repeatedly in the book) shows that the variable has two discrete values. By contrast, conventional diagrams like DoodleBUGS indicate continuous versus discrete by the arbitrary shape of the figure that surrounds the variable: oval for continuous and square for discrete. Or was it oval for discrete and square for continuous? It's easy to get confused by arbitrary conventions. Which diagram is better for understanding the corresponding JAGS/BUGS model specification? For me, it's the diagrams in DBDA . The key reason is that the diagrams in DBDA have a much more direct correspondence to lines of code in JAGS/BUGS: (Usually) each arrow in the DBDA diagram corresponds to a line of code in the JAGS/BUGS model specificaion . Notice in the DBDA diagram above, there are five arrows. Each arrow has a corresponding line of code in the model specification:  Notice that the DoodleBUGS diagram also has five arrows, but those arrows have no direct correspondence to the model specification! In particular, there is no line of code that says y is related to tau, and a separate line of code that says y is related mu, and a separate line of code that says mu is related to alpha, and another line of code that says mu is related to beta. The style of diagrams in DBDA are a direct expression of the conceptual distributions and dependencies in the model. And, if you can draw such a picture, it is relatively straightforward to express it in JAGS/BUGS. But the conventional diagrams like DoodleBUGS leave out a huge amount of important conceptual information, and provide little guidance for how to express the model in JAGS/BUGS. Thus, both pedagogically and practically, I prefer the diagrams in DBDA. One thing that might be improved in the DBDA diagrams is the specification of iteration . In its current form, iteration is indicated ambiguously with an ellipsis that does not indicate explicitly which index is being iterated. In some hierarchical models it can be unclear which index is implied. This could be clarified by using some sort of \"plate\" notation like what is used in DoodleBUGS, but when plates are drawn in the DBDA diagrams, the overall effect gets visually messy. A simple fix is simply to indicate the index and its limits next to the ellipsis ."], "link": "http://doingbayesiandataanalysis.blogspot.com/feeds/828775613818160485/comments/default", "bloglinks": {}, "links": {"http://4.blogspot.com/": 1, "http://1.blogspot.com/": 2, "http://www.ac.uk/": 2}, "blogtitle": "Doing Bayesian Data Analysis"}, {"content": ["Consider a generic model for simple linear regression. The data are metric values, modeled as coming from a normal distribution that has mean parameter \u03bc=\u03b2 0 +\u03b2 1 x 1 and precision parameter \u03c4 (=1/\u03c3 2 ). The priors on the intercept and slope parameters (\u03b2 0 and \u03b2 1 ) are normal, and the prior on the precision is gamma. Notice that the description of the model started with the nature of the data, then described the likelihood function, then described the prior. This is the sequential order of description that makes sense for communicating to people. First you have to know the nature of the data being modeled. Next, you have to know the choice of likelihood function. For example, the metric data might have been modeled by a normal distribution, or by a log-normal distribution, or by a Weibull distribution, or by a t distribution, or whatever. Each of those likelihood functions has different parameters. Once the likelihood function is specified, with its corresponding parameters, then it makes sense to talk about the prior on those parameters. The JAGS/BUGS code, in all the book's programs, specifies the model details in that order: from data, to likelihood, to prior. For example, here is the model specification for simple linear regression:  But, unlike the JAGS/BUGS code, the hierarchical diagrams in the book put the data at the bottom and the priors on the top. This might feel \"upside down\" relative to the JAGS/BUGS code, but the diagrams are forced to be this way because of pre-existing conventions for drawing probability distributions. The convention is to put the parameter axis on the abscissa (x axis), with the probability density on the ordinate (y axis). Therefore the parameter being modeled must be oriented at the bottom, and the parameters describing the density must be at the top, like this:  Therefore, the hierarchical diagrams should always be read starting at the bottom, then working upward."], "link": "http://doingbayesiandataanalysis.blogspot.com/feeds/6894477623451900634/comments/default", "bloglinks": {}, "links": {"http://4.blogspot.com/": 1, "http://2.blogspot.com/": 1}, "blogtitle": "Doing Bayesian Data Analysis"}, {"content": ["An interesting recent article emphasized that asking students to generate what should be reported from a Bayesian analysis also gets them to think about why things need to be reported, which in turn can get students to understand better how Bayesian analysis works and what it means. In this blog post I briefly summarize the article, compare it with the recommendations for reporting a Bayesian analysis in Doing Bayesian Data Analysis, and suggest that there are some important points for reporting that might be difficult for beginning students to generate on their own. The article is: Pullenayegum, E. M., Guo, Q., & Hopkins, R. B. (2012). Developing critical thinking about reporting of Bayesian analyses. Journal of Statistics Education , 20(1). It's available at this link . Here are some excerpts: [Abstract:] Whilst there are published guidelines on reporting of Bayesian analyses, students should also be encouraged to think about why some items need to be reported whereas others do not. We describe a classroom activity in which students develop their own reporting guideline. ... [Section 1:] Since Bayesian analyses are far less widely used in medicine [than frequentist analyses], it is difficult for students to gauge what is typical. Thus, teaching students how to report Bayesian analyses in the medical literature is an important component of a course in Bayesian biostatistics. When teaching reporting, we need to avoid training students to follow a set of rules unthinkingly. Rather we need to focus on helping students to think critically about what is needed. That is, we need to teach not just the \u201cwhat\u201d, but also the \u201cwhy\u201d. ... [Section 4.4:] Two of us (RBH and QG) participated in the first implementation of the exercise as students. As the exercise progressed, we found ourselves thinking as readers, reviewers or editors rather than as the statistician or author. ... [Section 5:] The value of the activity is in the learning process rather than the guideline itself. The exercise itself consists of students anonymously generating candidate items for inclusion, then having the items collated onto a master list of candidates, then rating the items for importance and discussing why they are important. (See the article for details about the group dynamic.) Importantly, but perhaps not emphasized enough in the article, the instructor can (and did) anonymously contribute items to the list during the first round. This strikes me as a very useful exercise for students, and I may try some variation of it myself next time I teach my course. The article reports the lists of items generated by two different classes. The lists included points about the prior distributions, the likelihood function, the analysis technique, and the results. Please see Table 1 of the article for details. Although the emphasis of the article was on getting students to think about why items should or need not be reported, rather than on the actual list created, it is still informative to see what items the students settled on, and whether anything went missing that might be considered to be important. In particular, it's natural for me to compare the student-generated lists with my own recommendations in Doing Bayesian Data Analysis (Ch. 23, pp. 620-622):     There is notable overlap with items in the student-generated lists, but the first two \"essential\" points raised in DBDA were not emphasized by the students. These points are (1) Motivate the use of Bayesian (non-NHST) analysis, and (2) Clearly describe the model and its parameters. Both of these points are about reporting the forest before reporting the trees. Both of these points are about contextualizing the analysis and giving it meaning. In particular, the second point entails the idea that the model is a particular description of data, selected from the space of all possible models because it is meaningful in the particular context. Finally, the \"essential\" points in DBDA are meant to be reported in sequence. This temporal, sequential order of points is important for the comprehensibility of the report. For example, the likelihood function and its parameters must be explained before the prior and its parameters can be explained. (And the structure of the data must be explained before the likelihood function can be described.) I think that all these issues ---motivating use of Bayesian analysis, describing the model and parameters, and reporting in a particular sequential order--- are about understanding the larger context in which statistical analysis resides, and this larger context might be relatively difficult for beginning students to apprehend. Therefore instructors who adopt the exercise, of students generating guidelines for reporting, may want to seed the candidate list with these sorts of items, or at least be sure that they are brought up during discussion."], "link": "http://doingbayesiandataanalysis.blogspot.com/feeds/2873576327885833829/comments/default", "bloglinks": {}, "links": {"http://www.amstat.org/": 2, "http://3.blogspot.com/": 1, "http://2.blogspot.com/": 1, "http://1.blogspot.com/": 1}, "blogtitle": "Doing Bayesian Data Analysis"}, {"content": ["I'll be doing a workshop at the meeting of the Association for Psychological Science in Chicago, Thursday May 24. Details can be found here . (I'm also doing a workshop in Chicago on May 4; details here .) A list of future and past workshops can be found here ."], "link": "http://doingbayesiandataanalysis.blogspot.com/feeds/1577708163430933073/comments/default", "bloglinks": {}, "links": {"http://1.blogspot.com/": 1, "http://www.indiana.edu/": 3}, "blogtitle": "Doing Bayesian Data Analysis"}, {"content": ["I've made three important changes in the programs for hierarchical Bayesian ANOVA.  First, I changed the hyperprior on the variance (standard deviation) parameters. I was never pleased with the \"+.1\" kludge that I used in the book, explained on p. 496: \"There is one other trick in the BUGS model specification that is not in the hierarchical diagram of Figure 18.1. One line of the BUGS model specifies that the standard deviation of the group effects, denoted aSDunabs, comes from a t distribution: aSDunabs ~ dt(0,0.001,2). Another line takes the absolute value to \u201cfold\u201d the t distribution onto the nonnegative numbers: aSD <- abs(aSDunabs) + .1. But that line also mysteriously adds a small constant, namely 0.1. This constant keeps aSD from venturing extremely close to zero. The reason for keeping aSD away from zero is that shrinkage can become overwhelmingly strong when there are many groups with few data points per group. This becomes especially problematic in the next chapter when we consider interaction of factors.\" A problem with that kludge is that the aSD parameter can never be less than 0.1, which is unlikely to reflect a real prior belief. It can produce strangely truncated posterior distributions. Therefore I simply abandoned the folded-t prior (recommended by Gelman, 2006) and used a reasonable gamma instead. The gamma prior, for each SD parameter, has a mode at 0.1 and a standard deviation of 10, which seems to be an appropriate scaling when the data are standardized (as indeed they are in the programs). Here's a picture of this prior:  The neat thing about this prior is that it smoothly drops down to zero as the parameter value gets close to zero. (For how to specify a gamma prior with a desired mode and standard deviation, see this previous blog post .) The prior on the within-cell SD remains uniform, as in the original programs and recommended by Gelman (2006). Second, I changed the plots of the variance parameters so that they are on the original data scale , not the standardized scale. This was achieved merely by multiplying by ySDorig . Third, I changed how contrasts are specified. The original method was problematic because the contrasts were specified as vectors of contrast coefficients, which (a) lacked explicit meaning and (b) only made sense if the order of the levels of the factors was exactly as assumed by the contrast coefficients. Unfortunately, it turns out that different settings of R's \"locale\" can produce different orderings of the factor levels, rendering the contrast coefficients nonsensical! (Thanks to Damion Junk for pointing out this problem to me.) The new method uses logical indexing of named levels, so that the contrast specification is meaningful and independent of local ordering conventions. For example, for the mussel muscle data, the old contrast specification was contrastList = list( ...  ORE1vORE2 = c(1,-1,0,0,0) ,  ALAvORE = c(-1/2,-1/2,1,0,0) ,  ... ) but the new specification is normalize = function( v ){ return( v / sum(v) ) }  contrastList = list( ...  ORE1vORE2 = (xnames==\"OregonN\")-(xnames==\"OregonT\") ,  ALAvORE = (xnames==\"Alaska\")-normalize(xnames==\"OregonN\"|xnames==\"OregonT\") ,  ... ) Fourth, I improved the program for displaying posterior histograms , so that it now defaults to better breaks based on the HDI. Therefore it is best to use plotPost without a breaks argument unless the (new) default looks bad. Where are the new programs? Get the updated files, ANOVAonewayJagsSTZ.R, ANOVAtwowayJagsSTZ.R, plotPost.R, and McDonaldSK1991data.txt, from the usual place (click the column labeled \"Last Modified\" to get the most recent listed first). ** Updated April 25, 2012. Also with the program PoissonExponentialJagsSTZ.R **"], "link": "http://doingbayesiandataanalysis.blogspot.com/feeds/7685633590557405107/comments/default", "bloglinks": {}, "links": {"http://4.blogspot.com/": 1, "http://damionjunk.com/": 1, "http://www.indiana.edu/": 1, "http://doingbayesiandataanalysis.blogspot.com/": 1}, "blogtitle": "Doing Bayesian Data Analysis"}]
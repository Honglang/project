[{"blogurl": "http://bayesianbiologist.com\n", "blogroll": [], "title": "bayesianbiologist"}, {"content": ["After a bit of a summer lull, the Montreal R User Group is meeting up again! We\u2019re trying out a new venue this time. Notman House is the home of the web in Montreal. They hold hackathons and other tech user group meetups, and they are all around great people in an all around great space in downtown Montreal. \n Our meetup will feature R super-user Etienne Low-Decarie , who will give a walk through of some of the most powerful packages in R, many of which were built by rstats rock star Hadley Wickham . \n I will also kick off the meetup with a short session on how R is revolutionizing data science in academia, journalism, business and beyond. \n \n November 14th, 7pm at 51 Sherbrooke W. \n BYOL&D (Bring Your Own Laptop & Data) \n \n Don\u2019t forget to RSVP . Hope to see you there!"], "link": "http://bayesianbiologist.com/2012/10/29/montreal-r-user-group-meetup-nov-14th/", "bloglinks": {}, "links": {"http://notman.org/": 1, "http://feeds.wordpress.com/": 1, "http://etienne.webhop.org/": 1, "http://bayesianbiologist.wordpress.com/": 1, "http://had.co.nz/": 1, "http://www.meetup.com/": 2}, "blogtitle": "bayesianbiologist"}, {"content": ["I recently posted the slides from a guest lecture that I gave on Bayesian methods for biologists/ecologist. In an effort to promote active learning , the class was not a straight forward lecture, but rather a combination of informational input from me and opportunities for students to engage with the concepts via activities and discussion of demonstrations. These active components were designed with the goal of promoting students\u2019 construction of knowledge, as opposed to a passive transfer from teacher to learner. \n In order to bring the online reader into closer allignment with the experience of attending the class, I have decided to provide the additional materials that I used to promote active learning. \n 1) Monte-Carlo activity: \n In pairs, students are provided with a random number sheet and a circle plot handout : \n  \n One student is the random number generator, the other is the plotter. After students plot a few points, we collect all the data and walk through a discussion of why this works. We then scale up and take a look at the same experiment using a computer simulation to see how our estimate converges toward the correct value. \n  \n 2) Metropolis-Hastings in action: \n In this demonstration, we walk through the steps of the MH algorithm visually . \n  \n Discussion is then facilitated regarding the choice of proposal distribution, autocorrelation, and convergence diagnosis around this demonstration. \n I hope that you find this helpful. If you are teaching this topic in your class, feel free to borrow, and improve upon, these materials. If you do, drop me a note and let me know how it went!"], "link": "http://bayesianbiologist.com/2012/10/19/introduction-to-bayesian-lecture-accompanying-handouts-and-demos/", "bloglinks": {}, "links": {"http://www.mcgill.ca/": 1, "http://feeds.wordpress.com/": 1, "http://bayesianbiologist.com/": 1, "http://madere.mcgill.ca/": 7}, "blogtitle": "bayesianbiologist"}, {"content": ["This is a talk I gave this week in Advanced Biostatistics at McGill. The goal was to provide an gentle introduction to Bayesian methodology and to demonstrate how it is used for inference and prediction. There is a link to an accompanying R script in the slides."], "link": "http://bayesianbiologist.com/2012/10/18/introduction-to-bayesian-methods-guest-lecture/", "bloglinks": {}, "links": {"http://biology.mcgill.ca/": 1, "http://feeds.wordpress.com/": 1}, "blogtitle": "bayesianbiologist"}, {"content": ["The three benchmark algorithms for predicting the location of dark matter halos are, for the most part, all over the map. Most of the test skies look something like this: \n  \n There are, however, some skies with rather strong halo signals that get a decent amount of agreement: \n  \n The Lenstool MLE algorithm is the current state of the art. As such, it\u2019s the algo to beat. As of this morning, there was only one entry on the leader board with a score topping this benchmark. \n *cracks fingers* \u2013 Let\u2019s see if we can give it a run for it\u2019s money."], "link": "http://bayesianbiologist.com/2012/10/14/dark-matter-benchmarks-all-over-the-map/", "bloglinks": {}, "links": {"http://feeds.wordpress.com/": 1, "http://bayesianbiologist.com/": 1, "http://bayesianbiologist.wordpress.com/": 2}, "blogtitle": "bayesianbiologist"}, {"content": ["Some people like to do crossword puzzles. I like to do machine learning puzzles. \n Lucky for me, a new contest was just posted yesterday on Kaggle . So naturally, my lazy Saturday was spent getting elbow deep into the data. \n The training set consists of a series of \u2018skies\u2019, each containing a bunch of galaxies. Normally, these galaxies would exhibit random ellipticity. That is, if it weren\u2019t for all that dark matter out there! The dark matter, while itself invisible (it is dark after all), tends to aggregate and do some pretty funky stuff. These aggregations of dark matter produce massive halos which bend the heck out of spacetime itself! The result is that any galaxies behind these halos (from our perspective here on earth) appear contorted around the halo. \n The tricky bit is to distinguish between the background noise in the ellipticity of galaxies, and the regular effect of the dark matter halos. How hard could it be? \n Step one, as always, is to have a look at what you\u2019re working with using some visualization. \n  An example of the training data. This sky has 3 dark matter halos. I f you squint, you can kind of see the effect on the ellipticity of the surrounding galaxies. \n If you want to try it yourself, I\u2019ve posted the code here . \n If you don\u2019t feel like running it yourself, here are all 300 skies from the training set. \n\n \n Now for the simple matter of the predictions. Looks like Sunday will be a fun day too! Stay tuned\u2026"], "link": "http://bayesianbiologist.com/2012/10/13/observing-dark-worlds-visualizing-dark-matters-distorting-effect-on-galaxies/", "bloglinks": {}, "links": {"http://feeds.wordpress.com/": 1, "http://www.kaggle.com/": 1, "https://gist.github.com/": 1, "http://bayesianbiologist.wordpress.com/": 1}, "blogtitle": "bayesianbiologist"}, {"content": ["On Friday, I gave a guest lecture on statistics to a group of biology students at Dawson College in Montreal. We had some fun testing whether name brand cookies contained more chocolate chips, on average, than generic brand cookies."], "link": "http://bayesianbiologist.com/2012/09/29/guest-lecture-at-dawson-college/", "bloglinks": {}, "links": {"http://feeds.wordpress.com/": 1}, "blogtitle": "bayesianbiologist"}, {"content": ["If you\u2019ve ever written code that generates a whole whack of files, you may have came across the following problem when processing them. Using a naming convention wherein files are numbered will\u00a0 gum up any ordering which is based on string sorting ( ls , for example). What you end up with is something like this: \n \nresults10.txt\nresults11.txt\nresults12.txt\nresults1.txt\nresults2.txt\n...\n \n Which is just no good, no good at all. A solution to this is to pad the file number with zeros, like so: \n \nresults0001.txt\nresults0002.txt\n...\nresults0010.txt\n \n I wrote a little function to make this easy: \n \npad_int<-function(n,scale){\n out_string<-paste(10*scale + n,sep='')\n out_string<-substr(out_string,2,nchar(out_string))\n return(out_string)\n}\n \n *EDIT: Very soon after posting this, ggplot creator and general rstats rockstar Hadley Wickham noted on twitter that you can do this in one line using: \n \nsprintf(\u201c%03d\u201d, 1)\n \n Then, simply pass this function your file number (n) and the number of zeros that you\u2019d like to pad it with (scale). This should be the order of magnitude of the number of files you\u2019re creating. For example: \n \nfor(i in 1:1000){\n padded<-pad_int(i,1000)\n file_name<-paste('results_',padded,'.txt',sep='')\n print(file_name)\n}\n \n This little bit of code came in quite handy in generating this video of dispersal on a discrete lattice . Enjoy!"], "link": "http://bayesianbiologist.com/2012/09/29/padding-integers-for-use-in-filenames/", "bloglinks": {}, "links": {"http://statistics.rice.edu/": 1, "http://feeds.wordpress.com/": 1, "http://en.wikipedia.org/": 1, "http://bayesianbiologist.com/": 1}, "blogtitle": "bayesianbiologist"}, {"content": ["*Edit: I made a video! \n Dispersal is a key process in many domains, and particularly in ecology. Individuals move in space, and this movement can be modelled as a random process following some kernel. The dispersal kernel is simply a probability distribution describing the distance travelled in a given time frame. Since space is continuous, it is natural to use a continuous kernel. However, some modelling frameworks are formulated on a lattice, or discrete array of patches. \n So how can we implement a continuous kernel in discrete space? \n As with many modelling situations, we could approach this in a number of ways.\u00a0 Here is the implementation that I can up with, and I welcome your suggestions, dear reader, for alternatives or improvements to this approach. \n \n Draw a random variate d from the dispersal kernel. \n Draw a uniform random number \u03b8 between 0 and 2\u03c0, which we will use to choose a direction. \n Calculate the relative location (in continuous space) of the dispersed individuals using some trig: \n \u00a0\u00a0\u00a0\u00a0 x\u00a0 = cos(\u03b8) d \n \u00a0\u00a0\u00a0\u00a0 y = sin(\u03b8) d \n Determine the new location on the lattice for each individual by adding the relative x and y positions to the current location. Round these locations to the nearest integer and take the modulo of this integer and the lattice size. This creates a torus out of the lattice such that the outer edges loop back on each other. If you remember the old Donkey Kong games, you can think of this like how when you leave out the right side of the screen you enter from the left. \n \n I implemented this approach in R as a function that takes in a population in a lattice, and returns a lattice with the dispersed population. The user can also specify which dispersal kernel to use. Here is the result using a negative-exponential kernel on a 50\u00d750 lattice. \n  \n Created by iterating over the dispersal function: \n \n## General function to take in a lattice and disperse\n## according to a user provided dispersal kernel\n## Author: Corey Chivers\nlat_disp<-function(pop,kernel,...)\n{\nlattice_size<-dim(pop)\nnew_pop<-array(0,dim=lattice_size)\nfor(i in 1:lattice_size[1])\n{\nfor(j in 1:lattice_size[2])\n{\nN<-pop[i,j]\ndist<-kernel(N,...)\ntheta<-runif(N,0,2*pi)\nx<-cos(theta)*dist\ny<-sin(theta)*dist\n\nfor(k in 1:N)\n{\nx_ind<-(round(i+x[k])-1) %% lattice_size[1] + 1\ny_ind<-(round(j+y[k])-1) %% lattice_size[2] + 1\nnew_pop[x_ind,y_ind]<-new_pop[x_ind,y_ind]+1\n}\n}\n}\nreturn(new_pop)\n}\n \n For comparison, I also ran the same population using a Gaussian kernel. I defined the parameters of both kernels to have a mean dispersal distance of 1. \n Here is the result using a Gaussian kernel: \n  \n The resulting population after 35 time steps has a smaller range than when using the exponential kernel, highlighting the importance of the shape of the dispersal kernel for spreading populations (remember that in both cases the average dispersal distance is the same). \n Code for generating the plots: \n \n############## Run and plot #######################\n\n## Custom colour ramp\ncolours<-c('grey','blue','black')\ncus_col<-colorRampPalette(colors=colours, space = c(\"rgb\", \"Lab\"),interpolate = c(\"linear\", \"spline\"))\n\n## Initialize population array\nTime=35\npop<-array(0,dim=c(Time,50,50))\npop[1,25,25]<-10000\n\n### Normal Kernel ###\npar(mfrow=c(1,1))\nfor(i in 2:Time)\n{\nimage(pop[i-1,,],col=cus_col(100),xaxt='n',yaxt='n')\npop[i,,]<-lat_disp(pop[i-1,,],kernel=rnorm,mean=0,sd=1)\n}\n\n## Plot\npng('normal_kern.png', width = 800, height = 800)\npar(mfrow=c(2,2),pty='s',omi=c(0.1,0.1,0.5,0.1),mar=c(2,0,2,0))\ntimes<-c(5,15,25,35)\nfor(i in times)\nimage(pop[i-1,,],\ncol=cus_col(100),\nxaxt='n',\nyaxt='n',\nuseRaster=TRUE,\nmain=paste(\"Time =\",i))\n\nmtext(\"Gaussian Kernel\",outer=TRUE,cex=1.5)\ndev.off()\n\n### Exponential Kernel ###\npar(mfrow=c(1,1))\nfor(i in 2:Time)\n{\nimage(pop[i-1,,],col=cus_col(100),xaxt='n',yaxt='n')\npop[i,,]<-lat_disp(pop[i-1,,],kernel=rexp,rate=1)\n}\n\n## Plot\npng('exp_kern.png',\u00a0 width = 800, height = 800)\npar(mfrow=c(2,2),pty='s',omi=c(0.1,0.1,0.5,0.1),mar=c(2,0,2,0))\ntimes<-c(5,15,25,35)\nfor(i in times)\nimage(pop[i-1,,],\ncol=cus_col(100),\nxaxt='n',\nyaxt='n',\nuseRaster=TRUE,\nmain=paste(\"Time =\",i))\n\nmtext(\"Exponential Kernel\",outer=TRUE,cex=1.5)\ndev.off()\n\n############################################################"], "link": "http://bayesianbiologist.com/2012/09/27/continuous-dispersal-on-a-descrete-lattice/", "bloglinks": {}, "links": {"https://www.youtube.com/": 1, "http://feeds.wordpress.com/": 1, "http://bayesianbiologist.wordpress.com/": 2}, "blogtitle": "bayesianbiologist"}, {"content": ["At last weekend\u2019s Hack Ta Ville event here in Montreal, I joined up with some talented urban planners and web devs to realize V\u00e9lobstacles . The idea of the project is to crowd source information on cycling conditions around the city. As with any crowd sourcing project, we were faced with the problem of seeding the site with some data to draw the attention of users to get the ball rolling. \n Fortunately, we had access to a data set of all reported cycling accidents between 2006-2010 . Once we seeded V\u00e9lobstacles with this data, the web devs went to town adding features to the site, and I had outlived my usefulness as a data geek. So I decided to play with the accident data a little and produce some visualization. I plotted all the accidents on a map and animated it through time. I also calculated and plotted the monthly accident rate using a moving average. \n Be sure to select HD quality: \n \n Not surprisingly, the accident rate goes way up in the summer months as Montreal winters are braved on two wheels by only a rarefied few. What is interesting is the mid-summer dip in the accident rate. This dip is notably correlated with Montreal\u2019s much beloved construction holiday \u2013 though the causal relationship is unclear. If you have any alternative explanations, or an idea about how to test the construction holiday hypothesis, drop a note in the comments. \n As always, you can get the code on my github page ."], "link": "http://bayesianbiologist.com/2012/09/14/mapping-bike-accidents-in-r/", "bloglinks": {}, "links": {"http://www.montrealgazette.com/": 1, "http://feeds.wordpress.com/": 1, "https://github.com/": 1, "http://hacktaville.ca/": 1, "https://velobstacle.crowdmap.com/": 2}, "blogtitle": "bayesianbiologist"}, {"content": ["This image comes from the cover of Preliminary Papers of the Second International Workshop on Artificial Intelligence and Statistics (1989) . Someone abandoned it in the lobby of my building at school. Whatever for, I\u2019ll never know. \n  \n I just love the idea of machine learning/AI/Statistics evoking a robot hand drawing a best fit line through some points on graph paper with a pen. \n What other funny, or interesting, metaphorical visual representations of machine learning have you seen? Drop a link in the comments and I\u2019ll get my robot arm to compile the results."], "link": "http://bayesianbiologist.com/2012/09/06/the-future-of-artificial-intelligence-as-imagined-in-1989/", "bloglinks": {}, "links": {"http://feeds.wordpress.com/": 1, "http://bayesianbiologist.wordpress.com/": 1}, "blogtitle": "bayesianbiologist"}]
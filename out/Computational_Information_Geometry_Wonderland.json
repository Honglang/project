[{"blogurl": "http://blog.informationgeometry.org\n", "blogroll": [], "title": "Computational Information Geometry Wonderland"}, {"content": ["I have uploaded the slides for the talk: \nA glance at information-geometric signal processing \n \n \n slides ."], "link": "http://blog.informationgeometry.org/article.php?id=227", "bloglinks": {}, "links": {"http://www.co.jp/": 1}, "blogtitle": "Computational Information Geometry Wonderland"}, {"content": ["I will be presenting a talk entitled: \n \n A glance at information-geometric signal processing (see 2012-T-MAHI-JGSSP.pdf )\nat\n MAHI: Methodological Aspects of Hyperspectral Imaging"], "link": "http://blog.informationgeometry.org/article.php?id=226", "bloglinks": {}, "links": {"http://www-n.oca.eu/": 1, "http://blog.informationgeometry.org/": 1}, "blogtitle": "Computational Information Geometry Wonderland"}, {"content": ["I have developed a simple UI for selecting areas in photos. See here .\nAlthough information geometry is not directly concerned, it can be used during two stages: \n \n \n Segmentation\n Estimation of robust homographies in the space of two-views homographies."], "link": "http://blog.informationgeometry.org/article.php?id=225", "bloglinks": {}, "links": {"http://www.informationgeometry.org/": 1}, "blogtitle": "Computational Information Geometry Wonderland"}, {"content": ["Hyperbolic geometry is fascinating, especially in high dims and with complex numbers.\nUsing the many models of hyperbolic geometry, one can choose the best model for a computation purpose.\nFor example, the hyperbolic Voronoi diagram has better be computed in the Klein ball (non-conformal).:\n Hyperbolic Voronoi diagrams made easy \n \n \n \nI did some travelling experiment on travelling myself on the 2D upper plane: \n \n\n\n \n \n \n Frank."], "link": "http://blog.informationgeometry.org/article.php?id=224", "bloglinks": {}, "links": {"http://www.informationgeometry.org/": 1}, "blogtitle": "Computational Information Geometry Wonderland"}, {"content": ["... I did not update the publication list. Here is the journal section."], "link": "http://blog.informationgeometry.org/article.php?id=223", "bloglinks": {}, "links": {"http://www.informationgeometry.org/": 1}, "blogtitle": "Computational Information Geometry Wonderland"}, {"content": ["A very neat paper is the Diffusion Kernels on Statistical Manifolds \n \n \n \n@article{DiffusionKernelsStatManifolds-2005,\n author = {Lafferty, John and Lebanon, Guy},\n title = {Diffusion Kernels on Statistical Manifolds},\n journal = JMLR,\n issue_date = {12/1/2005},\n volume = {6},\n month = dec,\n year = {2005},\n issn = {1532-4435},\n pages = {129--163},\n numpages = {35},\n publisher = {JMLR.org},\n bibEntryDate = {2012/8/20},\n bibEntryAuthor={Frank Nielsen}\n} \n \n The authors recall that the Fisher-Rao geometry amounts to the spherical geometry,, and design the multinomial diffusion kernel. Application to text classification using tfidf (weighted bag of words) is presented. \n @FrnkNlsn"], "link": "http://blog.informationgeometry.org/article.php?id=222", "bloglinks": {}, "links": {"http://jmlr.mit.edu/": 1, "https://twitter.com/": 1}, "blogtitle": "Computational Information Geometry Wonderland"}, {"content": ["Segmentation consists in partitioning the image into homogeneous regions intended to represent objects.\nHuman excels in segmenting but computers have the difficult task to solve this problem is a bottom-top approach.\nIn fact, each individual may bring its own segmentation result but computers solve some optimization problem. \n \n \n Graph (MST, normalized cuts) \n Clustering (k-means, GMMs) \n Region growing (SRM) \nNock R., Nielsen, F., (2004). Statistical region merging. IEEE Transactions on Pattern Analysis and Machine Intelligence, 26(11):1452-1458. \n see some ecological applications \n \n Watershed \n etc \n \n An interesting result by Kleinberg is to define a set of three essential properties one good clustering should have, and then prove that there does not exist an objective function to optimize yielding those properties... \nJ. Kleinberg. An Impossibility Theorem for Clustering. Advances in Neural Information Processing Systems (NIPS) 15, 2002. \n \n \n Watershed is a segmentation technique that proceeds by filling/detecting basins by dropping water.\nIt takes a greyscale image and manipulate it as a heightmap. To see that it is not trivial task, look at the right column and try to guess the corresponding image on the left column... !!! \nSegmentation is a never-ending problem, so what are the next big milestones to focus on? \n \n \n \n \n \n \n \n \n \n \n \n \n \n @FrnkNlsn"], "link": "http://blog.informationgeometry.org/article.php?id=221", "bloglinks": {}, "links": {"https://twitter.com/": 1, "http://www.aegean.gr/": 1}, "blogtitle": "Computational Information Geometry Wonderland"}, {"content": ["The web page is freshly out: \n \n \n \n \n \n \n \n \n @FrnkNlsn"], "link": "http://blog.informationgeometry.org/article.php?id=220", "bloglinks": {}, "links": {"https://twitter.com/": 1, "http://www.informationgeometry.org/": 1}, "blogtitle": "Computational Information Geometry Wonderland"}, {"content": ["@FrnkNlsn"], "link": "http://blog.informationgeometry.org/article.php?id=219", "bloglinks": {}, "links": {"https://twitter.com/": 1}, "blogtitle": "Computational Information Geometry Wonderland"}, {"content": ["@FrnkNlsn"], "link": "http://blog.informationgeometry.org/article.php?id=218", "bloglinks": {}, "links": {"https://twitter.com/": 1}, "blogtitle": "Computational Information Geometry Wonderland"}, {"content": ["@FrnkNlsn"], "link": "http://blog.informationgeometry.org/article.php?id=217", "bloglinks": {}, "links": {"https://twitter.com/": 1}, "blogtitle": "Computational Information Geometry Wonderland"}, {"content": ["Well, I was reading a 1979 article by KQ Brown on the construction of Voronoi diagrams from convex hulls (solving it using inversion and not the classical paraboloid lifting map) when I saw the 1978 reference of a PhD on \"computational geometry\": \n \n@phdthesis{PhD-Zolnowsky-1978,\n author = {John Edward Zolnowsky},\n title = {Topics in computational geometry},\n year = {1978},\n month = feb,\n publisher = {Stanford University},\n address = {Stanford, CA, USA},\n} \n \n A web search on Google books gave me the PDF.\nThe thesis was defended in Stanford before the M. I Shamos' one (May 1978, Yale U).\nI am impressed by its concision: 52 pages and 12 references. (The PDF has more pages because it scanned recto-verso... -:) ) \n \n \n Here you can browse it. \n \n Frank."], "link": "http://blog.informationgeometry.org/article.php?id=216", "bloglinks": {}, "links": {"http://books.co.jp/": 2}, "blogtitle": "Computational Information Geometry Wonderland"}, {"content": ["@FrnkNlsn"], "link": "http://blog.informationgeometry.org/article.php?id=215", "bloglinks": {}, "links": {"https://twitter.com/": 1}, "blogtitle": "Computational Information Geometry Wonderland"}, {"content": ["@FrnkNlsn"], "link": "http://blog.informationgeometry.org/article.php?id=214", "bloglinks": {}, "links": {"https://twitter.com/": 1}, "blogtitle": "Computational Information Geometry Wonderland"}, {"content": ["The Leon Brillouin seminar hosts invited lectures on topics concerning distances, information geometry, and their applications.\nIt is held downtown Paris at IRCAM center close to the Pompidou center.\nRecently, we have uploaded the videos/slides of speakers. \n For example, the video on \n The Burbea-Rao and Bhattacharyya centroids \nis available from the past events tab. \n \n \n \n\n\n\n\n\n\n\n \n \n \n \n There is a much more to listen to.\n \n \n Also, there is the international mailing list on information geometry . \n \n \n @FrnkNlsn"], "link": "http://blog.informationgeometry.org/article.php?id=213", "bloglinks": {}, "links": {"https://twitter.com/": 1, "http://www.informationgeometry.org/": 1, "http://blog.informationgeometry.org/": 1}, "blogtitle": "Computational Information Geometry Wonderland"}, {"content": ["\"A problem clearly stated is a problem half solved.\" - Dorothea Brande (1893 - 1948), American Writer and Editor. \nThinking about this when writing papers... \n \n @FrnkNlsn"], "link": "http://blog.informationgeometry.org/article.php?id=212", "bloglinks": {}, "links": {"https://twitter.com/": 1, "http://en.wikipedia.org/": 1}, "blogtitle": "Computational Information Geometry Wonderland"}, {"content": ["When defining a centroid with respect to a divergence as the minimizer of the average distortion, one asks whether the minimizer is unique or not: \n \n \n Sided and symmetrized Bregman centroids. IEEE Transactions on Information Theory 55(6): 2882-2904 (2009) \n \n \n For f-divergences, convexity in both arguments ensure that it is the case, and setting the gradient to zero does the job.\nBut when it is not convex , we may still hope (and prove) that the centroid is unique.\nThis was the case for the Burbea-Rao centroid (or Jensen centroid induced by the Jensen convexity gap of a function): \n \n \n The Burbea-Rao and Bhattacharyya centroids \nusing a fixed-point equation and property of interness of quasi-arithmetic means. \n However, in general the centroid defined as a minimizer may not be unique if the average distortion has many local minima.\nSuch simple functions may indeed yield exponentially many maxima as shown by Auer and his colleagues: \n \n \n Exponentially many local minima for single neurons \n \n \n They proved that a single neuron with the logistic transfer function and square loss to optimze can yield exponential many extrema for learning the weight vector. \n \n \n \n \n \n@inproceedings{ManyLocalMinima-1995,\n author = {Peter Auer and Mark Herbster and Manfred K. Warmuth},\n title  = {Exponentially many local minima for single neurons},\n booktitle = {Neural Information Processing Society (NIPS)},\n year  = {1995},\n pages  = {316-322}\n}\n \n \n \n \n \n @FrnkNlsn"], "link": "http://blog.informationgeometry.org/article.php?id=211", "bloglinks": {}, "links": {"http://dl.acm.org/": 1, "http://arxiv.org/": 1, "https://twitter.com/": 1, "http://blog.informationgeometry.org/": 1}, "blogtitle": "Computational Information Geometry Wonderland"}, {"content": ["In 1921 (published 1922), Sir R. A. Fisher came up with a (the?) mathematical theory of statistics.\nAt the core of it is the notion of sufficiency: \n \n... the statistic chosen should summarize the whole of the relevant information supplied by the sample.\n \n \n \nNowadays, with Big Data hunt for Better Data, model selection and sufficiency is crucial.\nThe question remains on how much information is there in the data. \nFrank."], "link": "http://blog.informationgeometry.org/article.php?id=209", "bloglinks": {}, "links": {}, "blogtitle": "Computational Information Geometry Wonderland"}, {"content": ["When learning statistical mixtures, there are two basic questions: (1) how good can we learn a model, and (2) how fast can we do it?\n \nAt ICASSP, we have presented k-MLE for learning mixtures with k components by maximizing the complete likelihood function. \nAnother strategy, is to start from a kernel density estimator, and then simplify it.\nFor 1D normal mixtures, the Fisher-Rao geometry amounts to hyperbolic geometry, but the centroid has not a closed-form.\nWe have proposed to use another definition of center of mass in closed form in hyperbolic geometry to simplify a KDE.\nThus we learn a mixture by simplifying a KDE. \nThe details of the paper are here . \nFrank."], "link": "http://blog.informationgeometry.org/article.php?id=208", "bloglinks": {}, "links": {"http://arxiv.org/": 1, "http://www.polytechnique.fr/": 1}, "blogtitle": "Computational Information Geometry Wonderland"}, {"content": ["In 2007, I was thinking of rendering transparency by building a prototype with a light field acquisition (camera array) piped to a light field renderer (projector array). I wrote a column in CGA. \n \n \n \n How crazy or realistic is this idea? Well, I suggest you to look at that video for convincing you that it is not so SciFI: \n \n \n \n \n\n\n \n \n \nFrank."], "link": "http://blog.informationgeometry.org/article.php?id=207", "bloglinks": {}, "links": {}, "blogtitle": "Computational Information Geometry Wonderland"}, {"content": ["Finite mixture models occur ubiquituously in many signal processing applications.\nThe standard base solution is to use the Expectation-Maximization algorithm (EM) that is proven to converge monotonically by improving the incomplete likelihood. One problem is proper initialization, another problem is the stopping criterion to force EM to stop. What if we rather maximizes the complete likelihood. Then for components of exponential families (like Gaussian mixture models), we can design a simple algorithm that performs a dual additive Bregman clustering for updating expectation parameters followed by a cross-entropy minimization for updating weights, and reiterate finitely until it reaches a local optimum: This is the essence of k-MLE. MLE stands for maximum likelihood estimation. \n \n \n $k$-MLE: A fast algorithm for learning statistical mixture models \n \n \n The two major questions: \n \n How good can you learn a mixture model?, \n and how fast can you do it?\n \n Many interesting trade-offs to unravel!\n \n \n \n \n \n \n Frank."], "link": "http://blog.informationgeometry.org/article.php?id=206", "bloglinks": {}, "links": {"http://arxiv.org/": 1}, "blogtitle": "Computational Information Geometry Wonderland"}, {"content": ["The paper is out there"], "link": "http://blog.informationgeometry.org/article.php?id=205", "bloglinks": {}, "links": {"http://journals.cambridge.org/": 1}, "blogtitle": "Computational Information Geometry Wonderland"}, {"content": ["Well, I am preparing slides with latex Beamer and using Ipe figures.\nI like to include graphics with png and eps, and often discard .pdf figures.\nSo I am rather dvips than pdflatex...To compile my Beamer slides using dvips, here is the trick (with color figures and proper sizes): \n \n \ndvips -T 128mm,96mm -Ic slides.dvi \nps2pdf slides.ps \n \n \n Frank."], "link": "http://blog.informationgeometry.org/article.php?id=204", "bloglinks": {}, "links": {}, "blogtitle": "Computational Information Geometry Wonderland"}, {"content": ["Rayleigh mixture models (RMMs) are mixtures of exponential families (as Gaussian mixture models, GMMs).\nHere is a simple image where the foreground text has been synthesized with Rayleigh variates (lamda1) while the background is synthesized using Rayleigh variates (lamda2). I am curious to know how good human is at distinguishing distributions, compare to usual measures, say Kullback-Leibler divergence. Of course, it depends on the viewing distance/precision, otherwise we get expectation colors, and we have some work on this. Does stochasticity help in discriminating objects. I guess so."], "link": "http://blog.informationgeometry.org/article.php?id=203", "bloglinks": {}, "links": {}, "blogtitle": "Computational Information Geometry Wonderland"}, {"content": [], "link": "http://blog.informationgeometry.org/article.php?id=202", "bloglinks": {}, "links": {}, "blogtitle": "Computational Information Geometry Wonderland"}, {"content": ["Long time since I last updated my publication list. \n FN-Journal-Jan2012.pdf \n FN-Journal-Jan2012.bib"], "link": "http://blog.informationgeometry.org/article.php?id=201", "bloglinks": {}, "links": {"http://blog.informationgeometry.org/": 2}, "blogtitle": "Computational Information Geometry Wonderland"}, {"content": ["Since the work of Banerjee et al. that showed that the expectation-maximization of mixtures of exponential families is a Bregman soft clustering in disguise, there has been a strong interest in further using the bijection between exp fam and Bregman divergences. \n \n In \nShape Retrieval Using Hierarchical Total\nBregman Soft Clustering \nsimilarly it is proven that\nfor total Bregman divergences (tBD), there exists a distribution which belongs to the lifted exponential family of statistical distributions\nThis leads to a new clustering technique namely, the total Bregman soft clustering algorithm. \n \n See paper . \nFrank."], "link": "http://blog.informationgeometry.org/article.php?id=200", "bloglinks": {}, "links": {"http://www.ufl.edu/": 1}, "blogtitle": "Computational Information Geometry Wonderland"}, {"content": ["List of papers and citations automatically aggregated... :-) \n \n sci.ans \nFrank."], "link": "http://blog.informationgeometry.org/article.php?id=199", "bloglinks": {}, "links": {"http://scholar.google.com/": 1}, "blogtitle": "Computational Information Geometry Wonderland"}, {"content": ["Legendre-Fenchel duality is at the heart of dually flat spaces in information geometry.\nConvex functions come in pairs, called convex conjugates.\nThe basic principle is that if you plot the epigraph of the function F and reinterpret it at the intersection of support halfspaces, you get the dual geometric representation of the epigraph. You can parameterize this dual representation using the convex conjugate function. Thus the Legendre-Fenchel transformation is sometimes called the slope transform. \n More details in the memo: \n NoteLegendreTransformation.pdf \n \n \n ++x-x,\n \nFrank."], "link": "http://blog.informationgeometry.org/article.php?id=198", "bloglinks": {}, "links": {"http://blog.informationgeometry.org/": 1}, "blogtitle": "Computational Information Geometry Wonderland"}, {"content": ["I have implemented a visual interface that generalizes de Badoiu-Clarkson algorithm to arbitrary Riemmanian geometry\n(see On Approximating the Riemannian 1-Center ).\nThe javascript demo that should run on any platform is available here . \n \n Frank."], "link": "http://blog.informationgeometry.org/article.php?id=197", "bloglinks": {}, "links": {"http://arxiv.org/": 1, "http://www.informationgeometry.org/": 1}, "blogtitle": "Computational Information Geometry Wonderland"}, {"content": ["Please send me your favorite application of information geometry.\nHappy new year to all of you. Frank \n \n Digital cameras are quickly merging with smart phones, and\nvisual computing applications [1] that support computational\nphotography and augmented reality applications are flourishing at a\nfast pace.\nBy 2013, the annual worldwide IP traffic is predicted to be a zettabyte: \n90% of consumer IP traffic and 60% of\nmobile IP traffic will be video. \n \n \nHow do we extract and use rich information from those massive data sets?\nAs visual data abound, computer vision and computer graphics are\nincreasingly relying on machine learning and information-theoretic methods. \nComputational Information Geometry is a novel paradigm to perform high-fidelity data analysis using the language and thinking of geometry.\n \n \nGeometry allows us to map the data in space for efficient processing and retrieval of intrinsic information. \nGeometry is in essence coordinate-free and allows one to extract the very information from data.\n \n \nGeometrization of statistics has provided novel algorithms for manipulating statistical mixture models\nsuch as Gaussian mixture models [2] that are commonly used in image processing:\nAn image pixel at position (x,y) with color attributes (red, green,\nblue) is embedded into a 5D space so that a 2D color image is\ninterpreted as a 5D spatial point cloud. We then seek for a compact\ngenerative statistical representation of the image point set.\nSuch statistical methods are useful for explaning human cognitive\nand learning skills [3], and analyzing emerging phenomena of complex\nsystems using hierarchical Bayesian models.\n \n \nGeometry is well alive and continue to play a crucial role in natural\nsciences. For example, the propagation of seismic waves from an\nepicenter follows Fermat's principle of shortest paths (minimum arrival\ntime). Since the Earth is made of anisotropic media such as the\nperidotite, shortest paths are not line segments: The geometry is not\nEuclidean. Seismic wave propagation is currently best modeled using\nFinsler geometry that extends Riemmanian geometry by taking into account\nthe anisotropic direction of materials. In [4], we recently show how to\naggregate and cluster information in such Finslerian spaces.\nFinsler geometry is also considered for advanced medical imaging of\nDT-MRI data-sets.\n \n \nLast but not least, the theory of portfolio allocation has been traditionally carried out using the mean-variance method of Markowitz. \nConsidering universal statistical distributions (exponential families) allows one to bypass the Gaussian assumption, \nand to derive the exact expression of the risk premium (a Bregman divergence) and certainty equivalent [5].\nMoreover, we design an on-line learning algorithm with guaranteed lower bounds on its cumulated certainty equivalents [5].\nIt is interesting to note that portfolio theory has also been considered to explain robustness trade-offs of cells in biology [6] (bioeconomics).\n \n \n \n \n REFERENCES: \n \n \n \n \n[1] Frank Nielsen: Visual Computing: Geometry, Graphics, and Vision;\n  Charles River Media, ISBN: 1-58450-427-7, 2005.\n \n[2] Frank Nielsen, Sylvain Boltz: The Burbea-Rao and Bhattacharyya\nCentroids.\n  IEEE Transactions on Information Theory 57(8): 5455-5466, 2011.\n \n[3] Joshua B. Tenenbaum, Charles Kemp, Thomas L. Griffiths, and Noah D.\nGoodman: How to Grow a Mind: Statistics, Structure, and Abstraction\n  Science 331(6022):1279-1285, 2011. \n \n \n[4] Marc Arnaudon, Frank Nielsen: Medians and means in Finsler geometry,\n  Cambridge LMS Journal of Computation and Mathematics, 2011. \n \n \n[5] Richard Nock, Brice Magdalou, Eric Briys and Frank Nielsen: On tracking portfolios with certainty equivalents on a generalization of Markowitz model: the Fool, the Wise and the Adaptive\n International Conference on Machine Learning, pp. 73-80, 2011.\n \n \n [6] Hiroaki Kitano: Violations of robustness trade-offs \n Mol Syst Biol. 2010; 6: 384. 10.1038/msb.2010.40"], "link": "http://blog.informationgeometry.org/article.php?id=196", "bloglinks": {}, "links": {}, "blogtitle": "Computational Information Geometry Wonderland"}]
[{"blogurl": "http://statmethods.wordpress.com\n", "blogroll": [], "title": "statMethods blog"}, {"content": ["Permuation tests (also called randomization or re-randomization tests) have been around for a long time, but it took the advent of high-speed computers to make them practically available. They can be particularly useful when your data are sampled from unkown distributions, when sample sizes are small, or when outliers are present. \n R has two powerful packages for permutation tests \u2013 the coin package and the lmPerm package. In this post, we will take a look at the later. \n The lmPerm package provides permutation tests for linear models and is particularly easy to impliment. You can use it for all manner of ANOVA/ANCOVA designs, as well as simple, polynomial, and multiple regression. Simply use lmp() and aovp() where you would have used lm() and aov(). \n Example \n Consider the following analysis of covariance senario. Seventy five pregnant mice are divided into four groups and each group receives a different drug dosage (0, 5, 50, or 500) during pregnancy. Does the dosage of the drug affect the birthweight of the resulting\u00a0litters, after controlling for gestation time and litter size? \n The data are contained in the litter dataframe available in the multcomp package. The dependent variable is weight (average post-birth weights for each litter). The independent variable is dose , and\u00a0gestation time\u00a0and \u00a0 litter size\u00a0are covariates contained in the variables gesttime and number respectively . \n If we were going to carry out a traditional ANCOVA on this data, it would look something like this: \n \n> library(multcomp)\n> data(litter)\n> mod1 <- aov(weight ~ number + gesttime + dose, data=litter)\n> summary(mod1)\n   Df Sum Sq Mean Sq F value Pr(>F) \nnumber  1 69.8 69.77 4.367 0.04038 * \ngesttime  1 143.7 143.70 8.994 0.00378 **\ndose   3 122.8 40.93 2.562 0.06196 . \nResiduals 68 1086.4 15.98     \n---\nSignif. codes: 0 \u2018***\u2019 0.001 \u2018**\u2019 0.01 \u2018*\u2019 0.05 \u2018.\u2019 0.1 \u2018 \u2019 1 \n \n It appears that while litter size and gestation time are significantly related to average birthweight for a litter, the drug dosage is not (p = 0.062). (Note that the order of effects in the aov statement is important. Effects later in the list are adjusted for effects earlier in the list. This is the sequential or Type I sums of squares approach.) \n One of the assumptions of the ANCOVA model is that residuals are normally distributed. Let\u2019s take a look. \n \n> qqnorm(resid(mod1), main=\"Normal Q-Q Plot\")\n> qqline(resid(mod1), col=\"red\"))\n \n From the graph, we have to question the normality assumption here. Note the deviations from the line. \n \n An alternative to the tradional analysis of covariance is a permutation verion of the test. The test is valid even if we violate the normality assumption. To perform the test, simply replace the aov() function with aovp(). \n \n> library(lmPerm)\n> mod2 <- aovp(weight ~ number + gesttime + dose, data=litter)\n[1] \"Settings: unique SS : numeric variables centered\"\n> summary(mod2)\nComponent 1 :\n   Df R Sum Sq R Mean Sq Iter Pr(Prob) \nnumber  1 64.85 64.849 4724 0.02075 * \ngesttime  1 153.99 153.986 5000 0.00340 **\ndose   3 122.80 40.934 5000 0.03720 * \nResiduals 68 1086.42 15.977     \n---\nSignif. codes: 0 \u2018***\u2019 0.001 \u2018**\u2019 0.01 \u2018*\u2019 0.05 \u2018.\u2019 0.1 \u2018 \u2019 1 \n \n There two things to note here. First, the aovp() function calculates unique sums of squares (also called Type III SS). Each effect is adjusted for all other effects, so order does not matter. Second, the dose effect is now significant (p = 0.038), suggesting that drug dose impacts birth weight after controlling for litter size and gestation period. \n There are many situations were traditional linear model significance tests are not optimal (including when data is notably non-normal, there are outliers, and when sample sizes are too small to trust asymptotic results). In these cases, permuation tests may be viable alternatives. \n To learn more about permuation tests in R see chapter 12 of R in Action ."], "link": "http://statmethods.wordpress.com/2012/05/21/permutation-tests-in-r/", "bloglinks": {}, "links": {"http://www.manning.com/": 1, "https://statmethods.wordpress.com/": 1, "http://cran.r-project.org/": 3}, "blogtitle": "statMethods blog"}, {"content": ["An introduction to R for sofware developers and data analysts \nSaturday March 10th, 2012 \n8:30-5:00pm \nEBay \n2161 North 1st Street \nSan Jose, California \n I will be presenting a one day professional development workshop on R programming for software developers and data scientists, sponsored by the ACM San Francisco Bay Area Professional Chapter and Revolution Analytics. \n Details are available at http://www.sfbayacm.org/event/introduction-r-software-developers-and-data-analysts . I am very excited about this opportunity and will provide more information as the date approaches."], "link": "http://statmethods.wordpress.com/2012/02/01/r-training-course-in-the-bay-area/", "bloglinks": {}, "links": {"http://www.sfbayacm.org/": 1, "http://statmethods.wordpress.com/": 1}, "blogtitle": "statMethods blog"}, {"content": ["R has some great functions for generating scatterplots in 3 dimensions. Two of the best are the scatter3d() function in John Fox\u2019s car package, and the scatterplot3d() function in Uwe Ligges\u2019 scatterplot3d package. In this post, we will focus on the later. \n Let\u2019s say that we want to plot automobile mileage vs. engine displacement\u00a0vs. car weight using the data in the mtcars dataframe. \n \nlibrary(scatterplot3d)\nwith(mtcars, {\n scatterplot3d(disp, # x axis\n     wt,  # y axis\n     mpg, # z axis\n     main=\"3-D Scatterplot Example 1\")\n})\n \n The resulting plot is given below. \n \n Now lets, modify the graph by replacing the points with filled blue circles, add drop lines to the x-y plane, and create more meaningful labels. \n \nlibrary(scatterplot3d)\nwith(mtcars, {\n scatterplot3d(disp, wt, mpg,  # x y and z axis\n     color=\"blue\", pch=19, # filled blue circles\n     type=\"h\",    # lines to the horizontal plane\n     main=\"3-D Scatterplot Example 2\",\n     xlab=\"Displacement (cu. in.)\",\n     ylab=\"Weight (lb/1000)\",\n     zlab=\"Miles/(US) Gallon\")\n})\n \n  \n Next, let\u2019s label the points. We can do this by saving the results of the scatterplot3d() function to an object, using the xyz.convert() function to convert coordinates from 3D (x, y, z) to 2D-projections (x, y), and apply the text() function to add labels to the graph. \n \nlibrary(scatterplot3d)\nwith(mtcars, {\n s3d <- scatterplot3d(disp, wt, mpg,  # x y and z axis\n     color=\"blue\", pch=19,  # filled blue circles\n     type=\"h\",     # vertical lines to the x-y plane\n     main=\"3-D Scatterplot Example 3\",\n     xlab=\"Displacement (cu. in.)\",\n     ylab=\"Weight (lb/1000)\",\n     zlab=\"Miles/(US) Gallon\")\n s3d.coords <- s3d$xyz.convert(disp, wt, mpg) # convert 3D coords to 2D projection\n text(s3d.coords$x, s3d.coords$y,    # x and y coordinates\n   labels=row.names(mtcars),    # text to plot\n   cex=.5, pos=4)   # shrink text 50% and place to right of points)\n})\n \n  \n Almost there. As a final step, we will add information on the number of cylinders each car has. To do this, we will add a column to the mtcars dataframe indicating the color for each point. For good measure, we will shorten the y axis, change the drop lines to dashed lines, and add a legend. \n \nlibrary(scatterplot3d)\n# create column indicating point color\nmtcars$pcolor[mtcars$cyl==4] <- \"red\"\nmtcars$pcolor[mtcars$cyl==6] <- \"blue\"\nmtcars$pcolor[mtcars$cyl==8] <- \"darkgreen\"\nwith(mtcars, {\n s3d <- scatterplot3d(disp, wt, mpg,  # x y and z axis\n     color=pcolor, pch=19,  # circle color indicates no. of cylinders\n     type=\"h\", lty.hplot=2,  # lines to the horizontal plane\n     scale.y=.75,     # scale y axis (reduce by 25%)\n     main=\"3-D Scatterplot Example 4\",\n     xlab=\"Displacement (cu. in.)\",\n     ylab=\"Weight (lb/1000)\",\n     zlab=\"Miles/(US) Gallon\")\n  s3d.coords <- s3d$xyz.convert(disp, wt, mpg)\n  text(s3d.coords$x, s3d.coords$y,  # x and y coordinates\n   labels=row.names(mtcars),  # text to plot\n   pos=4, cex=.5)     # shrink text 50% and place to right of points)\n# add the legend\nlegend(\"topleft\", inset=.05,  # location and inset\n bty=\"n\", cex=.5,    # suppress legend box, shrink text 50%\n title=\"Number of Cylinders\",\n c(\"4\", \"6\", \"8\"), fill=c(\"red\", \"blue\", \"darkgreen\"))\n})\n \n \n One of R \u2018s most attractive features is that it allows us to manipulate output and deeply customize graphs. This article has just touched the surface. Since colors and text labels can be input as vectors, you could programmatically use them to represent almost anything. For example, point colors and/or labels could be used to highlight observations that are outliers, have high leverage, or are unusual in some other way. Simply create a vector that has colors or labels for notable observations and missing (NA) values otherwise."], "link": "http://statmethods.wordpress.com/2012/01/30/getting-fancy-with-3-d-scatterplots/", "bloglinks": {}, "links": {"http://statmethods.wordpress.com/": 4}, "blogtitle": "statMethods blog"}, {"content": ["No, I don\u2019t mean late night coding. R is constantly changing \u2013 both as a language and a platform. Updates containing new functionality are frequent. New and revised packages appear several times a week. \u00a0Staying\u00a0current with these myriad changes can be a challenge. \n In this post, I thought that I would share some of the online resources that I have found to be most useful for keeping current with what is happening in world of R. \n Of course the R project homepage ( www.r-project.org ) and the Comprehensive R Archive Network (CRAN; cran.r-project.org ) are\u00a0\u00a0your first stops for all things R. \n CRANberries ( dirk.eddelbuettel.com/cranberries/ ) is a site that aggregates information about new and updated packages, and contains links to CRAN for each. \n Planet R ( planetr.stderr.org ) is a great site aggregor, and includes information from a wide range of sources (including CRANberries). This is my first stop for staying up on new packages. \n R Bloggers ( www.r-bloggers.com )\u00a0 is a central hub (blog aggregator) for collecting content from bloggers writing about R. It contains several new articles each day and I am addicted to it. It is a great place to learn new analytic and programming techniques. \n The R Journal ( journal.r-project.org ) is a freely accessible refereed journal containing articles on the R project and contributed packages. This is a great way to gain deeper insight into what specific packages can do. \n The Journal of Statistical Software ( www.jstatsoft.org ) is also a freely accessbile refereed journal and contains articles, book reviews, and code snippets on statistical computing topics. There are frequent articles about R. \n Finally,\u00a0 R-Help ,\u00a0the\u00a0main R mailing list ( stat.ethz.ch/mailman/listinfo/r-help ), is the best place to ask questions about R.\u00a0Be sure to read the FAQ before posting or you may get flamed by veteran programmers.\u00a0The archives are searchable and contain a wealth of information. \n These are my favorites \u2013 the ones I go back to again and again. What are yours?"], "link": "http://statmethods.wordpress.com/2012/01/14/staying-up-with-r/", "bloglinks": {}, "links": {"https://stat.ethz.ch/": 1, "http://www.jstatsoft.org": 1, "http://journal.r-project.org": 1, "http://cran.r-project.org": 1, "http://statmethods.wordpress.com/": 1, "http://www.r-bloggers.com": 1, "http://www.r-project.org": 1, "http://planetr.stderr.org": 1, "http://dirk.eddelbuettel.com/": 1}, "blogtitle": "statMethods blog"}, {"content": ["A common task when analyzing multi-group designs is obtaining descriptive statistics for various cells\u00a0and cell combinations. \n There are many functions that can help you accomplish this, including aggregate() and by() in the base installation, summaryBy() in the doBy package, and describe.by() in the psych package. However, I find it easiest to use the melt() and cast() functions in the reshape package. \n As an example, consider the mtcars dataframe (included in the base installation) containing road test information on automobiles assessed in 1974. Suppose that you want to obtain the means, standard deviations, and sample sizes for the variables miles per gallon (mpg), horsepower (hp), and weight (wt). You want these statistics for all cars in the dataset, separately by\u00a0transmission type (am) and number of gears (gear), and for\u00a0the cells formed by crossing these two variables. \n You can accomplish this with the following code: \n \noptions(digits = 3)\nlibrary(reshape)\n\n# define and name the statistics of interest\nstats <- function(x)(c(N = length(x), Mean = mean(x), SD = sd(x)))\n\n# label the levels of the classification variables (optional)\nmtcars$am <- factor(mtcars$am, levels = c(0, 1), labels = c(\"Automatic\", \"Manual\"))\nmtcars$gear <- factor(mtcars$gear, levels = c(3, 4, 5),\n      labels = c(\"3-Cyl\", \"4-Cyl\", \"5-Cyl\"))\n\n# melt the dataset\ndfm <- melt(mtcars,\n    # outcome variables\n    measure.vars = c(\"mpg\", \"hp\", \"wt\"),\n    # classification variables\n    id.vars = c(\"am\", \"gear\"))\n\n# statistics for the entire sample\ncast(dfm, variable ~ ., stats)\n\n# statistics for cells defined by transmission type\ncast(dfm, am + variable ~ ., stats)\n\n# statistics for cells defined by number of gears\ncast(dfm, gear + variable ~ ., stats)\n\n# statistics for cells defined by each am x gear combination\ncast(dfm, am + gear + variable ~ ., stats)\n \n The output is given below: \n variable N Mean  SD\n1  mpg 32 20.09 6.027\n2  hp 32 146.69 68.563\n3  wt 32 3.22 0.978\n\n   am variable N Mean  SD\n1 Automatic  mpg 19 17.15 3.834\n2 Automatic  hp 19 160.26 53.908\n3 Automatic  wt 19 3.77 0.777\n4 Manual  mpg 13 24.39 6.167\n5 Manual  hp 13 126.85 84.062\n6 Manual  wt 13 2.41 0.617\n\n gear variable N Mean  SD\n\n1 3-Cyl  mpg 15 16.11 3.372\n2 3-Cyl  hp 15 176.13 47.689\n3 3-Cyl  wt 15 3.89 0.833\n4 4-Cyl  mpg 12 24.53 5.277\n5 4-Cyl  hp 12 89.50 25.893\n6 4-Cyl  wt 12 2.62 0.633\n7 5-Cyl  mpg 5 21.38 6.659\n8 5-Cyl  hp 5 195.60 102.834\n9 5-Cyl  wt 5 2.63 0.819\n\n   am gear variable N Mean  SD\n1 Automatic 3-Cyl  mpg 15 16.11 3.372\n2 Automatic 3-Cyl  hp 15 176.13 47.689\n3 Automatic 3-Cyl  wt 15 3.89 0.833\n4 Automatic 4-Cyl  mpg 4 21.05 3.070\n5 Automatic 4-Cyl  hp 4 100.75 29.010\n6 Automatic 4-Cyl  wt 4 3.30 0.157\n7  Manual 4-Cyl  mpg 8 26.27 5.414\n8  Manual 4-Cyl  hp 8 83.88 24.175\n9  Manual 4-Cyl  wt 8 2.27 0.461\n10 Manual 5-Cyl  mpg 5 21.38 6.659\n11 Manual 5-Cyl  hp 5 195.60 102.834\n12 Manual 5-Cyl  wt 5 2.63 0.819 \n The approach is easily generalized to any number of grouping variables (factors), dependent/outcome variables, and statistics, and gives you a powerful tool for slicing and dicing data."], "link": "http://statmethods.wordpress.com/2011/12/02/easy-cell-statistics-for-factorial-designs/", "bloglinks": {}, "links": {}, "blogtitle": "statMethods blog"}, {"content": ["After maintaining the \u00a0 Quick-R \u00a0website (R tutorials and jumpstart) for the past 5 years, I\u2019ve decided to add a blog so that I can go into more detail on topics related to practical data analysis. \n The statMethods blog will contain articles about data analysis, statistics, and graphics, with an emphasis on the R language. \n Of course, I\u2019ll continue to maintain Quick-R, and hope that you find this addition resource\u00a0useful. Let me know if there are topics that you would like to hear about. \n - Rob Kabacoff"], "link": "http://statmethods.wordpress.com/2011/11/21/quick-r-gets-a-blog/", "bloglinks": {}, "links": {"http://statmethods.wordpress.com": 1, "http://www.statmethods.net": 2}, "blogtitle": "statMethods blog"}]
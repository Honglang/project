[{"blogurl": "http://rbresearch.wordpress.com\n", "blogroll": [], "title": "rbresearch"}, {"content": ["Many of the sites I linked to in the previous post have articles or papers on momentum investing that investigate the typical ranking factors; 3, 6, 9, and 12 month returns. Most (not all) of the articles seek to find which is the \u201cbest\u201d look-back period to rank the assets. Say that the outcome of the article is that the 6 month look-back has the highest returns. A trading a strategy that just uses a 6 month look-back period to rank the assets leaves me vulnerable to over-fitting based on the backtest results. The backtest tells us nothing more than which strategy performed the best in the past, it tells us nothing about the future\u2026 duh! \n Whenever I review the results from backtests, I always ask myself a lot of \u201cwhat if\u201d questions. Here are 3 \u201cwhat if\u201d questions that I would ask for this backtest are: \n \n What if the strategy based on a 6 month look-back under performs and the 9 month or 3 month starts to over perform? \n What if the strategies based on 3, 6, and 9 month look-back periods have about the same return and risk profile, which strategy should I trade? \n What if the assets with high volatility are dominating the rankings and hence driving the returns? \n \n The backtests shown are simple backtests meant to demonstrate the variability in returns based on look-back periods and number of assets traded. \n The graphs below show the performance of a momentum strategy using 3, 6, 9, and 12 month returns and trading the Top 1, 4, and 8 ranked assets. You will notice that there is significant volatility and variability in returns only trading 1 asset. The variability between look-back periods is reduced, but there is still no one clear \u201cbest\u201d look-back period. There are periods of under performance and over performance for all look back periods in the test. \n  rbresearch \n \n \n  \n rbresearch \n \n \n \n  rbresearch \n \n Here is the R code used for the backtests and the plots. Leave a comment if you have any questions about the code below. \n \n \n library ( FinancialInstrument ) \n library ( TTR ) \n library ( PerformanceAnalytics ) \n\nRankRB <- function ( x ) { \n # Computes the rank of an xts object of ranking factors \n # ranking factors are the factors that are ranked (i.e. asset returns) \n # \n # args: \n # x = xts object of ranking factors \n # \n # Returns: \n # Returns an xts object with ranks \n # (e.g. for ranking asset returns, the asset with the greatest return \n # receives a rank of 1) \n\n r <- as.xts ( t ( apply ( -x , 1 , rank , na.last = \"keep\" ) ) ) \n return ( r ) \n } \n\nMonthlyAd <- function ( x ) { \n # Converts daily data to monthly and returns only the monthly close \n # Note: only used with Yahoo Finance data so far \n # Thanks to Joshua Ulrich for the Monthly Ad function \n # \n # args: \n # x = daily price data from Yahoo Finance \n # \n # Returns: \n # xts object with the monthly adjusted close prices \n\n sym <- sub ( \" \\\\ ..*$\" , \"\" , names ( x ) [ 1 ] ) \n Ad ( to.monthly ( x , indexAt = 'lastof' , drop.time = TRUE , name = sym ) ) \n } \n\nCAGR <- function ( x , m ) { \n # Function to compute the CAGR given simple returns \n # \n # args: \n # x = xts of simple returns \n # m = periods per year (i.e. monthly = 12, daily = 252) \n # \n # Returns the Compound Annual Growth Rate \n x <- na.omit ( x ) \n cagr <- apply ( x , 2 , function ( x , m ) prod ( 1 + x ) ^ ( 1 / ( length ( x ) / m ) ) - 1 , m = m ) \n return ( cagr ) \n } \n\nSimpleMomentumTest <- function ( xts.ret , xts.rank , n = 1 , ret.fill.na = 3 ) { \n # returns a list containing a matrix of individual asset returns \n # and the comnbined returns \n # args: \n # xts.ret = xts of one period returns \n # xts.rank = xts of ranks \n # n = number of top ranked assets to trade \n # ret.fill.na = number of return periods to fill with NA \n # \n # Returns: \n # returns an xts object of simple returns \n\n # trade the top n asset(s) \n # if the rank of last period is less than or equal to n, \n # then I would experience the return for this month. \n\n # lag the rank object by one period to avoid look ahead bias \n lag.rank <- lag ( xts.rank , k = 1 , na.pad = TRUE ) \n n2 <- nrow ( lag.rank [ is.na ( lag.rank [ , 1 ] ) == TRUE ] ) \n z <- max ( n2 , ret.fill.na ) \n\n # for trading the top ranked asset, replace all ranks above n \n # with NA to set up for element wise multiplication to get \n # the realized returns \n lag.rank <- as.matrix ( lag.rank ) \n lag.rank [ lag.rank > n ] <- NA \n # set the element to 1 for assets ranked <= to rank \n lag.rank [ lag.rank <= n ] <- 1 \n\n # element wise multiplication of the \n # 1 period return matrix and lagged rank matrix \n mat.ret <- as.matrix ( xts.ret ) * lag.rank\n\n # average the rows of the mat.ret to get the \n # return for that period \n vec.ret <- rowMeans ( mat.ret , na.rm = TRUE ) \n vec.ret [ 1 :z ] <- NA \n\n # convert to an xts object \n vec.ret <- xts ( x = vec.ret , order.by = index ( xts.ret ) ) \n f <- list ( mat = mat.ret , ret = vec.ret , rank = lag.rank ) \n return ( f ) \n } \n\ncurrency ( \"USD\" ) \n symbols <- c ( \"XLY\" , \"XLP\" , \"XLE\" , \"XLF\" , \"XLV\" , \"XLI\" , \"XLK\" , \"XLB\" , \"XLU\" , \"EFA\" ) #, \"TLT\", \"IEF\", \"SHY\") \nstock ( symbols , currency = \"USD\" , multiplier = 1 ) \n\n # create new environment to store symbols \nsymEnv <- new.env ( ) \n\n # getSymbols and assign the symbols to the symEnv environment \ngetSymbols ( symbols , from = '2002-09-01' , to = '2012-10-20' , env = symEnv ) \n\n # xts object of the monthly adjusted close prices \nsymbols.close <- do.call ( merge , eapply ( symEnv , MonthlyAd ) ) \n\n # monthly returns \nmonthly.returns <- ROC ( x = symbols.close , n = 1 , type = \"discrete\" , na.pad = TRUE ) \n\n ############################################################################# \n # rate of change and rank based on a single period for 3, 6, 9, and 12 months \n ############################################################################# \n\nroc.three <- ROC ( x = symbols.close , n = 3 , type = \"discrete\" ) \nrank.three <- RankRB ( roc.three ) \n\nroc.six <- ROC ( x = symbols.close , n = 6 , type = \"discrete\" ) \nrank.six <- RankRB ( roc.six ) \n\nroc.nine <- ROC ( x = symbols.close , n = 9 , type = \"discrete\" ) \nrank.nine <- RankRB ( roc.nine ) \n\nroc.twelve <- ROC ( x = symbols.close , n = 12 , type = \"discrete\" ) \nrank.twelve <- RankRB ( roc.twelve ) \n\nnum.assets <- 4 \n\n # simple momentum test based on 3 month ROC to rank \ncase1 <- SimpleMomentumTest ( xts.ret = monthly.returns , xts.rank = rank.three , \n       n = num.assets , ret.fill.na = 15 ) \n\n # simple momentum test based on 6 month ROC to rank \ncase2 <- SimpleMomentumTest ( xts.ret = monthly.returns , xts.rank = rank.six , \n       n = num.assets , ret.fill.na = 15 ) \n\n # simple momentum test based on 9 month ROC to rank \ncase3 <- SimpleMomentumTest ( xts.ret = monthly.returns , xts.rank = rank.nine , \n       n = num.assets , ret.fill.na = 15 ) \n\n # simple momentum test based on 12 month ROC to rank \ncase4 <- SimpleMomentumTest ( xts.ret = monthly.returns , xts.rank = rank.twelve , \n       n = num.assets , ret.fill.na = 15 ) \n\nreturns <- cbind ( case1$ret , case2$ret , case3$ret , case4$ret ) \n colnames ( returns ) <- c ( \"3-Month\" , \"6-Month\" , \"9-Month\" , \"12-Month\" ) \n\ncharts.PerformanceSummary ( R = returns , Rf = 0 , geometric = TRUE , \n       main = \"Momentum Cumulative Return: Top 4 Assets\" ) \n\ntable.Stats ( returns ) \n\nCAGR ( returns , m = 12 ) \n\n print ( \"End\" ) \n \n \n Created by Pretty R at inside-R.org"], "link": "http://rbresearch.wordpress.com/2012/10/20/momentum-in-r-part-2/", "bloglinks": {}, "links": {"http://inside-r.org/": 44, "http://feeds.wordpress.com/": 1, "http://rbresearch.wordpress.com/": 3, "http://www.inside-r.org/": 1}, "blogtitle": "rbresearch"}, {"content": ["Time really flies\u2026 it is hard to believe that it has been over a month since my last post. Work and life in general have consumed much of my time lately and left little time for research and blog posts. Anyway, on to the post! \n This post will be the first in a series of to cover a momentum strategy using R. \n One of my favorite strategies is a momentum or relative strength strategy. Here are just a few of the reasons why I like momentum: \n \n Simple to implement \n Long only or long/short portfolios \n Many ways to define the strength or momentum measure \n It just works \n \n Also, a momentum strategy lends itself well to potential for diversification. The universe of instruments can be infinite, but the instruments traded are finite. Think about it this way\u2026 Investor A looks at 10 instruments and invests $1000 in the top 5 instruments ranked by momentum. Investor B looks at 100 instruments and invests $1000 in the top 5 instruments ranked by momentum. Investor A is limiting his potential for diversification by only having a universe of 10 instruments. Investor B has a much larger universe of instruments and can in theory be more diversified. Theoretically speaking, you can trade an infinite number of instruments with a finite amount of trading capital using a momentum or relative strength strategy. \n Check out these links for further reading \n \n AQR Momentum Research \n CXO Advisory \n SSRN search \u201cmomentum\u201d \n Systematic Relative Strength \n \n In this first post of the series on momentum, I will go over some of the basic setup and functions we will be using. \n The first step is to get data from yahoo. \n \n \n require ( quantstrat ) \n\n #Load ETFs from yahoo \ncurrency ( \"USD\" ) \n symbols = c ( \"XLY\" , \"XLP\" , \"XLE\" , \"XLF\" ) \nstock ( symbols , currency= \"USD\" , multiplier= 1 ) \ngetSymbols ( symbols , src= 'yahoo' , index.class= c ( \"POSIXt\" , \"POSIXct\" ) , from= '2000-01-01' ) \n\n #Convert to monthly and drop all columns except Adjusted Close \n for ( symbol in symbols ) { \n x <- get ( symbol ) \n x <- to.monthly ( x , indexAt= 'lastof' , drop.time= TRUE ) \n indexFormat ( x ) <- '%Y-%m-%d' \n colnames ( x ) <- gsub ( \"x\" , symbol , colnames ( x ) ) \n x <- x [ , 6 ] #drops all columns except Adjusted Close which is 6th column \n assign ( symbol , x ) \n } \n \n \n Note that the for loop converts the data to monthly and subsets the data so that the only column we keep is the adjusted close column. We now have four objects (XLY, XLP, XLE, XLF) that have the Adjusted Close price. \n > head(XLE)\n   XLE.Adjusted\n2000-01-31  22.89\n2000-02-29  21.92\n2000-03-31  24.56\n2000-04-30  24.19\n2000-05-31  27.04\n2000-06-30  25.55 \n The next step is to merge these four objects into a single object holding the Adjusted Close price. We can do this in a simple one-liner in R! \n \n \n #merge the symbols into a single object with just the close prices \nsymbols_close <- do.call ( merge , lapply ( symbols , get ) ) \n \n \n > head(symbols_close)\n   XLY.Adjusted XLP.Adjusted XLE.Adjusted XLF.Adjusted\n2000-01-31  24.06  18.36  22.89  18.09\n2000-02-29  22.72  16.22  21.92  16.15\n2000-03-31  25.89  16.77  24.56  19.04\n2000-04-30  25.35  17.65  24.19  19.22\n2000-05-31  23.98  18.92  27.04  19.65\n2000-06-30  22.68  19.98  25.55  18.70 \n For the factor that will be ranked, I will use the 3 period rate of change (ROC). \n \n \n #xts object of the 3 period ROC of each column in the close object \n #The 3 period ROC will be used as the ranking factor \nroc <- ROC ( symbols_close , n = 3 , type = \"discrete\" )\n \n \n \n > head(roc)\n   XLY.Adjusted XLP.Adjusted XLE.Adjusted XLF.Adjusted\n2000-01-31   NA   NA   NA   NA\n2000-02-29   NA   NA   NA   NA\n2000-03-31   NA   NA   NA   NA\n2000-04-30 0.05361596 -0.03867102 0.05679336 0.06246545\n2000-05-31 0.05545775 0.16646116 0.23357664 0.21671827\n2000-06-30 -0.12398610 0.19141324 0.04030945 -0.01785714 \n Then we apply the rank function across each row of the roc object. \n \n \n #xts object with ranks \n #symbol with a rank of 1 has the highest ROC \nr <- as.xts ( t ( apply ( -roc , 1 , rank ) ) ) \n \n \n \u00a0 \n > head(r)\n   XLY.Adjusted XLP.Adjusted XLE.Adjusted XLF.Adjusted\n2000-01-31   1   2   3   4\n2000-02-29   1   2   3   4\n2000-03-31   1   2   3   4\n2000-04-30   3   4   2   1\n2000-05-31   4   3   1   2\n2000-06-30   4   1   2   3 \n That will wrap up this first post for a quick and easy way to rank assets based on 3 month simple returns. Future posts will explore other methods for ranking and using quantstrat to backtest momentum. \n Here is the code in full. \n \n \n require ( quantstrat ) \n\n #Load ETFs from yahoo \ncurrency ( \"USD\" ) \n symbols = c ( \"XLY\" , \"XLP\" , \"XLE\" , \"XLF\" ) \nstock ( symbols , currency= \"USD\" , multiplier= 1 ) \ngetSymbols ( symbols , src= 'yahoo' , index.class= c ( \"POSIXt\" , \"POSIXct\" ) , from= '2000-01-01' ) \n\n #Convert to monthly and drop all columns except Adjusted Close \n for ( symbol in symbols ) { \n x <- get ( symbol ) \n x <- to.monthly ( x , indexAt= 'lastof' , drop.time= TRUE ) \n indexFormat ( x ) <- '%Y-%m-%d' \n colnames ( x ) <- gsub ( \"x\" , symbol , colnames ( x ) ) \n x <- x [ , 6 ] #drops all columns except Adjusted Close which is 6th column \n assign ( symbol , x ) \n } \n\n #merge the symbols into a single object with just the close prices \nsymbols_close <- do.call ( merge , lapply ( symbols , get ) ) \n\n #xts object of the 3 period ROC of each column in the close object \n #The 3 period ROC will be used as the ranking factor \nroc <- ROC ( symbols_close , n = 3 , type = \"discrete\" ) \n\n #xts object with ranks \n #symbol with a rank of 1 has the highest ROC \nr <- as.xts ( t ( apply ( -roc , 1 , rank ) ) ) \n \n \n Created by Pretty R at inside-R.org"], "link": "http://rbresearch.wordpress.com/2012/08/23/momentum-with-r-part-1/", "bloglinks": {}, "links": {"http://www.cxoadvisory.com/": 1, "http://www.inside-r.org/": 2, "http://inside-r.org/": 48, "http://www.ssrn.com/": 1, "http://feeds.wordpress.com/": 1, "http://www.aqrindex.com/": 1, "http://systematicrelativestrength.com/": 1}, "blogtitle": "rbresearch"}, {"content": ["Just stumbled on across a course on coursera titled \u201cComputing for Data Analysis\u201d taught by Roger D. Peng\u00a0the Johns Hopkins Bloomberg School of Public Health. \n Here is the description of the course. \n In this course you will learn how to program in R and how to use R for effective data analysis. You will learn how to install and configure software necessary for a statistical programming environment, discuss generic programming language concepts as they are implemented in a high-level statistical language. The course covers practical issues in statistical computing which includes programming in R, reading data into R, creating informative data graphics, accessing R packages, creating R packages with documentation, writing R functions, debugging, and organizing and commenting R code. Topics in statistical data analysis and optimization will provide working examples. \n I just signed up for it! This course looks like a great opportunity to sharpen \u00a0skills in R and learn new things."], "link": "http://rbresearch.wordpress.com/2012/07/17/computing-for-data-analysis-with-r-on-coursera/", "bloglinks": {}, "links": {"https://www.coursera.org/": 1, "http://feeds.wordpress.com/": 1}, "blogtitle": "rbresearch"}, {"content": ["When we backtest a strategy on a portfolio, it is a simple analysis of a single period in time. There are ways to \u201cstress test\u201d a strategy such as monte carlo, random portfolios, or shuffling the returns in a random order. I could never really wrap my head around monte carlo and shuffling the returns seemed to be a better approach because the actual returns of the backtest are used, but it misses one important thing\u2026 the impact of consecutive periods of returns. If we are backtesting a strategy and we want to minimize max drawdown, consecutive down periods have a significant impact on max drawdown. If, for example, the max drawdown occured due to 4 consecutive months during 2008, we wan\u2019t to keep those 4 months together when shuffling returns. \n In my opinion, a better way to shuffle returns is to shuffle \u201cblocks\u201d of returns. This is nothing new, the TradingBlox software does monte carlo analysis this way. I had a look at the boot package and tseries package for their boot functions, but it was not giving me what I wanted. I wanted to visual a number of equity curves with blocks of returns randomly shuffled. \n To accomplish this in R, I wrote two functions. \u00a0The shuffle_returns function takes an xts object of returns, the number of samples to run (i.e. how many equity curves to generate), and\u00a0a number for how many periods of returns makes up a \u2018block\u2019 as arguments.The ran_gen function function is a function within the shuffle_returns function that is used to generate random blocks of returns. \n shuffle_returns returns an xts object with the random blocks of returns so we can do further analysis such as max drawdown, plotting, or pretty much anything in the PerformanceAnalytics package that takes an xts object as an argument. \n This is not a perfect implementation of this idea, so if anybody knows of a better way I\u2019d be glad to hear from you. \n The example below uses sample data from edhec and generates 100 equity curves with blocks of 5 consecutive period of returns. \n  \n R code: \n \n \n require ( PerformanceAnalytics ) \n\n #Function that grabs a random number and then repeats that number r times \nran_gen <- function ( x , r ) { \n\u00a0 #x is an xts object of asset returns \n\u00a0 #r is for how many consecutive returns make up a 'block' \n\u00a0 vec <- c ( ) \n\u00a0 total_length <- length ( x ) \n\u00a0 n <- total_length/r\n\u00a0 for ( i in 1 :n ) { \n\u00a0 \u00a0 vec <- append ( vec , c ( rep ( sample ( 1 : ( n* 100 ) , 1 ) , r ) ) ) \n\u00a0 } \n\u00a0 diff <- as.integer ( total_length - length ( vec ) ) \n\u00a0 vec <- append ( vec , c ( rep ( sample ( 1 : ( n* 100 ) , 1 ) , len = diff ) ) ) \n\u00a0 return ( vec ) \n } \n\nshuffle_returns <- function ( x , n , r ) { \n\u00a0 #x is an xts object of asset returns \n\u00a0 #n is the number of samples to run \n\u00a0 #r is for how many consecutive returns make up a 'block' and is passed to ran_gen \n\n\u00a0 mat <- matrix ( data = x , nrow = length ( x ) ) \n\u00a0 for ( i in 1 :n ) { \n\u00a0 \u00a0 temp_random <- ran_gen ( x = x , r = r ) \n\u00a0 \u00a0 temp_mat <- as.matrix ( cbind ( x , temp_random ) ) \n\u00a0 \u00a0 temp_mat <- temp_mat [ order ( temp_mat [ , 2 ] ) , ] \n\u00a0 \u00a0 temp_ret_mat <- matrix ( data = temp_mat [ , 1 ] ) \n\u00a0 \u00a0 mat <- cbind ( mat , temp_ret_mat ) \n\u00a0 } \n\u00a0 final_xts <- xts ( mat , index ( x ) ) \n\u00a0 return ( final_xts ) \n } \n\n #get sample data \n data ( edhec ) \na <- edhec [ , 1 ] \na <- head ( a , - 1 ) \n\n start <- Sys.time ( ) \nyy <- shuffle_returns ( a , 100 , 5 ) \nchart.CumReturns ( yy [ , 1 : NCOL ( yy ) ] , wealth.index = TRUE , ylab = \"Equity\" , main = \"Generated Equity Curve of Shuffled Returns\" ) \n end <- Sys.time ( ) \n print ( end- start ) \n \n \n Created by Pretty R at inside-R.org"], "link": "http://rbresearch.wordpress.com/2012/07/04/alternative-to-monte-carlo-testing/", "bloglinks": {}, "links": {"http://inside-r.org/": 40, "http://feeds.wordpress.com/": 1, "http://rbresearch.wordpress.com/": 1, "http://www.inside-r.org/": 1}, "blogtitle": "rbresearch"}, {"content": ["Using packages such as ggplot and lattice can produce some great charts and visualization, but googleVis is tough to beat for interactive charts to share on the web. Click on the image below to open up the html page. \n  rbresearch \n This was all done in R! \n I will warn you that it is too easy to blow an entire Saturday afternoon playing with the googleVis charts"], "link": "http://rbresearch.wordpress.com/2012/06/30/fun-with-the-googlevis-package-for-r/", "bloglinks": {}, "links": {"http://feeds.wordpress.com/": 1, "http://dl.dropbox.com/": 2}, "blogtitle": "rbresearch"}, {"content": ["The strategies used in Strategy Diversification in R were labeled as Strategy1 and Strategy2. \n Strategy1 \n \n Indicator: 52 week Simple Moving Average \n Entry Rule: Buy 1000 shares when price crosses and closes above 52 week Simple Moving Average \n Exit Rule: Exit all positions when prices crosses and closes below 52 week Simple Moving Average \n Classification: Long term trend following strategy \n \n Strategy 2 \n \n Indicator: RSI(2) on weekly data \n Entry Rule: Buy 100 shares when RSI(2) is less than 20 (Note that if RSI(2) is below 20 for N days, then you will have accumulated N * 100 shares) \n Exit Rule: Exit all positions when RSI(2) is greater than 50 \n Classification: Short-Medium term reversal (dip buying) strategy \n \n What did we diversify? \n \n Symbols? \u2013 No, the exact same instruments were used in the strategy. \n Markets? -\u00a0No, see #1. \n Timeframe? Sort of, Strategy1 is a long term strategy and Strategy2 is a shorter term strategy, but both are on the weekly timeframe. We could diversify further by trading even shorter timeframes (i.e. Daily, Hourly, minute, tick, etc.) \n Strategy? Yes, Strategy1 is a trend following strategy and Strategy2 is a reversal strategy. \n Risk Levels? Yes, Strategy2 trades more often, but in smaller increments. \n \n We achieved fairly low correlations by achieving only three \u201clevels\u201d of diversification. Think what we could do by using a \u201ckitchen sink\u201d portfolio with grains, softs, metals, currencies, stocks, fixed income, international stocks, international fixed income, style ETFs, etc. \n Three R script files were used in the last post . \n strategy1.R,\u00a0strategy2.R, and correlation chart.R \n The R scripts are pretty self explanatory so I won\u2019t go into much detail. However, I do want to call attention to 2 lines of code from strategy1.R. The code for strategy2.R is virtually identical. \n \n \n # logarithmic returns of the equity curve of strategy1. \nstrategy1_eclogret <- ec$logret\n\n # write the logarithmic returns of strategy 1 to a csv file with the filename \"strategy1.csv\" \n # you will have to change the file where you want to save it \nwrite.zoo ( strategy1_eclogret , file = \"~/R/strats_for_cor/strategy1.csv\" , sep= \",\" ) \n \n \n Created by Pretty R at inside-R.org \n Here is the code to make the correlation chart. \n \n \n #Load the packages used \n require ( PerformanceAnalytics ) \n\n # load the strategy 1 returns \nstrat1 <- as.xts ( read.zoo ( file = \"~/R/strats_for_cor/strategy1.csv\" , header = TRUE , sep= \",\" ) ) \n colnames ( strat1 ) <- \"strat1\" \n\n # load the strategy 2 returns \nstrat2 <- as.xts ( read.zoo ( file = \"~/R/strats_for_cor/strategy2.csv\" , header = TRUE , sep= \",\" ) ) \n colnames ( strat2 ) <- \"strat2\" \n\n suppressWarnings ( chart.RollingCorrelation ( strat1 , strat2 , width = 52 , xaxis = TRUE , \n           colorset = rich8equal , legend.loc = \"bottomright\" , \n           main = \"Rolling 52 Week Correlation\" ) ) \n \n \n Created by Pretty R at inside-R.org \n And that is all there is to it. (run strategy1.R, run strategy2.R, then run correlation chart.R \u2013 don\u2019t forget to change the file directory!) \n I listed 5 \u201clevels\u201d or ways to achieve diversification\u2026 what are other ways we can diversify? \u2013 post your ideas in the comments"], "link": "http://rbresearch.wordpress.com/2012/06/25/strategy-diversification-in-r-follow-up/", "bloglinks": {}, "links": {"https://docs.google.com/": 1, "http://feeds.wordpress.com/": 1, "http://rbresearch.wordpress.com/": 2, "http://inside-r.org/": 8, "http://www.inside-r.org/": 2}, "blogtitle": "rbresearch"}, {"content": ["In my last post , I looked at the correlations of different instruments. Understanding the correlations of instruments is important when developing a strategy and selecting the assets to include. In theory, selecting highly correlated instruments for a portfolio or strategy will be more volatile than a portfolio or strategy with several uncorrelated instruments. This sounds great in theory, but can be difficult to apply in real life. Why? \u2013 correlations change over time and just diversifying among instruments is not enough. Just take a look at the graph below from my post on correlations as well as Systematic Investor\u2019s analysis of Cross Sectional Correlation . \n \n Correlations are changing over time and markets are becoming more correlated in recent times. As the correlations between markets and instruments increases, the impact of diversification decreases. You may be asking yourself (like I am), \u201cIf I can\u2019t diversify among assets, what else can I do to diversify?\u201d My answer to this is to diversify in as many ways as you can \u2013 trade multiple strategies, multiple timeframes, multiple risk levels, multiple markets, multiple instruments, etc. \n To demonstrate this, I will take two strategies: \n \n Strategy1 \u2013 longer term strategy \n Strategy2 \u2013 shorter term strategy \n \n (Yes\u2026 I realize that I am being very vague about the strategies at this point, more on the strategy details later in the post.) \n Here are the outcomes of each strategy using quantstrat to backtest. \n Strategy 1 \n \n \n \n CAGR \n maxDD \n MAR \n \n \n 6.599 \n -36.358 \n 0.182 \n \n \n \n  rbresearch \n Strategy 2 \n \n \n \n CAGR \n maxDD \n MAR \n \n \n 2.637 \n -9.637 \n 0.274 \n \n \n \n  rbresearch \n How does each strategy correlate to eachother? \n  rbresearch \n The chart above shows that Strategy 1 is not very strongly correlated with Strategy 2. \n Now for more information on the strategies. \n \n Strategy 1 and Strategy 2 both trade the same universe of instruments\u00a0(\u201cXLY\u201d, \u201cXLP\u201d, \u201cXLE\u201d, \u201cXLF\u201d, \u201cXLV\u201d, \u201cXLI\u201d, \u201cXLK\u201d, \u201cXLB\u201d, \u201cXLU\u201d) \n Strategy 1 is a 52 week moving average strategy and trades 1000 contracts per trade* \n Strategy 2 is a RSI(2) on weekly data strategy and trades 100 contracts per trade* \n *Note on position sizing. Normally I would do a volatility based position sizing, but the RSI(2) strategy took about 20 minutes to complete the test because of the looping in the order sizing function. So for brevity and testing purposes I used fixed contract sizes as stated above for each strategy. \n \n Are you surprised that two strategies that trade the exact same set of instruments would not have a higher correlation? I was! \n This example reinforces how diversification can be achieved in more ways than one. \n In follow-up posts, I will share the R code for the strategies and show how I plotted the correlations."], "link": "http://rbresearch.wordpress.com/2012/06/17/strategy-diversification-in-r/", "bloglinks": {}, "links": {"http://systematicinvestor.wordpress.com/": 1, "http://feeds.wordpress.com/": 1, "http://rbresearch.wordpress.com/": 4}, "blogtitle": "rbresearch"}, {"content": ["In this post, I will demonstrate how to quickly visualize correlations using the PerformanceAnalytics package. Thanks to the package creators, it is really easy correlation and many other performance metrics. \n The first chart looks at the rolling 252 day correlation of nine sector ETFs using SPY as the benchmark. As expected the correlation is rather high because the sector ETFs are part of the S&P 500 index, but has been even more pronounced the last few years. \n  rbresearch \n Chart 2 shows the correlation of five ETFs. Note that there is no single instrument I am using as a benchmark, all five ETFs will be benchmarked against one another. (note that I removed the legend because it literally took up the entire plot). \n  rbresearch \n Chart 3 shows the same 4 ETFs, this time using SPY as a benchmark. \n  rbresearch \n In my opinion, the beauty of the chart.RollingCorrelation function is that the inputs are time series returns. This means that the correlations of instruments (ETFs, stocks, mutual funds, etc.), hedge fund managers, portfolios, and even strategies we test in quantstrat. \n Here is the R code used to generate the first chart. To do you own correlation analysis, just change the symbols or add in new data sets of different returns. \n \n \n #Correlations of Sector ETFs to benchmarked against SPY \n\n #Load the packages used \n require ( PerformanceAnalytics ) \n require ( quantmod ) \n\n #create a list of symbols \n symbols = c ( \"XLY\" , \"XLP\" , \"XLE\" , \"XLF\" , \"XLV\" , \"XLI\" , \"XLK\" , \"XLB\" , \"XLU\" ) \nretsymbols <- paste ( \"ret\" , symbols , sep = \".\" ) \n\n #Downlad the data from yahoo \ngetSymbols ( symbols , src = 'yahoo' , index.class = c ( \"POSIXt\" , \"POSIXct\" ) , from = '2000-01-01' ) \ngetSymbols ( \"SPY\" , src = 'yahoo' , index.class = c ( \"POSIXt\" , \"POSIXct\" ) , from = '2000-01-01' ) \n\n #The benchmark is the return vector of which the other assets will be benchmarked against \nbenchmark <- ROC ( Ad ( SPY ) , n= 1 , type= \"continuous\" , na.pad= TRUE ) \n colnames ( benchmark ) <- \"SPY\" \n\n #Loop to create new xts objects with just the returns \n for ( symbol in symbols ) { \n x <- get ( symbol ) \n x1 <- ROC ( Ad ( x ) , n= 1 , type= \"continuous\" , na.pad= TRUE ) \n colnames ( x1 ) <- gsub ( \"x\" , symbol , colnames ( x1 ) ) \n assign ( paste ( \"ret\" , symbol , sep = \".\" ) , x1 ) \n } \n\n #this merges all of the objects in 'retsymbols' into one object named 'ret' \nret <- do.call ( merge , lapply ( retsymbols , get ) ) \n\n suppressWarnings ( chart.RollingCorrelation ( ret [ , 1 : ncol ( ret ) ] , benchmark , width = 252 , xaxis = TRUE , \n       colorset = rich8equal , legend.loc = \"bottomright\" , \n       main = \"Rolling 252 Day Correlation\" ) ) \n \n \n Created by Pretty R at inside-R.org"], "link": "http://rbresearch.wordpress.com/2012/05/24/quick-view-on-correlations-of-different-asset-classes/", "bloglinks": {}, "links": {"http://inside-r.org/": 29, "http://feeds.wordpress.com/": 1, "http://rbresearch.wordpress.com/": 3, "http://www.inside-r.org/": 1}, "blogtitle": "rbresearch"}, {"content": ["In part 2 , we saw that adding a volatility filter to a single instrument test did little to improve performance or risk adjusted returns. How will the volatility filter impact a multiple instrument portfolio? \n In part 3 of the follow up, I will evaluate the impact of the volatility filter on a multiple instrument test. \n The tests will use nine of the Select Sector SPDR ETFs listed below. \n XLY \u2013 Consumer Discretionary Select Sector SPDR \nXLP \u2013 Consumer Staples Select Sector SPDR \nXLE \u2013 Energy Select Sector SPDR \nXLF \u2013 Financial Select Sector SPDR \nXLV \u2013 Health Care Select Sector SPDR \nXLI \u2013 Industrial Select Sector SPDR \nXLK \u2013 Technology Select Sector SPDR \nXLB \u2013 Materials Select Sector SPDR \nXLU \u2013 Utilities Select Sector SPDR \n Test #1 \u2013 without volatility filter \n Start Date*: 2001-01-01 \n Test#2 \u2013 with volatility filter \n Start Date*: 2000-01-01 \n *Note the difference in start dates. The volatility filter requires an extra 52 periodsto process the RBrev1 indicator so the test dates are offset by 52 weeks (one year). \n Both tests will risk 1% of account equity and the stop size is 1 standard deviation. \n Test #1 is a simple moving average strategy without a volatility filter on a portfolio of the nine sector ETFs mentioned previously. This will be the baseline for comparison of the strategy with the volatility filter. \n Test #1 Buy and Exit Rules \n \n Buy Rule: Go long if close crosses above the 52 period SMA \n Exit Rule: Exit if close crosses below the 52 period SMA \n \n Test #1 Performance Statistics \n \n \n \n \n \n \n \n \n \n Test \n CAGR (%) \n MaxDD (%) \n MAR \n \n \n Test#1 \n 7.976377 \n -14.92415 \n 0.534461 \n \n \n \n \n \n \n  rbresearch \n \n Test #2 will be a simple moving average strategy\u00a0with a volatility filter on the same 9 ETFs. The volatility filter is the same measure used in Follow-Up Part 2 . The volatility filter is simply the\u00a052 period standard deviation of close prices. \n Test #2 Buy and Exit Rules \n The new volatility filter will be the 52 period standard deviation of close prices. Now, the buy rule can be interpreted as follows: \n \n Buy Rule: Go long if close is greater than the 52 period SMA and the 52 period standard deviation of close prices is less than its median over the last 52 periods. \n Exit Rule: Exit if long and close is less than the 52 period SMA \n \n Test#2 Performance Statistics \n \n \n \n \n \n \n \n Test \n CAGR (%) \n MaxDD (%) \n MAR \n \n \n Test#2 \n 7.6694587 \n -14.6590123 \n 0.523191 \n \n \n \n  rbresearch \n Both strategies perform fairly well. I would give a slight edge to Test#1, the strategy without a volatility filter. The strategy without a volatility filter has a slightly higher maximum drawdown (MaxDD), but also a higher CAGR. \n \n \n \n Test \n CAGR (%) \n MaxDD (%) \n MAR \n \n \n Test#1 \n 7.976377 \n -14.92415 \n 0.534461 \n \n \n Test#2 \n 7.6694587 \n -14.65901 \n 0.523191 \n \n \n \n Below I will include the R code for the test#2, shoot me an email if you want the code for test#1. \n \n \n #Weekly Timing Strategy with Volatility Filter \n require ( PerformanceAnalytics ) \n require ( quantstrat ) \n\n suppressWarnings ( rm ( \"order_book.TimingWeekly\" , pos=.strategy ) ) \n suppressWarnings ( rm ( \"account.TimingWeekly\" , \"portfolio.TimingWeekly\" , pos=.blotter ) ) \n suppressWarnings ( rm ( \"account.st\" , \"portfolio.st\" , \"symbols\" , \"stratBBands\" , \"initDate\" , \"initEq\" , 'start_t' , 'end_t' ) ) \n\n ##### Begin Functions ##### \n\n #Custom Order Sizing Function to trade percent of equity based on a stopsize \nosPCTEQ <- function ( timestamp , orderqty , portfolio , symbol , ruletype , ... ) { \n tempPortfolio <- getPortfolio ( portfolio.st ) \n dummy <- updatePortf ( Portfolio =portfolio.st , Dates = paste ( '::' , as.Date ( timestamp ) , sep= '' ) ) \n trading.pl <- sum ( getPortfolio ( portfolio.st ) $summary$Realized.PL ) #change to ..$summary$Net.Trading.PL for Total Equity Position Sizing \n assign ( paste ( \"portfolio.\" , portfolio.st , sep= \"\" ) , tempPortfolio , pos=.blotter ) \n total.equity <- initEq+trading.pl\n DollarRisk <- total.equity * trade.percent\n ClosePrice <- as.numeric ( Cl ( mktdata [ timestamp , ] ) ) \n mavg <- as.numeric ( mktdata$SMA [ timestamp , ] ) \n sign1 <- ifelse ( ClosePrice > mavg , 1 , - 1 ) \n sign1 [ is.na ( sign1 ) ] <- 1 \n Posn = getPosQty ( Portfolio = portfolio.st , Symbol = symbol , Date = timestamp ) \n StopSize <- as.numeric ( mktdata$SDEV [ timestamp , ] *StopMult ) #Stop = SDAVG * StopMult !Must have SDAVG or other indictor to determine stop size \n #orderqty <- round(DollarRisk/StopSize, digits=0) \n orderqty <- ifelse ( Posn == 0 , sign1* round ( DollarRisk/StopSize ) , 0 ) # number contracts traded is equal to DollarRisk/StopSize \n return ( orderqty ) \n } \n\n #Function that calculates the n period standard deviation of close prices. \n #This is used in place of ATR so that I can use only close prices. \nSDEV <- function ( x , n ) { \n sdev <- runSD ( x , n , sample = FALSE ) \n colnames ( sdev ) <- \"SDEV\" \n reclass ( sdev , x ) \n } \n\n #Custom indicator function \nRBrev1 <- function ( x , n ) { \n x <- x\n sd <- runSD ( x , n , sample = FALSE ) \n med <- runMedian ( sd , n ) \n mavg <- SMA ( x , n ) \n signal <- ifelse ( sd < med & x > mavg , 1 , 0 ) \n colnames ( signal ) <- \"RB\" \n #ret <- cbind(x,roc,sd,med,mavg,signal) #Only use for further analysis of indicator \n #colnames(ret) <- c(\"close\",\"roc\",\"sd\",\"med\",\"mavg\",\"RB\") #Only use for further analysis of indicator \n reclass ( signal , x ) \n } \n\n ##### End Functions ##### \n\n #Symbols to be used in test \n #XLY - Consumer Discretionary Select Sector SPDR \n #XLP - Consumer Staples Select Sector SPDR \n #XLE - Energy Select Sector SPDR \n #XLF - Financial Select Sector SPDR \n #XLV - Health Care Select Sector SPDR \n #XLI - Industrial Select Sector SPDR \n #XLK - Technology Select Sector SPDR \n #XLB - Materials Select Sector SPDR \n #XLU - Utilities Select Sector SPDR \n\n #Symbol list to pass to the getSymbols function \n symbols = c ( \"XLY\" , \"XLP\" , \"XLE\" , \"XLF\" , \"XLV\" , \"XLI\" , \"XLK\" , \"XLB\" , \"XLU\" ) \n\n #Load ETFs from yahoo \ncurrency ( \"USD\" ) \nstock ( symbols , currency= \"USD\" , multiplier= 1 ) \ngetSymbols ( symbols , src= 'yahoo' , index.class= c ( \"POSIXt\" , \"POSIXct\" ) , from= '2000-01-01' ) \n\n #Data is downloaded as daily data \n #Convert to weekly \n for ( symbol in symbols ) { \n x<- get ( symbol ) \n x<-to.weekly ( x , indexAt= 'lastof' , drop.time= TRUE ) \n indexFormat ( x ) <- '%Y-%m-%d' \n colnames ( x ) <- gsub ( \"x\" , symbol , colnames ( x ) ) \n assign ( symbol , x ) \n } \n\n #Use the adjusted close prices \n #this for loop sets the \"Close\" column equal to the \"Adjusted Close\" column \n #because the trades are executed based on the \"Close\" column \n for ( symbol in symbols ) { \n x<- get ( symbol ) \n x [ , 4 ] <- x [ , 6 ] \n assign ( symbol , x ) \n } \n\ninitDate= '1900-01-01' \ninitEq <- 100000 \n\ntrade.percent <- 0.01 #percent risk used in sizing function \nStopMult = 1 #stop size used in sizing function \n\n #Name the portfolio and account \nportfolio.st = 'TimingWeekly' \naccount.st = 'TimingWeekly' \n\n #Initialization \ninitPortf ( portfolio.st , symbols = symbols , initPosQty= 0 , initDate=initDate , currency= \"USD\" ) \ninitAcct ( account.st , portfolios=portfolio.st , initDate=initDate , initEq=initEq ) \ninitOrders ( portfolio =portfolio.st , initDate=initDate ) \n\n #Name the strategy \nstrat <- strategy ( 'TimingWeekly' ) \n\n #Add indicators \n #The first indicator is the 52 period SMA \n #The second indicator is the SDEV indicator used for stop and position sizing \nstrat <- add.indicator ( strategy = strat , name = \"SMA\" , arguments = list ( x = quote ( Cl ( mktdata ) ) , n= 52 ) , label= \"SMA\" ) \nstrat <- add.indicator ( strategy = strat , name = \"RBrev1\" , arguments = list ( x = quote ( Cl ( mktdata ) ) , n= 52 ) , label= \"RB\" ) \nstrat <- add.indicator ( strategy = strat , name = \"SDEV\" , arguments = list ( x = quote ( Cl ( mktdata ) ) , n= 52 ) , label= \"SDEV\" ) \n\n #Add signals \n #The buy signal is when the RB indicator crosses from 0 to 1 \n #The exit signal is when the close crosses below the SMA \nstrat <- add.signal ( strategy = strat , name= \"sigThreshold\" , arguments = list ( threshold= 1 , column= \"RB\" , relationship= \"gte\" , cross= TRUE ) , label= \"RB.gte.1\" ) \nstrat <- add.signal ( strategy = strat , name= \"sigCrossover\" , arguments = list ( columns= c ( \"Close\" , \"SMA\" ) , relationship= \"lt\" ) , label= \"Cl.lt.SMA\" ) \n\n #Add rules \nstrat <- add.rule ( strategy = strat , name= 'ruleSignal' , arguments = list ( sigcol= \"RB.gte.1\" , sigval= TRUE , orderqty= 1000 , ordertype= 'market' , orderside= 'long' , osFUN = 'osPCTEQ' , pricemethod= 'market' , replace = FALSE ) , type= 'enter' , path.dep= TRUE ) \nstrat <- add.rule ( strategy = strat , name= 'ruleSignal' , arguments = list ( sigcol= \"Cl.lt.SMA\" , sigval= TRUE , orderqty= 'all' , ordertype= 'market' , orderside= 'long' , pricemethod= 'market' , TxnFees= 0 ) , type= 'exit' , path.dep= TRUE ) \n\n # Process the indicators and generate trades \nstart_t<- Sys.time ( ) \nout<- try ( applyStrategy ( strategy = strat , portfolios = portfolio.st ) ) \nend_t<- Sys.time ( ) \n print ( \"Strategy Loop:\" ) \n print ( end_t-start_t ) \n\nstart_t<- Sys.time ( ) \nupdatePortf ( Portfolio =portfolio.st , Dates = paste ( '::' , as.Date ( Sys.time ( ) ) , sep= '' ) ) \nend_t<- Sys.time ( ) \n print ( \"updatePortf execution time:\" ) \n print ( end_t-start_t ) \n\n #chart.Posn(Portfolio=portfolio.st,Symbol=symbols) \n\n #Update Account \nupdateAcct ( account.st ) \n\n #Update Ending Equity \nupdateEndEq ( account.st ) \n\n #ending equity \ngetEndEq ( account.st , Sys.Date ( ) ) + initEq\n\ntstats <- tradeStats ( Portfolio =portfolio.st , Symbol= symbols ) \n\n #View order book to confirm trades \n #getOrderBook(portfolio.st) \n\n #Trade Statistics for CAGR, Max DD, and MAR \n #calculate total equity curve performance Statistics \nec <- tail ( cumsum ( getPortfolio ( portfolio.st ) $summary$Net.Trading.PL ) , - 1 ) \nec$initEq <- initEq\nec$totalEq <- ec$Net.Trading.PL + ec$initEq\nec$maxDD <- ec$totalEq/cummax ( ec$totalEq ) - 1 \nec$logret <- ROC ( ec$totalEq , n= 1 , type= \"continuous\" ) \nec$logret [ is.na ( ec$logret ) ] <- 0 \n\nWI <- exp ( cumsum ( ec$logret ) ) #growth of $1 \n #write.zoo(nofilterWI, file = \"E:\\\\nofiltertest.csv\", sep=\",\") \n\nperiod.count <- NROW ( ec ) - 104 #Use 104 because there is a 104 week lag for the 52 week SD and 52 week median of SD \nyear.count <- period.count/ 52 \nmaxDD <- min ( ec$maxDD ) * 100 \ntotret <- as.numeric ( last ( ec$totalEq ) ) /as.numeric ( first ( ec$totalEq ) ) \nCAGR <- ( totret^ ( 1 /year.count ) - 1 ) * 100 \n MAR <- CAGR/abs ( maxDD ) \n\nPerf.Stats <- c ( CAGR , maxDD , MAR ) \n names ( Perf.Stats ) <- c ( \"CAGR\" , \"maxDD\" , \"MAR\" ) \nPerf.Stats\n\n #transactions <- getTxns(Portfolio = portfolio.st, Symbol = symbols) \n #write.zoo(transactions, file = \"E:\\\\nofiltertxn.csv\") \n\ncharts.PerformanceSummary ( ec$logret , wealth.index = TRUE , ylog = TRUE , colorset = \"steelblue2\" , main = \"Strategy with Volatility Filter\" ) \n \n \n Created by Pretty R at inside-R.org"], "link": "http://rbresearch.wordpress.com/2012/05/10/simple-moving-average-strategy-with-a-volatility-filter-follow-up-part-3/", "bloglinks": {}, "links": {"http://inside-r.org/": 116, "http://feeds.wordpress.com/": 1, "http://rbresearch.wordpress.com/": 5, "http://www.inside-r.org/": 1}, "blogtitle": "rbresearch"}, {"content": ["In the Follow-Up Part 1 , I explored some of the functions in the quantstrat package that allowed us to drill down trade by trade to explain the difference in performance of the two strategies. By doing this, I found that my choice of a volatility measure may not have been the best choice. Although the volatility filter kept me out of trades during periods of higher volatility, it also had a negative impact on position sizing and overall return. \n The volatility measure presented in the original post was\u00a0the 52 period standard deviation of the 1 period change of close prices. I made a custom indicator to incorporate the volatility filter into the buy rule. Here is the original RB function: \n \n \n #Custom indicator function \nRB <- function ( x , n ) { \n x <- x\n roc <- ROC ( x , n= 1 , type= \"discrete\" ) \n sd <- runSD ( roc , n , sample = FALSE ) \n med <- runMedian ( sd , n ) \n mavg <- SMA ( x , n ) \n signal <- ifelse ( sd < med & x > mavg , 1 , 0 ) \n colnames ( signal ) <- \"RB\" \n reclass ( signal , x ) \n } \n \n \n Created by Pretty R at inside-R.org \n The new volatility filter will be the 52 period standard deviation of close prices. Now, the buy rule can be interpreted as follows: \n \n Buy Rule: Go long if close is greater than the 52 period SMA and the 52 period standard deviation of close prices is less than its median over the last N periods. \n Exit Rule: Exit if long and close is less than the N period SMA \n \n A slight change to the RB function will do the trick, I will call it RBrev1 (that is my creative side coming out ) \n \n \n #Custom indicator function \nRBrev1 <- function ( x , n ) { \n x <- x\n sd <- runSD ( x , n , sample = FALSE ) \n med <- runMedian ( sd , n ) \n mavg <- SMA ( x , n ) \n signal <- ifelse ( sd < med & x > mavg , 1 , 0 ) \n colnames ( signal ) <- \"RB\" \n #ret <- cbind(x,roc,sd,med,mavg,signal) #Only use for further analysis of indicator \n #colnames(ret) <- c(\"close\",\"roc\",\"sd\",\"med\",\"mavg\",\"RB\") #Only use for further analysis of indicator \n reclass ( signal , x ) \n } \n \n \n Created by Pretty R at inside-R.org \n I will test the strategy on the adjusted close of the S&P500 using weekly prices from 1/1/1990 to 1/1/2000 just as in the previous post. \n And the winner is\u2026 both! There is no difference in performance on this single instrument in this specific window of time I used for the test. \n  rbresearch \n Always do your own testing to decide whether or not a filter of any kind will add value to your system. This single instrument test in the series of posts showed that choosing the \u201cwrong\u201d volatility filter can hinder performance and another choice of volatility filter doesn\u2019t have much impact, if any, at all. \n How do you think the volatility filter will affect a multiple instrument test? \n \n \n require ( PerformanceAnalytics ) \n require ( quantstrat ) \n\n suppressWarnings ( rm ( \"order_book.RBtest\" , pos=.strategy ) ) \n suppressWarnings ( rm ( \"account.RBtest\" , \"portfolio.RBtest\" , pos=.blotter ) ) \n suppressWarnings ( rm ( \"account.st\" , \"portfolio.st\" , \"symbols\" , \"stratBBands\" , \"initDate\" , \"initEq\" , 'start_t' , 'end_t' ) ) \n\nsym.st = \"GSPC\" \ncurrency ( \"USD\" ) \nstock ( sym.st , currency= \"USD\" , multiplier= 1 ) \ngetSymbols ( \"^GSPC\" , src= 'yahoo' , index.class= c ( \"POSIXt\" , \"POSIXct\" ) , from= '1990-01-01' , to= '2012-04-17' ) \nGSPC <- to.weekly ( GSPC , indexAt= 'lastof' , drop.time= TRUE ) \n\n #Custom Order Sizing Function to trade percent of equity based on a stopsize \nosPCTEQ <- function ( timestamp , orderqty , portfolio , symbol , ruletype , ... ) { \n tempPortfolio <- getPortfolio ( portfolio.st ) \n dummy <- updatePortf ( Portfolio =portfolio.st , Dates = paste ( '::' , as.Date ( timestamp ) , sep= '' ) ) \n trading.pl <- sum ( getPortfolio ( portfolio.st ) $summary$Realized.PL ) #change to ..$summary$Net.Trading.PL for Total Equity Position Sizing \n assign ( paste ( \"portfolio.\" , portfolio.st , sep= \"\" ) , tempPortfolio , pos=.blotter ) \n total.equity <- initEq+trading.pl\n DollarRisk <- total.equity * trade.percent\n ClosePrice <- as.numeric ( Cl ( mktdata [ timestamp , ] ) ) \n mavg <- as.numeric ( mktdata$SMA52 [ timestamp , ] ) \n sign1 <- ifelse ( ClosePrice > mavg , 1 , - 1 ) \n sign1 [ is.na ( sign1 ) ] <- 1 \n Posn = getPosQty ( Portfolio = portfolio.st , Symbol = sym.st , Date = timestamp ) \n StopSize <- as.numeric ( mktdata$SDEV [ timestamp , ] *StopMult ) #Stop = SDAVG * StopMult !Must have SDAVG or other indictor to determine stop size \n orderqty <- ifelse ( Posn == 0 , sign1* round ( DollarRisk/StopSize ) , 0 ) # number contracts traded is equal to DollarRisk/StopSize \n return ( orderqty ) \n } \n\n #Function that calculates the n period standard deviation of close prices. \n #This is used in place of ATR so that I can use only close prices. \nSDEV <- function ( x , n ) { \n sdev <- runSD ( x , n , sample = FALSE ) \n colnames ( sdev ) <- \"SDEV\" \n reclass ( sdev , x ) \n } \n\n #Custom indicator function \nRBrev1 <- function ( x , n ) { \n x <- x\n sd <- runSD ( x , n , sample = FALSE ) \n med <- runMedian ( sd , n ) \n mavg <- SMA ( x , n ) \n signal <- ifelse ( sd < med & x > mavg , 1 , 0 ) \n colnames ( signal ) <- \"RB\" \n #ret <- cbind(x,roc,sd,med,mavg,signal) #Only use for further analysis of indicator \n #colnames(ret) <- c(\"close\",\"roc\",\"sd\",\"med\",\"mavg\",\"RB\") #Only use for further analysis of indicator \n reclass ( signal , x ) \n } \n\ninitDate= '1900-01-01' \ninitEq <- 100000 \n\ntrade.percent <- .05 #percent risk used in sizing function \nStopMult = 1 #stop size used in sizing function \n\n #Name the portfolio and account \nportfolio.st= 'RBtest' \naccount.st= 'RBtest' \n\n #Initialization \ninitPortf ( portfolio.st , symbols =sym.st , initPosQty= 0 , initDate=initDate , currency= \"USD\" ) \ninitAcct ( account.st , portfolios=portfolio.st , initDate=initDate , initEq=initEq ) \ninitOrders ( portfolio =portfolio.st , initDate=initDate ) \n\n #Name the strategy \nstratRB <- strategy ( 'RBtest' ) \n\n #Add indicators \n #The first indicator is the 52 period SMA \n #The second indicator is the RB indicator. The RB indicator returns a value of 1 when close > SMA & volatility < runMedian(volatility, n = 52) \nstratRB <- add.indicator ( strategy = stratRB , name = \"SMA\" , arguments = list ( x = quote ( Cl ( mktdata ) ) , n= 52 ) , label= \"SMA52\" ) \nstratRB <- add.indicator ( strategy = stratRB , name = \"RBrev1\" , arguments = list ( x = quote ( Cl ( mktdata ) ) , n= 52 ) , label= \"RB\" ) \nstratRB <- add.indicator ( strategy = stratRB , name = \"SDEV\" , arguments = list ( x = quote ( Cl ( mktdata ) ) , n= 52 ) , label= \"SDEV\" ) \n\n #Add signals \n #The buy signal is when the RB indicator crosses from 0 to 1 \n #The exit signal is when the close crosses below the SMA \nstratRB <- add.signal ( strategy = stratRB , name= \"sigThreshold\" , arguments = list ( threshold= 1 , column= \"RB\" , relationship= \"gte\" , cross= TRUE ) , label= \"RB.gte.1\" ) \nstratRB <- add.signal ( strategy = stratRB , name= \"sigCrossover\" , arguments = list ( columns= c ( \"Close\" , \"SMA52\" ) , relationship= \"lt\" ) , label= \"Cl.lt.SMA\" ) \n\n #Add rules \nstratRB <- add.rule ( strategy = stratRB , name= 'ruleSignal' , arguments = list ( sigcol= \"RB.gte.1\" , sigval= TRUE , orderqty= 1000 , ordertype= 'market' , orderside= 'long' , osFUN = 'osPCTEQ' , pricemethod= 'market' , replace = FALSE ) , type= 'enter' , path.dep= TRUE ) \nstratRB <- add.rule ( strategy = stratRB , name= 'ruleSignal' , arguments = list ( sigcol= \"Cl.lt.SMA\" , sigval= TRUE , orderqty= 'all' , ordertype= 'market' , orderside= 'long' , pricemethod= 'market' , TxnFees= 0 ) , type= 'exit' , path.dep= TRUE ) \n\n # Process the indicators and generate trades \nstart_t<- Sys.time ( ) \nout<- try ( applyStrategy ( strategy=stratRB , portfolios=portfolio.st ) ) \nend_t<- Sys.time ( ) \n print ( \"Strategy Loop:\" ) \n print ( end_t-start_t ) \n\nstart_t<- Sys.time ( ) \nupdatePortf ( Portfolio =portfolio.st , Dates = paste ( '::' , as.Date ( Sys.time ( ) ) , sep= '' ) ) \nend_t<- Sys.time ( ) \n print ( \"updatePortf execution time:\" ) \n print ( end_t-start_t ) \n\nchart.Posn ( Portfolio =portfolio.st , Symbol=sym.st ) \n\n #Update Account \nupdateAcct ( account.st ) \n\n #Update Ending Equity \nupdateEndEq ( account.st ) \n\n #ending equity \ngetEndEq ( account.st , Sys.Date ( ) ) + initEq\n\ntstats <- tradeStats ( Portfolio =portfolio.st , Symbol=sym.st ) \n\n #View order book to confirm trades \ngetOrderBook ( portfolio.st ) \n\n #Trade Statistics for CAGR, Max DD, and MAR \n #calculate total equity curve performance Statistics \nec <- tail ( cumsum ( getPortfolio ( portfolio.st ) $summary$Net.Trading.PL ) , - 1 ) \nec$initEq <- initEq\nec$totalEq <- ec$Net.Trading.PL + ec$initEq\nec$maxDD <- ec$totalEq/cummax ( ec$totalEq ) - 1 \nec$logret <- ROC ( ec$totalEq , n= 1 , type= \"continuous\" ) \nec$logret [ is.na ( ec$logret ) ] <- 0 \n\nRBrev1WI <- exp ( cumsum ( ec$logret ) ) #growth of $1 \n #write.zoo(RBrev1WI, file = \"E:\\\\volfiltertest.csv\", sep=\",\") \n\nperiod.count <- NROW ( ec ) - 104 #Use 104 because there is a 104 week lag for the 52 week SD and 52 week median of SD \nyear.count <- period.count/ 52 \nmaxDD <- min ( ec$maxDD ) * 100 \ntotret <- as.numeric ( last ( ec$totalEq ) ) /as.numeric ( first ( ec$totalEq ) ) \nCAGR <- ( totret^ ( 1 /year.count ) - 1 ) * 100 \n MAR <- CAGR/abs ( maxDD ) \n\nPerf.Stats <- c ( CAGR , maxDD , MAR ) \n names ( Perf.Stats ) <- c ( \"CAGR\" , \"maxDD\" , \"MAR\" ) \nPerf.Stats\n\ntransactions <- getTxns ( Portfolio = portfolio.st , Symbol = sym.st ) \n #write.zoo(transactions, file = \"E:\\\\filtertxn.csv\") \n\ncharts.PerformanceSummary ( ec$logret , wealth.index = TRUE , ylog = TRUE , colorset = \"steelblue2\" , main = \"SMA with Volatility Filter System Performance\" ) \n \n \n Created by Pretty R at inside-R.org"], "link": "http://rbresearch.wordpress.com/2012/04/30/simple-moving-average-strategy-with-a-volatility-filter-follow-up-part-2/", "bloglinks": {}, "links": {"http://inside-r.org/": 117, "http://feeds.wordpress.com/": 1, "http://rbresearch.wordpress.com/": 3, "http://www.inside-r.org/": 3}, "blogtitle": "rbresearch"}]
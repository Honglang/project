[{"blogurl": "http://bergmanlab.smith.man.ac.uk/?page_id=45\n", "blogroll": [], "title": "Bergman Lab"}, {"content": ["We in the Bergman Lab are big supporters of the Public Library of Science , and increasingly have been submitting papers to PLOS ONE over the last few years because we believe this journal represents the true values of science: openness, technical rigor and objectivity. Because PLOS ONE uses a streamlined production process, their author guidelines are very strict, with article formatting responsibilities falling on the author that would be traditionally handled with the help of a copy editor. \n One area of PLOS ONE article formatting that I have found particularly difficult in the past is to get the exact figure specifications that pass the automated checks of the PLOS ONE Editorial Manager system.\u00a0 Personally, I find the guidelines for figure preparation for PLOS ONE to be somewhat bewildering. In my first few submissions, I wasted substantial time uploading files that failed the automated checks and/or I had nerve-wracking requests to change figure formats at the post-acceptance stage, where I did not get another chance to look at the manuscript before it goes live. After some trial and error, I have gotten my head around what actually works to prepare figures for a trouble-free PLOS ONE submission. So to save a headache and speed up the publication process for one or more scientist out there (and so I have access to these notes out of the office), I\u2019ve typed up a protocol that should work for preparing PLOS ONE-ready figures using Illustrator on OSX. \n 1. Prepare your figure in your favorite sofware (R, Illustrator, etc) and Save. \n 2. Open/Import into Illustrator. \n 3. In Illustrator, under the \u201cFile\u201d menu, select \u201cExport\u2026\u201d. You will now see a window entitled \u201cExport\u201d. \n 4. Select \u201cTIFF (tif)\u201d from the \u201cFormat\u201d dropdown menu. You should see something like this: \n \n 5. Click \u201cExport\u201d. You will now see a window entitled \u201cTIFF Options\u201d. \n 6. Set the \u201cColor Model\u201d drop-down menu to \u201cRGB\u201d. \n 7. Click the \u201cOther\u201d radio button for the \u201cResolution\u201d setting and set to 500 dpi. \n 8. Select the \u201cAnti-Aliasing\u201d check-box. \n 9. Select the \u201cLZW Compression\u201d check-box. At this point you should see a screen something like this: \n \n 10. Click \u201cOK\u201d. \n You should now have a 500 dpi .tif file that is ready to upload with minimal (to no) complaints by the PLOS ONE Editorial Manager, and hopefully your next open-access manuscript will be speeding to publication soon. \n Notes: This recipe was developed using an Illustrator 11.0.0 on a MacBook Air running OSX 10.6.8. Please don\u2019t laugh at my ancient software \u2013 I find upgrading is the enemy of efficiency."], "link": "http://bergmanlab.smith.man.ac.uk/?p=1788", "bloglinks": {}, "links": {"http://www.plos.org/": 1, "http://www.plosone.org/": 1, "http://plosone.org/": 1}, "blogtitle": "Bergman Lab"}, {"content": ["Background: As part of an ongoing efforts to characterize genetic diversity in the nuclear and cytoplasmic genomes of D. melanogaster , the Haddrill and Bergman Labs have collaborated to sequence the complete genomes of 20 D. melanogaster isofemale strains collected by Penny Haddrill in Montpellier, France in August 2010. These 20 genomes represent a random sample of the full collection described by Haddrill and Vespoor (2011) , which also describes microsatellite variation data for these strains. \n Following on from the very generous early release of D. melanogaster genomes by major resequencing efforts in Drosophila , we have decided to follow suit and release these genomes prior to publication to maximise their utility by the wider research community and prevent unnecessary duplication of effort. One major aim for our sequencing of a reasonably high number of strains from this European population is to provide a complementary dataset to help interpret the larger samples of North American and (predominantly) African strains from the Drosophila Genetic Reference Panel and Drosophila Population Genomics Project , respectively. For more on the philosophy behind why we have made the decision to release these data early, please see this blog post on genomic data release by individual labs in the next-generation sequencing era. \n Methods: Genomic DNA was prepared by Penny Haddrill for each isofemale line by pooling fifty females, snap freezing them in liquid nitrogen, extracting DNA using a standard phenol-chloroform extraction protocol with ethanol and ammonium acetate precipitation. 500 bp short-insert libraries were constructed\u00a0and 91 bp paired-end reads were generated using an Illumina HiSeq 2000 to an estimated coverage of ~50x per strain by BGI-Hong Kong. Basic QC on reads was performed by BGI and mapping to the Wolbachia genome following the protocol in Richardson et al. (submitted) confirmed the same infection status for as determined by PCR in Haddrill and Vespoor (2011) . \n Conditions for use: The Haddrill and Bergman labs intend to use these data to study patterns of genetic diversity in the nuclear and cytoplasmic genomes, to estimate the ratio of diversity on the X chromosome relative to the autosomes, to detect signatures of both positive and negative selection in the nuclear and cytoplasmic genomes, and investigate the impact of variation in recombination rate around the genome. \n We have decidede to release these genomic data under a Creative Commons CC-BY license, which requires only that you credit the originators of the work as specified below.\u00a0 However, we hope that users of these data respect the established model of genomic data release under the Ft. Lauderdale agreement that is traditionally honored for major sequencing centers.\u00a0 Until the paper describing these genomes is published, please cite these data as: \n \n Haddrill, P. and C.M. Bergman (2012) 20 Drosophila melanogaster genomes from Montpellier, France. http://bergmanlab.smith.man.ac.uk/?p=1685 \n \n We also ask that downloads of this data be conducted in serial to allow normal functioning of live web services running on this server (see below). \n The data: Gzipped Illumina fastq files for forward and reverse paired reads can be downloaded at the following locations. A script to dowload all files in serial can be found below the table. \n \n \n \n \n Strain \n \n \n Forward (*_1.fq.gz) \n \n \n Reverse (*_2.fq.gz) \n \n \n \n FR23 \n FR23_1.fq.gz \n FR23_2.fq.gz \n \n \n FR24 \n FR24_1.fq.gz \n FR24_2.fq.gz \n \n \n FR25 \n FR25_1.fq.gz \n FR25_2.fq.gz \n \n \n FR26 \n FR26_1.fq.gz \n FR26_2.fq.gz \n \n \n FR28 \n FR28_1.fq.gz \n FR28_2.fq.gz \n \n \n FR29 \n FR29_1.fq.gz \n FR29_2.fq.gz \n \n \n FR30 \n FR30_1.fq.gz \n FR30_2.fq.gz \n \n \n FR31 \n FR31_1.fq.gz \n FR31_2.fq.gz \n \n \n FR32 \n FR32_1.fq.gz \n FR32_2.fq.gz \n \n \n FR33 \n FR33_1.fq.gz \n FR33_2.fq.gz \n \n \n FR34 \n FR34_1.fq.gz \n FR34_2.fq.gz \n \n \n FR35 \n FR35_1.fq.gz \n FR35_2.fq.gz \n \n \n FR37 \n FR37_1.fq.gz \n FR37_2.fq.gz \n \n \n FR38 \n FR38_1.fq.gz \n FR38_2.fq.gz \n \n \n FR39 \n FR39_1.fq.gz \n FR39_2.fq.gz \n \n \n FR42 \n FR42_1.fq.gz \n FR42_2.fq.gz \n \n \n FR44 \n FR44_1.fq.gz \n FR44_2.fq.gz \n \n \n FR45 \n FR45_1.fq.gz \n FR45_2.fq.gz \n \n \n FR46 \n FR46_1.fq.gz \n FR46_2.fq.gz \n \n \n FR48 \n FR48_1.fq.gz \n FR48_2.fq.gz \n \n \n \n A shell script to dowload all files in serial can be found below. \n \n#!/bin/bash\nwget http://bergman.smith.man.ac.uk/data/genomes/FR23_1.fq.gz\nwget http://bergman.smith.man.ac.uk/data/genomes/FR23_2.fq.gz\nwget http://bergman.smith.man.ac.uk/data/genomes/FR24_1.fq.gz\nwget http://bergman.smith.man.ac.uk/data/genomes/FR24_2.fq.gz\nwget http://bergman.smith.man.ac.uk/data/genomes/FR25_1.fq.gz\nwget http://bergman.smith.man.ac.uk/data/genomes/FR25_2.fq.gz\nwget http://bergman.smith.man.ac.uk/data/genomes/FR26_1.fq.gz\nwget http://bergman.smith.man.ac.uk/data/genomes/FR26_2.fq.gz\nwget http://bergman.smith.man.ac.uk/data/genomes/FR28_1.fq.gz\nwget http://bergman.smith.man.ac.uk/data/genomes/FR28_2.fq.gz\nwget http://bergman.smith.man.ac.uk/data/genomes/FR29_1.fq.gz\nwget http://bergman.smith.man.ac.uk/data/genomes/FR29_2.fq.gz\nwget http://bergman.smith.man.ac.uk/data/genomes/FR30_1.fq.gz\nwget http://bergman.smith.man.ac.uk/data/genomes/FR30_2.fq.gz\nwget http://bergman.smith.man.ac.uk/data/genomes/FR31_1.fq.gz\nwget http://bergman.smith.man.ac.uk/data/genomes/FR31_2.fq.gz\nwget http://bergman.smith.man.ac.uk/data/genomes/FR32_1.fq.gz\nwget http://bergman.smith.man.ac.uk/data/genomes/FR32_2.fq.gz\nwget http://bergman.smith.man.ac.uk/data/genomes/FR33_1.fq.gz\nwget http://bergman.smith.man.ac.uk/data/genomes/FR33_2.fq.gz\nwget http://bergman.smith.man.ac.uk/data/genomes/FR34_1.fq.gz\nwget http://bergman.smith.man.ac.uk/data/genomes/FR34_2.fq.gz\nwget http://bergman.smith.man.ac.uk/data/genomes/FR35_1.fq.gz\nwget http://bergman.smith.man.ac.uk/data/genomes/FR35_2.fq.gz\nwget http://bergman.smith.man.ac.uk/data/genomes/FR37_1.fq.gz\nwget http://bergman.smith.man.ac.uk/data/genomes/FR37_2.fq.gz\nwget http://bergman.smith.man.ac.uk/data/genomes/FR38_1.fq.gz\nwget http://bergman.smith.man.ac.uk/data/genomes/FR38_2.fq.gz\nwget http://bergman.smith.man.ac.uk/data/genomes/FR39_1.fq.gz\nwget http://bergman.smith.man.ac.uk/data/genomes/FR39_2.fq.gz\nwget http://bergman.smith.man.ac.uk/data/genomes/FR42_1.fq.gz\nwget http://bergman.smith.man.ac.uk/data/genomes/FR42_2.fq.gz\nwget http://bergman.smith.man.ac.uk/data/genomes/FR44_1.fq.gz\nwget http://bergman.smith.man.ac.uk/data/genomes/FR44_2.fq.gz\nwget http://bergman.smith.man.ac.uk/data/genomes/FR45_1.fq.gz\nwget http://bergman.smith.man.ac.uk/data/genomes/FR45_2.fq.gz\nwget http://bergman.smith.man.ac.uk/data/genomes/FR46_1.fq.gz\nwget http://bergman.smith.man.ac.uk/data/genomes/FR46_2.fq.gz\nwget http://bergman.smith.man.ac.uk/data/genomes/FR48_1.fq.gz\nwget http://bergman.smith.man.ac.uk/data/genomes/FR48_2.fq.gz"], "link": "http://bergmanlab.smith.man.ac.uk/?p=1685", "bloglinks": {}, "links": {"http://www.genome.gov/": 1, "http://www.dpgp.org/": 1, "https://www.bcm.edu/": 1, "http://caseybergman.wordpress.com/": 1, "http://www.plosone.org/": 2, "http://bergman.ac.uk/": 40, "http://creativecommons.org/": 1, "http://arxiv.org/": 1, "http://liberty.ac.uk/": 1, "http://bergmanlab.ac.uk/": 2}, "blogtitle": "Bergman Lab"}, {"content": ["[For a some background on this initiative, please see this Blog post.\u00a0 -CMB] \n The Public Library of Science (PLoS) seeks submissions in the broad field of text-mining research for a collection to be launched across all of its journals in 2013. All submissions submitted before October 30th, 2012 will be considered for the launch of the collection. Please read the following post for further information on how to submit your article. \n The scientific literature is exponentially increasing in size, with thousands of new papers published every day. Few researchers are able to keep track of all new publications, even in their own field, reducing the quality of scholarship and leading to undesirable outcomes like redundant publication. While social media and expert recommendation systems provide partial solutions to the problem of keeping up with the literature, systematically identifying relevant articles and extracting key information from them can only come through automated text-mining technologies. \n Research in text mining has made incredible advances over the last decade, driven through community challenges and increasingly sophisticated computational technologies. However, the promise of text mining to accelerate and enhance research largely has not yet been fulfilled, primarily since the vast majority of the published scientific literature is not published under an Open Access model. As Open Access publishing yields an ever-growing archive of unrestricted full-text articles, text mining will play an increasingly important role in drilling down to essential research and data in scientific literature in the 21st century scholarly landscape. \n As part of its commitment to realizing the maximal utility of Open Access literature, PLoS is launching a collection of articles dedicated to highlighting the importance of research in the area of text mining. The launch of this Text Mining Collection complements related PLoS Collections on Open Access and Altmetrics (forthcoming), as well as the recent release of the PLoS Application Programming Interface , which provides an open API to PLoS journal content. \n As part of this Text Mining Collection, we are making a call for high quality submissions that advance the field of text-mining research, including: \n \n New methods for the retrieval or extraction of published scientific facts \n Large-scale analysis of data extracted from the scientific literature \n New interfaces for accessing the scientific literature \n Semantic enrichment of scientific articles \n Linking the literature to scientific databases \n Application of text mining to database curation \n Approaches for integrating text mining into workflows \n Resources (ontologies, corpora) to improve text mining research \n \n Please note that all submissions submitted before October 30th, 2012 will be considered for the launch of the collection (expected early 2013); submissions after this date will still be considered for the collection, but may not appear in the collection at launch. \n Submission Guidelines \nIf you wish to submit your research to the PLoS Text Mining Collection, please consider the following when preparing your manuscript: \n All articles must adhere to the submission guidelines of the PLoS journal to which you submit. \nStandard PLoS policies and relevant publication fees apply to all submissions. \nSubmission to any PLoS journal as part of the Text Mining Collection does not guarantee publication. \n When you are ready to submit your manuscript to the collection, please log in to the relevant PLoS manuscript submission system and mention the Collection\u2019s name in your cover letter. This will ensure that the staff is aware of your submission to the Collection. The submission systems can be found on the individual journal websites . \n Please contact Samuel Moore (smoore@plos.org) if you would like further information about how to submit your research to the PLoS Text Mining Collection. \n Organizers \n Casey Bergman (University of Manchester) \n Lawrence Hunter (University of Colorado-Denver) \n Andrey Rzhetsky (University of Chicago) \n Cross posted at the PLoS Blog"], "link": "http://bergmanlab.smith.man.ac.uk/?p=1656", "bloglinks": {}, "links": {"http://caseybergman.wordpress.com/": 1, "http://blogs.plos.org/": 2, "http://www.ac.uk/": 1, "http://www.colorado.edu/": 1, "http://genes.uchicago.edu/": 1, "http://api.plos.org/": 1, "http://www.plos.org/": 1, "http://www.ploscollections.org/": 1}, "blogtitle": "Bergman Lab"}, {"content": ["Since the publication of the Drosophila melanogaster genome, the D. pseudoobscura genome, and the remaining 10 species from the Drosophila 12 Genomes Project , a number of other Drosophila genomes have been sequenced and assembled using whole genome shotgun approaches. Periodically, I find myself needing to find versions of these assemblies from the data producer, NCBI, Flybase, or UCSC, and so to help streamline this process I\u2019ve collected these links together into a single compendium here, along with links to the original stocks used for sequencing. Hopefully this will be of use to others as well. \n \n \n \n \n Species \n \n \n Data Producer \n \n \n NCBI \n \n \n Flybase \n \n \n UCSC Genome Browser \n \n \n Stock Center \n ID \n \n \n \n D. melanogaster \n Berkeley Drosophila Genome Project \n AABU00000000 \n dmel \n dm3 \n 1522 \n \n \n D. simulans \n Washington University Genome Sequencing Center \n AAGH00000000 \n dsim \n droSim1 \n n.a. \n \n \n D. simulans \n Andolfatto Lab \n n.a. \n n.a. \n n.a. \n 1380 \n \n \n D. mauritiana \n Schlotterer Lab \n n.a. \n n.a. \n n.a. \n E-18912 \n \n \n D. sechellia \n Broad Institute \n AAKO00000000 \n dsec \n droSec1 \n 1373 \n \n \n D. \u00a0yakuba \n Washington University Genome Sequencing Center \n AAEU00000000 \n dyak \n droYak2 \n 1385 \n \n \n D. \u00a0santomea \n Andolfatto Lab \n n.a. \n n.a. \n n.a. \n 2367 \n \n \n D. \u00a0erecta \n Agencourt Biosciences \n AAPQ00000000 \n dere \n droEre2 \n 1374 \n \n \n D. \u00a0ficusphila \n Baylor College of Medicine Genome Center \n AFFG00000000 \n n.a. \n n.a. \n 2332 \n \n \n D. \u00a0eugracilis \n Baylor College of Medicine Genome Center \n AFPQ00000000 \n n.a. \n n.a. \n 2350 \n \n \n D. \u00a0biarmipes \n Baylor College of Medicine Genome Center \n AFFD00000000 \n n.a. \n n.a. \n 2312 \n \n \n D. \u00a0takahashii \n Baylor College of Medicine Genome Center \n AFFI00000000 \n n.a. \n n.a. \n 2325 \n \n \n D. \u00a0elegans \n Baylor College of Medicine Genome Center \n AFFF00000000 \n n.a. \n n.a. \n 2334 \n \n \n D. \u00a0rhopaloa \n Baylor College of Medicine Genome Center \n AFPP00000000 \n n.a. \n n.a. \n 2327 \n \n \n D. \u00a0kikkawai \n Baylor College of Medicine Genome Center \n AFFH00000000 \n n.a. \n n.a. \n 2330 \n \n \n D. \u00a0bipectinata \n Baylor College of Medicine Genome Center \n AFFE00000000 \n n.a. \n n.a. \n 2329 \n \n \n D. \u00a0ananassae \n Agencourt Biosciences \n AAPP00000000 \n dana \n droAna3 \n 1368 \n \n \n D. \u00a0pseudoobscura \n Baylor College of Medicine Genome Center \n AADE00000000 \n dpse \n dp4 \n 1277 \n \n \n D. \u00a0persimilis \n Broad Institute \n AAIZ00000000 \n dper \n droPer1 \n 1369 \n \n \n D. miranda \n Bachtrog Lab \n AJMI00000000 \n n.a. \n n.a. \n n.a. \n \n \n D. \u00a0willistoni \n J. Craig Venter Institute \n AAQB00000000 \n dwil \n droWil1 \n 1375 \n \n \n D. \u00a0virilis \n Agencourt Biosciences \n AANI00000000 \n dvir \n droVir3 \n 1371 \n \n \n D. \u00a0americana \n Vieira Lab \n n.a. \n n.a. \n n.a. \n n.a. \n \n \n D. \u00a0mojavensis \n Agencourt Biosciences \n AAPU00000000 \n dmoj \n droMoj3 \n 1370 \n \n \n D. \u00a0grimshawi \n Agencourt Biosciences \n AAPT00000000 \n dgri \n droGri2 \n 1225 \n \n \n D.\u00a0albomicans \n Wang/Bachtrog Labs \n ACVV00000000 \n n.a. \n n.a. \n n.a."], "link": "http://bergmanlab.smith.man.ac.uk/?p=1612", "bloglinks": {}, "links": {"http://hgdownload.ucsc.edu/": 12, "http://genomics.princeton.edu/": 1, "ftp://ftp.flybase.net/genomes/Drosophila_sechellia": 1, "http://www.nih.gov/": 25, "ftp://ftp.flybase.net/genomes/Drosophila_mojavensis": 1, "http://www.popoolation.at/": 1, "ftp://ftp.flybase.net/genomes/Drosophila_persimilis": 1, "http://kyotofly.kit.jp/": 1, "ftp://ftp.flybase.net/genomes/Drosophila_yakuba": 1, "ftp://ftp.flybase.net/genomes/Drosophila_virilis": 1, "http://cracs.up.pt/": 1, "http://hgsc-vmweb-08.bcm.edu/": 1, "http://www.fruitfly.org/": 1, "https://stockcenter.ucsd.edu/": 21, "ftp://ftp.flybase.net/genomes/Drosophila_melanogaster": 1, "http://www.princeton.edu/": 1, "ftp://ftp.flybase.net/genomes/Drosophila_ananassae": 1, "ftp://ftp.flybase.net/genomes/Drosophila_pseudoobscura": 1, "http://www.tmc.edu/": 8, "ftp://ftp.flybase.net/genomes/Drosophila_erecta": 1, "ftp://ftp.flybase.net/genomes/Drosophila_grimshawi": 1, "ftp://ftp.flybase.net/genomes/Drosophila_simulans": 1, "http://genome.wustl.edu/": 2, "ftp://ftp.flybase.net/genomes/Drosophila_willistoni": 1}, "blogtitle": "Bergman Lab"}, {"content": ["As part of ongoing efforts to characterize complete genome sequences of microbial symbioints of Drosophila species, the Bergman Lab has been involved in mining complete genomes of the Wolbachia endosymbiont from whole-genome shotgun sequences of D. melanogaster . This work is inspired by Steve Salzberg and colleagues\u2019 pioneering paper in 2005 showing that Wolbachia genomes can be extracted from the whole-genome shotgun sequence assemblies of Drosophila species. We have adapted this technique to utilize short-read next generation sequencing data from population genomics projects in D. melanogaster, together with the reference Wolbachia genome published by Wu et al. (2005) . \n Currently we have identified infection status and extracted nearly-complete genomes from the two major resequencing efforts in D. melanogaster : the Drosophila Genetic Reference Panel (DGRP) and Drosophila Population Genomics Project (DPGP). We employ a fairly standard BWA / SAMtools \u00a0 pipeline, with a few tricks that are essential for getting good quality assemblies and consensus sequences. Details of the methods will be forthcoming in a manuscript we have in preparation with colleagues at the University of Cambridge and University College London. \n Our first iteration of this pipeline was used to predict infection status in the DGRP strains. These results have been published in the DGRP main paper published in early 2012, and can be found in Supplemental Table 9 of the DGRP paper or more usefully in a comma-separated file at the\u00a0 DGRP website. \n We have now applied an update version of our pipeline to both the DGRP and DPGP datasets and are now busy preparing a manuscript on the recent evolutionary history of Wolbachia in D. melanogaster using these \u201cessentially complete\u201d genome sequences. We have had several recent inquiries about the status of this project so, in the spirit of Open Science that makes genomics such a productive field, we are releasing the consensus sequences and alignments of 179 Wolbachia and 290 mitochondrial genomes from the DGRP and DPGP prior to submission or publication of our manuscript. \n Since we are not the primary data producer for these assemblies, it is not approporiate to employ a data release policy based on the NHGRI guidelines . Instead, we have chosen to release these data under a Creative Commons Attribution 3.0 Unported License . If you use these assemblies or alignments in a project prior to publication of our manuscript, please cite the main DGRP and DPGP papers and attribute the mtDNA or Wolbachia data to: \n Richardson M.F., Weinert L.A., Welch J.J., Linheiro R.S., Magwire M.M., Jiggins F.M. & Bergman C.M. (2012) Population genomics of the Wolbachia endosymbiont in Drosophila melanogaster . http://arxiv.org/abs/1205.5829 \n \n We will update this citation information as our project comes to completion, and provide a more stable URI to these assemblies (e.g. via Dryad ) when the manuscript describing these data is published. \n A tar.gz archive contaning a reference-based multiple sequence alignment of release 1.0 of the complete D. melanogaster mtDNA and Wolbachia assemblies can be obtained here . If you have questions about the methods used to produce these assemblies, any associated meta-data from these assemblies, or the content of our manuscript please contact Casey Bergman for details."], "link": "http://bergmanlab.smith.man.ac.uk/?p=1398", "bloglinks": {}, "links": {"http://datadryad.org/": 1, "http://www.plosbiology.org/": 1, "http://samtools.sourceforge.net/": 1, "https://www.bcm.edu/": 1, "http://dgrp.ncsu.edu/": 1, "http://genomebiology.com/": 1, "http://www.dpgp.org/": 1, "http://bergman.ac.uk/": 1, "http://www.nature.com/": 2, "http://creativecommons.org/": 1, "http://arxiv.org/": 1, "http://www.genome.gov/": 1, "http://bio-bwa.sourceforge.net/": 1, "http://www.nih.gov/": 1, "http://en.wikipedia.org/": 3}, "blogtitle": "Bergman Lab"}, {"content": ["In the second post of this series we examined the grp and trackDb tables within an organism database in the UCSC genome browser schema, and how they are used to build a UCSC genome browser display by specifying: (i) what sort of data a track contains, (ii) how it should be displayed, and (iii) how tracks should be organized within the display. In this last post of three, we will look at how to load and subsequently display custom data into a UCSC genome browser instance. As an example, we\u2019ll be using a set of data from the modENCODE project formatted for loading into the UCSC browser. For this you\u2019ll need a working browser install and the dm3 organism database (see the first post in this series for details). \n An important feature of the genome browser schema that permits easy customization is that you can have multiple grp and trackDb tables within an organism database.\u00a0 This allows separation of tracks for different purposes, such as trackDb_privateData, trackDb_chipSeq, trackDb_UserName etc. The same goes for grp tables. Thus, you can pull in data from the main UCSC site, leave it untouched, and simply add new data by creating new trackDb and grp tables. \n This post outlines the five steps for adding custom data into a local UCSC genome browser: \n 1) Getting the data into the correct format \n2) Building the required loader code \n3) Loading the data \n4) Configuring the track\u2019s display options \n5) Creating the new trackDb and grp tables and configuring the browser to use it. \n 1) The UCSC browser supports a number of different data formats, which are described at the UCSC format FAQ . Defining where your data comes from, and what sort of data it is (e.g. an alignment, microarray expression data etc.) will go a long way towards determining what sort of file you need to load. In many cases your data will already be in one of the supported formats so the decision will have been made for you. If your data isn\u2019t in one of the supported formats, you\u2019ll need to decide which one is the most appropriate and then reformat the data using a suitable tool, e.g. a perl or bash script. The example data we will be loading is taken from this paper . The supplementary data contains an Excel spreadsheet that we need to reformat into a number of BED files and then load into the UCSC database. \n 2) Each of the data formats that can be loaded into the browser system has its own loader program. These are found in the same source tree that we used to build the browser CGIs. You will find the source code for the loaders in the Kent source tree, the BED loader is in the directory kent/src/hg/makeDb/hgLoadBed. Assuming you have followed the instructions in the first part of this blog post then to compile the BED loader you simply cd to its directory and type make. \n cd kent/src/hg/makeDb/hgLoadBed\nmake \n The hgLoadBed executable will now be in ~/bin/$MACHTYPE. If you haven\u2019t already it is a good idea to add this directory to your path, add the following line to ~/.bashrc: \n export PATH=$PATH:~/bin/$MACHTYPE \n The other loader we\u2019ll require for the example custom data included in this blog is hgBbiDbLink: \n cd kent/src/hg/makeDb/hgBbiDbLink\nmake \n 3) To load data, e.g. a BED file, the command is simply: \n hgLoadBed databaseName tableName pathToBEDfile \n The data-loaders supplied with the browser can be divided into two broad groups. The first of these, as represented by hgLoadBed, actually load the data into a table within the organism database. For example, one of the histone-modification datasets looks like this as a BED file: \n chr2L 5982 6949 ID=Embryo_0_12h_GAF_ChIP_chip.GAF  5.54\nchr2L 65947 68135 ID=Embryo_0_12h_GAF_ChIP_chip.GAF  10.54\nchr2L 72137 73344 ID=Embryo_0_12h_GAF_ChIP_chip.GAF  6.55\nchr2L 107044 109963 ID=Embryo_0_12h_GAF_ChIP_chip.GAF  8.93\nchr2L 127917 130678 ID=Embryo_0_12h_GAF_ChIP_chip.GAF  9.17 \n When this BED file is loaded using hgLoadBed it produces a table that has the following structure: \n DESC MdEncHistonesGAFBG3DccId2651;\n+------------+----------------------+------+-----+---------+-------+\n| Field  | Type     | Null | Key | Default | Extra |\n+------------+----------------------+------+-----+---------+-------+\n| bin  | smallint(5) unsigned | NO |  | NULL |  |\n| chrom  | varchar(255)   | NO | MUL | NULL |  |\n| chromStart | int(10) unsigned  | NO |  | NULL |  |\n| chromEnd | int(10) unsigned  | NO |  | NULL |  |\n+------------+----------------------+------+-----+---------+-------+\n4 rows in set (0.00 sec) \n And contains (results set truncated): \n select * from MdEncHistonesGAFBG3DccId2651;\n| 754 | chrX  | 22237479 | 22239805 |\n| 754 | chrX  | 22255450 | 22257285 |\n| 754 | chrX  | 22257996 | 22259538 |\n| 754 | chrX  | 22259653 | 22261174 |\n| 754 | chrX  | 22264098 | 22265194 |\n| 585 | chrYHet |  84149 | 85164 |\n| 585 | chrYHet |  104864 | 105879 |\n| 586 | chrYHet |  150067 | 151212 |\n+-----+----------+------------+----------+\n5104 rows in set (0.06 sec)\n \n The second type of loader doesn\u2019t insert the data into a database table directly. Instead data in formats such as bigWig and bigBed are deposited in a particular location on the filesystem and a table with a single row simply points to them. For example: \n desc mdEncReprocCbpAdultMaleTreat;\n+----------+--------------+------+-----+---------+-------+\n| Field | Type   | Null | Key | Default | Extra |\n+----------+--------------+------+-----+---------+-------+\n| fileName | varchar(255) | NO |  | NULL |  |\n+----------+--------------+------+-----+---------+-------+\n1 row in set (0.00 sec) \n Which contains: \n select * from mdEncReprocCbpAdultMaleTreat;\n+----------------------------------------------+\n| fileName          |\n+----------------------------------------------+\n| /gbdb/dm3/modencode/AdultMale_treat.bw |\n+----------------------------------------------+\n1 row in set (0.02 sec) \n The loader hgBbiDbLink is responsible for producing this simple table that points to the location of the data on the filesystem. When the browser comes to display a track that is specified as bigWig in trackDb\u2019s type field it knows that the table specified in trackDb\u2019s tableName field will give point it at the bigWig file rather than containing the data itself. Supposed we have placed our bigWig file in the /gbdb directory: \n cp AdultTreat.bw /gbdb/dm3/modencode/. \n Then we must execute hgBbiDbLink as follows: \n hgBbiDbLink databaseName desiredTableName pathToDataFile \n Specifically: \n hgBbiDbLink dm3 mdEncReprocCbpAdultMaleTreat /gbdb/dm3/modencode/AdultTreat.bw \n 4) Once the data is loaded into the database we need to tell the browser how it should be displayed, this is the role of the trackDb table. We create a new trackDb table for our data using the command hgTrackDb. This is found in the same branch of the source tree and the individual loaders themselves. The way in which tracks and grouped and displayed by the browser is specified in a file which you pass to hgTrackDb called a .ra file, which specifies the contents of the different fields in the trackDb table, as well as the parent-child relationship for composite tracks. The example data provided in this blog post contains a trackDb.ra file that looks like this: \n track dnaseLi\nshortLabel DNAse Li 2011\nlongLabel DNAse Li Eisen Biggin Genome Biol 2011\ngroup blog\npriority 100\nvisibility hide\ncolor 200,20,20\naltcolor 200,20,20\ncompositeTrack on\ntype bed 3\n\n track dnaseLiStage5\n shortLabel Stage 5\n longLabel Li Dnase Stage 5\n parent dnaseLi\n priority 1\n\n track dnaseLiStage9\n shortLabel Stage 9\n longLabel Li Dnase Stage 9\n parent dnaseLi\n priority 2\n\n track dnaseLiStage10\n shortLabel Stage 10\n longLabel Li Dnase Stage 10\n parent dnaseLi\n priority 3\n\n track dnaseLiStage11\n shortLabel Stage 11\n longLabel Li Dnase Stage 11\n parent dnaseLi\n priority 4\n\n track dnaseLiStage14\n shortLabel Stage 14\n longLabel Li Dnase Stage 14\n parent dnaseLi\n priority 5\n \n The example data (e.g. /root/ucsc_example_data) comes from 5 different stages of embryonic development so we have 5 BED files. The trackDb.ra file groups these as a composite track so we have the top level track (dnaseLi) which is the parent of the 5 individual tracks. To load these definitions into the database we execute hgTrackDb as follows: \n ~/bin/i386/hgTrackDb drosophila dm3 trackDb_NEW kent/src/hg/lib/trackDb.sql /root/ucsc_example_data \n The complete set of commands to download the example data and load it are is therefore: \n cd\nwget http://genome.smith.man.ac.uk/downloads/blogData.tar.gz\ntar xzvf blogData.tar.gz\ncd ucsc_example_data\n~/bin/i386/hgLoadBed dm3 dnaseLiStage5 stage5.bed\n~/bin/i386/hgLoadBed dm3 dnaseLiStage9 stage9.bed\n~/bin/i386/hgLoadBed dm3 dnaseLiStage10 stage10.bed\n~/bin/i386/hgLoadBed dm3 dnaseLiStage11 stage11.bed\n~/bin/i386/hgLoadBed dm3 dnaseLiStage14 stage14.bed\n~/bin/i386/hgTrackDb drosophila dm3 trackDb_NEW kent/src/hg/lib/trackDb.sql /root/ucsc_example_data \n 5) Tell the browser to use our new trackDb table by editing the hg.conf configuration file in /var/www/cgi-bin and adding the new trackDB table name to the db.trackDb line. The db.TrackDb line takes a comma-separated list of trackDb tables that the browser will display. Assuming that our new trackDb table is called trackDb_NEW then we must edit hg.conf from this: \n db.trackDb=trackDb \n to this: \n db.trackDb=trackDb,trackDb_NEW \n You\u2019ll notice in the supplied trackDb.ra file that the tracks belong to a group called \u2018blog\u2019. This group doesn\u2019t currently exist in the database. There are two ways we can go about rectifying this. The first is to add blog to the existing grp table like so: \n INSERT INTO grp (name,label,priority) VALUES('blog','Example Data',11); \n Or you can create an entirely new grp table. The browser handles multiple grp tables in the same fashion as multiple trackDb tables, i.e. they are specified as a comma-separated list in hg.conf. To create a new grp table, execute: \n CREATE TABLE grp_NEW AS SELECT * FROM grp WHERE 1=2;\nINSERT INTO grp_NEW (name,label,priority) VALUES('blog','Example Data',11); \n And then edit hg.conf to add grp_NEW to the db.grp line: \n db.grp=grp,grp_NEW \n If you now refresh your web browser the cgi scripts should create a new session with the new data tracks displayed as configured in the grp table."], "link": "http://bergmanlab.smith.man.ac.uk/?p=1282", "bloglinks": {}, "links": {"http://genome.ucsc.edu/": 1, "http://bergmanlab.ac.uk/": 2, "http://www.modencode.org/": 1, "http://genomebiology.com/": 2}, "blogtitle": "Bergman Lab"}, {"content": ["This is the second of three posts on how to set up a local mirror of the UCSC genome browser hosting custom data. In the previous post , I covered how to perform a basic installation of the UCSC genome In this post, I\u2019ll provide an overview of the mySQL database structure that serves data to the genome browser using the Bergman Lab mirror ( http://genome.smith.man.ac.uk/ ) as an example. In the next post , I focus on how to load custom data into a local mirror. \n General databases \n hgcentral \u2013 this is the central control database of the browser. It holds information relating to each assembly available on the server, organizing them into groups according to their clade and organism. For instance the mammalian clade may contain human and mouse assemblies, and for mouse we may have multiple assemblies (e.g. mm9, mm8 etc.). \n The contents of the clade , genomeClade , dbDb and defaultDb tables control the three dropdown menus on the gateway page of the browser. The clade and genomeClade tables have a priority field that controls the order of the dropdown menus (see figure 1). \n  \n The defaultDb table specifies which assembly is the default for a particular organism. This is usually the latest assembly e.g. mm9 for mouse. You can alter this if, for whatever reason, you want to use a different assembly as your default: \n UPDATE defaultDb SET name = 'mm8' WHERE genome = 'mouse'; \n Databases for each organism/assembly are listed in the dbDb table within hgcentral (see more below). For example the latest mouse assembly (mm9) has an entry that contains information relating to this build, an example query (not retrieving all the information contained within dbDb) looks like this: \n > select name,description,organism,sourceName,taxId from dbDb where name = 'mm9';</pre>\n +------+-------------+----------+---------------+-------+\n | name | description | organism | sourceName | taxId |\n +------+-------------+----------+---------------+-------+\n | mm9 | July 2007 | Mouse | NCBI Build 37 | 10090 |\n+------+-------------+----------+---------------+-------+ \n hgFixed \u2013 this database contains a bunch of human related information, predominately microarray stuff. If you are running a human mirror then you may wish to populate this database. If not, then it can be left empty. \n Genome databases \n We will now look at the structure of a genome database for a specific organism/assembly using mm9 as an example. \n The first table to consider is chromInfo , this simple table specifies the name of each chromosome, its size and the location of its sequence file. Mouse has 19 chromosomes (named chr1 \u2013 chr19) plus the two sex chromosomes (chrX and chrY), mitochondrial DNA (chrM) and unmapped clone contigs (chrUn). If we list the tables within our minimal mm9 install we will see that most of the tables can clearly be identified as belonging to a particular chromosome by virtue of their names, e.g. all the tables with names starting chr10_* contain data relating to chromosome 10. \n Of the remainder, the two tables of most interest to understanding how the browser works, and leading us towards the ability to load custom data, are the grp and trackDb tables. These two tables control the actual genome browser display, as we discussed above for the hgcentral tables that control the gateway web interface. Not surprisingly, the trackDb table holds information about all the data tracks you can see (see figure 2), and grp tells the browser how all these tracks should be organized (e.g. we may want a separate group for different types of experimental data, another for predictions made using some computational technique etc.). \n Figure 2 shows a screenshot of the mm9 browser we developed in the Bergman Lab as part of the CISSTEM project . \n  \n Here, we can see that the tracks are grouped into particular types (Mapping & Sequence Tracks, Genes and Gene Prediction tracks etc.) \u2013 these are specified in mm9\u2019s grp table and, like the dropdowns on the gateway page, ordered using a priority field \n > select * from grp order by priority asc\n+-------------+----------------------------------+----------+\n| name  | label       | priority |\n+-------------+----------------------------------+----------+\n| user  | Custom Tracks     |  1 |\n| map   | Mapping and Sequencing Tracks |  2 |\n| genes  | Genes and Gene Prediction Tracks |  3 |\n| rna   | mRNA and EST Tracks    |  4 |\n| regulation | Expression and Regulation  |  5 |\n| compGeno | Comparative Genomics    |  6 |\n| varRep  | Variation and Repeats   |  7 |\n| x   | Experimental Tracks    |  10 |\n| phenoAllele | Phenotype and Allele    |  4.5 |\n+-------------+----------------------------------+----------+ \n The tracks that constitute these groups are specified in the trackDb table, we can see the tracks for a particular group like so: \n > select longLabel from trackDb where grp = 'map' order by priority asc;\n+-----------------------------------------------------------------------------+\n| longLabel                 |\n+-----------------------------------------------------------------------------+\n| Chromosome Bands Based On ISCN Lengths (for Ideogram)      |\n| Chromosome Bands Based On ISCN Lengths          |\n| Mapability - CRG GEM Alignability of 36mers with no more than 2 mismatches |\n| Mapability - CRG GEM Alignability of 40mers with no more than 2 mismatches |\n| Mapability - CRG GEM Alignability of 50mers with no more than 2 mismatches |\n| Mapability - CRG GEM Alignability of 75mers with no more than 2 mismatches |\n| STS Markers on Genetic and Radiation Hybrid Maps       |\n| Mapability - CRG GEM Alignability of 100mers with no more than 2 mismatches |\n| Physical Map Contigs              |\n| Assembly from Fragments              |\n| Gap Locations                |\n| BAC End Pairs                |\n| Quantitative Trait Loci From Jackson Laboratory / Mouse Genome Informatics |\n| GC Percent in 5-Base Windows            |\n| Mapability or Uniqueness of Reference Genome        |\n+-----------------------------------------------------------------------------+ \n These two tables provide information to the browser to know which groups to display, which tracks belong to a particular group, and in which order they should be displayed. The remaining fields in the trackDb table fill in the gaps: what sort of data the track contains and how the browser is to display it. I won\u2019t say anymore about trackDb here \u2013 we will naturally cover the details of how trackDb functions when we talk about loading custom data in the next post . \n You will probably have noticed that there is not an exact equivalence between the query above and the tracks in the browser (e.g. the query returns a number of Mapability tracks whereas there is only a single Mapability dropdown in the browser). This is because some tracks are composite tracks \u2014 if you click Mapability in the browser you will see that the multiple tracks are contained within it. Composite tracks are specified in trackDb, we will investigate this in the next part of this blog post. \n [This tutorial continues in Part III: Loading Custom Data ]"], "link": "http://bergmanlab.smith.man.ac.uk/?p=1280", "bloglinks": {}, "links": {"http://bergmanlab.ac.uk/": 6, "http://genome.ac.uk/": 1, "http://cisstem.ac.uk/": 1}, "blogtitle": "Bergman Lab"}, {"content": ["The UCSC Genome Bioinformatics site is widely regarded as one of the most powerful bioinformatics portals for experimental and computational biologists on the web. While the UCSC Genome Browser provides excellent functionality for loading and visualizing custom data tracks, there are cases when your lab may have genome-wide data it wishes to share internally or with the wider scientific community, or when you might want to use the Genome Browser for an assembly that is not in the main or microbial Genome Browser sites. If so then you might need to install a local copy of the genome browser. \n A blog post by noborujs on E-nota\u00e7\u00f5es explains how to install the UCSC genome browser on an Ubuntu system, and the UCSC Genome genome browser team provides a general walk-through on their wiki and an internal presentation . Here I will provide a similar walkthrough for installing it on a CentOS system. The focus of these posts is go beyond the basic installation to explain the structure of the databases that underlie the browser; how these database table are used to create the web front-end, and how to customize a local installation with your own data. Hopefully having a clearer understanding of the database and browser architecture should make the process of loading your own data far easier. \n This blog entry has grown to quite a size, so I\u2019ve decided to split it into 3 more manageable parts and you can find a link to the next part at the end of this post. \n The 3 parts are as follows: \n 1) Introduction and CentOS install (this post) \n2) The databases & web front-end \n3) Loading custom data \n The walk-through presented here installs CentOS 5.7 using VirtualBox so you can follow this on your desktop if you have sufficient disk space. Like the Ubuntu walk-through linked to above, this will speed you through the install process with little or no reference to what the databases actually contain, or how they relate to the browser, this information will be included in part 2 . \n CentOS Installation \n \u2022 Grab CentOS 5.7 i386 CD iso\u2019s from one of the mirrors . Discs 1-5 are required for this install. \n\u2022 Start VirtualBox and select \u2018New\u2019. Settings chosen: \n\u2022 Name = CentOS 5.7 \n\u2022 OS = linux \n\u2022 Version = Red Hat \n\u2022 Virtual memory of 1GB \n\u2022 Create a new hard disk with fixed virtual storage of 64GB \n\u2022 Start the new virtual machine and select the first CentOS iso file as the installation source \n\u2022 Choose \u2018Server GUI\u2019 as the installation type when prompted \n\u2022 Set the hostname, time etc. and make sure you enable http when asked about services \n\u2022 When the install prompts you for a different CD, select \u201cDevices -> CD/DVD devices -> Choose a virtual CD/DVD disk file\u201d and choose the relevant ISO file. \n\u2022 Login as root, run Package Updater, reboot. \n UCSC Browser Install \n \u2022 Install dependencies: \n yum install libpng-devel\nyum install mysql-devel \n \u2022 Set environment variables, the following were added to root\u2019s .bashrc: \n export MACHTYPE=i386\nexport MYSQLLIBS=\"/usr/lib/mysql/libmysqlclient.a -lz\"\nexport MYSQLINC=/usr/include/mysql\nexport WEBROOT=/var/www \n Each time you open a new terminal these environment variables will be set automatically. \n \u2022 Download the Kent source tree from http://hgdownload.cse.ucsc.edu/admin/jksrc.zip , unpack it and then build it: \n wget http://hgdownload.cse.ucsc.edu/admin/jksrc.zip\nunzip jksrc.zip\nmkdir -p ~/bin/$MACHTYPE # only used when you build other utilities from the source tree\ncd kent/src/lib\nmkdir $MACHTYPE\nmake\ncd ../jkOwnLib\nmake\ncd ../hg/lib\nmake\ncd ..\nmake install DESTDIR=$WEBROOT CGI_BIN=/cgi-bin DOCUMENTROOT=$WEBROOT/html \n You will now have all the cgi\u2019s necessary to run the browser in /var/www/cgi-bin and some JavaScript and CSS in /var/www/html. We need to tell SELinux to allow access to these: \n restorecon -R -v '/var/www' \n \u2022 Grab the static web content. First edit kent/src/product/scripts/browserEnvironment.txt to reflect your environment (MACHTYPE, DOCUMENTROOT etc.) then \n cd kent/src/product/scripts\n./updateHtml.sh browserEnvironment.txt \n \u2022 Create directories to hold temporary files for the browser: \n mkdir $WEBROOT/trash\nchmod 777 $WEBROOT/trash\nln -s $WEBROOT/trash $WEBROOT/html/trash \n \u2022 Set up MySQL for the browser. We need an admin user with full access to the databases we\u2019ll be creating later, and a read-only user for the cgi\u2019s. \n In MySQL: \n GRANT SELECT, INSERT, UPDATE, DELETE, CREATE, DROP,\nALTER, CREATE TEMPORARY TABLES\n ON hgcentral.*\n TO ucsc_admin@localhost\n IDENTIFIED BY 'admin_password';\n\nGRANT SELECT, CREATE TEMPORARY TABLES\n ON hgcentral.*\n TO ucsc_browser@localhost\n IDENTIFIED BY 'browser_password'; \n The above commands will need repeating for each of the databases that we subsequently create. \n We also need a third user that has read/write permissions to the hgcentral\u00a0 database only: \n GRANT SELECT, INSERT, UPDATE, DELETE, CREATE, DROP, ALTER\n ON hgcentral.*\n TO ucsc_readwrite@localhost\n IDENTIFIED BY 'readwrite_password'; \n Note: You should replace the passwords listed here with something sensible! \n The installation README (path/to/installation/readme) suggests granting FILE to the admin user, but FILE can only be granted globally (i.e. GRANT FILE ON *.*) , so we must do this as follows: \n GRANT FILE ON *.* TO ucsc_admin@localhost; \n We now have the code for the browser and a database engine ready to receive some data. As an example, getting a human genome assembly installed requires the following: \n \u2022 Create the primary gateway database for the browser: \n mysql -u ucsc_admin -p -e \"CREATE DATABASE hgcentral\"\nwget http://hgdownload.cse.ucsc.edu/admin/hgcentral.sql\nmysql -u ucsc_admin -p hgcentral < hgcentral.sql \n \u2022 Create the main configuration file for the browser hg.conf and save it in /var/www/cgi-bin: \n cp kent/src/product/ex.hg.conf /var/www/cgi-bin/hg.conf \n Then edit /var/www/cgi-bin/hg.conf to reflect the specifics of your installation. \n \u2022 Admin users should also maintain a copy of this file saved as ~/.hg.conf, since the data loader applications look in your home directory for hg.conf. It is a good idea for ~/.hg.conf to be made private (i.e. only the owner can access it) otherwise your database admin password will be accessible by other users: \n cp /var/www/cgi-bin/hg.conf ~/.hg.conf\nchmod 600 ~/.hg.conf \n When we issue commands to load custom data (see part 3 ) it is this copy of hg.conf that will supply the necessary database passwords. \n The browser is now installed and functional, but will generate errors because the databases specified in the hgcentral database are not there yet. The gateway page needs a minimum human database in order to function even if the browser is being built for the display of other genomes. \n To install a human genome database, the minimal set of mySQL tables required within the hg19 database is: \n\u2022 grp \n\u2022 trackDb \n\u2022 hgFindSpec \n\u2022 chromInfo \n\u2022 gold \u2013 for performance this table is split by chromosome so we need chr*_gold* \n\u2022 gap \u2013 split by chromosome as with gold so we need chr*_gap* \n To install minimal hg19: \n GRANT SELECT, INSERT, UPDATE, DELETE, CREATE, DROP,\nALTER, CREATE TEMPORARY TABLES\n ON hg19.*\n TO ucsc_admin@localhost\n IDENTIFIED BY 'admin_password';\n\nGRANT SELECT, CREATE TEMPORARY TABLES\n ON hg19.*\n TO ucsc_browser@localhost\n IDENTIFIED BY 'browser_password';\n\nmysql -u ucsc_admin -p -e \"CREATE DATABASE hg19\"\ncd /var/lib/mysql/hg19\nrsync -avP rsync://hgdownload.cse.ucsc/mysql/hg19/grp* .\nrsync -avP rsync://hgdownload.cse.ucsc/mysql/hg19/trackDb* .\nrsync -avP rsync://hgdownload.cse.ucsc/mysql/hg19/hgFindSpec* .\nrsync -avP rsync://hgdownload.cse.ucsc/mysql/hg19/chromInfo* .\nrsync -avP rsync://hgdownload.cse.ucsc/mysql/hg19/chr*_gold* .\nrsync -avP rsync://hgdownload.cse.ucsc/mysql/hg19/chr*_gap* . \n The DNA sequence can be downloaded thus: \n cd /gbdb\nmkdir -p hg19/nib\ncd hg19/nib\nrsync -avP rsync://hgdownload.cse.ucsc.edu/gbdb/hg18/nib/chr*.nib . \n Again we will need to tell SELinux to allow the webserver to access these files: \n semanage fcontext -a -t httpd_sys_content_t \"/gbdb\" \n Create hgFixed database: \n GRANT SELECT, INSERT, UPDATE, DELETE, CREATE, DROP,\nALTER, CREATE TEMPORARY TABLES\n ON hgFixed.*\n TO ucsc_admin@localhost\n IDENTIFIED BY 'admin_password';\n\nGRANT SELECT, CREATE TEMPORARY TABLES\n ON hgFixed.*\n TO ucsc_browser@localhost\n IDENTIFIED BY 'browser_password';\n\nmysql -u ucsc_admin -p -e \"create database hgFixed\" \n The browser now functions properly and we can browse the hg19 assembly. \n The 3rd part of this blog post looks at loading custom data, for this we will use some Drosophila melanogaster data taken from the modENCODE project. Therefore we will need repeat the steps we used to mirror the hg18 assembly to produce a local copy of the dm3 database. Alternatively, if you have sufficient disk space on your virtual machine you can grab all the D.melanogaster data like so: \n mysql -u ucsc_admin -p -e \"create database dm3\"\ncd /var/lib/mysql/dm3\nrsync -avP rsync://hgdownload.cse.ucsc.edu/mysql/dm3/* .\ncd gbdb\nmkdir dm3\ncd dm3\nrsync -avP rsync://hgdownload.cse.ucsc.edu/gbdb/dm3/* . \n At present these commands will download approximately 30Gb. \n [This tutorial continues in Part 2: The UCSC genome browser database structure ]"], "link": "http://bergmanlab.smith.man.ac.uk/?p=1111", "bloglinks": {}, "links": {"http://www.centos.org/": 1, "http://enotacoes.wordpress.com/": 1, "http://www.modencode.org/": 1, "http://microbes.ucsc.edu/": 1, "http://genome.ucsc.edu/": 3, "http://bergmanlab.ac.uk/": 7, "https://banana-slug.ucsc.edu/": 1, "http://genomewiki.ucsc.edu/": 1, "http://hgdownload.ucsc.edu/": 1}, "blogtitle": "Bergman Lab"}, {"content": ["One of the most enjoyable parts of teaching genomics and bioinformatics introducing people to the UCSC Genome Browser and Galaxy systems.\u00a0 Both systems are powerful, intuitive, reliable and user-friendly services, and lend themselves easily to student practicals, as the good folks at Open Helix have amply demonstrated . Over the last few years, I\u2019ve developed a fairly reliable advanced undergraduate/early graduate teaching practical that uses the UCSC Genome Browser and Galaxy to\u00a0 study regulatory sequence evolution in Drosophila , based on data I curated a few years back into the Drosophila DNAse I footprint database .\u00a0 As part of opening up the resources from my group, I thought I would post this tutorial with the hope that someone else can use it for teaching purposes or their own edification. The UCSC half can be done pretty reliably in a 50 minute session, and the Galaxy part is much more variable \u2013 some people take 20 min or less and others up to an hour.\u00a0 Feedback and comments are most welcome. \n Enjoy! \n Aims \n \n Become familiar with the UCSC Genome Browser. \n \n \n Become familiar with the UCSC Table Browser. \n \n \n Become familiar with Galaxy Analysis Tools and Histories. \n \n \n Study the conservation of transcription factor binding sites in Drosophila . \n \n Introduction \n This lab is an exercise in performing a comparative genomic analysis of transcription factor binding sites (TFBSs) in Drosophila . You will use the UCSC Genome Browser, Table Browser and Galaxy to identify TFBSs that are conserved across multiple Drosophila species. Highly conserved TFBSs are likely to play important roles in Drosophila development. TFBSs that are not conserved may represent regulatory sequences that have contributed to developmental evolution across Drosophila species, or those that simply have been lost as part of the process of TFBSs turnover in a conserved regulatory element. The skill you learn in this lab will be generally applicable to many questions for a wide range of species with genome sequences in the UCSC Genome Database. \n Finding the even-skipped region at the UCSC Genome Browser \n 1) Go to the UCSC Genome Bioinformatics site at http://genome.ucsc.edu . \n 2) Select the \u201cGenome Browser\u201d option from the light blue panel on the left hand side of the page. \n 3) From the Gateway page, select \u201cInsect\u201d, \u201cD. melanogaster\u201d and \u201cApr 2004\u2033 from the \u201cclade\u201d, \u201cgenome\u201d and \u201cassembly\u201d pull-down menus. Take a minute to read the text at the bottom of the page \u201cAbout the D. melanogaster Apr. 2004 (dm2) assembly\u201d. \n 4) Enter the gene \u201ceve\u201d (an abbreviated name for the gene even-skipped ) into the \u201cposition or search term\u201d box and click the \u201csubmit\u201d button. \n 5) From the search results page, select the top link under the \u201cFlyBase Protein-Coding Genes\u201d header taking you to \u201ceve at chr2R:5491054-5492592\u2033. This will take you to a graphical view of the even-skipped gene with boxes indication exons and lines indication introns. (Note: the thick part of the boxes denote the parts of exons are translated into protein, the thinner parts are UTRs) \n Customising the UCSC Genome Browser to display transcription factor binding sites in the even-skipped region \n 1) The Genome Browser page displays information about a selected genomic region and contains several components. They are, from top to bottom: a list of links to complementary tools and resources on the dark blue background; buttons for navigating left and right and zooming in and out on the chromosome; search boxes for jumping to new regions of the genome; a pictoral representation of the region shown on the chromosome; the main display window, comprising several tracks showing different types of information about the genomic region on display; a set of buttons to modify the main display; and several rows of pull-down menus, each controlling the display status of an individual track in the main display window. \n 2) Click the \u201chide all\u201d button in the second panel of display controls to remove all tracks from the browser. Then select the \u201cfull\u201d option from the drop-down FlyBase Genes menu under \u201cGenes and Gene Prediction Tracks\u201d and click refresh. \n 3) In the main display window, the top feature in light blue is the 2-exon gene eve . Click on one of the blue exons of the eve gene. This will send you to a detailed page about the eve gene. Scroll down to see the data linked to eve, including information imported from external sources like FlyBase, links to other resources like \u201cOrthologous Genes in Other Species\u201d also at the UCSC genome browser, and links to other resources outside the UCSC Database such as \u201cProtein Domain and Structure Information\u201d at the InterPro database. [Note: you can minimise subsections of this page by clicking the \"-\" button next to each major heading.] \n 3) Click the white \u201cGenome Browser\u201d link on the top blue banner to return to the main browser page. Scroll down the page and read the names of the various tracks available for this genome sequence. Sets of tracks are organised into logical groups (e.g. \u201cGenes and Gene Prediction Tracks\u201d). To find out more information about the data in any track, you can click on the blue title above each track\u2019s pulldown menu, which leads to a detail page explaining the track and additional track-specific display controls. [Note: the same detail page can be displayed by clicking on the blue/grey rectangle at the very left of the track display in the main display window.] \n 4) Click on the blue title for the \u201cFlyReg\u201d track under the \u201cExpression and regulation\u201d heading. Take a minute to read about the FlyReg track and where the data comes from. Set the display mode pull-down menu to \u201cpack\u201d and then click \u201crefresh\u201d. [Note: visit http://www.flyreg.org/ for more information.] \n 5) Click the \u201czoom out 10x\u201d button in the top right corner of the page to expand your window to display ten times the current sequence length. Each annotated regulatory element you are seeing in the FlyReg track is an experimentally-validated transcription factor binding site (TFBS) that regulates eve . \n 6) Click directly on one of the brown TFBSs features in the FlyReg track upstream of the eve gene. As with all data in different tracks, clicking on a feature will send you to a detail page about the feature, in this case the TFBS. In the detail page, click on the \u201cPosition\u201d link and this will return you to the main Genome Browser window window showing just the coordinates of the TFBS you just selected. \n \n Investigating the conservation of individual TFBSs using the UCSC Genome Browser \n 1) Select the \u201cfull\u201d option from the Conservation drop-down menu under \u201cComparative genomics\u201d and click refresh. \n 2) The browser should now be displaying exactly one TFBS and conservation of this TFBS using the \u201c12 Flies, Mosquito, Honeybee, Beetle Multiz Alignments & phastCons Scores\u201d track. Is this TFBS conserved across the Drosophila species? If so, which ones? Is this TFBS conserved in Anopheles gambiae , Tribolium castaneum or Apis mellifera ? \n 3) Click the \u201czoom out 10x\u201d button twice and select a different TFBS from the FlyReg Track, click on the \u201cPosition\u201d link in the detail page and evaluate if this TFBS is conserved and in which species. Now repeat for every TFBS in the genome (only joking!). \n 4) To see the general correspondence between TFBS and highly conserved sequences, set the pull-down menu to \u201cpack\u201d for the \u201cMost Conserved\u201d Track. Zoom out 10x so you are displaying a few hundred bp. How well do the most highly conserved sequences correspond the TFBSs? Are TFBSs typically longer or shorter than a highly conserved region? Zoom out 10x so you are displaying a ~1 Kbp. Are there more TFBSs than conserved sequences or vice versa? Why might this be the case? \n Investigating the conservation of all known TFBSs using the UCSC Table Browser \n 1) Click the \u201cTables\u201d link on the dark blue background at the top of the Genome Browser window. This will send you to an alternative interface to access data in the UCSC Genome Database called the \u201cTable Browser.\u201d The pull-down menus you see here correspond to the same tracks you saw in the Genome Browser. \n 2) Select \u201cInsect\u201d, \u201cD. melanogaster\u201d and \u201cApr 2004\u2033 from the \u201cclade\u201d, \u201cgenome\u201d and \u201cassembly\u201d pull-down menus. \n 3) Select \u201cExpression and Regulation\u201d and \u201cFlyReg\u201d from the \u201cgroup\u201d and \u201ctrack\u201d pull-down menus, respectively. \n 4) Click the radio button (the circle with a dot indicating which option is selected) next to \u201cgenome\u201d as the \u201cregion\u201d you will analyse. This will select the whole genome for inclusion in your analysis. \n 5) Select \u201cHyperlinks to Genome Browser\u201d from the \u201coutput format\u201d pull-down menu and click \u201cget output\u201d.\u00a0 This will send you to a page with >1,300 hyperlinks that send you to all the annotated TFBS in Drosophila , each of which corresponds to one row in the FlyReg data track. [Note: this is a general method to export data from any track the whole genome or a specific region.] \n 6) Click the \u201cTables\u201d link on the dark blue background at the top of the page to return to the Table Browser. We are now going to use the Table Browser to ask \u201chow many TFBS in Drosophila are found in highly conserved sequences?\u201d We will do this by using the Table Browser to overlap all of the TFBS with all of the Most Conserved segments of the genome. \n 7) Click the \u201ccreate\u201d button next to the \u201cintersection\u201d option. This will send you to a page where you can set conditions for the overlap analysis of the FlyReg TFBS with the Most Conserved regions. \n 8 ) Select \u201cComparative Genomics\u201d and \u201cMost Conserved\u201d from the \u201cgroup\u201d and \u201ctrack\u201d pull-down menus. Click the \u201cAll FlyReg records that have at least X% overlap with Most Conserved\u201d. Set the X% value to \u201c100\u2033 and click \u201csubmit\u201d to return to the main Table Browser page. \n 9) Notice that the Table Browser now shows the \u201cintersection with phastConsElements15way\u201d option is selected. Select \u201cHyperlinks to Genome Browser\u201d from the \u201coutput format\u201d pull-down menu and click \u201cget output\u201d.\u00a0 This will send you to a page with hyperlinks that send you to all the annotated TFBS in Drosophila that are 100% contained in the Most Conserved regions of the genome. Click on a few links to convince yourself that this analysis has generated the correct results. At this point you have a great result \u2013 all fully conserved TFBS in Drosophila \u2013 but it is difficult to quantitatively summarize these data in the Table Browser, so let\u2019s move on to Galaxy where analysis like this is a lot easier. \n Quantifying TFBS conservation using Galaxy \n 1) Click the \u201cTables\u201d link on the dark blue background at the top of the page to return to the Table Browser. Select \u201cBED \u2013 browser extensible data\u201d from the \u201coutput format\u201d pull-down menu and check the \u201cGalaxy\u201d check box. Now click the \u201cget output\u201d button at the bottom of the page. This will send you to a detail page. Leave all the default options set here and click \u201cSend query to Galaxy\u201d. \n 2) This will launch a new Galaxy session as an anonymous user. [For more information on Galaxy, visit http://usegalaxy.org ] The results of this Table Browser query will be executed as a Galaxy \u201canalysis\u201d which will appear in the right hand \u201cHistory\u201d pane of the Galaxy browser window as \u201c1: UCSC Main on D. melanogaster: flyreg2 (genome)\u201d. While the Table Browser query is running, this analysis will be grey in the history pane, but will turn green when it is completed. \n 3) When the analysis has completed, you will have created a new dataset numbered \u201c1\u2033 in your Galaxy history. Click on the link entitled \u201c1: UCSC Main on D. melanogaster: flyreg2 (genome)\u201d in the history to reveal a dropdown which contains a snapshot of this dataset. [This dataset should contain 533 regions. If it doesn't stop here and get help before moving on.] Now click on the eye icon to reveal the contents of this data set in the middle pane of the Galaxy window. Use the scroll bar on the right hand side of the middle pane to browse the contents of this data set. \n 4) Click on the pencil icon to \u201cEdit attributes\u201d of this data set. In the middle pane replace \u201c1: UCSC Main on D. melanogaster: flyreg2 (genome)\u201d in the \u201cName\u201d text box with something shorter and more descriptive like \u201cconserved TFBS\u201d. Click the \u201cSave\u201d button at the bottom of the middle pane. \n 5) Now let\u2019s get the complete set of FlyReg TFBS by querying the UCSC Table Browser from inside Galaxy. Click \u201cGet Data\u201d under \u201cTools\u201d in the left hand pane of the Galaxy page. This will explode a list of options to get data into Galaxy. Click \u201cUCSC Main\u201d which will bring up the Table Browser inside the middle pane of the Galaxy page. Click the \u201cclear\u201d button next to \u201cintersection with phastConsElements15way:\u201d. Make sure the \u201cGalaxy\u201d check box is selected and click \u201cget output\u201d and then click \u201cSend query to Galaxy\u201d on the next page. This will create a new dataset \u201c2: UCSC Main on D. melanogaster: flyreg2 (genome)\u201d which you can rename \u201call TFBS\u201d as above using the pencil icon. [Note: this dataset should have 1,362 regions in it; if your does not, please stop and ask for help.] \n 6) You can now perform many different analyses on these datasets using the many \u201cTools\u201d available in the left hand pane of the Galaxy window. Let\u2019s start by summarizing how many TFBS are present in the \u201c1: conserved TFBS\u201d and \u201c2: all TFBS\u201d datasets. To do this, click the \u201cStatistics\u201d link on the left hand side, which will open up a set of other analysis tools including the \u201cCount\u201d tool. Click on the \u201cCount\u201d tool, and in the middle pane select \u201c1: conserved TFBS\u201d in the \u201cfrom dataset\u201d menu and click on \u201cc4\u2033 to activate the counting to occur on column 4 containing the name of the TFBS in the \u201c1: conserved TFBS\u201d dataset. Repeat this analysis for the \u201c2: all TFBS\u201d dataset. This should lead to two more datasets of 70 and 88 lines, respectively, which you should again rename to something more meaningful than the default values, such as \u201c3: conserved TFBS counts\u201d and 4: all TFBS counts\u201d. \n 7) Now let\u2019s use the \u201cJoin, Subtract and Group->Join two Datasets\u201d tool to join the results of the two previous analyses into one merged dataset. Click \u201cJoin, Subtract and Group->Join two Datasets\u201d, select \u201c4: all TFBS counts\u201d in the \u201cJoin\u201d drop-down menu, \u201cc2\u2033 for the \u201cusing column\u201d drop-down menu, \u201c3: conserved TFBS counts\u201d in the \u201cwith\u201d drop-down menu and \u201cc2\u2033 for the \u201cand column\u201d drop-down menu. Set the \u201cKeep lines of first input that do not join with second input:\u201d, \u201cKeep lines of first input that are incomplete:\u201d, and \u201cFill empty columns:\u201d drop-down menus to \u201cyes\u201d. Setting the \u201d Fill empty columns\u201d menu to yes will pull up a few more menus, which should be set as follows: \u201cOnly fill unjoined rows:\u201d set to \u201cYes\u201d; \u201cFill Columns by:\u201d set to \u201csingle Fill Value\u201d, and \u201cFill value\u201d to \u201c0\u2033. Now click \u201cExecute\u201d. What you have just achieved is one of the trickier basic operations on bioinformatics, and is the underlying process in most relational database queries.\u00a0 Pat yourself on the back! \n 8 ) Now let\u2019s try to do some science and ask the question: \u201cwhat is the proportion of conserved TFBS for each transcription factor?\u201d This will give us some insight into whether TFBS turnover is the same for all TFs or might be higher or lower for some TFs. To do this, use the \u201cText manipulation->compute\u201d Tool and set the \u201cAdd expression\u201d box to \u201c(c1-c3)/c1\u2033 and \u201cas a new column to:\u201d to \u201c5: Join two Datasets on data 3 and data 4\u2033 and click \u201cExecute\u201d. This will add a new column to the joined dataset with the proportion of conserved TFBS for each transcription factor. \n For Further Exploration\u2026 \n 1) Format the output of your last analysis in a more meaningful manner using the \u201cFilter and Sort->Sort\u201d tool. \n 2) Plot the distribution of the proportion of conserved TFBS per TF using the \u201cGraph/Display Data->Histogram\u201d tool. \n 3) Go back to the original TFBS datasets and derive new datasets to investigate if different chromosomes have different rates of TFBS evolution? \n 4) Develop your own question about TFBS evolution, create a custom analysis pipeline in Galaxy and wow us with your findings."], "link": "http://bergmanlab.smith.man.ac.uk/?p=1248", "bloglinks": {}, "links": {"http://usegalaxy.org": 1, "http://genome.ucsc.edu/": 1, "http://www.flyreg.org/": 2, "http://www.openhelix.com/": 3, "http://genome.ucsc.edu": 1, "http://main.psu.edu/": 1}, "blogtitle": "Bergman Lab"}, {"content": ["NCBI\u2019s Sequence Read Archive (SRA) is one of the primary repositories for next-generation sequencing data.\u00a0 Submissions to SRA are often complex, with multiple samples from a given submission, or multiple sequencing runs associated with a given sample. As a result, a given SRA submission \u201cenvelope\u201d can be associated with database records at several levels, each with corresponding identifiers and nomenclature. Valid levels in the SRA data model include: the study (prefixed with SRP), the experiment (prefixed with SRX), the sample (prefixed with SRS), and the run (prefixed with SRR). Mapping identifiers between the different parts of an SRA submission is important when you need to access meta-data from different parts of a submission or you need to aggregate data across different levels of a submission (e.g. sequencing runs from the same biological sample). \n In the past, we\u2019ve been guilty of using PERL to screen-scrape meta-data from the SRA html pages to aggregate accessions from different sequencing runs conducted by the Drosophila Genetic Reference Panel (DGRP) project. However, this is a non-optimal strategy because of changes to the SRA html format that make this approach brittle. Recently, I stumbled across a much better way to map IDs and access meta-data in SRA, using the SRAdb package from Bioconductor . The developers of SRAdb provide a nicely repackaged version of all SRA meta-data in SQLlite that can easily be accessed using a few lines of R. \n The following example shows how to map IDs at all levels for SRA accessions from the two major Drosophila resequencing projects the DGRP (SRA study\u00a0 SRP000694 ) and the Drosophila Population Genomics Project (SRA studies SRP000224 & SRP005599 ). \n \n\n#install the SRAdb bioconductor package\nsource(\"http://www.bioconductor.org/biocLite.R\")\nbiocLite(\"SRAdb\")\nlibrary(SRAdb)\n\n#download and connect to the SRA SQLlite database\nsqlfile <- getSRAdbFile()\nsra_connection <- dbConnect(SQLite(), \"SRAmetadb.sqlite\")\n\n# make linking table between SRP, SRA, SRS, SRX & SRR for DPGP & DGRP projects\nconversion <- sraConvert(c(\"SRP000694\",\"SRP000224\", \"SRP005599\"), sra_con = sra_connection)\n\n# open outfile & print header\noutFile <- file(\"DrosophilaPopulationGenomicData.tsv\", \"w\")\ncat(\"Project\\tAccession\\tSample\\tExperiment\\tRun\\tSampleAlias\\tSampleDescription\\n\", file=outFile)\n\n# loop through conversion table and look-up meta-data for each sample\nfor (i in 1:nrow(conversion)) {\nsample_metadata_sql <- paste(\"select sample_alias, description from sample where sample_accession like '\", conversion[i,3], \"'\", sep=\"\")\nsample_metadata_results <- dbGetQuery(sra_connection, sample_metadata_sql)\ncat(conversion[i,1], conversion[i,2], conversion[i,3], conversion[i,4], conversion[i,5], sample_metadata_results[1,1], sample_metadata_results[1,2], \"\\n\", file=outFile, sep = \"\\t\")\n}\n\n#close filehandle\nclose(outFile)\n\n \n For those interested in the actual output of this mapping exercise please find the DrosophilaPopulationGenomicData.tsv file here . \n Credits: Thanks to Pedro Olivares-Chauvet for R syntax help and Jack Zhu for a prompt bug fix in the SRAdb files."], "link": "http://bergmanlab.smith.man.ac.uk/?p=1072", "bloglinks": {}, "links": {"https://www.bcm.edu/": 1, "http://www.dpgp.org/": 1, "http://bergmanlab.ac.uk/": 1, "http://www.bioconductor.org/": 2, "http://www.nih.gov/": 2, "http://en.wikipedia.org/": 2, "http://trace.nih.gov/": 3}, "blogtitle": "Bergman Lab"}]
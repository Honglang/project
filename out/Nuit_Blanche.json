[{"blogurl": "http://nuit-blanche.blogspot.it\n", "blogroll": [], "title": "Nuit Blanche"}, {"content": ["Can you imagine how much effort it would taken 15 years ago to shoot that movie ? (re: Predicting the Future: The Steamrollers )\n\n\n \n \n \n \n \n \n \n \n Join our Reddit Experiment , Join the CompressiveSensing subreddit and post there !  Liked this entry ? subscribe to Nuit Blanche's feed, there's more where that came from . You can also subscribe to Nuit Blanche by Email , explore the Big Picture in Compressive Sensing or the Matrix Factorization Jungle and join the conversations on compressive sensing , advanced matrix factorization and calibration issues on Linkedin."], "link": "http://nuit-blanche.blogspot.com/feeds/7656679440361057752/comments/default", "bloglinks": {}, "links": {"http://www.reddit.com/": 2, "http://feedburner.google.com/": 1, "http://feeds.feedburner.com/blog": 1, "http://www.linkedin.com/": 3, "http://feedads.doubleclick.net/": 2, "https://sites.google.com/": 2, "http://nuit-blanche.blogspot.com/": 1}, "blogtitle": "Nuit Blanche"}, {"content": ["In order to provide some focus to the blog, I have started these Month In Review posts. This is the second installment, the first one is here . We'll see where that experiment might take us. Talking about experiments, we also started something on Reddit and the Sunday Morning Insights. For more on those, please see below. Here is how this post is broken down: \n \n General ideas \n Reproducible Research - Codes - \n Jobs \n Experiments: Month in Review / Reddit / Sunday Morning Insights \n Life of the community / The Business of Science \n Misc \n \n \n General ideas \n \n  \n \nThis past month saw the crossing of the one million five hundred thousand pages views. What does this mean in terms of reach out, check this entry out for more information. \n \n \n \n \nIf there is one lesson from this long list of preprints and papers showing up on What's New in Compressive Sensing and Matrix Factorization This Month , it's that ADMM is becoming a mainstay in reconstruction solvers. \n \n \n \nI don't know if this is a trend, but this October, we also saw an interest by the practitioners to develop domain specific dictionaries: \n \n \n \n \n Accelerated DSI with Compressed Sensing using Adaptive Dictionaries \n Lipid Suppression in CSI with Spatial Priors and Highly Undersampled Peripheral K-Space \n Super-resolution using Sparse Representations over Learned Dictionaries: Reconstruction of Brain Structure using Electron Microscopy \n \n \n \n \nWe'll see where that leads us especially in light of advances in our understanding of the analysis framework (see Analysis K-SVD: A Dictionary-Learning Algorithm for the Analysis Sparse Model , Sunday Morning Insight: The Linear Boltzmann Equation and Co-Sparsity for more) \n \n \n \nI was also particularly impressed by muon tomography this past month and wrote twice about it ( Imaging Damaged Reactors and Volcanoes , Muon Tomography as a Moore's Law Enabled Technology ) mostly because better algorithm and silicon speed provide for a better image of what's around us. \n \n \n \nI also came back to a very interesting paper in Pushing the Boundaries in Compressive Sensing ( and a connection with this video ) and noted the push toward unifying Group testing and compressive sensing ( Semi-Quantitative Group Testing: a General Paradigm with Applications in Genotyping ), a subject of paramount importance in the future . We also had some crazy ideas ( Imaging with a View or Imagine a GoPro2 at Supersonic speed ). There is still time for your students ( if you are US based) to get on HASP . What about getting a camera to fall at Mach 1 and take a movie that parallels that of Curiosity landing on Mars ? \n \n \n \nOther entries and papers of interest included a paper somehow connected to Randomized Numerical Linear Algebra ( Invariance of Principal Components under Low-Dimensional Random Projection of the Data ), the use of adaptive compressive sensing from actual experimental data ( A Data-Adaptive Compressed Sensing Approach to Polarimetric SAR Tomography of Forested Areas ) and the limits of super resolution ( Quantum limits of super-resolution of optical sparse objects via sparsity constraint ). \n \n \n \n \n \n \n \n \n \n \n Reproducible Research - Codes - \n \n \n \n \nIn the spirit of reproducible research, we also had a flurry of new implementations / codes made available by their authors \n \n \n Analysis K-SVD: A Dictionary-Learning Algorithm for the Analysis Sparse Model , \n Unbiased Risk Estimates for Singular Value Thresholding and Spectral Estimators \n GONDOLA: Generative-Discriminative Basis Learning for Medical Imaging \n Eulerian Video Magnification for Revealing Subtle Changes in the World \n MASTeR: Motion-Adaptive Spatio-Temporal Regularization for Accelerated Dynamic MRI \n Complex Matrix Factorization Toolbox \n Lipid Suppression in CSI with Spatial Priors and Highly Undersampled Peripheral K-Space \n nGpFBMP: A Fast Non-Gaussian Bayesian Matching Pursuit Method for Sparse Reconstruction \n Accelerated DSI with Compressed Sensing using Adaptive Dictionaries \n SCoBeP: Dense Image Registration using Sparse Coding and Belief Propagation \n \n \n \n Jobs \n \n \nWe also had a large set of job announcements: \n \n \n Three PostDocs at the Seismic Laboratory for Imaging and Modelling (UBC) \n Postdoc Positions, Graph Analysis or Compressed Sensing, Sandia, CA \n Five EECS positions at the Colorado School of Mines \n a Postdoc Position in Randomized Numerical Linear Algebra @ IBM \n Postdoctoral Researcher position at the Linnaeus Centre ACCESS \n Two Post-Docs Statistical Physics Approach to Reconstruction in Compressed Sensing at ESPCI in Paris \n Two jobs for students \n \n \n \n \n Experiments: Month in Review / Reddit / Sunday Morning Insights \n \nThe first installment for the Month in Review (September 2012) is here . \n \n \nAt the beginning of this month, we started an experiment on Reddit , so far we have 42 readers. This is good. I have mentioned this before but anybody can post a link there as long as it is somehow relevant to the subject at hand. Also, civil discussions are encouraged. \n \n Join our Reddit Experiment, Join the CompressiveSensing subreddit and post there ! \n Bursting the Filter of our Peers: A Reddit Experiment \n \n \n \n \nWhile this experiment might be a good thing in terms of bursting our peer filter, I also like the fact that several entries are getting a new life. Since the Blogger search engine is pretty calamitous, this is a way to get attention on a subject that is not necessarily old but cannot be easily found with the blogger layout. We'll see how this goes. \n \n \nSunday Morning Insight's goal is to provide some , you guessed it, insight on a subject you might have read several times on the blog, here are the first three installments: \n \n \n \n Sunday Morning Insight: Muon Tomography as a Moore's Law Enabled Technology \n Sunday Morning Insight: Ditching L_1 \n Sunday Morning Insight: The Linear Boltzmann Equation and Co-Sparsity \n \n \n \n \n Videos and Slides: \n \n \nThis past month, Nuit Blanche also featured a few videos and slides from conferences, I realize this is a time sink but it is worth it: \n \n \n \n Videos: Workshop on Algorithms for Modern Massive Datasets \n Video: David Brady, Coded Aperture X-Ray Scatter Imaging \n Occam's razor in massive data acquisition: a statistical physics approach \n Slides: Workshop on \"Randomized Numerical Linear Algebra (RandNLA): Theory and Practice\" \n \n \n \n \n \n Life of the community / The Business of Science (meetings/ talks / deadlines....) \n \n \n \n \n Seeking four new members for the international SPARS Steering Committee \n \n Meeting: Sparse Representations, Compressed Sensing and Applications \n SPARS 2013 Signal Processing with Adaptive Sparse Structured Representations. \n Abstract submission deadline for BASP workshop extended until 26 October \n Around the Blogs in 80 Summer Hours \n Around the blogs in 80 summer hours \n Random Bits: A course, a talk \n two talks. \n Open Access and Post Publication Peer Review \n \n \n \n \n Misc \n \n \n \n Ceci n'est pas le blog de Nuit Blanche \n \n \nCredit: NASA/GOES, NOAA's GOES-13 satellite captured this visible image of the massive Hurricane Sandy on Oct. 28 at 1302 UTC (9:02 a.m. EDT) (via Space.com ) \n \n \n \n \n \n \n \n Join our Reddit Experiment , Join the CompressiveSensing subreddit and post there !  Liked this entry ? subscribe to Nuit Blanche's feed, there's more where that came from . You can also subscribe to Nuit Blanche by Email , explore the Big Picture in Compressive Sensing or the Matrix Factorization Jungle and join the conversations on compressive sensing , advanced matrix factorization and calibration issues on Linkedin."], "link": "http://nuit-blanche.blogspot.com/feeds/109625298837381473/comments/default", "bloglinks": {}, "links": {"http://www.reddit.com/": 4, "http://feedburner.google.com/": 1, "http://3.blogspot.com/": 1, "http://www.linkedin.com/": 3, "http://feedads.doubleclick.net/": 2, "http://www.space.com/": 1, "http://feeds.feedburner.com/blog": 1, "https://sites.google.com/": 2, "http://nuit-blanche.blogspot.fr/": 56, "http://laspace.lsu.edu/": 1}, "blogtitle": "Nuit Blanche"}, {"content": ["Saw this on NA Digest today (a different call than the one we saw in August ) \n \n \n \n \n From: Tammy Kolda tgkolda@sandia.gov \n \n Date: Fri, 26 Oct 2012 17:38:42 -0400 \n \n Subject: Postdoc Positions, Graph Analysis or Compressed Sensing, Sandia/CA \n \n \n \n Job Title: Postdoc, Graph Analysis or Compressed Sensing \n \n \n \n Job ID: 641951 \n \n \n \n Summary: We currently have two openings for postdoctoral researchers in the following areas: (1) massive-scale graph analysis using MapReduce and (2) compressed sensing applied to problems of data compromise and robustness. The successful applicant will be expected to conduct innovative research, to develop open-source software, to present his or her findings at leading conferences and workshops, and to publish his or her results in leading journals. This postdoctoral position is for motivated and enthusiastic individuals with a background in computer science, mathematics, statistics, engineering, or related areas. \n \n \n \n Required: (1) Advanced degree (Ph.D. or equivalent) in computer science, mathematics, statistics, engineering, or a related area, with a strong record of academic performance; (2) ability to work in a collaborative research environment; (3) evidence of relevant research expertise in the form of technical publications, presentations, software, and/or knowledge of applications; (4) software development competence in Java, C++, or a related language; (5) proficiency in solving problems, prioritizing work, and making decisions; (6) excellent written and oral communication skills. \n \n \n \n Desired: (1) Expertise in one or more of the following areas: graph and network analysis, compressed sensing, linear algebra, parallel algorithm design, applied statistics, numerical optimization, computational combinatorics, cyber defense, power systems, image and network surveillance; (2) software engineering proficiency, especially Hadoop MapReduce and/or high-performance computing experience; (3) experience with standard research tools such as LaTeX, MATLAB, PowerPoint; (4) a background in solving practical problems in science and engineering that involve encounters with real-world data; and (5) evidence of professional service to the community, such as engagement in student service activities or seminar/workshop organization. \n \n \n \n Supervisor: Tamara G. Kolda, tgkolda@sandia.gov \n \n \n \n For more information, see http://goo.gl/IjY5I \n \n \n \n \n \n \n \n \n Join our Reddit Experiment , Join the CompressiveSensing subreddit and post there !  Liked this entry ? subscribe to Nuit Blanche's feed, there's more where that came from . You can also subscribe to Nuit Blanche by Email , explore the Big Picture in Compressive Sensing or the Matrix Factorization Jungle and join the conversations on compressive sensing , advanced matrix factorization and calibration issues on Linkedin."], "link": "http://nuit-blanche.blogspot.com/feeds/7666329869579300667/comments/default", "bloglinks": {}, "links": {"http://www.reddit.com/": 2, "http://feedburner.google.com/": 1, "http://feeds.feedburner.com/blog": 1, "http://www.linkedin.com/": 3, "http://feedads.doubleclick.net/": 2, "https://sites.google.com/": 2, "http://nuit-blanche.blogspot.fr/": 1, "http://www.netlib.org/": 1}, "blogtitle": "Nuit Blanche"}, {"content": ["In a previous entry ( Sunday Morning Insight: The Linear Boltzmann Equation and Co-Sparsity ), we mentioned that anytime you were describing a field that followed some sort of physical law, like \n \n \n \nLu = 0 \n \n \n \nL being the Boltzmann or the Maxwell operator, and you added some boundary conditions, then you were in effect making a statement on co-sparsity: i.e. the non-zero elements representing either some boundary conditions or a better approximation of the full operator (Linear Boltzmann replacing the Diffusion operator at the boundaries). This is profound because it connects the generic work happening in sampling to the real world of physics and engineering (see structured life ) \n \n \n \n \n \n \n \n \n \nUnless I am mistaken this the third dictionary learning implementation released in the wild dedicated to learning the Analysis Operator, in effect learning the equivalent discretization of the operator of interest with its attendant boundary conditions. The first two were featured in Noise Aware Analysis Operator Learning for Approximately Cosparse Signals and in 90% missing pixels and you reconstructed that ?! Analysis Operator Learning and Its Application to Image Reconstruction . The paper illustrating what this new solver can do is: Analysis K-SVD: A Dictionary-Learning Algorithm for the Analysis Sparse Model by Ron Rubinstein , Tomer Peleg and Michael Elad \n \n \n \n \n \n \n \n \nThe synthesis-based sparse representation model for signals has drawn considerable interest in the past decade. Such a model assumes that the signal of interest can be decomposed as a linear combination of a few atoms from a given dictionary. In this paper we concentrate on an alternative, analysis-based model, where an analysis operator \u2013 hereafter referred to as the analysis dictionary \u2013 multiplies the signal, leading to a sparse outcome. Our goal is to learn the analysis dictionary from a set of examples. The approach taken is parallel and similar to the one adopted by the K-SVD algorithm that serves the corresponding problem in the synthesis model. We present the development of the algorithm steps: This includes tailored pursuit algorithms \u2013 the Backward Greedy and the Optimized Backward Greedy algorithms, and a penalty function that de\ufb01nes the objective for the dictionary update stage. We demonstrate the effectiveness of the proposed dictionary learning in several experiments, treating synthetic data and real images, and showing a successful and meaningful recovery of the analysis dictionary. \n \n \n \n \n \n \n \nThe implementation is here . \n \n \n \n \n \n Join our Reddit Experiment , Join the CompressiveSensing subreddit and post there !  Liked this entry ? subscribe to Nuit Blanche's feed, there's more where that came from . You can also subscribe to Nuit Blanche by Email , explore the Big Picture in Compressive Sensing or the Matrix Factorization Jungle and join the conversations on compressive sensing , advanced matrix factorization and calibration issues on Linkedin."], "link": "http://nuit-blanche.blogspot.com/feeds/4955422498589341908/comments/default", "bloglinks": {}, "links": {"http://www.ac.il/": 4, "http://www.linkedin.com/": 4, "http://feedburner.google.com/": 1, "http://3.blogspot.com/": 1, "http://www.reddit.com/": 2, "http://feedads.doubleclick.net/": 2, "http://feeds.feedburner.com/blog": 1, "https://sites.google.com/": 2, "http://nuit-blanche.blogspot.fr/": 3, "http://nuit-blanche.blogspot.com/": 1}, "blogtitle": "Nuit Blanche"}, {"content": ["Felix Hermann just sent me the following: \n \n \n \n \n Dear colleagues, \n \n \n \n We have three open postdoctoral positions at the Seismic Laboratory for Imaging and Modelling in the following areas: \n \n computational and theoretical seismology: seismic modelling, wave-equation based imaging and inversion \n \n \n observational seismology: development of practical data acquisition scenarios and workflows for full-waveform inversion \n \n \n compressive sensing : design and implementation of novel acquisition, sparse/low-rank recovery algorithms, and directional transforms including curvelets \n \n \n scientific computing & inverse problems: PDE-constrained optimization and direct and indirect solvers for the Helmholtz equation and \n \n \n optimization & machine learning: large-scale convex and stochastic optimization, etc . \n \nFor more information please follow https://www.slim.eos.ubc.ca/node/50662 or to our add at mathjobs (Position ID: UBC-SLIMPDF [#4250]) https://www.mathjobs.org/jobs/UBC/4250 where the candidates can submit their applications. Please, forward this information to potential candidates. Thank you. Kind regards, Felix J. Herrmann Director of UBC-Seismic Laboratory for Imaging and Modeling (SLIM) EOS-UBC phone: (+1) 604-822-8628 https://www.slim.eos.ubc.ca \n \n \n \n \n \n \n \n \n \n Join our Reddit Experiment , Join the CompressiveSensing subreddit and post there !  Liked this entry ? subscribe to Nuit Blanche's feed, there's more where that came from . You can also subscribe to Nuit Blanche by Email , explore the Big Picture in Compressive Sensing or the Matrix Factorization Jungle and join the conversations on compressive sensing , advanced matrix factorization and calibration issues on Linkedin."], "link": "http://nuit-blanche.blogspot.com/feeds/1737094321199063954/comments/default", "bloglinks": {}, "links": {"": 1, "http://www.reddit.com/": 2, "http://feedburner.google.com/": 1, "http://feeds.feedburner.com/blog": 1, "http://www.linkedin.com/": 3, "https://www.mathjobs.org/": 2, "http://feedads.doubleclick.net/": 2, "https://www.ubc.ca/": 4, "https://sites.google.com/": 2, "http://www.ubc.ca/": 1}, "blogtitle": "Nuit Blanche"}, {"content": ["In Predicting the Future, the steamrollers , one realizes that Moore's law is interesting but somehow we cannot point to a specific instance as to why this is really interesting. Let's shine some light in that direction. \n \n \n \nWhen David Brady talks about Coded Aperture X-Ray Scatter Imaging , one gets the impression that at some point in time, one could use scattering as a supplemental information to, potentially, extract hyperspectral information in CT-scans. That information is not going to be easy to extract in bulk measurements but one senses that this is because it involves a more complex modeling. That modeling is only accessible with better and faster computational power. \n \n \n \n \n \nIn a similar line of thought, it is interesting to see how the improvement of computational power has also transformed muon tomography imaging. In Imaging Damaged Reactors and Volcanoes , we noted how the use of a more advanced reconstruction algorithm [18] permitted the imaging of a relevant information. \n \n \n \nThe starting point of muon tomography technology can be traced back to Luis Alavrez's [22] negative results on the possibility of the Egyptian pyramids holding another chamber [23]. At that point in time, the technology could reconstruct image using an attenuation argument. While detectors were getting better, the real breakthrough lied with the possibility of utilizing s cattering simulation from Monte Carlo codes like MCNP or GEANT4. With that information one can evaluate whether or not the material being interrogated by muons contains high-Z material in it. And indeed, in the initial study for the detection of potential Fukushima corium [18], scattering seems to provide this additional bit of information that attenuation studies alone cannot provide. Current reconstruction algorithm taking into the coulomb scattering can be found in [5,6]. \n \n \n \n \n \n \n \nFor those interested, here is a rough survey of the type of problems being investigated with muon tomography. Let us note that some of the attenuation only experiments are very recent as they focus on the mapping of civil engineering structures and void underneath them, a subject of considerable interest: \n \n the detection of smuggled nuclear warheads [3, 8,9,13] \n the detection of orphan nuclear materials in scrap metal factories [1,9] \n the detection of empty spaces in the pyramids (Egyptian or Mayan pyramids) [2,5] -attenuation only - \n the detection of density inhomogeneities in volcanoes [12,14] -attenuation only - \n the detection of potential corium at Fukushima [10,11] \n the detection of voids in civil engineering structures [15,16,17] -attenuation only - \n Nuclear Waste Imaging and Spent Fuel Verification [26] \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n[1] Muon tomography to improve safety in Steel Plants \n \n \n \n \n \n[2] Imaging Maya Pyramids with Cosmic Ray Muons by Roy Schwitters \n \n \n[3] Imaging with 1 ft3 Muon Tomography Station and Analysis of Future Station Geometries by Nathan Mertins, Michael Staib, William Bittner, Marcus Hohlmann \n \n \n[4] Cosmic Ray Muon Radiography by Larry Schultz \n \n \n[5] A Detector for Muon Tomography: Data Acquisition and Preliminary Results Eric T. Wright \n \n \n \n[6] Advances in Cosmic Ray Muon Tomography Reconstruction Algorithms by Richard Claude Hoch \n \n \n[7] Statistical Reconstruction for Cosmic Ray Muon Tomography Larry J. Schultz, Member, Gary S. Blanpied, Konstantin N. Borozdin, Andrew M. Fraser, Nicolas W. Hengartner, Alexei V. Klimenko, Christopher L. Morris, Chris Orum, and Michael J. Sossong \n \n \n[8] Enabling Port Security using Passive Muon Radiography , Nicolas Hengartner, Bill Priedhorski, Konstantin Borozdin, Alexi Klimenco, Tom Asaki, Rick Chartrand, Larry Shultz, Andrew Green, Richard Shirato. \n \n \n[9] Applications of Muon Tomography for the Detection of Hidden Nuclear Substances in Containers by M. Benettoni, P. Checchia, E. Conti, F. Gonella, G. Nebbia, G. Mariotti, S. Pesente, S. Vanini, G. Viesti, G, G. Bonomi, A. Zenoni, P. Calvini, , S. Squarcia \n \n \n[10] Discussion - Next Step for Fukushima Daiichi Muon Tomography by Miyadera, Haruo \n \n \n[11] Our Next Two Steps for Fukushima Daiichi Muon Tomography by Jeffrey D. Bacon, Konstantin N. Borozdin, Michael Brockwell, Edward C. Milner, Haruo Miyadera, Christopher Morris, John O. Perry, Zarija Lukic. Koji Masuda \n \n [12] DIAPHANE web site devoted to the \"Development of cosmic-ray muons tomography in geophysics\" \n [13] COSMIC-RAY MUON TOMOGRAPHY AND ITS APPLICATION TO THE DETECTION OF HIGH-Z MATERIALS by Konstantin Borozdin, Thomas Asaki, Rick Chartrand, Mark Galassi, Andrew Greene, Nicolas Hengartner, Gary Hogan, Alexei Klimenko, Christopher Morris, William Priedhorsky, Alexander Saunders, Richard Schirato, Larry Schultz, Matthew Sottile, Gary Blanpied \n \n \n \n[14] Density imaging of volcanos with atmospheric muons by Felix Fehr . \n \n[15] FY 2008 Hollowing subsurface engineering applications of muon. Study on the surveillance system, Report \n \n \n[16] FY 2009 Hollowing subsurface engineering applications of muon. Study on the surveillance system, Report \n \n[17] FY 2010 Development of multi-instrumentation utilizing muon, Feasibility Study. Report \n \n [ 18] Non-Invasive Imaging of Reactor Cores Using Using Cosmic Ray Muons Cosmic Ray Muons by Cas Milner: Jeff Bacon, Konstantin Borozdin , Michael Brockwell, Steven Greene , Haruo Miyadera , Christopher Morris , John Perry \n \n \n \n \n \n \n \n \n \n[19] Minato,S. (1988) Feasibility of cosmic-ray radiography: A case study of a temple gate as a testpiece, Materials Evaluation, 46: 1468-1470. \n \n[20] Minato,S. (1987) Feasibility study on cosmic-ray nondestructive testing through structural analysis of subway stations, NDT International, 20: 231-234. \n \n[21] Minato,S. (1986) Bulk density estimates of buildings using cosmic rays, Applied Radiation and Isotopes, 37: 941-946. \n \n[22] S CIENTIST AS DETECTIVE, LUIS ALVAREZ AND THE PYRAMID BURIAL CHAMBERS, \n \n THE JFK ASSASSINATION, AND THE END OF THE DINOSAURS by Charles G. Wohl \n \n[23] Luis W. Alvarez, Jared A. Anderson, F. El Bedwei, James Burkhard, Ahmed Fakhry, Adib Girgis, Amr Goneid, Fikhry Hassan, Dennis Iverson, Gerald Lynch, Zenab Miligy, Ali Hilmy Moussa, Mohammed-Sharkawi, Lauren Yazolino, Search for Hidden Chambers in the Pyramids,\" Science 167, 832 (1969). \n[24] Designs for Muon Tomography Station Prototypes Using GEM Detectors , Leonard V. Grasso III \n \n \n[25] Imaging of high-Z material for nuclear contraband detection with a minimal prototype of a Muon Tomography station based on GEM detectors by Kondo Gnanvo, Leonard V. Grasso III, Marcus Hohlmann, Judson B. Locke, Amilkar S. Quintero, Debasis Mitra \n [26] Nuclear Waste Imaging and Spent Fuel Verification by Muon Tomography , G. Jonkmans , V. N. P. Anghel , C. Jewett , M. Thompson \n \n \n \n \n \n \n \n \n \n Join our Reddit Experiment , Join the CompressiveSensing subreddit and post there !  Liked this entry ? subscribe to Nuit Blanche's feed, there's more where that came from . You can also subscribe to Nuit Blanche by Email , explore the Big Picture in Compressive Sensing or the Matrix Factorization Jungle and join the conversations on compressive sensing , advanced matrix factorization and calibration issues on Linkedin."], "link": "http://nuit-blanche.blogspot.com/feeds/1677844046233040847/comments/default", "bloglinks": {}, "links": {"http://3.blogspot.com/": 2, "http://www.infn.it/": 1, "http://www.google.fr/": 1, "https://sites.google.com/": 3, "http://4.blogspot.com/": 1, "http://permalink.lanl.gov/": 2, "http://research.fit.edu/": 1, "http://research2.fit.edu/": 1, "http://www.cgsd.com/": 1, "http://math.lanl.gov/": 1, "http://nuit-blanche.blogspot.com/": 3, "http://www.davidbrady.net/": 1, "http://feedburner.google.com/": 1, "http://feeds.feedburner.com/blog": 1, "http://repositories.utexas.edu/": 1, "http://www.or.jp/": 4, "http://www.6911norfolk.com/": 2, "http://arxiv.org/": 6, "http://www.mermecgroup.com/": 1, "http://hal.in2p3.fr/": 2, "http://www.utexas.edu/": 3, "http://dimacs.rutgers.edu/": 1, "http://www.linkedin.com/": 3, "http://www.ac.ir/": 1, "http://feedads.doubleclick.net/": 2, "http://www1.ne.jp/": 3, "http://www.reddit.com/": 2, "http://2.blogspot.com/": 1}, "blogtitle": "Nuit Blanche"}, {"content": ["I'll come back to some of them in the future, but in the meantime, here is the large batch for the month. Enjoy! \n \n \n \nSlides: Constrained Overcomplete Analysis Operator Learning for Cosparse Signal Modelling by Mehrdad Yaghoobi , Sangnam Nam, Remi Gribonval, and Mike E. Davies \n \n \n \n \n Relaxed Analysis Operator Learning \n \n Mehrdad Yaghoobi Mike E. Davies \n \n \n \nThe problem of analysis operator learning can be formulated as a constrained optimisation problem. This problem has been approximately solved using projected gradient or geometric gradient descent methods. We will propose a relaxation for the constrained analysis operator learning in this paper. The relaxation has been suggested here to, a) reduce the computational complexity of the optimisation and b) include a larger set of admissible operators. We will show here that an appropriate relaxation can be useful in presenting a projection-free optimisation algorithm, while preventing the problem to become ill-posed. The relaxed optimisation objective is not convex and it is thus not always possible to \ufb01nd the global optimum. However, when a rich set of training samples are given, we empirically show that the desired synthetic analysis operator is recoverable, using the introduced sub-gradient descent algorithm. \n \n \n \n \n \n Constrained Overcomplete Analysis Operator Learning for Cosparse Signal Modelling \n \n Mehrdad Yaghoobi Sangnam Nam, R\u00b4emi Gribonval and Mike E. Davies \n \n \n \nAbstract\u2014We consider the problem of learning a low-dimensional signal model from a collection of training samples. The mainstream approach would be to learn an overcomplete dictionary to provide good approximations of the training samples using sparse synthesis coef\ufb01cients. This famous sparse model has a less well known counterpart, in analysis form, called the cosparse analysis model. In this new model, signals are characterised by their parsimony in a transformed domain using an overcomplete (linear) analysis operator. We propose to learn an analysis operator from a training corpus using a constrained optimisation framework based on L1 optimisation. The reason for introducing a constraint in the optimisation framework is to exclude trivial solutions. Although there is no \ufb01nal answer here for which constraint is the most relevant constraint, we investigate some conventional constraints in the model adaptation \ufb01eld and use the uniformly normalised tight frame (UNTF) for this purpose. We then derive a practical learning algorithm, based on projected subgradients and Douglas-Rachford splitting technique, and demonstrate its ability to robustly recover a ground truth analysis operator, when provided with a clean training set, of suf\ufb01cient size. We also \ufb01nd an analysis operator for images, using some noisy cosparse signals, which is indeed a more realistic experiment. As the derived optimisation problem is not a convex program, we often \ufb01nd a local minimum using such variational methods. For two different settings, we provide preliminary theoretical support for the well-posedness of the learning problem, which can be practically used to test the local identi\ufb01ability conditions of learnt operators. \n \n \n \n \n \n Auto-focus for Under-sampled Synthetic Aperture Radar \n \nShaun I. Kelly, Mehrdad Yaghoobi, and Mike E. Davies \n \n \n \nAbstract\u2014We investigate the effects of phase errors on undersampled synthetic aperture radar (SAR) systems. We show that the standard methods of auto-focus, which are used as a postprocessing step, are typically not suitable. Instead of applying auto-focus as a post-processor we propose using a stable algorithm, which is based on algorithms from the dictionary learning literature, that corrects phase errors during the reconstruction and is found empirically to recover sparse SAR images. \n \n \n \n \n \n \n A New Regularization Path for Logistic Regression via Linearized Bregman \n \nJianing V. Shi, Wotao Yin and Stanley J. Osher \n \n \n \nThe \u21131-regularized logistic regression is an important linear classi\ufb01er in statistical learning, providing an attractive route for feature selection. The hyperparameter \u03bb a\ufb00ects the level of sparsity. For arbitrary data, the optimal level of sparsity that yields the best classi\ufb01cation performance is usually not known a priori. Current methodologies for seeking the optimal level of sparsity include the grid search method and the Bayesian approach. The grid search method typically requires constructing a regularization path, by solving a sequence of minimization problems with varying values of hyperparameter. Such a procedure can be time consuming. In this paper, we introduce a fast procedure that generates a new regularization path without tuning the hyperparameter. Our algorithm can e\ufb03ciently sample the regularization path at \ufb01nely grained points, through an iterative algorithm based on Bregman divergence. We \ufb01rst derive a new regularization path by replacing the \u21131-norm by Bregman divergence, and contrast it with the grid search method. The direct Bregman method requires solving each subproblem accurately, and turns out to be computationally ine\ufb03cient. Therefore we further derive a linearized Bregman algorithm, which is algebraically simple and computationally e\ufb03cient. Finally we demonstrate some empirical results for the linearized Bregman algorithm on benchmark data and study feature selection as an inverse problem. Compared with the grid search method, the linearized Bregman algorithm generates a regularization path with comparable accuracy, in a much more computationally e\ufb03cient manner. \n \n \n \n \n \n \n \n \n Ef\ufb01cient Background Subtraction for Real-time Tracking in Embedded Camera Networks \n \nYiran Shen, Wen Hu , Junbin Liu, Mingrui Yang, Bo Wei and Chun Tung Chou \n \n \n \nBackground subtraction is often the \ufb01rst step of many computer vision applications. For a background subtraction method to be useful in embedded camera networks, it must be both accurate and computationally ef\ufb01cient because of the resource constraints on embedded platforms. This makes many traditional background subtraction algorithms unsuitable for embedded platforms because they use complex statistical models to handle subtle illumination changes. These models make them accurate but the computational requirement of these complex models is often too high for embedded platforms. In this paper, we propose a new background subtraction method which is both accurate and computational ef\ufb01cient. The key idea is to use compressive sensing to reduce the dimensionality of the data while retaining most of the information. By using multiple datasets, we show that the accuracy of our proposed background subtraction method is comparable to that of the traditional background subtraction methods. Moreover, real implementation on an embedded camera platform shows that our proposed method is at least 5 times faster, and consumes signi\ufb01cantly less energy and memory resources than the conventional approaches. Finally, we demonstrated the feasibility of the proposed method by the implementation and evaluation of an end-to-end real-time embedded camera network target tracking application. \n \n \n \n \n \n \n \n A Fast Gradient Projection Algorithm for Ef\ufb01cient Cross-Correlation via Sparse Representation in Sensor Networks \n \nPrasant Misra, Mingrui Yang, Wen Hu , Sanjay Jha \n \n \n \nCross-correlation is a popular signal processing technique used for obtaining reliable range information. Recently, a practical and ef\ufb01cient implementation of cross-correlation (via sparse approximation) was demonstrated on resource constrained wireless sensor network platforms, where the key idea was to compress the received signal samples, and transfer them to central device where the range information \n \nwas retrieved by `1-minimization. Although, this mechanism yields accurate ranging results, its applicability is limited due to its slow execution speed and inaccurate recovery of the correlation peak magnitude, which implicitly provides the useful measure of signal-to-noise ratio. In this work, we propose Fast Gradient Projection (F-GP), a new `1-minimization algorithm, which overcomes the existing limitations, and provides fast and accurate ranging. \n \n \n \n \n \n Sorting Electrophysiological Data via Dictionary Learning & Mixture Modeling \n \nQisong Wu, David Carlson, Wenzhao Lian, Mingyuan Zhou, Colin R. Stoetzner, Daryl Kipke, Douglas Weber, Joshua Vogelstein, David Dunson and Lawrence Carin \n \n \n \nAbstract\u2014A new model is developed for feature learning and clustering of electrophysiological (ephys) data across multiple recording periods. The model is applicable to situations in which the detected spikes may be clipped (constituting missing data). It is demonstrated that joint feature (dictionary) learning and clustering allows one to perform forensics on the characteristics of the data (distinguishing single-unit spikes from non-local phenomena and artifacts). We explicitly model the number of spikes within a measurement interval, addressing a time-evolving \ufb01ring rate. Further, we model the number of clusters, mitigating limitations of methods like the Dirichlet process. Model properties are discussed, state-of-the-art results are presented on public data, and the methodology is demonstrated on new measured (experimental) ephys data. \n \n \n \n \n \n Structured Sparsity Models for Multiparty Speech Recovery from Reverberant Recordings \n \n Afsaneh Asaei , Mohammad Golbabaee , Herv\u00e9 Bourlard , Volkan Cevher \n \n \n \nWe tackle the multi-party speech recovery problem through modeling the acoustic of the reverberant chambers. Our approach exploits structured sparsity models to perform room modeling and speech recovery. We propose a scheme for characterizing the room acoustic from the unknown competing speech sources relying on localization of the early images of the speakers by sparse approximation of the spatial spectra of the virtual sources in a free-space model. The images are then clustered exploiting the low-rank structure of the spectro-temporal components belonging to each source. This enables us to identify the early support of the room impulse response function and its unique map to the room geometry. To further tackle the ambiguity of the reflection ratios, we propose a novel formulation of the reverberation model and estimate the absorption coefficients through a convex optimization exploiting joint sparsity model formulated upon spatio-spectral sparsity of concurrent speech representation. The acoustic parameters are then incorporated for separating individual speech signals through either structured sparse recovery or inverse filtering the acoustic channels. The experiments conducted on real data recordings demonstrate the effectiveness of the proposed approach for multi-party speech recovery and recognition. \n \n \n \n REGULARIZED BAYESIAN COMPRESSED SENSING IN ULTRASOUND IMAGING \n \n Nicolas Dobigeon , Adrian Basarab, Denis Kouame\u00b4and Jean-Yves Tourneret \n \n \n \nCompressed sensing has recently shown much interest for ultrasound imaging. In particular, exploiting the sparsity of ultrasound images in the frequency domain, a speci\ufb01c random sampling of ultrasound images can be used advantageously for designing ef\ufb01cient Bayesian image reconstruction methods. We showed in a previous work that assigning independent Bernoulli Gaussian priors to the ultrasound image in the frequency domain provides Bayesian reconstruction errors similar to a classical \u21131 minimization technique. However, the advantage of Bayesian methods is to estimate the sparsity level of the image by using a hierarchical algorithm. This paper goes a step further by exploiting the spatial correlations between the image pixels in the frequency domain. A new Bayesian model based on a correlated Bernoulli Gaussian model is proposed for that purpose. The parameters of this model can be estimated by sampling the corresponding posterior distribution using an MCMC method. The resulting algorithm provides very low reconstruction errors even when reducing signi\ufb01cantly the number of measurements via random sampling. \n \n \n \n \n \n An Improved Lower Bound of The Spark With Application \n \n Wajeb Gharibi \n \n \n \nSpark plays a great role in studying uniqueness of sparse solutions of the underdetermined linear equations. In this article, we derive a new lower bound of spark. As an application, we obtain a new criterion for the uniqueness of sparse solutions of linear equations. \n \n \n \n Mixture model for designs in high dimensional regression and the LASSO \n \n St\u00e9phane Chr\u00e9tien \n \n \n \nThe LASSO is a recent technique for variable selection in the regression model \\bean y & = & X\\beta +\\epsilon, \\eean where $X\\in \\R^{n\\times p}$ and $\\epsilon$ is a centered gaussian i.i.d. noise vector $\\mathcal N(0,\\sigma^2I)$. The LASSO has been proved to perform exact support recovery for regression vectors when the design matrix satisfies certain algebraic conditions and $\\beta$ is sufficiently sparse. Estimation of the vector $X\\beta$ has also extensively been studied for the purpose of prediction under the same algebraic conditions on $X$ and under sufficient sparsity of $\\beta$. Among many other, the coherence is an index which can be used to study these nice properties of the LASSO. More precisely, a small coherence implies that most sparse vectors, with less nonzero components than the order $n/\\log(p)$, can be recovered with high probability if its nonzero components are larger than the order $\\sigma \\sqrt{\\log(p)}$. However, many matrices occuring in practice do not have a small coherence and thus, most results which have appeared in the litterature cannot be applied. The goal of this paper is to study a model for which precise results can be obtained. In the proposed model, the columns of the design matrix are drawn from a Gaussian mixture model and the coherence condition is imposed on the much smaller matrix whose columns are the mixture's centers, instead of on $X$ itself. Our main theorem states that $X\\beta$ is as well estimated as in the case of small coherence up to a correction parametrized by the maximal variance in the mixture model. \n \n \n \n \n \n Compressed Sensing Signal Recovery via Forward-Backward Pursuit \n \n Nazim Burak Karahanoglu , Hakan Erdogan \n \n \n \nRecovery of sparse signals from compressed measurements constitutes an l0 norm minimization problem, which is unpractical to solve. A number of sparse recovery approaches have appeared in the literature, including l1 minimization techniques, greedy pursuit algorithms, Bayesian methods and nonconvex optimization techniques among others. This manuscript introduces a novel two-stage greedy approach, called the Forward-Backward Pursuit (FBP). FBP is an iterative approach where each iteration consists of consecutive forward and backward stages. The forward step first expands the support estimate by the forward step size, while the following backward step shrinks it by the backward step size. The forward step size is higher than the backward step size, hence the initially empty support estimate is expanded at the end of each iteration. Forward and backward steps are iterated until the residual power of the observation vector falls below a threshold. This structure of FBP does not necessitate the sparsity level to be known a priori in contrast to the Subspace Pursuit or Compressive Sampling Matching Pursuit algorithms. FBP recovery performance is demonstrated via simulations including recovery of random sparse signals with different nonzero coefficient distributions in noisy and noise-free scenarios in addition to the recovery of a sparse image. \n \n \n \n Accelerating Iterative Detection for Spatially Coupled Systems by Collaborative Training \n \n Keigo Takeuchi \n \n \n \nThis letter proposes a novel method for accelerating iterative detection for spatially coupled (SC) systems. An SC system is constructed by one-dimensional coupling of many subsystems, which are classified into training and propagation parts. An irregular structure is introduced into the subsystems in the training part so that information in that part can be detected successfully. The obtained reliable information may spread over the whole system via the subsystems in the propagation part. In order to allow the subsystems in the training part to collaborate, shortcuts between them are created to accelerate iterative detection for that part. As an example of SC systems, SC code-division multiple-access (CDMA) systems are considered. Density Evolution for SC CDMA systems shows that the proposed method can provide a significant reduction in the number of iterations for highly loaded systems, compared to conventional methods. \n \n \n \n On the Theoretical Analysis of Orthogonal Matching Pursuit with Termination Based on the Residue \n \n Nazim Burak Karahanoglu , Hakan Erdogan \n \n \n \nOrthogonal Matching Pursuit (OMP) is a simple, yet empirically competitive algorithm for sparse recovery. Recent developments have shown that OMP guarantees exact recovery of $K$-sparse signals in $K$ iterations if the observation matrix $\\Phi$ satisfies the Restricted Isometry Property (RIP) with Restricted Isometry Constant (RIC) $\\delta_{K+1}<\\frac{1}{\\sqrt{K}+1}$. On the other hand, OMP empirically promises higher recovery rates when it runs for more than $K$ iterations. In order to support this theoretically, we extend the theoretical analysis of OMP to cover more than $K$ iterations. We develop exact recovery guarantees for $K$-sparse signals in more than $K$ iterations when $\\Phi$ satisfies an RIP condition which depends on the number of correct and false indices in the support estimates of intermediate iterations. In addition, we present an upper bound on the number of false indices in the support estimate for the derived RIP condition to be less restrictive than $\\delta_{K+1}<\\frac{1}{\\sqrt{K}+1}$. Moreover, we provide recovery simulations which demonstrate the performance improvement when more than $K$ iterations are allowed. Finally, we empirically analyse the number of false indices in the support estimate, which indicates that these do not violate the developed upper bound in practice. \n \n \n \n \n \n Epigraphical Projection and Proximal Tools for Solving Constrained Convex Optimization Problems: Part I \n \n Giovanni Chierchia , Nelly Pustelnik , Jean-Christophe Pesquet , B\u00e9atrice Pesquet-Popescu \n \n \n \nWe propose a proximal approach to deal with convex optimization problems involving nonlinear constraints. A large family of such constraints, proven to be effective in the solution of inverse problems, can be expressed as the lower level set of a sum of convex functions evaluated over different, but possibly overlapping, blocks of the signal. For this class of constraints, the associated projection operator generally does not have a closed form. We circumvent this difficulty by splitting the lower level set into as many epigraphs as functions involved in the sum. A closed half-space constraint is also enforced, in order to limit the sum of the introduced epigraphical variables to the upper bound of the original lower level set. \n \nIn this paper, we focus on a family of constraints involving linear transforms of l_1,p balls. Our main theoretical contribution is to provide closed form expressions of the epigraphical projections associated with the Euclidean norm and the sup norm. The proposed approach is validated in the context of image restoration with missing samples, by making use of TV-like constraints. Experiments show that our method leads to significant improvements in term of convergence speed over existing algorithms for solving similar constrained problems. \n \n \n \n \n \n Sparse Stabilization and Control of the Cucker-Smale Model \n \n Marco Caponigro , Massimo Fornasier , Benedetto Piccoli , Emmanuel Tr\u00e9lat \n \n \n \nFrom a mathematical point of view self-organization can be described as patterns to which certain dynamical systems modeling social dynamics tend spontaneously to be attracted. In this paper we explore situations beyond self-organization, in particular how to externally control such dynamical systems in order to eventually enforce pattern formation also in those situations where this wished phenomenon does not result from spontaneous convergence. Our focus is on dynamical systems of Cucker-Smale type, modeling consensus emergence, and we question the existence of stabilization and optimal control strategies which require the minimal amount of external intervention for nevertheless inducing consensus in a group of interacting agents. We provide a variational criterion to explicitly design feedback controls that are componentwise sparse, i.e. with at most one nonzero component at every instant of time. Controls sharing this sparsity feature are very realistic and convenient for practical issues. Moreover, the maximally sparse ones are instantaneously optimal in terms of the decay rate of a suitably designed Lyapunov functional, measuring the distance from consensus. As a consequence we provide a mathematical justification to the general principle according to which \"sparse is better\" in the sense that a policy maker, who is not allowed to predict future developments, should always consider more favorable to intervene with stronger action on the fewest possible instantaneous optimal leaders rather than trying to control more agents with minor strength in order to achieve group consensus. We then establish local and global sparse controllability properties to consensus and, finally, we analyze the sparsity of solutions of the finite time optimal control problem where the minimization criterion is a combination of the distance from consensus and of the l1-norm of the control. \n \n \n \n \n \n \n \n \n \n Bayesian Estimation for Continuous-Time Sparse Stochastic Processes \n \n Arash Amini , Ulugbek S. Kamilov , Emrah Bostan , Michael Unser \n \n \n \nWe consider continuous-time sparse stochastic processes from which we have only a finite number of noisy/noiseless samples. Our goal is to estimate the noiseless samples (denoising) and the signal in-between (interpolation problem). \n \nBy relying on tools from the theory of splines, we derive the joint a priori distribution of the samples and show how this probability density function can be factorized. The factorization enables us to tractably implement the maximum a posteriori and minimum mean-square error (MMSE) criteria as two statistical approaches for estimating the unknowns. We compare the derived statistical methods with well-known techniques for the recovery of sparse signals, such as the $\\ell_1$ norm and Log ($\\ell_1$-$\\ell_0$ relaxation) regularization methods. The simulation results show that, under certain conditions, the performance of the regularization techniques can be very close to that of the MMSE estimator. \n \n \n \n \n \n \n \n \n \n A Fast Iterative Algorithm for Recovery of Sparse Signals from One-Bit Quantized Measurements \n \n Jun Fang , Yanning Shen , Hongbin Li \n \n \n \nThis paper considers the problem of reconstructing sparse or compressible signals from one-bit quantized measurements. We study a new method that uses a log-sum penalty function, also referred to as the Gaussian entropy, for sparse signal recovery. Also, in the proposed method, sigmoid functions are introduced to quantify the consistency between the acquired one-bit quantized data and the reconstructed measurements. A fast iterative algorithm is developed by iteratively minimizing a convex surrogate function that bounds the original objective function, which leads to an iterative reweighted process that alternates between estimating the sparse signal and refining the weights of the surrogate function. Connections between the proposed algorithm and other existing methods are discussed. Numerical results are provided to illustrate the effectiveness of the proposed algorithm. \n \n \n \n \n \n The performance of orthogonal multi-matching pursuit under RIP \n \n Zhiqiang Xu \n \n \n \nThe orthogonal multi-matching pursuit (OMMP) is a natural extension of orthogonal matching pursuit (OMP). We denote the OMMP with the parameter $M$ as OMMP(M) where $M\\geq 1$ is an integer. The main difference between OMP and OMMP(M) is that OMMP(M) selects $M$ atoms per iteration, while OMP only adds one atom to the optimal atom set. In this paper, we study the performance of orthogonal multi-matching pursuit (OMMP) under RIP. In particular, we show that, when the measurement matrix A satisfies $(9s, 1/10)$-RIP, there exists an absolutely constant $M_0\\leq 8$ so that OMMP(M_0) can recover $s$-sparse signal within $s$ iterations. We furthermore prove that, for slowly-decaying $s$-sparse signal, OMMP(M) can recover s-sparse signal within $O(\\frac{s}{M})$ iterations for a large class of $M$. In particular, for $M=s^a$ with $a\\in [0,1/2]$, OMMP(M) can recover slowly-decaying $s$-sparse signal within $O(s^{1-a})$ iterations. The result implies that OMMP can reduce the computational complexity heavily. \n \n \n \n Reconstruction of Arbitrary Biochemical Reaction Networks: A Compressive Sensing Approach by Wei Pan, Ye Yuan, Jorge Gonc\u00b8alves and Guy-Bart Stan \n \n \n \nAbstract\u2014 Reconstruction of biochemical reaction networks (BRN) and genetic regulatory networks (GRN) in particular is a central topic in systems biology which raises crucial theoretical challenges in system identi\ufb01cation. Nonlinear Ordinary Differential Equations (ODEs) that involve polynomial and rational functions are typically used to model biochemical reaction networks. Such nonlinear models make the problem of determining the connectivity of biochemical networks from time-series experimental data quite dif\ufb01cult. In this paper, we present a network reconstruction algorithm that can deal with ODE model descriptions containing polynomial and rational functions. Rather than identifying the parameters of linear or \n \nnonlinear ODEs characterised by pre-de\ufb01ned equation structures, our methodology allows us to determine the nonlinear ODEs structure together with their associated parameters. To solve the network reconstruction problem, we cast it as a compressive sensing (CS) problem and use sparse Bayesian learning (SBL) algorithms as a computationally ef\ufb01cient and robust way to obtain its solution. \n \n \n \n \n Sparse Stochastic Processes and Discretization of Linear Inverse Problems \n \n Emrah Bostan , Ulugbek S. Kamilov , Masih Nilchian , Michael Unser \n \n \n \nWe present a novel statistically-based discretization paradigm and derive a class of maximum a posteriori (MAP) estimators for solving ill-conditioned linear inverse problems. We are guided by the theory of sparse stochastic processes, which specifies continuous-domain signals as solutions of linear stochastic differential equations. Accordingly, we show that the class of admissible priors for the discretized version of the signal is confined to the family of infinitely divisible distributions. Our estimators not only cover the well-studied methods of Tikhonov and $\\ell_1$-type regularizations as particular cases, but also open the door to a broader class of sparsity-promoting regularization schemes that are typically nonconvex. We provide an algorithm that handles the corresponding nonconvex problems and illustrate the use of our formalism by applying it to deconvolution, MRI, and X-ray tomographic reconstruction problems. Finally, we compare the performance of estimators associated with models of increasing sparsity. \n \n \n \n Calibrationless Parallel Imaging Reconstruction Based on Structured Low-Rank Matrix Completion by Peter J. Shin, Peder E.Z. Larson, Michael A. Ohliger, Michael Elad, John M. Pauly, Daniel B. Vigneron, Michael Lustig \n \n \n \nA calibrationless parallel imaging reconstruction method, termed simultaneous autocalibrating and k-space estimation (SAK\u00c9), is presented. It is a data-driven, coil-by-coil reconstruction method that does not require fully sampled calibrating signals. In SAK\u00c9, an under-sampled multi-channel dataset is structured into a single matrix and data reconstruction is formulated as a structured low-rank matrix completion problem. An iterative solution that implements a projection-onto-sets algorithm with singular value hard-thresholding is described. Reconstruction results are demonstrated for undersampled, multi-channel Cartesian and non-Cartesian data with no calibration data. These exhibit excellent image quality comparable to those obtained with calibration data. Finally, improved image quality is demonstrated by combining SAK\u00c9 with waveletbased compressed sensing. This method could benefit MR applications where acquiring accurate calibration data is limiting or not possible at all. \n \n \n \n \n \n 1-bit Compressed Sensing with Edge Detection for Compressed Radio Wave Data Transfer \n \nTakayuki Yamada, Doohwan Lee, Hideki Toshinaga, Kazunori Akabane, Yo Yamaguchi, and Kazuhiro Uehara \n \n \n \nAbstract\u2014The \u201cFlexible Wireless System (FWS)\u201d has been proposed as a networked system for the \u201cUser-Centric Wireless Network (UCWN)\u201d. The UCWN will allow users to make network connections easily at all times without being conscious of any upgrades or differences in wireless systems. The FWS is a unified wireless platform that simultaneously deals with various types of wireless signals. It consists of flexible access points and a wireless signal processing platform. Various types of wireless signals are received at a distributed flexible access point and transferred to a server in the wireless signal processing platform through the wired access line. Transferred signals are separated and demodulated at the server. To achieve highly flexible and efficient radio wave data transfer between the access point and the FWS server, we consider compression of transfer data. In this paper, we propose 1-bit compressed sensing with smoothed edge detection, which enhances compression and reconstruction performance. This paper shows the performance of the proposed method by using computer simulations to explore the method\u2019s validity for transferring compressed radio wave data. \n \n \n \n Sparse Learning via Maximum Margin Matrix Factorization \n \n Dong Xia \n \n \n \nIn this paper, an algorithm for sparse learning via Maximum Margin Matrix Factorization(MMMF) is proposed. The algorithm is based on L1 penality and Alternating Direction Method of Multipliers. It shows that with sparse factors, sparse factors method can obtain result as good as dense factors. \n \n \n \n \n \n Matrix Factorization and Matrix Concentration \n \nLester Mackey \n \n \n \nMotivated by the constrained factorization problems of sparse principal components analysis (PCA) for gene expression modeling, low-rank matrix completion for recommender systems, and robust matrix factorization for video surveillance, this dissertation explores the modeling, methodology, and theory of matrix factorization. We begin by exposing the theoretical and empirical shortcomings of standard deflation techniques for sparse PCA and developing alternative methodology more suitable for deflation with sparse \u201cpseudo-eigenvectors.\u201d We then explicitly reformulate the sparse PCA optimization problem and derive a generalized deflation procedure that typically outperforms more standard techniques on real-world datasets. We next develop a fully Bayesian matrix completion framework for integrating the complementary approaches of discrete mixed membership modeling and continuous matrix factorization. We introduce two Mixed Membership Matrix Factorization (M3F) models, develop highly parallelizable Gibbs sampling inference procedures, and find that M3F is both more parsimonious and more accurate than state-of-the-art baselines on real-world collaborative filtering datasets. Our third contribution is Divide-Factor-Combine (DFC), a parallel divide-and-conquer framework for boosting the scalability of a matrix completion or robust matrix factorization algorithm while retaining its theoretical guarantees. Our experiments demonstrate the near-linear to super-linear speed-ups attainable with this approach, and our analysis shows that DFC enjoys high-probability recovery guarantees comparable to those of its base algorithm. Finally, inspired by the analyses of matrix completion and randomized factorization procedures, we show how Stein\u2019s method of exchangeable pairs can be used to derive concentration inequalities for matrix-valued random elements. As an immediate consequence, we obtain analogues of classical moment inequalities and exponential tail inequalities for independent and dependent sums of random matrices. We moreover derive comparable concentration inequalities for self-bounding matrix functions of dependent random elements. \n \n \n \n Improving Smoothed l0 Norm in Compressive Sensing Using Adaptive Parameter Selection \n \n Christian Schou Oxvig , Patrick Steffen Pedersen , Thomas Arildsen , Torben Larsen \n \n \n \nSignal reconstruction in compressive sensing involves finding a sparse solution that satisfies a set of linear constraints. Several approaches to this problem have been considered in existing reconstruction algorithms. They each provide a trade-off between reconstruction capabilities and required computation time. In an attempt to push the limits for this trade-off, we consider a smoothed l0 norm (SL0) algorithm in a noiseless setup. We argue that using a set of carefully chosen parameters in our proposed adaptive SL0 algorithm may result in significantly better reconstruction capabilities in terms of phase transition while retaining the same required computation time as existing SL0 algorithms. A large set of simulations further support this claim. Simulations even reveal that the theoretical l1 curve may be surpassed in major parts of the phase space. \n \n \n \n \n \n Power-efficient Hierarchical Data Aggregation using Compressive Sensing in WSN \n \n Xi Xu , Rashid Ansari , Ashfaq Khokhar \n \n \n \nCompressive Sensing (CS) method is a burgeoning technique being applied to diverse areas including wireless sensor networks (WSNs). In WSNs, it has been studied in the context of data gathering and aggregation, particularly aimed at reducing data transmission cost and improving power efficiency. Existing CS based data gathering work in WSNs assume fixed and uniform compression threshold across the network, regard- less of the data field characteristics. In this paper, we present a novel data aggregation architecture model that combines a multi- resolution structure with compressed sensing. The compression thresholds vary over the aggregation hierarchy, reflecting the underlying data field. Compared with previous relevant work, the proposed model shows its significant energy saving from theoretical analysis. We have also implemented the proposed CS- based data aggregation framework on a SIDnet SWANS platform, discrete event simulator commonly used for WSN simulations. Our experiments show substantial energy savings, ranging from 37% to 77% for different nodes in the networking depending on the position of hierarchy. \n \n \n \n \n \n \n \n \n \n \n \n \n \n Proximal Splitting Derivatives for Risk Estimation \n \n \n \n Charles Deledalle , Samuel Vaiter , Gabriel Peyr\u00e9 , Jalal Fadili , Charles Dossal \n \n \n \n \n \nThis paper develops a novel framework to compute a projected Generalized Stein Unbiased Risk Estimator (GSURE) for a wide class of sparsely regularized solutions of inverse problems. This class includes arbitrary convex data fidelities with both analysis and synthesis mixed L1-L2 norms. The GSURE necessitates to compute the (weak) derivative of a solution w.r.t.~the observations. However, as the solution is not available in analytical form but rather through iterative schemes such as proximal splitting, we propose to iteratively compute the GSURE by differentiating the sequence of iterates. This provides us with a sequence of differential mappings, which, hopefully, converge to the desired derivative and allows to compute the GSURE. We illustrate this approach on total variation regularization with Gaussian noise and to sparse regularization with poisson noise, to automatically select the regularization parameter. \n \n \n \n \n \n \n \n \n \n \n \n Learning Locality-Constrained Collaborative Representation for Face Recognition \n \n Peng Xi , Zhang Lei , Zhang Yi , Kok Kiong Tan \n \n \n \nThe model of low-dimensional manifold and sparse representation are two well-known concise models that suggest each data can be described by a few characteristics. Manifold learning is usually investigated for dimension reduction by preserving some expected local geometric structures from original space to low-dimensional space. The structures are generally determined by using pairwise distance, e.g., Euclidean distance. Alternatively, sparse representation denotes a data point as a linear combination of the points from the same subspace. In practical applications, however, the nearby points in terms of pairwise distance, may not belong to the same subspace, and vice versa. Consequently, it is interesting and important to explore how to get a better representation by integrating these two models together. To this end, this paper proposes a novel coding algorithm, called Locality-Constrained Collaborative Representation (LCCR), which improves the robustness and discrimination of data representation by incorporating the locality based on pairwise distance into coding process. In addition, the proposed objective function has an analytical solution, and it does not involve local minima. The empirical studies based on three public facial databases, ORL, AR and Extend Yale B, demonstrate that LCCR outperforms three state-of-the-art models, sparse representation based classification (SRC) \\cite{Wright2009}, $\\ell^2$-FR cite{Shi2011} and CRC-RLS \\cite{Zhang2011} in the context of recognizing human faces from frontal views with varying expression and illumination, as well as various corruptions and occlusions. \n \n \n \n \n \n Multistage Adaptive Estimation of Sparse Signals \n \n Dennis Wei , Alfred O. Hero III \n \n \n \nThis paper considers sequential adaptive estimation of sparse signals under a constraint on the total sensing effort. The advantage of adaptivity in this context is the ability to focus more resources on regions of space where signal components exist, thereby improving performance. A dynamic programming formulation is derived for the allocation of sensing effort to minimize the expected estimation loss. Based on the method of open-loop feedback control, allocation policies are then developed for a variety of loss functions. The policies are optimal in the two-stage case and improve monotonically thereafter with the number of stages. Numerical simulations show gains up to several dB as compared to recently proposed adaptive methods, and dramatic gains approaching the oracle limit compared to non-adaptive estimation. An application to radar imaging is also presented. \n \n \n \n Online computation of sparse representations of time varying stimuli using a biologically motivated neural network \n \n Tao Hu , Dmitri B. Chklovskii \n \n \n \nNatural stimuli are highly redundant, possessing significant spatial and temporal correlations. While sparse coding has been proposed as an efficient strategy employed by neural systems to encode sensory stimuli, the underlying mechanisms are still not well understood. Most previous approaches model the neural dynamics by the sparse representation dictionary itself and compute the representation coefficients offline. In reality, faced with the challenge of constantly changing stimuli, neurons must compute the sparse representations dynamically in an online fashion. Here, we describe a leaky linearized Bregman iteration (LLBI) algorithm which computes the time varying sparse representations using a biologically motivated network of leaky rectifying neurons. Compared to previous attempt of dynamic sparse coding, LLBI exploits the temporal correlation of stimuli and demonstrate better performance both in representation error and the smoothness of temporal evolution of sparse coefficients. \n \n \n \n \n \n Joint Sparsity with Different Measurement Matrices \n \n Reinhard Heckel , Helmut B\u00f6lcskei \n \n \n \nWe consider a generalization of the multiple measurement vector (MMV) problem, where the measurement matrices are allowed to differ across measurements. This problem arises naturally when multiple measurements are taken over time, e.g., and the measurement modality (matrix) is time-varying. We derive probabilistic recovery guarantees showing that---under certain (mild) conditions on the measurement matrices---l2/l1-norm minimization and a variant of orthogonal matching pursuit fail with a probability that decays exponentially in the number of measurements. This allows us to conclude that, perhaps surprisingly, recovery performance does not suffer from the individual measurements being taken through different measurement matrices. What is more, recovery performance typically benefits (significantly) from diversity in the measurement matrices; we specify conditions under which such improvements are obtained. These results continue to hold when the measurements are subject to (bounded) noise. \n \n \n \n Degrees of Freedom in Vector Interference Channels \n \n David Stotz , Helmut B\u00f6lcskei \n \n \n \nThis paper continues the Wu-Shamai-Verd\\'u program [1] on characterizing the degrees of freedom (DoF) of interference channels (ICs) through R\\'enyi information dimension. Concretely, we find a general formula for the DoF of vector ICs, encompassing multiple-input multiple-output (MIMO) ICs, time- and/or frequency-selective ICs, and combinations thereof, as well as constant single-antenna ICs considered in [1]. As in the case of constant single-antenna ICs, achieving full DoF requires the use of singular input distributions. Strikingly, in the vector case it suffices to enforce singularity on the joint distribution of individual transmit vectors. This can be realized through signaling in subspaces of the ambient signal space, which is in accordance with the idea of interference alignment, and, most importantly, allows the scalar components of the transmit vectors to have non-singular distributions. We recover the result by Cadambe and Jafar on the non-separability of parallel ICs [2] and we show that almost all parallel ICs are separable. Finally, our results extend the main finding in [1] to the complex case. \n \n \n \n A network of spiking neurons for computing sparse representations in an energy efficient way \n \n Tao Hu , Alexander Genkin , Dmitri B. Chklovskii \n \n \n \nComputing sparse redundant representations is an important problem both in applied mathematics and neuroscience. In many applications, this problem must be solved in an energy efficient way. Here, we propose a hybrid distributed algorithm (HDA), which solves this problem on a network of simple nodes communicating via low-bandwidth channels. HDA nodes perform both gradient-descent-like steps on analog internal variables and coordinate-descent-like steps via quantized external variables communicated to each other. Interestingly, such operation is equivalent to a network of integrate-and-fire neurons, suggesting that HDA may serve as a model of neural computation. We show that the numerical performance of HDA is on par with existing algorithms. In the asymptotic regime the representation error of HDA decays with time, t, as 1/t. HDA is stable against time-varying noise, specifically, the representation error decays as 1/sqrt(t) for Gaussian white noise. \n \n \n \n \n \n A Compressive Sensing Approach for Secret Key Agreement Based on UWB Channel Reciprocity \n \n Ghasem Naddafzadeh Shirazi, and Lutz Lampe \n \n \n \nAbstract\u2014We present a compressive sensing (CS) approach for secret key agreement based on UWB channel reciprocity. More generally, we show that the CS problem can be used for solving the distributed source coding problem. We also show that the proposed CS-based secret key agreement protocol (CS-SKAP) provides perfect secrecy, a better key agreement probability, and sometimes a longer secret key length, compared to the traditional syndrome-based distributed source coding techniques. \n \n \n \n \n \n Compressive imaging: stable and robust recovery from variable density frequency samples \n \nFelix Krahmer and Rachel Ward \n \n \n \nTo date, the theory for compressive sampling with frequency measurements has only been developed for bases that, like the canonical or `pixel' basis, are incoherent with the Fourier basis. In many applications, such as Magnetic Resonance Imaging (MRI) or inverse scattering, one instead acquires images that are sparse in transform domains such as spatial nite di erences or wavelets which are not incoherent with the Fourier basis. For these applications, overwhelming empirical evidence and heuristic arguments have suggested that superior image reconstruction can be obtained through certain variable density sampling strategies which concentrate on lower frequencies. Here we fortify these empirical studies with theoretical reconstruction guarantees, showing that sampling frequencies according to suitable power-law densities enables image reconstructions that are stable to sparsity defects and robust to measurement noise. Our results hinge on proving that the coherence between the Fourier and Haar wavelet basis is su ciently concentrated on low frequencies that an incoherent preconditioned system results by resampling the Fourier basis appropriately. \n \n \n \n A proximity algorithm solving indicator functions based l1-norm minimization problems in compressive sampling by Feishe Chen (current student), Lixin Shen, Bruce W. Suter, and Yuesheng Xu \n \n \n \nAbstract: An accurate and efficient algorithm for an l1-norm minimization problem is highly needed and is crucial for the success of sparse signal recovery in compressive sampling, a recent development in the field of data analysis. Most of existing algorithms in the literature give an approximated solution to the problem. We tackle the \u21131-norm minimization problem by equivalently reformulating it via an indicator function which describes the constraints for the problem. It turns out that the resulting model can be solved efficiently and accurately by using an elegant proximity operator based algorithm. We establish the convergence analysis of the resulting algorithm. Numerical experiments show that the proposed algorithm performs well for sparse signals with magnitudes over a high dynamic range. Furthermore, it performs significantly better than the well-known algorithm NESTA in terms of the quality of restored signals and the computational complexity measured in the CPU-time consumed. \n \n \n \n Preconditioning of the fluorescence diffuse optical tomography sensing matrix based on compressive sensing \n \n An Jin , Birsen Yazici , Angelique Ale , and Vasilis Ntziachristos \n \n \n \nImage reconstruction in fluorescence diffuse optical tomography (FDOT) is a highly ill-posed inverse problem due to a large number of unknowns and limited measurements. In FDOT, the fluorophore distribution is often sparse in the imaging domain, since most fluorophores are designed to accumulate in relatively small regions. Compressive sensing theory has shown that sparse signals can be recovered exactly from only a small number of measurements when the forward sensing matrix is sufficiently incoherent. In this Letter, we present a method of preconditioning the FDOT forward matrix to reduce its coherence. The reconstruction results using real data obtained from a phantom experiment show visual and quantitative improvements due to preconditioning in conjunction with convex relaxation and greedy-type sparse signal recovery algorithms. \n \n \n \n VARIANTES SUR UN TH\u00c9OR\u00c8ME DE CAND\u00c8S, ROMBERG ET TAO \n \n Jean-Pierre Kahane \n \n \n \nVariations on a theorem of Cand\u00e8s, Romberg and Tao The CRT theorem reconstructs a signal from a sparse set of frequencies, a paradigm of Compressed sensing. The signal is assumed to be carried by a small number of points, s , in a large cyclic set, of order N ; the frequencies consist of C s log N points chosen randomly in Z/N Z ; the reconstruction is based on a minimal extrapolation in the Wiener algebra of Z/N Z of the restriction of the Fourier transform of the signal to the chosen set of frequencies. The probability of reconstructing the signal is nearly 1 when C is large. The statement should be modified when we want all signals carried by s points to be reconstructed in that way. The CRT approach is based on random matrices, here the approach is classical Fourier analysis. \n \n \n \n \n \n Accelerated aortic flow assessment with compressed sensing with and without use of the sparsity of the complex difference image \n \nYongjun Kwak, Seunghoon Nam, Mehmet Ak\u00e7akaya, Tamer A. Basha, Beth Goddu, Warren J. Manningm Vahid Tarokh, Reza Nezafat \n \n \n \nPhase contrast (PC) cardiac MR is widely used for the clinical assessment of blood flow in cardiovascular disease. One of the challenges of PC cardiac MR is the long scan time which limits both spatial and temporal resolution. Compressed sensing reconstruction with accelerated PC acquisitions is a promising technique to increase the scan efficiency. In this study, we sought to use the sparsity of the complex difference of the two flow-encoded images as an additional constraint term to improve the compressed sensing reconstruction of the corresponding accelerated PC data acquisition. Using retrospectively under-sampled data, the proposed reconstruction technique was optimized and validated in vivo on 15 healthy subjects. Then, prospectively under-sampled data was acquired on 11 healthy subjects and reconstructed with the proposed technique. The results show that there is good agreement between the cardiac output measurements from the fully sampled data and the proposed compressed sensing reconstruction method using complex difference sparsity up to acceleration rate 5. In conclusion, we have developed and evaluated an improved reconstruction technique for accelerated PC cardiac MR that uses the sparsity of the complex difference of the two flow-encoded images \n \n \n \n \n \n Location Constrained Approximate Message Passing (LCAMP) Algorithm for Compressed Sensing by K. Sung, B. L. Daniel, and B. A. Hargreaves \n \n \n \nIntroduction: Fast iterative thresholding methods [1,2] have been extensively studied as alternatives to convex optimization for high-dimensional large-sized problems in compressed sensing (CS) [3]. A common large-sized problem is dynamic contrast enhanced (DCE) MRI, where the dynamic measurements possess data redundancies that can be used to estimate non-zero signal locations. In this work, we present a novel iterative thresholding method called LCAMP (Location Constrained Approximate Message Passing) that combines a non-zero location assumption and an approximate message passing term to previous methods [4]. The method can reduce computational complexity and improve reconstruction accuracy. We demonstrate the proposed reconstruction using 4D breast DCE MRI data, of a size that is often challenging for constrained reconstructions. \n \n \n \n \n \n Sequential Group Testing with Graph Constraints \n \n Karbasi, Amin ; Zadimoghaddam, Morteza \n \n \n \nIn conventional group testing, the goal is to detect a small subset of defecting items D in a large population N by grouping \\textit{arbitrary} subset of N into different pools. The result of each group test T is a binary output depending on whether the group contains a defective item or not. The main challenge is to minimize the number of pools required to identify the set D. Motivated by applications in network monitoring and infection propagation, we consider the problem of group testing with graph constraints. As opposed to conventional group testing where \\textit{any} subset of items can be pooled, here a test is admissible if it induces a connected subgraph H\u2282G. In contrast to the non-adaptive pooling process used in previous work, we first show that by exploiting an adaptive strategy, one can dramatically reduce the number of tests. More specifically, for \\textit{any} graph G, we devise a 2-approximation algorithm (and hence order optimal) that locates the set of defective items D. To obtain a good compromise between adaptive and non-adaptive strategies, we then devise a multi-stage algorithm. In particular, we show that if the set of defective items are uniformly distributed, then an l-stage pooling strategy can identify the defective set in O(l\u22c5|D|\u22c5|N|1/l) tests, on the average. In particular, for l=log(|N|) stages, the number of tests reduces to 4|D|log(|N|), which in turn is order optimum. \n \n \n \n \n \n Online `1-Dictionary Learning with Application to Novel Document Detection Shiva Prasad Kasiviswanathan, Huahua Wang, Arindam Banerjee, Prem Melville \n \n \n \n Abstract Given their pervasive use, social media, such as Twitter, have become a leading source of breaking news. A key task in the automated identi\ufb01cation of such news is the detection of novel documents from a voluminous stream of text documents in a scalable manner. Motivated by this challenge, we introduce the problem of online `1-dictionary learning where unlike traditional dictionary learning, which uses squared loss, the `1-penalty is used for measuring the reconstruction error. We present an ef\ufb01cient online algorithm for this problem based on alternating directions method of multipliers, and establish a sublinear regret bound for this algorithm. Empirical results on news-stream and Twitter data, shows that this online `1-dictionary learning algorithm for novel document detection gives more than an order of magnitude speedup over the previously known batch algorithm, without any signi\ufb01cant loss in quality of results. Our algorithm for online `1- dictionary learning could be of independent interest. Robust Doppler radar demodulation via compressed sensing W. Xu , C. Gu, C. Li and M. Sarrafzadeh The microwave Doppler radar sensor enables a non-contact approach for measuring movement in various applications. One of the most challenging issues is radar signal demodulation because it requires accurate DC offset compensation. Existing works either request a complicated setup procedure or are sensitive to environmental changes. In this letter, we discuss a compressed sensing based approach to effectively demodulate radar signals. Through \u21131 minimization, the proposed method can reliably demodulate noisy signals with large measurement residuals. To validate the algorithm, we run three sets of experiments to evaluate the demodulation performance. Experimental results show that our proposed method is promising in both simulation and real-case studies. \n \n \n \n Quick Search for Rare Events \n \n Ali Tajer , H. Vincent Poor \n \n \n \nRare events can potentially occur in many applications. When manifested as opportunities to be exploited, risks to be ameliorated, or certain features to be extracted, such events become of paramount significance. Due to their sporadic nature, the information-bearing signals associated with rare events often lie in a large set of irrelevant signals and are not easily accessible. This paper provides a statistical framework for detecting such events so that an optimal balance between detection reliability and agility, as two opposing performance measures, is established. The core component of this framework is a sampling procedure that adaptively and quickly focuses the information-gathering resources on the segments of the dataset that bear the information pertinent to the rare events. Particular focus is placed on Gaussian signals with the aim of detecting signals with rare mean and variance values. \n \n \n \n Large-field-of-view Chip-scale Talbot-grid-based Fluorescence Microscopy \n \n Shuo Pang , Chao Han , Mihoko Kato , Paul W. Sternberg , Changhuei Yang \n \n \n \nThe fluorescence microscope is one of the most important tools in modern clinical diagnosis and biological science. However, its expense, size and limited field-of-view (FOV) are becoming bottlenecks in key applications such as large-scale phenotyping and low-resource-setting diagnostics. Here we report a low-cost, compact chip-scale fluorescence-imaging platform, termed the Fluorescence Talbot Microscopy (FTM), which utilizes the Talbot self-imaging effect to enable efficient fluorescence imaging over a large and directly-scalable FOV. The FTM prototype has a resolution of 1.2 microns and an FOV of 3.9 mm x 3.5 mm. We demonstrate the imaging capability of FTM on fluorescently labeled breast cancer cells (SK-BR-3) and HEK cells expressing green fluorescent protein. \n \n \n \n \n \n Level Set Estimation from Compressive Measurements using Box Constrained Total Variation Regularization \n \n Akshay Soni , Jarvis Haupt \n \n \n \nEstimating the level set of a signal from measurements is a task that arises in a variety of fields, including medical imaging, astronomy, and digital elevation mapping. Motivated by scenarios where accurate and complete measurements of the signal may not available, we examine here a simple procedure for estimating the level set of a signal from highly incomplete measurements, which may additionally be corrupted by additive noise. The proposed procedure is based on box-constrained Total Variation (TV) regularization. We demonstrate the performance of our approach, relative to existing state-of-the-art techniques for level set estimation from compressive measurements, via several simulation examples. \n \n \n \n \n \n \n \n New Generalizations of the Bethe Approximation via Asymptotic Expansion \n \n Ryuhei Mori , Toshiyuki Tanaka \n \n \n \nThe Bethe approximation, discovered in statistical physics, gives an efficient algorithm called belief propagation (BP) for approximating a partition function. BP empirically gives an accurate approximation for many problems, e.g., low-density parity-check codes, compressed sensing, etc. Recently, Vontobel gives a novel characterization of the Bethe approximation using graph cover. In this paper, a new approximation based on the Bethe approximation is proposed. The new approximation is derived from Vontobel's characterization using graph cover, and expressed by using the edge zeta function, which is related with the Hessian of the Bethe free energy as shown by Watanabe and Fukumizu. On some conditions, it is proved that the new approximation is asymptotically better than the Bethe approximation. \n \n \n \n \n \n Deconvolving Images with Unknown Boundaries Using the Alternating Direction Method of Multipliers \n \n Mariana S. C. Almeida , M\u00e1rio A. T. Figueiredo \n \n \n \nThe alternating direction method of multipliers (ADMM) has sparked recent interest as an efficient optimization tool for solving imaging inverse problems, such as deconvolution and reconstruction. ADMM-based approaches achieve state-of-the-art speed, by adopting a divide and conquer strategy that splits a hard problem into simpler, efficiently solvable sub-problems (e.g., using fast Fourier or wavelet transforms, or proximity operators with low computational cost). In deconvolution problems, one of these sub-problems involves a matrix inversion (i.e., solving a linear system), which can be performed efficiently (in the discrete Fourier domain) if the observation operator is circulant, that is, under periodic boundary conditions. This paper proposes an ADMM approach for image deconvolution in the more realistic scenario of unknown boundary conditions. To estimate the image and its unknown boundary, we model the observation operator as a composition of a cyclic convolution with a spatial mask that excludes those pixels where the cyclic convolution is invalid, i.e., the unknown boundary. The proposed method can also handle, at no additional cost, problems that combine inpating (recovery of missing pixels) and deblurring. We show that the resulting algorithm inherits the convergence guarantees of ADMM and illustrate its state-of-the-art performance on non-cyclic deblurring (with and without inpainting of interior pixels) under total-variation (TV) regularization. \n \n \n \n \n \n Total variation minimization for stable multidimensional signal recovery \n \n Deanna Needell , Rachel Ward \n \n \n \nConsider the problem of reconstructing a multidimensional signal from partial information. Without any additional assumptions, this problem is ill-posed. However, for signals such as natural images or movies, the minimal total variation estimate consistent with the measurements often produces a good approximation to the underlying signal, even if the number of measurements is far smaller than the ambient dimensionality. While reconstruction guarantees and optimal measurement designs have been established for related L1-minimization problems, the theory for total variation minimization has remained elusive until recently, when guarantees for two-dimensional images were established. This paper extends the recent theoretical results to signals of arbitrary dimension d>1. To be precise, we show that a multidimensional signal can be reconstructed from O(sd log(N^d)) linear measurements using total variation minimization to within a factor of the best s-term approximation of its gradient. The reconstruction guarantees we provide are necessarily optimal up to polynomial factors in the spatial dimension $d$ and a logarithmic factor in the signal dimension N^d. The proof relies on bounds in approximation theory concerning the compressibility of wavelet expansions of bounded-variation functions. \n \n \n \n \n \n Enhanced Compressed Sensing Recovery with Level Set Normals \n \n Virginia Estellers , Jean-Philippe Thiran , Xavier Bresson \n \n \n \nWe propose a compressive sensing algorithm that exploits geometric properties of images to recover images of high quality from few measurements. The image reconstruction is done by iterating the two following steps: 1) estimation of normal vectors of the image level curves and 2) reconstruction of an image fitting the normal vectors, the compressed sensing measurements and the sparsity constraint. The proposed technique can naturally extend to non local operators and graphs to exploit the repetitive nature of textured images in order to recover fine detail structures. In both cases, the problem is reduced to a series of convex minimization problems that can be efficiently solved with a combination of variable splitting and augmented Lagrangian methods, leading to fast and easy-to-code algorithms. Extended experiments show a clear improvement over related state-of-the-art algorithms in the quality of the reconstructed images and the robustness of the proposed method to noise, different kind of images and reduced measurements. \n \n \n \n The Restricted Isometry Property for Random Block Diagonal Matrices \n \n Armin Eftekhari , Han Lun Yap , Christopher J. Rozell , Michael B. Wakin \n \n \n \nIn Compressive Sensing, the Restricted Isometry Property (RIP) ensures that robust recovery of sparse vectors is possible from noisy, undersampled measurements via computationally tractable algorithms. It is by now well-known that Gaussian (or, more generally, sub-Gaussian) random matrices satisfy the RIP under certain conditions on the number of measurements. Their use can be limited in practice, however, due to storage limitations, computational considerations, or the mismatch of such matrices with certain measurement architectures. These issues have recently motivated considerable effort towards studying the RIP for structured random matrices. In this paper, we study the RIP for block diagonal measurement matrices where each block on the main diagonal is itself a sub-Gaussian random matrix. Our main result states that such matrices can indeed satisfy the RIP but that the requisite number of measurements depends on certain properties of the basis in which the signals are sparse. In the best case, these matrices perform nearly as well as dense Gaussian random matrices, despite having many fewer nonzero entries. \n \n \n \n \n Distributed Matrix Completion \n \nChristina Te\ufb02ioudi, Faraz Makari, Rainer Gemulla \n \n \n \nAbstract\u2014We discuss parallel and distributed algorithms for large-scale matrix completion on problems with millions of rows, millions of columns, and billions of revealed entries. We focus on in-memory algorithms that run on a small cluster of commodity nodes; even very large problems can be handled effectively in such a setup. Our DALS, ASGD, and DSGD++ algorithms are novel variants of the popular alternating least squares and stochastic gradient descent algorithms; they exploit thread-level parallelism, in-memory processing, and asynchronous communication. We provide some guidance on the asymptotic performance of each algorithm and investigate the performance of both our algorithms and previously proposed MapReduce algorithms in large-scale experiments. We found that DSGD++ outperforms competing methods in terms of overall runtime, memory consumption, and scalability. Using DSGD++, we can factor a matrix with 10B entries on 16 compute nodes in around 40 minutes. \n \n \n \n \n \n Matrix Completion by Franz J. Kir\u00e1ly, Louis Theran, Ryota Tomioka \n \n \n \n \n Image Credit: NASA/JPL/Space Science Institute, Full-Res: W00076440.jpg W00076440.jpg was taken on October 18, 2012 and received on Earth October 19, 2012. The camera was pointing toward SATURN-RINGS at approximately 339,982 miles (547,148 kilometers) away, and the image was taken using the CL1 and CL2 filters. \n \n \n \n Join our Reddit Experiment , Join the CompressiveSensing subreddit and post there !  Liked this entry ? subscribe to Nuit Blanche's feed, there's more where that came from . You can also subscribe to Nuit Blanche by Email , explore the Big Picture in Compressive Sensing or the Matrix Factorization Jungle and join the conversations on compressive sensing , advanced matrix factorization and calibration issues on Linkedin."], "link": "http://nuit-blanche.blogspot.com/feeds/4618013207703000297/comments/default", "bloglinks": {}, "links": {"http://infoscience.epfl.ch/": 3, "http://www.edu.au/": 4, "https://sites.google.com/": 2, "http://onlinelibrary.wiley.com/": 1, "http://submissions.miracd.com/": 1, "http://www.mpg.de/": 2, "http://www.blogger.com/blog": 4, "http://www.carolineuhler.com/": 1, "http://www.ucla.edu/": 2, "http://people.gatech.edu/": 2, "http://www.ubc.ca/": 2, "http://www.reddit.com/": 2, "http://feedburner.google.com/": 1, "http://feeds.feedburner.com/blog": 1, "http://arxiv.org/": 103, "http://num.uni-goettingen.de/": 1, "http://people.duke.edu/": 2, "http://hal.archives-ouvertes.fr/": 8, "http://www.opticsinfobase.org/": 1, "http://www.linkedin.com/": 3, "http://www.ac.jp/": 1, "ftp://ftp.math.ucla.edu/pub/camreport/cam12-63.pdf": 1, "http://feedads.doubleclick.net/": 2, "http://www.ac.uk/": 9, "ftp://ftp.math.ucla.edu/pub/camreport/cam12-67.pdf": 1, "http://dobigeon.enseeiht.fr/": 2, "http://www.psu.edu/": 1, "http://saturn.nasa.gov/": 2, "http://www.berkeley.edu/": 3}, "blogtitle": "Nuit Blanche"}, {"content": ["Remi Gribonval just sent me the following: \n \n \n \n \nDear Igor, Would you mind sharing this call with the readers of Nuit Blanche ? All the best, Remi. \n Sure Remi , here it is: \n \n Dear colleagues, \n \nWe are seeking up to four new members of the community to join the international SPARS Steering Committee, as part of its renewal process. The SPARS Steering Committee was created during the SPARS 2009 workshop (Signal Processing with Adaptive/Sparse Representations) in St-Malo, France. Its main purpose is to provide a framework to manage forthcoming SPARS workshops. Members of the Steering Committee will be expected to: have an active interest in the field; have presented at and/or attended previous workshops; and contribute their experience and ideas for the benefit of the research community. The next meeting of the SPARS Steering Committee, including the newly elected members, will take place during SPARS 2013 (July 8-11 2013, EPFL, Lausanne, Switzerland. http://spars2013.epfl.ch/ ). If you wish to nominate yourself or a colleague, please send the following to me, Remi Gribonval ( remi.gribonval@inria.fr ), as attachments to an email (PDF preferred): (1) A statement of qualification for the nominee (up to 1 page, CV style) (2) A Letter of Support (up to 2 pages) Deadline for nominations:  Friday 9 November 2012 (midnight GMT/UTC) Best wishes, Remi Gribonval Chair, international SPARS steering committee -- R\u00e9mi GRIBONVAL, Directeur de Recherche Inria Projet METISS, IRISA Campus de Beaulieu 35042 Rennes cedex France E-mail: Remi.Gribonval@inria.fr WWW : http://www.irisa.fr/metiss/members/remi \n \n \n \n \n \n \n \n \n \n \n Join our Reddit Experiment , Join the CompressiveSensing subreddit and post there !  Liked this entry ? subscribe to Nuit Blanche's feed, there's more where that came from . You can also subscribe to Nuit Blanche by Email , explore the Big Picture in Compressive Sensing or the Matrix Factorization Jungle and join the conversations on compressive sensing , advanced matrix factorization and calibration issues on Linkedin."], "link": "http://nuit-blanche.blogspot.com/feeds/3846433420912317164/comments/default", "bloglinks": {}, "links": {"http://www.reddit.com/": 2, "http://feedburner.google.com/": 1, "http://spars2013.epfl.ch/": 1, "http://www.linkedin.com/": 3, "http://feedads.doubleclick.net/": 2, "http://www.irisa.fr/": 3, "http://feeds.feedburner.com/blog": 1, "https://sites.google.com/": 2}, "blogtitle": "Nuit Blanche"}, {"content": ["Matthieu just sent me the following: \n \n \n \n \n Dear Igor, \n \n \n \n I found a nice video about Open Access Publishing on PhdComics ( http://www.phdcomics.com/comics.php?n=1533 ). At the end, it provides a link to the 6th Open Access Week ( http://www.openaccessweek.org/ ), which is described as: \n \n \n \n \n \n I think it might be of interest for your Nuit Blanche readers following the Post Peer-Review discussion . \n \n \n \n Best Regards, \n \n \n \n A global event, now in its 6th year, promoting Open Access as a new norm in scholarship and research. \n \n \n \nMatthieu \n \n \n \n \nThe post peer-review discussion and open access certainly are dealing with similar issues. Open Access could enable enterprising minds to set up a post peer review process. However most current versions of open access journals currently still rely on pre-publication peer review which is the crux of the assumption we are questioning. In short, the value of a paper is not in the quality of the journal or the very few and possibility uninformed gate-keepers, it is about how that work stands the unrelenting scrutiny of time. Thanks Matthieu . \n \n \n \n \n \n Join our Reddit Experiment , Join the CompressiveSensing subreddit and post there !  Liked this entry ? subscribe to Nuit Blanche's feed, there's more where that came from . You can also subscribe to Nuit Blanche by Email , explore the Big Picture in Compressive Sensing or the Matrix Factorization Jungle and join the conversations on compressive sensing , advanced matrix factorization and calibration issues on Linkedin."], "link": "http://nuit-blanche.blogspot.com/feeds/1760694209201835819/comments/default", "bloglinks": {}, "links": {"http://www.reddit.com/": 2, "http://feedburner.google.com/": 1, "http://feeds.feedburner.com/blog": 1, "https://plus.google.com/": 1, "http://www.linkedin.com/": 3, "http://feedads.doubleclick.net/": 2, "http://www-lisic.univ-littoral.fr/": 2, "http://www.phdcomics.com/": 1, "https://sites.google.com/": 2, "http://www.openaccessweek.org/": 1, "http://nuit-blanche.blogspot.fr/": 1}, "blogtitle": "Nuit Blanche"}, {"content": ["Cristian Rojas just sent me the following: \n \n \n \n \nDear Igor, \n \n \n \nMy name is Cristian Rojas, and I am an assistant professor at KTH, Stockholm, Sweden. At the ACCESS Linnaeus Centre at KTH, we are announcing a postdoctoral position on sparsity related techniques, and we are looking for someone with experience on compressive sensing, sparse estimation methods or similar areas. As such, the call is quite broad. I hope you could help us to distribute this call. Please find it attached, and at the website: \n \n http://www.kth.se/en/om/work-at-kth/vacancies/postdoctoral-researcher-position-at-the-linnaeus-centre-access-1.342681 \n \nThank you very much. \n \nBest regards, \n \nCristian R. Rojas \n \nAssistant Professor \n \nAutomatic Control Lab and ACCESS Linnaeus Centre \n \nSchool of Electrical Engineering \n \nKTH - Royal Institute of Technology \n \nSE 100 44 Stockholm \n \nSweden \n \n \n \n \n \n \n \n \n \n Join our Reddit Experiment , Join the CompressiveSensing subreddit and post there ! \n Liked this entry ? subscribe to Nuit Blanche's feed, there's more where that came from . You can also subscribe to Nuit Blanche by Email , explore the Big Picture in Compressive Sensing or the Matrix Factorization Jungle and join the conversations on compressive sensing , advanced matrix factorization and calibration issues on Linkedin."], "link": "http://nuit-blanche.blogspot.com/feeds/1140055400165531666/comments/default", "bloglinks": {}, "links": {"http://www.reddit.com/": 2, "http://feedburner.google.com/": 1, "http://www.kth.se/": 2, "http://www.linkedin.com/": 3, "http://feedads.doubleclick.net/": 2, "http://feeds.feedburner.com/blog": 1, "https://sites.google.com/": 2}, "blogtitle": "Nuit Blanche"}, {"content": ["Remember the Eulerian Video Magnification for Revealing Subtle Changes in the World by Hao-Yu Wu, Michael Rubinstein , Eugene Shih, John Guttag , Fr\u00e9do Durand , William T. Freeman . I stumbled upon the page again this week. The abstract of the paper reads: \n \n \nOur goal is to reveal temporal variations in videos that are difficult or impossible to see with the naked eye and display them in an indicative manner. Our method, which we call Eulerian Video Magnification, takes a standard video sequence as input, and applies spatial decomposition, followed by temporal filtering to the frames. The resulting signal is then amplified to reveal hidden information. Using our method, we are able to visualize the flow of blood as it fills the face and also to amplify and reveal small motions. Our technique can run in real time to show phenomena occurring at temporal frequencies selected by the user. \n \n \nThe attendant code is here . \n \n \n \n \n \n \n \n \n \n \n \n \n Join our Reddit Experiment , Join the CompressiveSensing subreddit and post there !  Liked this entry ? subscribe to Nuit Blanche's feed, there's more where that came from . You can also subscribe to Nuit Blanche by Email , explore the Big Picture in Compressive Sensing or the Matrix Factorization Jungle and join the conversations on compressive sensing , advanced matrix factorization and calibration issues on Linkedin."], "link": "http://nuit-blanche.blogspot.com/feeds/1591461222592043252/comments/default", "bloglinks": {}, "links": {"http://www.reddit.com/": 2, "http://feedburner.google.com/": 1, "http://feeds.feedburner.com/blog": 1, "http://www.linkedin.com/": 3, "http://feedads.doubleclick.net/": 2, "http://people.mit.edu/": 6, "https://sites.google.com/": 2, "http://nuit-blanche.blogspot.com/": 1}, "blogtitle": "Nuit Blanche"}, {"content": ["Haim Avron let me kniow that \". .. most of the slides of the talks in the RandNLA workshop last Saturday are now posted on the workshop's website \". Thanks Haim . And also thanks to Christos Boutsidis , and Petros Drineas and Abhisek Kundu for their work in setting up the meeting and the page. It definitely bring some visibility to the subject. Here are the presentations and the link to each researcher's page (for more): \n \n \n Petros Drineas Welcome and Introduction ( slides ) \n Michael Mahoney , Tutorial: Theory (and Some Practice) of Randomized Algorithms for Matrices and Data ( slides , abstract ) \n Nick Harvey , Matrix Concentration and Sparsification ( slides , abstract ) \n Nikhil Srivastava , Graph Sparsification ( slides , abstract ) \n Ilse Ipsen , Randomly Sampling from Orthonormal Matrices: Coherence and Leverage Scores ( slides , abstract ) \n Haim Avron , Randomized Preconditioning ( slides , abstract ) \n Ioannis Koutis , Solving Laplacian Linear Equations: Theory and Practice ( slides , abstract ) \n Anastasios Zouzias , Randomized Gossip Algorithms for Solving Laplacian Systems ( slides , abstract ) \n Christos Boutsidis , Near-Optimal Column-Based Matrix Reconstruction ( slides , abstract ) \n David Woodruff , Low Rank Approximation and Regression in Input Sparsity Time ( slides , abstract ) \n Ben Recht , An Incomplete Survey of Matrix Completion ( slides , abstract ) \n \nCredit Images: NASA/ESA \n \n \n \n \n \n \n \n Join our Reddit Experiment , Join the CompressiveSensing subreddit and post there !  Liked this entry ? subscribe to Nuit Blanche's feed, there's more where that came from . You can also subscribe to Nuit Blanche by Email , explore the Big Picture in Compressive Sensing or the Matrix Factorization Jungle and join the conversations on compressive sensing , advanced matrix factorization and calibration issues on Linkedin."], "link": "http://nuit-blanche.blogspot.com/feeds/6216430309769837704/comments/default", "bloglinks": {}, "links": {"http://www.cmu.edu/": 1, "http://feedburner.google.com/": 1, "http://cs.stanford.edu/": 1, "http://www.toronto.edu/": 1, "http://www4.ncsu.edu/": 1, "http://pages.wisc.edu/": 1, "http://sohowww.nasa.gov/": 2, "http://feedads.doubleclick.net/": 2, "http://feeds.feedburner.com/blog": 1, "http://researcher.ibm.com/": 5, "http://www.yale.edu/": 1, "http://www.ibm.com/": 1, "https://sites.google.com/": 2, "http://www.reddit.com/": 2, "http://www.linkedin.com/": 3, "http://www.ubc.ca/": 1, "http://www.rpi.edu/": 26}, "blogtitle": "Nuit Blanche"}, {"content": ["I am still wrapping my head around that number: 1.5 million pageviews since 2010. What is the real reach out ? for all we know these pageviews could be the results of the Googlebot spider process hitting this site 1.5 million times. Here is a map of the delivery process for these 2317 blog entries \n \n \n More than 2000 potential readers are reached using different Feeds \n 440 potential readers by direct e-mail \n 543 followers on Twitter (all entries are announced there) \n 1835 members in the LinkedIn Group on CS \n 447 members in the LinkedIn Group on Advanced Matrix Factorization \n 39 subscribers to the experimental CompressiveSensing subreddit . \n \n \nWhat about the actual impact ? As in many areas, this is a difficult question, I don't think I have a good answer, but with regards to : \n \n \n Pageviews , one should expect a minimum of 100 pageviews per blog entry. For the maximum (outside of some outliers) one should expect about 500 pageviews. \n E-mail : this one is difficult as I have no way of tracking how many people clicked on particular items. At the very least, the blog entry received some 400 or so eyeball \n Feeds : According to feedburner, at any one time, 1/4th of the readers looked at a specific entry (that's about 500 ) \n Videos : the recent video by David Brady has gotten 72 viewers (a 40 minutes video) but from what I have seen, outside of some outliers, from 50 to 500 people can decide to watch a video as a result of being featured here. I have noted some statistics were being featured here actually provided a stepping stone to a much larger audience. Here is a list automatically compiled by YouTube of all the Youtube videos featured on Nuit Blanche . \n Code sharing : I am making a targeted effort at putting code implementations in a single entry in order to provide focus. It works, see Brian King's recent reaction in the comment section featuring his toolbox. \n \n \n \n \n \nUse of the blog: besides information downloading and sharing: Some folks are providing feedback: \n \n \n The blog itself has reached 53 Google +1s so far, while the Big Picture has 22 and the Advanced Matrix Factorization Page has 12 . \n One blog entry has reached 8 Google +1 \n This is the second time so far recently, that somebody has used the comment section to provide some anonymous peer review of a paper featured on the blog, I like it very much. \n \n \n \nLet's see how those stats will be different when we hit 2 million page views! \n \n \n \n \n \n \n \n \n \n \n \n \n Join our Reddit Experiment , Join the CompressiveSensing subreddit and post there !  Liked this entry ? subscribe to Nuit Blanche's feed, there's more where that came from . You can also subscribe to Nuit Blanche by Email , explore the Big Picture in Compressive Sensing or the Matrix Factorization Jungle and join the conversations on compressive sensing , advanced matrix factorization and calibration issues on Linkedin."], "link": "http://nuit-blanche.blogspot.com/feeds/6643266683018243476/comments/default", "bloglinks": {}, "links": {"http://www.reddit.com/": 3, "https://twitter.com/": 1, "http://feeds.feedburner.com/blog": 2, "http://www.linkedin.com/": 5, "http://feedads.doubleclick.net/": 2, "http://feedburner.google.com/": 1, "http://www.youtube.com/": 1, "https://sites.google.com/": 4, "http://2.blogspot.com/": 1, "http://nuit-blanche.blogspot.fr/": 1}, "blogtitle": "Nuit Blanche"}, {"content": ["If you think that I did not cover your stuff this month and want to be counted in the new Nuit Blanche in Review for October , please let me know. \n \n \n \nThis fall at Rice there is a new course CAAM 654: Sparse Optimization by Wotao Yin and: Ming Yan . I note their judicious use of Nuit Blanche as one of the links to use for students :-) It might also have been interesting to add both the Big Picture in Compressive Sensing and the Matrix Factorization Jungle Page . \n \n \n \nThere are some interesting discussions and questions on the LinkedIn Compressive Sesning Group right now. The group now boast more than 1830 members. The LinkedIn Matrix Factorization group has more than 444 members. \n \n \n \nThere was an interesting talk this past week at Columbia by the ever interesting Bill Freeman on Leaning Matrix Decomposition Structures . The talk given a year earlier has this abstract: \n \n \n \nMany widely used models in unsupervised learning can be viewed as matrix decompositions, where the input matrix is expressed as sums and products of matrices drawn from a few simple priors. We present a unifying framework for matrix decompositions in terms of a context-free grammar which generates a wide variety of structures through the compositional application of a few simple rules. We use our grammar to generically and efficiently infer latent components and estimate predictive likelihood for nearly 1000 structures using a small toolbox of reusable algorithms. Using best-first search over our grammar, we can automatically choose the decomposition structure from raw data by evaluating only a tiny fraction of all models. This gives a recipe for selecting model structure in unsupervised learning situations. The proposed method almost always finds the right structure for synthetic data and backs off gracefully to simpler models under heavy noise. It learns plausible structures for datasets as diverse as image patches, motion capture, 20 Questions, and U.S. Senate votes, all using exactly the same code. \n \nI am impatient to see when it comes out. \n \n \n \nFinally, I found this on the NA-Digest list: \n \n \n \n \n From: Haim Avron < haimav@us.ibm.com > \n \n Date: Fri, 19 Oct 2012 11:32:59 -0400 \n \n Subject: Postdoc Position, Randomized Numerical Linear Algebra, IBM \n \n \n \n The High Performance Computing for Analytics group within the Business Analytics and Mathematical Sciences Department at IBM's T.J. Watson Research Center is seeking a Post Doctoral Researcher to work on investigating and implementing randomized numerical linear algebra kernels for distributed computing platforms, with applications to machine learning problems. The candidate is expected to contribute to the development of new ideas and implementations, publish in top-tier journals, and file patent disclosures when appropriate. We are especially interested in candidates who have experience and strong interest in large-scale distributed data analysis with emphasis on linear algebra techniques. The successful candidate will work with an interdisciplinary team of researchers. The candidate must have strong programming capabilities, and have excellent verbal and written skills. Preference may be given to candidates with extensive knowledge of C/C++ along with MPI and multi-threaded programming. Knowledge of Python is a plus. PhD candidates in Computer Science or Mathematics are preferred. \n \n \n \n For more information on the requirements, and to apply, see: \n \n https://jobs3.netmedia1.com/cp/job_summary.jsp?job_id=RES-0526905 \n \n \n \n IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national \n \n origin, genetics, disability, age, or veteran status. \n \n \n \n \n This image was taken by Front Hazcam: Left A (FHAZ_LEFT_A) onboard NASA's Mars rover Curiosity on Sol 77 (2012-10-24 02:36:48 UTC) .  Image Credit: NASA/JPL-Caltech \n \n \n \n Join our Reddit Experiment , Join the CompressiveSensing subreddit and post there !  Liked this entry ? subscribe to Nuit Blanche's feed, there's more where that came from . You can also subscribe to Nuit Blanche by Email , explore the Big Picture in Compressive Sensing or the Matrix Factorization Jungle and join the conversations on compressive sensing , advanced matrix factorization and calibration issues on Linkedin."], "link": "http://nuit-blanche.blogspot.com/feeds/2559902722811857803/comments/default", "bloglinks": {}, "links": {"http://www.linkedin.com/": 5, "http://feedburner.google.com/": 1, "http://feeds.feedburner.com/blog": 1, "http://www.reddit.com/": 2, "http://www.netlib.org/": 1, "http://feedads.doubleclick.net/": 2, "http://www.rice.edu/": 4, "http://people.mit.edu/": 1, "https://sites.google.com/": 4, "http://columbiascience.tumblr.com/": 1, "http://www.mit.edu/": 1, "https://jobs3.netmedia1.com/": 1, "http://mars.nasa.gov/": 2, "http://nuit-blanche.blogspot.com/": 1}, "blogtitle": "Nuit Blanche"}, {"content": ["Just received this from Josh Trzasko \n \n \nHi Igor- \n \nI wanted to highlight some recent work by Emmanuel Candes, Carlos Sing-Long, and myself on unbiased risk estimates for singular value thresholding (SVT). Amongst other things, the models developed in this work can be used to automatically tune SVT-based denoising models for image series (e.g., cardiac MRI). The manuscript, code, and data needed to replicate all experiments can be found at: http://www-stat.stanford.edu/~candes/SURE/index.html . If you think this work would be of interest to the Nuit Blanche community, we'd appreciate it being featured. \n \nAll the best, \nJosh Trzasko \nMayo Clinic \nThanks Josh for the heads-up: \n \n \n \n \n \n \n \n \n \n \n Unbiased Risk Estimates for Singular Value Thresholding and Spectral Estimators by Emmanuel J. Candes , Carlos A. Sing-Long , Joshua D. Trzasko . The abstract reads: \n \n \n \n \n \n \nIn an increasing number of applications, it is of interest to recover an approximately low-rank data matrix from noisy observations. This paper develops an unbiased risk estimate\u2014holding in a Gaussian model\u2014for any spectral estimator obeying some mild regularity assumptions. In particular, we give an unbiased risk estimate formula for singular value thresholding (SVT), a popular estimation strategy which applies a soft-thresholding rule to the singular values of the noisy observations. Among other things, our formulas o\ufb00er a principled and automated way of selecting regularization parameters in a variety of problems. In particular, we demonstrate the utility of the unbiased risk estimation for SVT-based denoising of real clinical cardiac MRI series data. We also give new results concerning the di\ufb00erentiability of certain matrix-valued functions. \n \n \n \n Data and code are here. \n \n \n \n \n \n \n \n \n \n \n \n Join our Reddit Experiment , Join the CompressiveSensing subreddit and post there !  Liked this entry ? subscribe to Nuit Blanche's feed, there's more where that came from . You can also subscribe to Nuit Blanche by Email , explore the Big Picture in Compressive Sensing or the Matrix Factorization Jungle and join the conversations on compressive sensing , advanced matrix factorization and calibration issues on Linkedin."], "link": "http://nuit-blanche.blogspot.com/feeds/4333570912429740556/comments/default", "bloglinks": {}, "links": {"http://www.reddit.com/": 2, "http://feedburner.google.com/": 1, "http://feeds.feedburner.com/blog": 1, "http://www.linkedin.com/": 3, "http://feedads.doubleclick.net/": 2, "https://sites.google.com/": 2, "http://1.blogspot.com/": 1, "http://www.convexoptimization.com/": 2, "http://www-stat.stanford.edu/": 4, "http://www.researchgate.net/": 1}, "blogtitle": "Nuit Blanche"}, {"content": ["Found through a discussion on the LinkedIn Compressive Sensing group \n \n \n \n \n \n \n \n SCoBeP: Dense Image Registration using Sparse Coding and Belief Propagation by Nafise Barzigar , Amin mohammad Roozgard , Samuel Cheng , Pramode Verma . The abstract reads: \n \n \n \n \n \n \nImage registration as a basic task in image processing has been studied widely in the literature. It is an important preprocessing step in various applications such as medical imaging, super resolution, and remote sensing. In this paper, we proposed a novel dense registration method based on sparse coding and belief propagation. We used image blocks as features, and then we employed sparse coding to find a set of candidate points. To select optimum matches, belief propagation was subsequently applied on these candidate points. Experimental results show that the proposed approach is able to robustly register scenes and is competitive as compared to high accuracy optical flow [1], and SIFT flow [2]. \n \n \nThe implementation of SCoBeP is here . \n \n \n \n \n \n \n \n \n \n \n \n Join our Reddit Experiment , Join the CompressiveSensing subreddit and post there !  Liked this entry ? subscribe to Nuit Blanche's feed, there's more where that came from . You can also subscribe to Nuit Blanche by Email , explore the Big Picture in Compressive Sensing or the Matrix Factorization Jungle and join the conversations on compressive sensing , advanced matrix factorization and calibration issues on Linkedin."], "link": "http://nuit-blanche.blogspot.com/feeds/3530293399566936977/comments/default", "bloglinks": {}, "links": {"http://www.linkedin.com/": 4, "http://feedburner.google.com/": 1, "http://feeds.feedburner.com/blog": 1, "http://www.reddit.com/": 2, "http://scholar.google.com/": 1, "http://feedads.doubleclick.net/": 2, "http://1.blogspot.com/": 1, "https://sites.google.com/": 2, "http://students.ou.edu/": 2, "http://tulsagrad.ou.edu/": 3}, "blogtitle": "Nuit Blanche"}, {"content": ["I just came across these two jobs for students and these two interesting talks. \n \n \n Internship (France) STAGE Compressive Sensing (H/F) (1 poste), Employeur : Thales Syst\u00e8mes A\u00e9roport\u00e9s S.A. / Elancourt, Yvelines France | 22/10/2012 | R\u00e9f. 56204214 \n PhD position in MR image reconstruction - compressed sensing , Image Sciences Institute, University Medical Center Utrecht \n \n \nThe talks: \n \n \n@ Supelec (France) but also broadcast here . \n Structure Based Bayesian Sparse Reconstruction Speakers: Tareq Y. Al-Naffouri, KAUST, Saudi Arabia Date: Wednesday, October 31, 2012 - 14:00 to 15:00 Location: Council room of L2S (room B4.40), Sup\u00e9lec, campus of Gif-sur-Yvette, Sup\u00e9lec. \nAbstract: There has been increased interest in sparse signal reconstruction algorithms (commonly known as compressed sensing) due to their wide applicability in various fields. In this talk, we present a novel low complexity Bayesian approach to the estimation of sparse signals.  The approach jointly utilizes 1) the sparsity information of the desired signal 2) the a priori statistical information about the signal and noise and 3) the inherent structure in the sensing matrix to obtain near optimal Bayesian estimates. The proposed approach is able to deal with both Gaussian and non-Gaussian priors. The approach also exhibits relatively low complexity compared to the widely used convex relaxation methods as well as greedy matching pursuit techniques. The discussion will be illuminated with several signal processing applications including channel estimation in UWB, seismic deconvolution, and estimation and cancellation of noise/distortion. \n \n \n \n \n \n@ UBC, Stephan Wenger Talk - Visualization Of Astronomical Nebulae Via Distributed Multi-GPU Compressed Sensing Tomography , DATE: TUESDAY, OCTOBER 23, 2012 | 1:00PM - 2:30PM \n \n \n \n \nTitle: Visualization of Astronomical Nebulae via Distributed Multi-GPU Compressed Sensing Tomography \n \n \n \nAbstract: \n \n \n \n\"The 3D visualization of astronomical nebulae is a challenging problem since only a single 2D projection is observable from our fixed vantage point on Earth. We attempt to generate plausible and realistic looking volumetric visualizations via a tomographic approach that exploits the spherical or axial symmetry prevalent in some relevant types of nebulae.Different types of symmetry can be implemented by using different randomized distributions of virtual cameras. Our approach is based on an iterative compressed sensing reconstruction algorithm that we extend with support for position-dependent volumetric regularization and linear equality constraints. We present a distributed multi-GPU implementation that is capable of reconstructing high-resolution datasets from arbitrary projections. Its robustness and scalability are demonstrated for astronomical imagery from the Hubble Space Telescope. The resulting volumetric data is visualized using direct volume rendering. Compared to previous approaches, our method preserves a much higher amount of detail and visual variety in the 3D visualization, especially for objects with only approximate symmetry.\" \n \n \n \n \n \n \n \n Join our Reddit Experiment , Join the CompressiveSensing subreddit and post there !  Liked this entry ? subscribe to Nuit Blanche's feed, there's more where that came from . You can also subscribe to Nuit Blanche by Email , explore the Big Picture in Compressive Sensing or the Matrix Factorization Jungle and join the conversations on compressive sensing , advanced matrix factorization and calibration issues on Linkedin."], "link": "http://nuit-blanche.blogspot.com/feeds/8539737553502710015/comments/default", "bloglinks": {}, "links": {"http://www.reddit.com/": 2, "http://feedburner.google.com/": 1, "http://feeds.feedburner.com/blog": 1, "http://www.linkedin.com/": 3, "http://feedads.doubleclick.net/": 2, "https://www.ubc.ca/": 1, "http://jobs-stages.letudiant.fr/": 1, "http://www.flexible-radio.com/": 1, "http://www.ximinds.com/": 1, "https://sites.google.com/": 2, "http://www.benelux-ismrm.org/": 1}, "blogtitle": "Nuit Blanche"}, {"content": ["Yves Wiaux mentioned to me that the abstract submission deadline for the BASP workshop has been extended until 26 October ( http://baspfrontiers.epfl.ch ) and that a few places are left for the sparsity workshop of the winter. Yves also tells me that nobody from the genomics/computational biology fields has shown up yet. \n \n \n \n \n \n \n \n Join our Reddit Experiment , Join the CompressiveSensing subreddit and post there !  Liked this entry ? subscribe to Nuit Blanche's feed, there's more where that came from . You can also subscribe to Nuit Blanche by Email , explore the Big Picture in Compressive Sensing or the Matrix Factorization Jungle and join the conversations on compressive sensing , advanced matrix factorization and calibration issues on Linkedin."], "link": "http://nuit-blanche.blogspot.com/feeds/2446753372968393838/comments/default", "bloglinks": {}, "links": {"http://www.reddit.com/": 2, "http://feedburner.google.com/": 1, "http://feeds.feedburner.com/blog": 1, "http://www.linkedin.com/": 3, "http://feedads.doubleclick.net/": 2, "http://miplab.epfl.ch/": 1, "https://sites.google.com/": 2, "http://baspfrontiers.epfl.ch/": 2}, "blogtitle": "Nuit Blanche"}, {"content": ["I just came across this presentation by Marc M\u00e9zard , explaining what I called a year ago a stunning development . It is interesting in that it provides some support for the paper in regards to the explanation of the Belief Propagation (or now AMP) algorithm. \n \n \n \n \n \n \n \nThe presentation is at videolectures and is entitled: Occam's razor in massive data acquisition: a statistical physics approach , Also, you may recall two postdoc announcements from that group . \n \n \n \nWith this cavity explanation, I wonder if these recent invisibility cloaks could not provide a way to physically implement those cavity measures, oh well.... \n \n \n \n \n \n Join our Reddit Experiment , Join the CompressiveSensing subreddit and post there !  Liked this entry ? subscribe to Nuit Blanche's feed, there's more where that came from . You can also subscribe to Nuit Blanche by Email , explore the Big Picture in Compressive Sensing or the Matrix Factorization Jungle and join the conversations on compressive sensing , advanced matrix factorization and calibration issues on Linkedin."], "link": "http://nuit-blanche.blogspot.com/feeds/5536844287857687160/comments/default", "bloglinks": {}, "links": {"http://www.reddit.com/": 2, "http://feedburner.google.com/": 1, "http://feeds.feedburner.com/blog": 1, "http://www.linkedin.com/": 3, "http://feedads.doubleclick.net/": 2, "https://sites.google.com/": 2, "http://www.u-psud.fr/": 1, "http://videolectures.net/": 1, "http://4.blogspot.com/": 1, "http://nuit-blanche.blogspot.com/": 2}, "blogtitle": "Nuit Blanche"}, {"content": ["Looks like some of the videos of the MMDS workshop are now out, woohoo! Here are some samples connected to some of the themes mentioned here: \n \n \n \n \n \n \nThe Pursuit of Low-dimensional Structures in High-dimensional Data, Yi Ma \n \n \n\n \nImplementing Randomized Matrix Algorithms in Parallel and Distributed Environments, Michael Mahoney\n \n\n \nLow Rank Approximation and Regression in Input Sparsity Time, David Woodruff \n \n \n\n \nLeverage Scores, the Column Subset Selection Problem, and Least-squares Problems, Petros Drineas \n \n \n\n \nOn Robust Regression Estimators in High-dimension, Noureddine El Karoui\n \n \n \nThe rest of the videos of the wrokshop can be found on the MMDS YouYube channel \n \n \n \n \n \n \n \n \n \n Join our Reddit Experiment , Join the CompressiveSensing subreddit and post there !  Liked this entry ? subscribe to Nuit Blanche's feed, there's more where that came from . You can also subscribe to Nuit Blanche by Email , explore the Big Picture in Compressive Sensing or the Matrix Factorization Jungle and join the conversations on compressive sensing , advanced matrix factorization and calibration issues on Linkedin."], "link": "http://nuit-blanche.blogspot.com/feeds/1657954756162631432/comments/default", "bloglinks": {}, "links": {"http://www.reddit.com/": 2, "http://feedburner.google.com/": 1, "http://feeds.feedburner.com/blog": 1, "http://www.linkedin.com/": 3, "http://feedads.doubleclick.net/": 2, "http://www.youtube.com/": 1, "https://sites.google.com/": 2, "http://nuit-blanche.blogspot.fr/": 1}, "blogtitle": "Nuit Blanche"}, {"content": [". \n \n David Brady, Duke University  Coded Aperture X-Ray Scatter Imaging \n \n \n \n \n \n \n \n \n \n \nYou probably recall that in Why do commercial CT scanners still employ traditional, filtered back-projection for image reconstruction? by Xiaochuan Pan , Emil Sidky , and Michael Vannier , it was mentioned that coded aperture could be used for X-rays as it could probably yield additional if were to use the ideas of compressive sensing. The central idea of compressive sensing, as you recall, is that the reconstruction solver actually use the fact that the field of view is sparse in some basis.\n\nThanks to Greg and his start-up which enabled and sponsored the CMU Next Generation Medical Imaging Workshop , we had the pleasure of watching David Brady 's presentation on Coded Aperture X-Ray Scatter Imaging . The idea of coded aperture in x-ray in not new, see for instance the discussion we had with Gerry Skinner, a Specialist in Coded Aperture Imaging . However, the deconvolution step using the fact that either that the scene is compressible is. There is much to be worked out beyond the simple models shown in this video but I submit that with the right use of codes like MCNP or GEANT4, we ought to be able to extract much more information from X-rays than we currently are. \n \n \n \n \n \n \n \n Join our Reddit Experiment , Join the CompressiveSensing subreddit and post there !  Liked this entry ? subscribe to Nuit Blanche's feed, there's more where that came from . You can also subscribe to Nuit Blanche by Email , explore the Big Picture in Compressive Sensing or the Matrix Factorization Jungle and join the conversations on compressive sensing , advanced matrix factorization and calibration issues on Linkedin."], "link": "http://nuit-blanche.blogspot.com/feeds/3341363949320919880/comments/default", "bloglinks": {}, "links": {"http://www.uchospitals.edu/": 1, "http://www.linkedin.com/": 4, "http://feedburner.google.com/": 1, "http://feeds.feedburner.com/blog": 1, "http://www.davidbrady.net/": 1, "http://feedads.doubleclick.net/": 2, "https://www.cmu.edu/": 2, "http://www.nih.gov/": 1, "https://sites.google.com/": 2, "http://wms.cmu.edu": 2, "http://www.reddit.com/": 2, "http://radiology.uchicago.edu/": 1, "http://nuit-blanche.blogspot.fr/": 1, "http://home.uchicago.edu/": 1}, "blogtitle": "Nuit Blanche"}, {"content": ["It's the summer somewhere. Here are some of the blog entries that caught my eye this past.....fifteen days \n \n \n \nPretty much in line with what Bob and Dirk did a month ago (i.e writing about meetings they attended), Dustin has a wonderful and in-depth presentation of what he saw at ESI 2012:on Phase retrieval . I think I may be tempted to make a full entry out of each of these meetings summaries next time as they are so insightful. I am in awe.. Thanks Dustin, Dirk and Bob. \n \n \n \nDo Yung has a sample app for movie recommendation demo with matrix factorization \n \n \n \n \n \nLarry wrote the following entries: \n Proof That Theory Matters \n The Robins-Ritov Example: A Post-Mortem \n The Normalizing Constant Paradox \n Testing Millions of Hypotheses: FDR \n \n \n \n \nGreg featured \n \n Lectures from Day 1 of the CMU Next Generation Medical Imaging Workshop \n Videos from Day 2 of the CMU Next Generation Medical Imaging Workshop \n Making sound waves visible with a lock-in amplifier \n \nVladimir had some news from the CMOS industry and more: \n More Market Data from Yole \n Microsoft Presents Alternative Gesture Recognition System \n \n \n \n \n \nDanny talked about \n \n Objectivity \n Machine Learning PostDoc Positions in Europe \n Spotlight: Trifacta \n Misc Updates \n The 10 recommender system metrics you should know about \n Interesting large scale dataset: D4D mobile data \n Item based similarity with GraphChi \n \n \n \n \n \nSeth is intrigued by an experiment on Reddit in The Reddit Protein Powder Tests \n \nRetraction Watch mentions that Elsevier talks about Retraction Watch: saying that \u201cscholarly publishing is better for it\u201d \n \nBrian talks about Looking for a new job \n \nWalking Randomly: talks about Free and commercial alternatives to Simulink \n \nBob talks about how [his] music is used in interesting contexts \n \n2physics tells us more about Avian Compass Reloaded \n \n \nMathBlogging has a new Mathematical Instrument with Katie Steckles \u2013 The Aperiodical \n \nTerry talks about The Chowla conjecture and the Sarnak conjecture \n \n \n \n \n Image Credit: NASA/JPL/Space Science Institute W00076422.jpg was taken on October 17, 2012 and received on Earth October 17, 2012. The camera was pointing toward ENCELADUS at approximately 584,365 miles (940,445 kilometers) away, and the image was taken using the IR3 and CL2 filters. T \n \n \n Join our Reddit Experiment , Join the CompressiveSensing subreddit and post there !  Liked this entry ? subscribe to Nuit Blanche's feed, there's more where that came from . You can also subscribe to Nuit Blanche by Email , explore the Big Picture in Compressive Sensing or the Matrix Factorization Jungle and join the conversations on compressive sensing , advanced matrix factorization and calibration issues on Linkedin."], "link": "http://nuit-blanche.blogspot.com/feeds/5467096723320821489/comments/default", "bloglinks": {}, "links": {"https://sites.google.com/": 2, "http://saturn.nasa.gov/": 2, "http://shom83.blogspot.fr/": 1, "http://machinevision4users.blogspot.fr/": 1, "http://terrytao.wordpress.com/": 1, "http://normaldeviate.wordpress.com/": 4, "http://dustingmixon.wordpress.com/": 1, "http://bickson.blogspot.fr/": 7, "http://retractionwatch.wordpress.com/": 1, "http://www.reddit.com/": 2, "http://feedburner.google.com/": 1, "http://feeds.feedburner.com/blog": 1, "http://www.2physics.com/": 1, "http://media.aau.dk/": 1, "http://image-sensors-world.blogspot.fr/": 2, "http://blog.sethroberts.net/": 1, "http://www.linkedin.com/": 3, "http://www.walkingrandomly.com/": 1, "http://aperiodical.com/": 1, "http://feedads.doubleclick.net/": 2, "http://mrvacuumtube.blogspot.fr/": 2, "https://www.cmu.edu/": 1, "http://mathblogging.wordpress.com/": 1, "http://nuit-blanche.blogspot.fr/": 2}, "blogtitle": "Nuit Blanche"}, {"content": ["Motion-Adaptive Spatio-Temporal Regularization (MASTeR) for Accelerated Dynamic MRI by M. Salman Asif , Lei Hamilton , Marijn Brummer , Justin Romberg . The abstract reads: \n \n \n \n \n \n \n \nAccelerated MRI techniques reduce signal acquisition time by undersampling k-space. A fundamental problem in accelerated MRI is the recovery of quality images from undersampled k-space data. Current state-of-the-art recovery algorithms exploit the spatial and temporal structures in underlying images to improve the reconstruction quality. In recent years, compressed sensing theory has helped formulate mathematical principles and conditions that ensure recovery of (structured) sparse signals from undersampled, incoherent measurements. In this paper, a new recovery algorithm, motion-adaptive spatio-temporal regularization (MASTeR), is presented. MASTeR, which uses compressed sensing principles to recover dynamic MR images from highly undersampled k-space data, takes advantage of spatial and temporal structured sparsity in MR images. In contrast to existing algorithms, MASTeR models temporal sparsity using motion-adaptive linear transformations between neighboring images. The e ciency of MASTeR is demonstrated with experiments on cardiac MRI for a range of reduction factors. Results are also compared with k-t FOCUSS with motion estimation and compensation|another recently proposed recovery algorithm for dynamic MRI. \n \n \n \n \n \nThe webpage and attendant can be found at this web page: MASTeR: Motion-Adaptive Spatio-Temporal Regularization for Accelerated Dynamic MRI that starts with: \n \n \n \n \n \n Introduction: \n \n \n \n This package provides various MATLAB codes for reconstructing quality cardiac MR images from highly under-sampled k-space data. The main theme in this work is to exploit spatial and temporal structure/ sparsity of the MR images during their reconstruction. \n \n \n \n Imaging model : Consider a dynamic MRI setup in which data consist of T images in a cardiac cycle. The vector form of the imaging system for an  th image can be written as \n \n \n \n  \n \n \n \n  is a complex-valued MR image,  is a vector with k-space measurements of  ,  is the encoding matrix which consists of subsampled Fourier transform weighted by coil sensitivity maps, and  is the noise in the measurements. \n \n \n \n Recovery problem : To recover image sequence  from all the available k-space data  , we solve a convex optimization program of the following general form: \n \n \n \n  \n \n \n \n The first term keeps the signal estimate close to the measurements and the second term promotes certain spatial/temporal sparse structure in  . For instance, wavelet transform or total-variation operator for can be used for spatial sparse representation and linear or motion-adaptive temporal differences can be used for temporal sparse representation. \n \n \n \n The code provides various options/combinations for sampling schemes, L1/L2 spatial/temporal regularizations (spatial: orthogonal or complex wavelet transform; temporal: frame difference, temporal DFT, motion-adaptive transforms), and more. Consult demo and job files for further details. \n \n \n \n Reference: \n \n \n \n \u00b7   M. Salman Asif, Lei Hamilton, Marijn Brummer , and Justin Romberg,  Motion-adaptive spatio -temporal regularization ( MASTeR ) for accelerated dynamic MRI,  Magnetic Resonance in Medicine, Accepted September 2012. \n \n MASTeR models temporal sparsity using motion-adaptive linear transformations between neighboring images. Spatial transform using dual-tree complex wavelet transform (DT-CWT) and motion estimation using phase of DT-CWT coefficients. \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n Join our Reddit Experiment , Join the CompressiveSensing subreddit and post there !  Liked this entry ? subscribe to Nuit Blanche's feed, there's more where that came from . You can also subscribe to Nuit Blanche by Email , explore the Big Picture in Compressive Sensing or the Matrix Factorization Jungle and join the conversations on compressive sensing , advanced matrix factorization and calibration issues on Linkedin."], "link": "http://nuit-blanche.blogspot.com/feeds/710102119288648990/comments/default", "bloglinks": {}, "links": {"http://www.linkedin.com/": 5, "http://feedburner.google.com/": 1, "http://feeds.feedburner.com/blog": 1, "http://www.reddit.com/": 2, "http://feedads.doubleclick.net/": 2, "http://users.gatech.edu/": 6, "https://sites.google.com/": 2}, "blogtitle": "Nuit Blanche"}, {"content": ["I got this from Florent Krzakala in my mailbox last night. If you recall Florent is one of the co-authors mentioned earlier here , here and more recently here . \n \n \n \n \nDear friends and colleagues, \n \n \n \nI would like to invite applications for two postdoctoral positions funded by the European Research Council Starting Grant program, in the context of the project SPARCS (Statistical Physics Approach to Reconstruction in Compressed Sensing) in my group in ESPCI in Paris. The appointments are intended to start in the fall of 2013 (or sooner) and will be for 2 years with a possibility of extension on 3 years. \n \nThe candidates can come from different areas (Statistical Physics, Signal Processing, Applied Mathematics, Error correcting codes, Information Theory, Inference and Machine learning) and are expected to bring their expertise. Successful candidates will thus conduct a vigorous research program within the scope of the project, and are expected to show independence and team working attitude at the same time. \n \nFor more information, please visit the post-doc announcement page: \n \n http://www.pct.espci.fr/~florent/postdoc.html \n \nDo not hesitate to spread the information around you. I apologize if \n \nyou receive this mail more than once. \n \nBest regards, \n \nFlorent Krzakala \n \n \n \n \n \n \n \n Join our Reddit Experiment , Join the CompressiveSensing subreddit and post there ! \n Liked this entry ? subscribe to Nuit Blanche's feed, there's more where that came from . You can also subscribe to Nuit Blanche by Email , explore the Big Picture in Compressive Sensing or the Matrix Factorization Jungle and join the conversations on compressive sensing , advanced matrix factorization and calibration issues on Linkedin."], "link": "http://nuit-blanche.blogspot.com/feeds/5294889535748324499/comments/default", "bloglinks": {}, "links": {"http://www.reddit.com/": 2, "http://feedburner.google.com/": 1, "http://feeds.feedburner.com/blog": 1, "http://www.linkedin.com/": 3, "http://feedads.doubleclick.net/": 2, "http://www.espci.fr/": 1, "https://sites.google.com/": 2, "http://goo.gl/": 1, "http://nuit-blanche.blogspot.fr/": 3}, "blogtitle": "Nuit Blanche"}, {"content": ["In And so it begins ... Compressive Genomics and Predicting the Future: Randomness and Parsimony , we made the case that algorithm development really needed to happen fast in order to face the tsunami of sequencing data we are being hit with. Recently in one of Sunday's Morning Insight entry, we slowly but surely woke up to the realization that we may have to change our vocabulary and ditch l_1 in favor of belief propagation (Approximate Message Passing) so that we could hit better phase transition than the ones given to us by the Donoho-Tanner transition. If you are in this frame of mind, you are ready to read the following paper: which \"... is the \ufb01rst step in developing a novel framework for group testing that caters to  the unique needs of the emerging \ufb01eld of genotyping through high-throughput sequencing. \" \n \n \n \n Semi-Quantitative Group Testing: a General Paradigm with Applications in Genotyping by Amin Emad , Olgica Milenkovic . The abstract reads: \n \nWe propose a novel group testing method, termed semi-quantitative group testing, motivated by a class of problems arising in genome screening experiments. Semi-quantitative group testing (SQGT) is a (possibly) non-binary pooling scheme that may be viewed as a concatenation of an adder channel and an integer-valued quantizer. In its full generality, SQGT can be viewed as a unifying framework for group testing, in the sense that most group testing models are special instances of SQGT. For the new general testing scheme, we define the notion of SQ-disjunct and SQ-separable codes, generalizations of the classic disjunct and separable codes. We describe several combinatorial and probabilistic constructions of such codes. While in most of these constructions, we assume that the number of defectives is much smaller than total number of test subjects, we also consider the case in which there is no restriction on the number of defectives and they can be as large as the total number of subjects. For these codes, we describe a number of decoding algorithms; in particular, we describe belief propagation decoders for sparse SQGT codes. We define the notion of capacity of SQGT and evaluate it for some special choices of parameters using information theoretic methods. \n \n \n \n Image Credit: NASA/JPL-Caltech \n \n This image was taken by Rear Hazcam: Left A (RHAZ_LEFT_A) onboard NASA's Mars rover Curiosity on Sol 69 (2012-10-15 23:47:13 UTC) .  \n \n \n \n Join our Reddit Experiment , Join the CompressiveSensing subreddit and post there !  Liked this entry ? subscribe to Nuit Blanche's feed, there's more where that came from . You can also subscribe to Nuit Blanche by Email , explore the Big Picture in Compressive Sensing or the Matrix Factorization Jungle and join the conversations on compressive sensing , advanced matrix factorization and calibration issues on Linkedin."], "link": "http://nuit-blanche.blogspot.com/feeds/2960212139992011307/comments/default", "bloglinks": {}, "links": {"http://www.linkedin.com/": 4, "http://feedburner.google.com/": 1, "http://feeds.feedburner.com/blog": 1, "http://faculty.illinois.edu/": 1, "http://www.reddit.com/": 2, "http://feedads.doubleclick.net/": 2, "http://arxiv.org/": 1, "https://sites.google.com/": 2, "http://nuit-blanche.blogspot.fr/": 3, "http://mars.nasa.gov/": 2}, "blogtitle": "Nuit Blanche"}]
[{"blogurl": "http://to-cs.blog.sohu.com\n", "blogroll": [], "title": "Compressive Sensing\uff1a\u4e00\u7f15\u6e05\u98ce"}, {"content": ["Today, Post the updated Igor's blog. \n  \n  As following: \n  \n  \n  \n CS: Matrix Completion via Thresholding, Dick Gordon's Op-Ed, Lianlin Li's Open Question on Compressible Priors Posted: 18 Jan 2010 10:01 PM PST \n Angshul Majumdar just released some new code on Matrix Completion via Thresholding at Matlab Central. From the presentation \n Contains three matrix completion algorithms and a demo script for running them. Also compares against other matrix completion algorithms - Singular Value Thresholding and Fixed Point Iteration. Solves the following three optimization problems: \n min rank(X) subject to ||y - M(X)||_2 \\lt via Iterated Hard Thresholding \n min nuclear-norm(X) subject to ||y - M(X)||_2 \\lt via Iterated Soft Thresholding \n min ||S||_p subject to ||y - M(X)||_2 \\lt err, where S = svd(X) via Iterated Soft Thresholding \n Requires Sparco since the masking operator has been defined in according to the Sparco framework. \n http://www.cs.ubc.ca/labs/scl/sparco/ \n The algorithms are general enough to work with any other linear operator, and not only the masking operator. The masking operator is just a special case when the problem boils down to one of matrix completion. For comparing the results with other algorithms download the Singular Value Thresholding toolbox http://svt.caltech.edu/ \n \n Thanks Angshul ! \n Dick Gordon, one of the first to develop ART for CT tomography just sent me the following (a follow up to a previous entry). I am reprinting it as is (except for some edit on the form and hyperlinks) \n \n How to get CT out of its high dose rut: CS for CT x-ray dose reduction is a political issue \n \n \n The article: \n Pan, X., E.Y. Sidky & M. Vannier (2009). Why do commercial CT scanners still employ traditional, filtered back-projection for image reconstruction? Inverse Problems 25, 36p. #123009. \n places the blame for what Igor Carron calls \u201cthe inability of ART to topple FBP\u201c on the theoreticians and the manufacturers, somehow expecting the latter\u2019s engineers, stuck in the middle, to overcome a number of sociological problems. These are scattered through the paper, so I pull them together here: \n \u201c...it makes little sense to spend endless time and effort refining an inversion formula for an idealized imaging model when there are some compromising factors earlier in the data-flow chain....\u201d \n \u201cMost of the research devoted to image reconstruction aims at developing new solutions to solving imaging model problems. The idea being that the imaging model problems evolve toward realistic situations and that this theory eventually finds its way into application. We submit that this style of research is not effective for translation based simply on the empirical evidence that not much of the work published in Inverse Problems over the past couple of decades is actually used in a CT scanner.\u201c \n \u201cThe bulk of the applied-mathematics research effort seems to go toward developing advanced techniques that will likely never be used in practice or address problems that have little application.\u201c \n \u201cAnd presently users of CT are used to some of the streak artifacts in FBP-based reconstructions, and there is not really a huge motivation of exchanging FBP streaks for some other type of artifact.\u201c \n \u201cParameter explosion is one of the challenges that face optimization-based algorithms for image reconstruction in commercial products.\u201c \n \u201cThe real progress in moving past FBP-based reconstruction will occur when engineers have real experience with advanced image-reconstruction algorithms and can use this knowledge to design more efficient and effective CT scanners. This development will likely occur first in dedicated CT systems such as head/neck CT, dental CT and breast CT.\u201c \n \u201cAmong the main reasons for slow progress on introduction of algorithmic innovations into clinical CT scanners may also be the proprietary nature of CT technologies and the subjective evaluation of performance by its users.\u201c \n \u201cThe door to innovation in CT algorithms requires an efficient and practical route to develop and test new algorithms. It is unlikely that any investigator, mathematician or engineer could effectively correct for the raw detector measurements from the CT scanner into a form suitable for algorithm testing without the manufacturer\u2019s blessing and assistance. However, manufacturers of CT scanners, in general, have not made the raw projection data available to anyone outside their organizations, even to customers that use their CT scanners.\u201c \n \u201cThere is no Digital Image COMmunication (DICOM) standard for CT raw data [86, 87]. In fact, there are no standards at all. Corrected raw projection-data sets are almost impossible to find in the public domain. Without this data, clinically realistic examples of images cannot be reconstructed. As a consequence, CT-algorithm developers almost universally use highly idealized numerical phantoms for their work and seldom show results obtained with \u2018real\u2019 experimental or clinical data. This is surely a major impediment to progress.\u201c \n \u201cIf the system was \u2018open\u2019 and could be refined by algorithm developers in the field, such algorithms could be tested and clinically validated. The benefits of new technology, especially in image-reconstruction algorithms, could reach patients without waiting for their possible inclusion in future generations of CT scanners (because this has not happened for the past 25 years and may not in the near future).\u201c \n \u201cPerhaps the need for an open-source-community-developed CTreconstruction toolkit (CTK) with a database of corrected raw projection data from real CT scanners will be recognized.\u201c \n I have been asking clinicians on and off for 40 years to put \u201copen access\u201d into their purchasing contracts with CT companies. But for most of them the role of the CT algorithm is invisible, and as is generally true in medicine and biology, the role of the theoretician is simply not recognized, let alone paid a salary or listened to. So how to break this impasse? \n I have a simple proposal: CS (Compressive Sampling) people need to demonstrate to politicians concerned with x-ray dose that they can get the dose down by an order of magnitude or more. This, I think, is the answer to Igor Carron\u2019s analysis:\u201dTherefore a CS system would have to provide something else\u201c. The politicians will then, in effect, legislate a role for CS people in CT design. The companies won\u2019t do it themselves. Nor will their customers, the radiologists. It won\u2019t happen in breast CT, because everyone will just use the dose ceiling already established in projection mammography. \n The only radiologist that I know of who vigorously lectures other radiologists on the need for dose reduction in CT is David A. Leswick of the University of Saskatchewan. His papers are a little less fiery: \n Leswick, D.A., N.S. Syed, C.S. Dumaine, H.J. Lim & D.A. Fladeland (2009). Radiation dose from diagnostic computed tomography in Saskatchewan. Can Assoc Radiol J 60(2), 71-78. \n Leswick, D.A., C.S. Dumaine, N.S. Syed & D.A. Fladeland (2009). Computed tomography radiation dose: a primer for administrators. Healthcare Quarterly 12(Special Issue), 15-22. \n Nevertheless, the latter starts: \n \u201cThe use of computed tomography (CT) is growing, and, consequently, the associated radiation dose to patients is increasing as well. There is increasing evidence linking the radiation dose within the range of diagnostic CT with a significantly increased risk of malignancy. These two factors combine to make radiation dose from diagnostic CT a public health concern.\u201d \n Yours, -Dick Gordon gordonr@cc.umanitoba.ca \n Thanks Dick, I agree with you that in the context of CT, maybe, the political whip is the only constraint that can force a dose reduction and opens the dor to more efficient algorithm like ART or other nonlinear reconstruction techniques introduced with compressive sensing. \n Lianlin Li mentioned this to me last week and he just wrote about this on his blog. Lianlin is particularly confused with three papers that seem to contradict each other on the subject of compressible priors for sparse bayesian estimation. The papers are: [1]M.E. Tipping. Sparse Bayesian learning and the relevance vector machine. The Journal of Machine Learning Research, 1, 211\u2013244, 2001. [2] David Wipf, Jason Palmer, and Bhaskar Rao. Perspectives on sparse Bayesian learning, Advances in Neural Information Processing Systems, 16, 2003 [3] Volkan Cevher. Learning with compressible Priors, Preprint, 2009. The slides in the blog entry are in English. The introduction is in Chinese but it is not relevant to the confusion at hand. If you want to clear up the misunderstanding between the papers as presented by Lianlin and feel you cannot comment in the blog with instructions in Chinese then you are welcome to put a comment here and I could make an entry of all y'alls responses. \n Thanks Lianlin for following up on this."], "link": "http://to-cs.blog.sohu.com/142722831.html", "bloglinks": {}, "links": {}, "blogtitle": "Compressive Sensing\uff1a\u4e00\u7f15\u6e05\u98ce"}, {"content": ["\u4e00\u76f4\u4ee5\u6765\uff0c\u4e00\u76f4\u4e3a\u201ccompressive sensing\u4f55\u53bb\u4f55\u4ece\u201d\u8fd9\u4e2a\u95ee\u9898\u611f\u5230\u56f0\u60d1\u3002\u636e\u538b\u7f29\u611f\u77e5\u7406\u8bba\u548c\u65b9\u6cd5\u7684\u63d0\u51fa\u4e00\u76f4\u5230\u73b0\u5728\uff0c\u5f53\u521d\u7684\u6b23\u6b23\u5411\u8363\uff0c\u9057\u61be\u7684\u662f\uff0c\u5176\u51b7\u5176\u6696\uff0c\u53ea\u6709\u4ece\u4e8b\u538b\u7f29\u611f\u77e5\u7684\u4eba\u81ea\u77e5\u3002\u6b63\u5982\u6211\u5f53\u521d\u6240\u7591\u60d1\u7684\uff0c\u201c\u538b\u7f29\u611f\u77e5\u662f\u4e00\u56e2\u706b\uff0c\u8fd8\u4ec5\u4ec5\u662f\u56e2\u70df\uff1f\u201d\u5c3d\u7ba1\u5982\u6b64\uff0c\u7531\u538b\u7f29\u611f\u77e5\u6240\u8bde\u751f\u7684\u5bf9\u5404\u79cd\u4f18\u5316\u7b56\u7565\u662f\u6781\u5176\u73cd\u8d35\u7684\u8d22\u5bcc\uff1b\u53e6\u5916\uff0c\u7ebf\u5f62\u95ee\u9898\u7684\u91cd\u65b0\u5ba1\u89c6\u4e5f\u5c06\u662f\u538b\u7f29\u611f\u77e5\u7684\u4e00\u5927\u529f\u52b3\uff1b\u6216\u8bb8\u6700\u91cd\u8981\u7684\u662f\uff0c\u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\uff0c\u538b\u7f29\u611f\u77e5\u4fc3\u8fdb\u4e86\u6570\u5b66\u7406\u8bba\u548c\u5de5\u7a0b\u5e94\u7528\u9886\u57df\u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u7684\u878d\u5408\u3002 \n \n \u8bb0\u5f97\u4e00\u4f4d\u670b\u53cb\u6258\u6211\u5199\u4e00\u70b9\u538b\u7f29\u611f\u77e5\u65b9\u6cd5\u7684\u4e1c\u897f\uff0c\u7531\u4e8e\u65f6\u95f4\u6bd4\u8f83\u7d27\u5f20\uff0c\u5230\u73b0\u5728\u4e3a\u6b62\u6ca1\u80fd\u5b8c\u6210\u3002\u4e0d\u8fc7\uff0c\u8d34\u4e0b\u9762\u82e5\u5e72ppt\uff0c\u8fd9ppt\u4e0a\u5217\u51fa\u4e86\u6211\u8ba4\u4e3a\u76ee\u524d\u6587\u732e\u5bf9compressible prior\u7406\u89e3\u7684\u76f8\u4e92\u77db\u76fe\u7684\u89e3\u91ca\uff0c\u5e0c\u671b\u80fd\u591f\u5bf9\u8fd9\u4e2a\u95ee\u9898\u4f5c\u8fdb\u4e00\u6b65\u7684\u63a2\u8ba8\u3002\u5e0c\u671b\u8fd9\u70b9\u4e1c\u897f\u5bf9\u8fd9\u4f4d\u670b\u53cb\u6709\u6240\u5e2e\u52a9\u3002 \n \n \n \n \n \n \n \n \n \n \n \n \u4e0b\u9762\u518d\u8d34Igor\u4eca\u5929\u7684\u5185\u5bb9 \n This week we have several papers looking at what can be detected in the measurement world before performing any type of reconstruction, enjoy: \n Compressed-Sensing MRI with Random Encoding by Justin Haldar, Diego Hernando, Zhi-Pei Liang. The abstract reads: Compressed sensing (CS) has the potential to reduce MR data acquisition time. There are two fundamental tenets to CS theory: (1) the signal of interest is sparse or compressible in a known representation, and (2) the measurement scheme has good mathematical properties (e.g., restricted isometry or incoherence properties) with respect to this representation. While MR images are often compressible, the second requirement is often only weakly satisfied with respect to commonly used Fourier encoding schemes. This paper investigates the possibility of improving CS-MRI performance using random encoding, in an effort to emulate the \"universal'' encoding schemes suggested by the theoretical CS literature. This random encoding is achieved experimentally with tailored spatially-selective RF pulses. Simulation and experimental results show that the proposed encoding scheme has different characteristics than more conventional Fourier-based schemes, and could prove useful in certain contexts. Hyperspectral target detection from incoherent projections by Kalyani Krishnamurthy, Maxim Raginsky and Rebecca Willett. The abstract reads: \n This paper studies the detection of spectral targets corrupted by a colored Gaussian background from noisy, incoherent projection measurements. Unlike many detection methods designed for incoherent projections, the proposed approach a) is computationally efficient, b) allows for spectral backgrounds behind potential targets, and c) yields theoretical guarantees on detector performance. In particular, the theoretical performance bounds highlight fundamental tradeoffs among the number of measurements collected, the spectral resolution of targets, the amount of background signal present, signal-tonoise ratio, and the similarity between potential targets in a dictionary. Compressive sensing and differential image motion estimation by Nathan Jacobs, Stephen Schuh, and Robert Pless. The abstract reads: Compressive-sensing cameras are an important new class of sensors that have different design constraints than standard cameras. Surprisingly, little work has explored the relationship between compressive-sensing measurements and differential image motion. We show that, given modest constraints on the measurements and image motions, we can omit the computationally expensive compressive-sensing reconstruction step and obtain more accurate motion estimates with significantly less computation time. We also formulate a compressive-sensing reconstruction problem that incorporates known image motion and show that this method outperforms the state-of-the-art in compressive-sensing video reconstruction. On unusual pixel shapes and image motion by Nathan Jacobs, Stephen Schuh, and Robert Pless.The abstract reads: We introduce the integral-pixel camera model, where measurements integrate over large and potentially overlapping parts of the visual field. This models a wide variety of novel camera designs, including omnidirectional cameras, compressive sensing cameras, and novel programmable-pixel imaging chips. We explore the relationship of integral-pixel measurements with image motion and find (a) that direct motion estimation using integral-pixels is possible and in some cases quite good, (b) standard compressive-sensing reconstructions are not good for estimating motion, and (c) when we design image reconstruction algorithms that explicitly reason about image motion, they outperform standard compressive-sensing video reconstruction. We show experimental results for a variety of simulated cases, and have preliminary results showing a prototype camera with integral-pixels whose design makes direct motion estimation possible. Sampling Piecewise Sinusoidal Signals with Finite Rate of Innovation Methods by Jesse Berent,P.L. Dragotti and Thierry Blu. The abstract reads: We consider the problem of sampling piecewise sinusoidal signals. Classical sampling theory does not enable perfect reconstruction of such signals since they are not bandlimited. However, they can be characterized by a finite number of parameters namely the frequency, amplitude and phase of the sinusoids and the location of the discontinuities. In this paper, we show that under certain hypotheses on the sampling kernel, it is possible to perfectly recover the parameters that define the piecewise sinusoidal signal from its sampled version. In particular, we show that, at least theoretically, it is possible to recover piecewise sine waves with arbitrarily high frequencies and arbitrarily close switching points. Extensions of the method are also presented such as the recovery of combinations of piecewise sine waves and polynomials. Finally, we study the effect of noise and present a robust reconstruction algorithm that is stable down to SNR levels of 7 [dB]. Information Theoretic Bounds for Low-Rank Matrix Completion by Sriram Vishwanath. The abstract reads: This paper studies the low-rank matrix completion problem from an information theoretic perspective. The completion problem is rephrased as a communication problem of an (uncoded) low-rank matrix source over an erasure channel. The paper then uses achievability and converse arguments to present order-wise optimal bounds for the completion problem. \n \n And finally a presentation entitled Subsampling, Spectral Methods and Semidefinite Programming by Noureddine El Karoui, Alexandre dAspremont"], "link": "http://to-cs.blog.sohu.com/142625002.html", "bloglinks": {}, "links": {}, "blogtitle": "Compressive Sensing\uff1a\u4e00\u7f15\u6e05\u98ce"}, {"content": ["\u65f6\u95f4\u8fc7\u7684\u771f\u5feb\uff0c\u4e09\u4e2a\u661f\u671f\u7684\u957f\u5047\u8f6c\u773c\u544a\u4e00\u6bb5\u843d\u4e86\u3002\u8fd9\u6b21\u56de\u56fd\uff0c\u89c1\u4e86\u597d\u51e0\u4e2a\u8001\u670b\u53cb\uff0c\u4e45\u522b\u91cd\u9022\u7684\u611f\u89c9\u771f\u597d\u3002 \n \u7531\u4e8e\u5b66\u6821\u8fd8\u6ca1\u6709\u5b8c\u5168\u5f00\u5b66\uff0c\u627e\u4e2a\u8425\u4e1a\u7684\u5496\u5561\u5e97\u8fd8\u6709\u70b9\u56f0\u96be\uff1b\u5c3d\u7ba1\u5982\u6b64\uff0c\u5728\u56fe\u4e66\u9986\u5916\u548cIgor\u804a\u4e86\u4e00\u5927\u534a\u4e2a\u4e0a\u5348\u3002\u7531\u4e8e\u56fd\u5185\u65e0\u6cd5\u767b\u9646Igor\u7684blog\uff0c\u4e14\u56fd\u5185\u6709\u4e0d\u5c11\u7684\u79d1\u7814\u4eba\u5458\u4ece\u4e8bcompressive sensing\u65b9\u9762\u7684\u5de5\u4f5c\uff0c\u56e0\u6b64\u6211\u5411Igor\u63d0\u8bae\uff0c\u5728\u6211\u7684\u8fd9\u4e2ablog\u8fde\u7eed\u8f6c\u8f7dIgor blog\u7684\u5185\u5bb9\uff0c\u7528\u4ee5\u8ba9\u56fd\u5185\u76f8\u5173\u7814\u7a76\u4eba\u5458\u53ca\u65f6\u4e86\u89e3compressive sensing\u53ca\u76f8\u5173\u8bfe\u9898\u7684\u7814\u7a76\u52a8\u6001\u3002Thanks, Igor\u3002 \n \n \u4e0b\u9762\u5c31\u8f6c\u8f7dIgor blog\u8fd1\u6765\u7684\u82e5\u5e72\u5185\u5bb9\uff0c\u5177\u4f53\u5982\u4e0b\uff1b \n \n CS; CS in infinite dimensional space, Ditributed Bearing Estimation via matrix Completion, Optimal incorporation of sparsity information Posted: 13 Jan 2010 06:24 AM PST \n If you thought some of the techniques used to reconstruct signals took long, you've never tried \"infinite dimensional convex optimization\" :-). This is the subject of today's first paper: Compressive Sampling in Infinite Dimensions by Anders C. Hansen. The abstract reads; \n We generalize the theory of Compressive Sampling in Cn to infinite dimensional Hilbert spaces. The typical O(log(n)) estimates (where n is the dimension of the space) are manipulated to fit an infinite dimensional framework. \n Looking at the other interest of the author, I wonder aloud if there is a connection between the computation pseudospectra and the RIP/NullSpace conditons ? For more information on computing pseudospectra of rectangular matrices, one can check Eigenvalues and Pseudospectra of rectangular matrices by Thomas Wright and L. Nick Trefethen. You'd think there is a connection and that theorem 2 would help (since multiplying a matrix with a class of sparse vector is really about reducing the number of columns of that matrix). There is also a connection between DOA and pseudospectra and DOA has been the subject of several papers mentioned here before. \n Volkan Cevher let me know of a new paper Ditributed Bearing Estimation via matrix Completion by Andrew Waters and Volkan Cevher. The abstract reads: \n We consider bearing estimation of multiple narrow-band plane waves impinging on an array of sensors. For this problem, bearing estimation algorithms such as minimum variance distortionless response (MVDR), multiple signal classification, and maximum likelihood generally require the array covariance matrix as sufficient statistics. Interestingly, the rank of the array covariance matrix is approximately equal to the number of the sources, which is typically much smaller than the number of sensors in many practical scenarios. In these scenarios, the covariance matrix is low-rank and can be estimated via matrix completion from only a small subset of its entries. We propose a distributed matrix completion framework to drastically reduce the inter-sensor communication in a network while still achieving near-optimal bearing estimation accuracy. Using recent results in noisy matrix completion, we provide sampling bounds and show how the additive noise at the sensor observations affects the reconstruction performance. We demonstrate via simulations that our approach sports desirable tradeoffs between communication costs and bearing estimation accuracy. Finally, today's arxiv new addtion: Optimal incorporation of sparsity information by weighted $L_1$ optimization by Toshiyuki Tanaka and Jack Raymond. The abstract reads: \n Compressed sensing of sparse sources can be improved by incorporating prior knowledge of the source. In this paper we demonstrate a method for optimal selection of weights in weighted $L_1$ norm minimization for a noiseless reconstruction model, and show the improvements in compression that can be achieved.  \n \n \n \n CS: Graph-Constrained Group Testing Posted: 12 Jan 2010 05:56 AM PST Found today on Arxiv. Interesting finding (emphasis below is mine): \n Graph-Constrained Group Testing by Mahdi Cheraghchi, Amin Karbasi, Soheil Mohajer, Venkatesh Saligrama. The abstract reads: \n Non-adaptive group testing involves grouping arbitrary subsets of $n$ items into different pools. Each pool is then tested and defective items are identified. A fundamental question involves minimizing the number of pools required to identify at most $d$ defective items. Motivated by applications in network tomography, sensor networks and infection propagation we formulate group testing problems on graphs. Unlike conventional group testing problems each group here must conform to the constraints imposed by a graph. For instance, items can be associated with vertices and each pool is any set of nodes that must be path connected. In this paper we associate a test with a random walk. In this context conventional group testing corresponds to the special case of a complete graph on $n$ vertices. For interesting classes of graphs we arrive at a rather surprising result, namely, that the number of tests required to identify $d$ defective items is substantially similar to that required in conventional group testing problems, where no such constraints on pooling is imposed. Specifically, if T(n) corresponds to the mixing time of the graph $G$, we show that with $m=O(d^2 T^2(n) log(n/d))$ non-adaptive tests, one can identify the defective items. Consequently, for the Erdos-Renyi random graph $G(n,p)$, as well as expander graphs with constant spectral gap, it follows that $m=O(d^2 log^3(n))$ non-adaptive tests are sufficient to identify $d$ defective items. We next consider a specific scenario that arises in network tomography and show that $m=O(d^3 log^3(n))$ non-adaptive tests are sufficient to identify $d$ defective items. We also consider noisy counterparts of the graph constrained group testing problem and develop parallel results for these cases. \n \n \n CS: LSH, Photon Sieves, Fieldstream Posted: 09 Jan 2010 04:09 PM PST Sergey Ten asks the following question on Twitter: \n Are there connection between locality sensitive hashing and compressed sensing ? (RIP) \n My take is that one could use random projections to reduce a very high dimensional dataset onto some lower dimensional manifold and then probably use LSH to evaluate how these reduced data are connected to each other. Piotr Indyk on his LSH page makes a different case in the presentation entitled: Near-Optimal Hashing Algorithms for Approximate Near(est) Neighbor Problem, where the following slide appear: \n On a related item, Piotr also taught some course at Rice last year, the list of presentation can be found below: \n These are the lecture notes for a short course \"Streaming etc.\", given at Rice University in Spring'09. \n Introduction to streaming algorithms. Estimating the number of distinct elements and the L0 norm. \n Estimating the L2 norm. \n Estimating the Lp norms using p-stable distributions. \n Heavy hitters and sparse approximations. \n Compressive sensing. Sparse recovery using sparse matrices. RIP1 principle. State of the art table. \n Lower bounds for streaming and compressed sensing. \n Laurent Jacques mentioned to me the use of coded aperture to perform X-ray focusing. As you recall Gerry Skinner does not like coded aperture for imaging x-rays and this is the reason he is looking into Fresnel lenses for x-rays. As it turns out a way of providing additional focus for x-rays is by drilling holes in Fresnel lenses. \n Instead of just using Fresnel Zone plates, they drill a (random ?) distribution of points on them: \n Light passing a circular pinhole produces a diffraction pattern of concentric rings of decreasing width with increasing radius. If light is passed through a mask made up of the same pattern of rings a focus is formed. These Fresnel zone plates are used to focus soft X-rays where conventional optics fail because of strong absorption of all materials in this spectral region. \n The ultimate resolution of a Fresnel zone plate is determined by the width of the outermost zone. The focal spot is surrounded by rings of intensity (secondary maxima) that blur the images obtained in X-ray microscopy and scanning spectroscopy. \n These limitations can be overcome by using a large number of appropriately distributed pinholes instead of rings as the diffracting elements. To obtain a distinct first-order focus, the pinholes have to be positioned such that the optical path length from the source via the center of the pinholes to the focal point is an integral number of wavelengths. \n Furthermore, with photon sieves, the unwanted ring-like secondary maxima generated by zone plates can be suppressed. For a zone plate each ring contributes equally to the amplitude in the focus. This contribution drops abruptly to zero beyond the outermost ring which leads to strong intensity oscillations in the diffraction pattern. With a photon sieve the number of pinholes per ring can be readily adjusted to yield a smooth transition which minimizes the secondary maxima. \n Thanks Laurent. Finally, the Google webcrawler just found the following recently funded project: Fieldstream. The compressive sensing part is currently empty. They seem to be connected to the Urban sensing project at UCLA."], "link": "http://to-cs.blog.sohu.com/142295611.html", "bloglinks": {}, "links": {}, "blogtitle": "Compressive Sensing\uff1a\u4e00\u7f15\u6e05\u98ce"}, {"content": ["\u6211\u5c06\u5728\u63a5\u4e0b\u6765\u7684\u4e09\u4e2a\u661f\u671f\u653e\u5047\uff0c\u8d81\u4eca\u5929\u6ca1\u6709\u653e\u5047\uff0c\u8d34\u4e00\u4e9b\u4e1c\u897f\u3002 \n \n \u9996\u5148\u8f6c\u8d34Igor\u535a\u5ba2\u7684\u4e00\u4e9b\u4e1c\u897f\uff0c \n \uff08note\uff0c\u94fe\u63a5\u5730\u5740\uff1a http://www.ceremade.dauphine.fr/~peyre/mia09/ \uff09 Some of the presentations of the MIA'09 meeting can be found below. I'll come back to the last post and some of these presentations later. \n [1]Some Remarks on Derivative Free Regularization by Otmar Scherzer [2]Some Recent Advances in Image Representation for image segmentation, object class detection and image classification by Frederic Jurie [3]Computational Information Geometry From Euclidean to flat Pythagorean geometries by Frank Nielsen [4]Computation is the New Optics by Fr\u00e9do Durand joint work with Anat Levin, Bill Freeman, Peter Sand, Tim Cho, Ce Liu, Antonio Torralba, Ted Adelson, and others [5]Geometric Medians and Radar Target Detection by Guillaume Bouyt, Le Yang [6]Periodic + Smooth Image Decomposition by Lionel Moisan Hypercomplex mathematical morphology by Jes\u00fas Angulo [7]Multifractal stochastic processes to model images and textures by Pierre Chainais [8]Wavelet-Based Statistical Estimators. Application to image restoration by Caroline Chaux [9]Dictionary learning for sparse representations using L1 minimization by R\u00e9mi Gribonval, Karin Schnass Sparseness, invariance and independent coding in the visual system by David J. Field \n [10]Proximal Splitting Methods in Signal Recovery by Patrick Louis Combettes [11]Theory and algorithms for anisotropic finite elements with applications to images by Albert Cohen with Nira Dyn, Frederic Hecht and Jean-Marie Mirebeau. \n \n \u4eca\u5929\u4e0a\u5348\u4ed4\u7ec6\u7814\u7a76\u4e86\u4e00\u4e0bFrank Nielsen\u7684slids\uff0c\u5f88\u6709\u610f\u601d\u3002\u4e0b\u9762\u8d34\u51e0\u5f20\u6709\u610f\u601d\u7684slids, \n   \n (NOTE,\u5173\u4e8e\u8be5poser\uff0c\u4e5f\u53ef\u4ee5\u53c2\u9605Matthias Seeger\u7684\u535a\u58eb\u8bba\u6587Bayesian Gaussian Process Models: PAC-Bayesian Generalisation Error Bounds and Sparse Approximations\u3002) \n \n \u63a5\u4e0b\u6765\u8d34R.G. Baraniuk, V. Cevher, M. B. Wakin\u7684\u8bba\u6587\u201cLow-dimensional models for dimensionality reduction and signal recovery: a geometric perspective\u201d\uff0c\u8bba\u6587\u6458\u8981\uff0c \n We compare and contrast from a geometric perspective a number of low-dimensional signal models that support stable information-preserving dimensionality reduction. We consider sparse and compressible signal models for deterministic and random signals, structured sparse and compressible signal models, point clouds, and manifold signal models. Each model has a particular geometrical structure that enables signal information to be stably preserved via a simple linear and nonadaptive projection to a much lower dimensional space; in each case the projection dimension is independent of the signal\u2019s ambient dimension at best or grows logarithmically with it at worst. As a bonus, we point out a common misconception related to probabilistic compressible signal models, namely, by showing that the oft-used generalized Gaussian and Laplacian models do not support stable linear dimensionality reduction\u3002 \n \n \u8be5\u8bba\u6587\u4ece\u201cdimensionality reduction\u201d\u7684\u89d2\u5ea6\u8bba\u8ff0\u4e86\u82e5\u5e72\u79cdlow dim signal models\u3002\u5176\u4e2d\u5173\u4e8elow dim signal\u7edf\u8ba1\u6a21\u578b\u7684\u8bba\u8ff0\uff0c\u5176\u7ed3\u8bba\u4e0eTipping\u7b49\u4ebasparse bayesian\u7684\u7ed3\u8bba\u4e0d\u751a\u4e00\u81f4\uff0c\u503c\u5f97\u63a8\u6572\u3002 \n \n \u518d\u8d34\u4e00\u4e2aradar\u65b9\u9762\u7684\u5de5\u4f5c\uff0c\u201cOn compressivesensingappliedtoradar\u201d\uff0c\u8bba\u6587\u6458\u8981\uff0c \n \n \u518d\u8d34\u4e00\u4e2aradar\u65b9\u9762\u7684\u5de5\u4f5c\uff0c \n Reduced Complexity Angle-Doppler-Range Estimation for MIMO Radar That Employs Compressive Sensing \n BY,Yao Yu, Athina P. Petropulu and H. Vincent Poor \n \u8bba\u6587\u6458\u8981\uff0c \n Abstract\u2014The authors recently proposed a MIMO radar system that is implemented by a small wireless network. By applying compressive sensing (CS) at the receive nodes, the MIMO radar super-resolution can be achieved with far fewer observations than conventional approaches. This previous work considered the estimation of direction of arrival and Doppler. Since the targets are sparse in the angle-velocity space, target information can be extracted by solving an `1 minimization problem. In this paper, the range information is exploited by introducing step frequency to MIMO radar with CS. The proposed approach is able to achieve high range resolution and also improve the ambiguous velocity. However, joint angle-Doppler-range estimation requires discretization of the angle-Doppler-range space which causes a sharp rise in the computational burden of the `1 minimization problem. To maintain an acceptable complexity, a technique is proposed to successively estimate angle, Doppler and range in a decoupled fashion. The proposed approach can significantly reduce the complexity without sacrificing performance."], "link": "http://to-cs.blog.sohu.com/139997345.html", "bloglinks": {}, "links": {"http://www.dauphine.fr/": 1}, "blogtitle": "Compressive Sensing\uff1a\u4e00\u7f15\u6e05\u98ce"}, {"content": ["\u6628\u591c\u98ce\u58f0\u4e0e\u96e8\u58f0\u9f50\u4f5c\uff0c\u6687\u4e4b\u4f59\uff0c\u53f2\u8bb0\u76f8\u4f34\u3002 \n \u9ad8\u4e2d\u5b66\u8fc7\u79e6\u8bba\u4ee5\u6765\uff0c\u8111\u6d77\u91cc\u4e00\u76f4\u52fe\u753b\u8fc7\u8d3e\u8c0a\u54e5\u54e5\u67d4\u5f31\u517c\u521a\u6bc5\u7684\u5916\u8868\uff0c\u6728\u7eb3\u517c\u777f\u667a\u7684\u6027\u683c... \n \u6628\u5929\u6070\u597d\u8bfb\u5230\u53f2\u8bb0\u7684\u201c\u5c48\u539f\u8d3e\u751f\u5217\u4f20\u201d\uff0c\u5b57\u91cc\u884c\u95f4\uff0c\u90fd\u900f\u9732\u51fa\u53f2\u592a\u516c\u5bf9\u8d3e\u8c0a\u524d\u65e0\u53e4\u4eba\uff0c\u540e\u65e0\u6765\u8005\u822c\u667a\u6167\u7684\u60fa\u60fa\u76f8\u60dc\uff0c\u4e5f\u900f\u6f0f\u51fa\u5bf9\u8d3e\u8c0a\u9ad8\u5c1a\u4eba\u683c\uff0c\u5353\u8d8a\u89c1\u8bc6\u7684....\u3002\u96be\u602a\u201c\u79e6\u7687\u6c49\u6b66\uff0c\u7565\u8f93\u6587\u91c7\u3002\u3002\u3002\u201d\u7684\u8584\u53e4\u539a\u4eca\u7684\u6bdb\u8001\u7237\u5b50\u4e5f\u7981\u4e0d\u4f4f\u8d5e\u53f9\u4e24\u58f0\u201c\u5c11\u5e74\u501c\u50a5\u5eca\u5e99\u624d\uff0c\u58ee\u5fd7\u672a\u916c\u4e8b\u582a\u54c0\u3002\u80f8\u7f57\u6587\u7ae0\u5175\u767e\u4e07\uff0c\u80c6\u7167\u534e\u56fd\u6811\u5343\u53f0\u201d(NOTE,\u5c3d\u7ba1\u6709\u5f88\u591a\u4eba\u6000\u7591\u8fd9\u9996\u8bd7\u4e0d\u662f\u6bdb\u4e3b\u5e2d\u4ed6\u8001\u4eba\u5bb6\u7684\u4f5c\u54c1) \n \u5c3d\u7ba1\u53f2\u592a\u516c\u5c06\u8d3e\u8c0a\u4e0e\u5c48\u539f\u5e76\u5217\uff0c\u53ef\u89c1\u8d3e\u8c0a\u54e5\u54e5\u5728\u5176\u5fc3\u4e2d\u7684\u5730\u4f4d\uff1b\u5c3d\u7ba1\u5982\u6b64\uff0c\u4e2a\u4eba\u89c9\u5f97\uff0c\u5c48\u539f\u7684\u6028\u5987\u60c5\u8282\u4f3c\u4e4e\u8fc7\u91cd\uff0c\u653f\u6cbb\u80fd\u529b\u7565\u6709\u4e0d\u8db3\uff1b\u4e5f\u4e0d\u5e78\u7684\u662f\uff0c\u9047\u4e0a\u4e00\u4e2a\u660f\u541b\u695a\u6000\u738b\u3002\u7136\uff0c\u8d3e\u8c0a\uff0c\u4e0d\u4ec5\u4ec5\u654f\u800c\u597d\u5b66\uff0c\u535a\u95fb\u5f3a\u8bb0\uff1b\u4e5f\u4e0d\u4ec5\u4ec5\u80fd\u5c06\u67af\u71e5\u4e4f\u5473\u7684\u653f\u6cbb\u8ff0\u804c\u62a5\u544a\u5199\u5f97\u6587\u91c7\u6590\u7136\uff1b\u66f4\u96be\u5f97\u662f\uff0c\u8be5\u751f\u6709\u8d85\u51e1\u7684\u653f\u6cbb\u8fdc\u89c1\u548c\u6267\u653f\u80fd\u529b\uff0c\u4f8b\u5982\uff0c\u300a\u9648\u653f\u4e8b\u758f\u300b\uff0c\u60c5\u771f\u610f\u5207\uff0c\u4e0d\u4ec5\u5217\u4e3e\u5927\u6c49\u5e1d\u56fd\u9762\u4e34\u7684\u79cd\u79cd\u5371\u673a\uff0c\u800c\u4e14\u63d0\u51fa\u4e86\u8d85\u8d8a\u65f6\u4ee3\u7684\u89e3\u51b3\u65b9\u6cd5\uff0c\u4f8b\u5982 \n \u201c....\u6b32\u5929\u4e0b\u4e4b\u6cbb\u5b89\uff0c\u83ab\u82e5\u4f17\u5efa\u8bf8\u4faf\u800c\u5c11\u5176\u529b\u3002\u529b\u5c11\u5219\u6613\u4f7f\u4ee5\u4e49\uff0c\u56fd\u5c0f\u5219\u4ea1\u90aa\u5fc3......\u201d\u3002\u5947\u624d\u554a\uff01\u53ef\u60dc\u554a\uff0c\u6ca1\u6709\u53d1\u6325\u624d\u80fd\u7684\u821e\u53f0\uff01 \n \u6458\u5f55\u54e6\u4e00\u4e9b\u8bed\u53e5\u5982\u4e0b\uff0c \n \u3000\u3000\u8d3e\u751f\u4ee5\u4e3a\u6c49\u5174\u81f3\u5b5d\u6587\u4e8c\u5341\u9980\u5e74\uff0c\u5929\u4e0b\u548c\u6d3d\uff0c\u800c\u56fa\u5f53\u6539\u6b63\u6714\uff0c\u6613\u670d\u8272\uff0c\u6cd5\u5236\u5ea6\uff0c\u5b9a\u5b98\u540d\uff0c\u5174\u793c\u4e50\uff0c\u4e43\u6089\u8349\u5177\u5176\u4e8b\u4eea\u6cd5\uff0c\u8272\u5c1a\u9ec4\uff0c\u6570\u7528\u4e94\uff0c\u4e3a\u5b98\u540d\uff0c\u6089\u66f4\u79e6\u4e4b\u6cd5\u3002\u5b5d\u6587\u5e1d\u521d\u5373\u4f4d\uff0c\u8c26\u8ba9\u672a\u9051\u4e5f\u3002\u8bf8\u5f8b\u4ee4\u6240\u66f4\u5b9a\uff0c\u53ca\u5217\u4faf\u6089\u5c31\u56fd\uff0c\u5176\u8bf4\u7686\u81ea\u8d3e\u751f\u53d1\u4e4b\u3002\u65bc\u662f\u5929\u5b50\u8bae\u4ee5\u4e3a\u8d3e\u751f\u4efb\u516c\u537f\u4e4b\u4f4d\u3002\u7edb\u3001\u704c\u3001\u4e1c\u9633\u4faf\u3001\u51af\u656c\u4e4b\u5c5e\u5c3d\u5bb3\u4e4b\uff0c\u4e43\u77ed\u8d3e\u751f\u66f0\uff1a\u201c\u96d2\u9633\u4e4b\u4eba\uff0c\u5e74\u5c11\u521d\u5b66\uff0c\u4e13\u6b32\u64c5\u6743\uff0c\u7eb7\u4e71\u8bf8\u4e8b\u3002\u201d\u65bc\u662f\u5929\u5b50\u5f8c\u4ea6\u758f\u4e4b\uff0c\u4e0d\u7528\u5176\u8bae\uff0c\u4e43\u4ee5\u8d3e\u751f\u4e3a\u957f\u6c99\u738b\u592a\u5085\u3002 \u3000\u3000\u8d3e\u751f\u65e2\u8f9e\u5f80\u884c\uff0c\u95fb\u957f\u6c99\u5351\u6e7f\uff0c\u81ea\u4ee5\u5bff\u4e0d\u5f97\u957f\uff0c\u53c8\u4ee5\u9069\u53bb\uff0c\u610f\u4e0d\u81ea\u5f97\u3002\u53ca\u6e21\u6e58\u6c34\uff0c\u4e3a\u8d4b\u4ee5\u540a\u5c48\u539f\u3002\u5176\u8f9e\u66f0\uff1a \u3000\u3000\u5171\u627f\u5609\u60e0\u516e\uff0c\u4fdf\u7f6a\u957f\u6c99\u3002\u4fa7\u95fb\u5c48\u539f\u516e\uff0c\u81ea\u6c88\u6c68\u7f57\u3002\u9020\u8bac\u6e58\u6d41\u516e\uff0c\u656c\u540a\u5148\u751f\u3002\u906d\u4e16\u7f54\u6781\u516e\uff0c\u4e43\u9668\u53a5\u8eab\u3002\u545c\u547c\u54c0\u54c9\uff0c\u9022\u65f6\u4e0d\u7965\uff01\u9e3e\u51e4\u4f0f\u7a9c\u516e\uff0c\u9e31\u67ad\u7ff1\u7fd4\u3002\u9618\u8338\u5c0a\u663e\u516e\uff0c\u8c17\u8c00\u5f97\u5fd7\uff1b\u8d24\u5723\u9006\u66f3\u516e\uff0c\u65b9\u6b63\u5012\u690d\u3002\u4e16\u8c13\u4f2f\u5937\u8d2a\u516e\uff0c\u8c13\u76d7\u8dd6\u5ec9\uff1b\u83ab\u90aa\u4e3a\u987f\u516e\uff0c\u94c5\u5200\u4e3a\u929b\u3002\u4e8e\u55df\u569c\u569c\u516e\uff0c\u751f\u4e4b\u65e0\u6545\uff01\u65a1\u5f03\u5468\u9f0e\u516e\u5b9d\u5eb7\u74e0\uff0c\u817e\u9a7e\u7f62\u725b\u516e\u9a96\u8e47\u9a74\uff0c\u9aa5\u5782\u4e24\u8033\u516e\u670d\u76d0\u8f66\u3002\u7ae0\u752b\u8350\u5c66\u516e\uff0c\u6e10\u4e0d\u53ef\u4e45\uff1b\u55df\u82e6\u5148\u751f\u516e\uff0c\u72ec\u79bb\u6b64\u548e\uff01 \u3000\u3000\u8baf\u66f0\uff1a\u5df2\u77e3\uff0c\u56fd\u5176\u83ab\u6211\u77e5\uff0c\u72ec\u5819\u90c1\u516e\u5176\u8c01\u8bed\uff1f\u51e4\u6f02\u6f02\u5176\u9ad8\u9070\u516e\uff0c\u592b\u56fa\u81ea\u7f29\u800c\u8fdc\u53bb\u3002\u88ad\u4e5d\u6e0a\u4e4b\u795e\u9f99\u516e\uff0c\u6c95\u6df1\u6f5c\u4ee5\u81ea\u73cd\u3002\u5f25\u878d\u721a\u4ee5\u9690\u5904\u516e\uff0c\u592b\u5c82\u4ece\u8798\u4e0e\u86ed\u87be\uff1f\u6240\u8d35\u5723\u4eba\u4e4b\u795e\u5fb7\u516e\uff0c\u8fdc\u6d4a\u4e16\u800c\u81ea\u85cf\u3002\u4f7f\u9a90\u9aa5\u53ef\u5f97\u7cfb\u7f81\u516e\uff0c\u5c82\u4e91\u5f02\u592b\u72ac\u7f8a\uff01\u822c\u7eb7\u7eb7\u5176\u79bb\u6b64\u5c24\u516e\uff0c\u4ea6\u592b\u5b50\u4e4b\u8f9c\u4e5f\uff01\u779d\u4e5d\u5dde\u800c\u76f8\u541b\u516e\uff0c\u4f55\u5fc5\u6000\u6b64\u90fd\u4e5f\uff1f\u51e4\u7687\u7fd4\u4e8e\u5343\u4ede\u4e4b\u4e0a\u516e\uff0c\u89c8\u5fb7\ue407\u519b\u800c\u4e0b\u4e4b\uff1b\u89c1\u7ec6\u5fb7\u4e4b\u9669\u516e\uff0c\u6447\u589e\u7fee\u901d\u800c\u53bb\u4e4b\u3002\u5f7c\u5bfb\u5e38\u4e4b\u6c59\u6e0e\u516e\uff0c\u5c82\u80fd\u5bb9\u541e\u821f\u4e4b\u9c7c\uff01\u6a2a\u6c5f\u6e56\u4e4b\u9ce3\u9c9f\u516e\uff0c\u56fa\u5c06\u5236\u65bc\u8681\u877c\u3002 ..... \n \n \u597d\u4e86\uff0c\u56de\u5f52\u6b63\u9898\u3002 \n \u6709\u51e0\u4e2a\u5de5\u4f5c\u503c\u5f97\u63a8\u8350\uff0c \n \u30101\u3011Learning with compressible prior By Volkan Cevher \n Can be obtain by google search \n \u8bba\u6587\u6458\u8981\uff0c \n \n \u8be5\u8bba\u6587\u4e00\u4e2a\u91cd\u8981\u7684\u7ed3\u8bba\uff0c\u975e\u5e38\u91cd\u8981\u7684\u7ed3\u8bba\uff0c \n Oft-used generalized Gaussian and Laplacian models DO NOT support stable linear dimensional deduction! \n \n \n [2]Sampling Theorems for Signals from the Union of Finite-Dimensional Linear Subspaces \n BY, Thomas Blumensath\uff0c Mike E. Davies \n Can be obtained from arXiv \n \u8bba\u6587\u6458\u8981\uff0c \n Compressed sensing is an emerging signal acquisition technique that enables signals to be sampled well below the Nyquist rate, given that the signal has a sparse representation in an orthonormal basis. In fact, sparsity in an orthonormal basis is only one possible signal model that allows for sampling strategies below the Nyquist rate. In this paper we consider a more general signal model and assume signals that live on or close to the union of linear subspaces of low dimension. We present sampling theorems for this model that are in the same spirit as the Nyquist-Shannon sampling theorem in that they connect the number of required samples to certain model parameters. Contrary to the Nyquist-Shannon sampling theorem, which gives a necessary and sufficient condition for the number of required samples as well as a simple linear algorithm for signal reconstruction, the model studied here is more complex. We therefore concentrate on two aspects of the signal model, the existence of one to one maps to lower dimensional observation spaces and the smoothness of the inverse map. We show that almost all linear maps are one to one when the observation space is at least of the same dimension as the largest dimension of the convex hull of the union of any two subspaces in the model. However, we also show that in order for the inverse map to have certain smoothness properties such as a given finite Lipschitz constant, the required observation dimension necessarily depends logarithmically on the number of subspaces in the signal model. In other words, whilst unique linear sampling schemes require a small number of samples depending only on the dimension of the subspaces involved, in order to have stable sampling methods, the number of samples depends necessarily logarithmically on the number of subspaces in the model. These results are then applied to two examples, the standard compressed sensing signal model in which the signal has a sparse representation in an orthonormalbasis and to a sparse signal model with additional tree structure\u3002 \n \n \u8be5\u8bba\u6587\u5728union of subspace\u6846\u67b6\u4e0b\u8ba8\u8bba\u4e86\u4e24\u4e2a\u91cd\u8981\u7684\u95ee\u9898\uff0c\u7b2c\u4e00\u662f\u7b97\u5b50\u7684one-to-one\u5b58\u5728\u6027\u95ee\u9898\uff0c\u5176\u83b7\u5f97\u7684\u7ed3\u8bba\u4e0eDo\u7b49\u4eba\u7684\u7ed3\u8bba\u76f8\u4f3c\uff0c\u5373\uff0c\u6d4b\u91cf\u6570\u636eM>=2k\uff0ck\u4e3a\u7a00\u758f\u5ea6(\u53ef\u4ee5\u63a8\u5e7f\u7406\u89e3\u201c\u7a00\u758f\u5ea6\u201d\u8fd9\u4e2a\u6982\u5ff5)\uff1b\u7b2c\u4e8c\u4e2a\u95ee\u9898\u662f\u6709\u6548\u89e3\u7b97\u6cd5\u5b58\u5728\u7684\u95ee\u9898\uff0c\u5373\uff0c \n \u7531\u4e0a\u8ff0\u5b9a\u7406\u53ef\u4ee5\u770b\u51fa\uff0c\u7531\u4e8esubspace\u66f4\u6709\u6548\u5730\u5efa\u7acb\u4fe1\u53f7\u6a21\u578b\uff0c\u56e0\u6b64\uff0c\u6240\u9700\u6d4b\u91cf\u6570\u636e\u660e\u663e\u51cf\u5c11\uff01 \n \n \u30103\u3011Why do commercial CT scanners still employ traditional, filtered back-projection for image reconstruction? \n BY, Xiaochuan Pan, Emil Y Sidky and Michael Vannier \n doi:10.1088/0266-5611/25/12/123009 \n \n \u8bba\u6587\u6458\u8981\uff0c \n Despite major advances in x-ray sources, detector arrays, gantry mechanical design and especially computer performance, one component of computed tomography (CT) scanners has remained virtually constant for the past 25 years\u2014the reconstruction algorithm. Fundamental advances have been made in the solution of inverse problems, especially tomographic reconstruction, but these works have not been translated into clinical and related practice. The reasons are not obvious and seldom discussed. This review seeks to examine the reasons for this discrepancy and provides recommendations on how it can be resolved. We take the example of field of compressive sensing (CS), summarizing this new area of research from the eyes of practical medical physicists and explaining the disconnection between theoretical and application-oriented research. Using a few issues specific to CT, which engineers have addressed in very specific ways, we try to distill the mathematical problem underlying each of these issues with the hope of demonstrating that there are interesting mathematical problems of general importance that can result from in depth analysis of specific issues. We then sketch some unconventional CT-imaging designs that have the potential to impact on CT applications, if the link between applied mathematicians and engineers/physicists were stronger. Finally, we close with some observations on how the link could be strengthened. There is, we believe, an important opportunity to rapidly improve the performance of CT and related tomographic imaging techniques by addressing these issues. \n \u8fd9\u7bc7\u8bba\u6587\u4ece\u5de5\u7a0b\u5e94\u7528\u89d2\u5ea6\u8bba\u8ff0\u4e86cs\u5728MRI\u5e94\u7528\u4e2d\u7684\u4e00\u4e9b\u95ee\u9898\uff0c\u56e0\u4e3a\u8be5\u89c2\u70b9\u662f\u4eceMRI\u89d2\u5ea6\u51fa\u53d1\uff0c\u6240\u4ee5\uff0c\u5176\u89c2\u70b9\u96be\u514d\u6709\u5931\u516c\u5141\uff0c\u65e0\u8bba\u5982\u4f55\uff0c\u4e00\u4e2a\u5f88\u597d\u7684review\u6587\u7ae0\uff0c\u503c\u5f97\u53c2\u8003\u3002"], "link": "http://to-cs.blog.sohu.com/139717675.html", "bloglinks": {}, "links": {}, "blogtitle": "Compressive Sensing\uff1a\u4e00\u7f15\u6e05\u98ce"}, {"content": ["\u6700\u8fd1\u8bfb\u4e86\u4e00\u904dT. Blumensath\u548cM. E. Davies\u7684\u201citerative thresholding for sparse approximations\u201d\u53ca\"Normalised Iterative Hard Thresholding;guaranteed stability and performance\"\u7b49\u4e00\u7cfb\u5217\u6587\u7ae0\u3002\u4e00\u76f4\u4ee5\u6765\u603b\u662f\u89c9\u5f97\u4ed6\u4eec\u5bf9\u6536\u655b\u6027\u95ee\u9898\u7684\u7814\u7a76\u6709\u70b9\u70e6\u7410\uff0c\u800c\u4e14\u6536\u655b\u6027\u7684\u7ed3\u679c\u6709\u70b9\u95ee\u9898\uff0c\u5177\u4f53\u6765\u8bf4\uff0c\u4ee5sparse signal \u91cd\u5efa\u4e3a\u4f8b\uff0c\u4ed6\u4eec\u7684\u7ed3\u679c\u5982\u4e0b\uff0c \n \u4ed6\u4eec\u5f97\u5230\u8fd9\u4e2a\u7ed3\u679c\u7684\u51fa\u53d1\u70b9\u662f\u5efa\u7acbsurrogate\u51fd\u6570\uff0c\u4e3a\u6b64\u5960\u5b9a\u4e86norm(hui,2)<1\u7684\u8fd9\u4e2a\u6761\u4ef6\u3002 \n \u6211\u7684\u7ed3\u8bba\u5982\u4e0b\uff0c \n \n \u8bc1\u660e\u601d\u8def\u5982\u4e0b\uff0c"], "link": "http://to-cs.blog.sohu.com/139401854.html", "bloglinks": {}, "links": {}, "blogtitle": "Compressive Sensing\uff1a\u4e00\u7f15\u6e05\u98ce"}, {"content": ["\u524d\u4e00\u6bb5\u65f6\u95f4\uff0c\u53d7\u56fd\u5185\u67d0\u4e2a\u6742\u5fd7\u7684\u9080\u8bf7\uff0c\u5199\u4e00\u7bc7\u5173\u4e8e\u538b\u7f29\u611f\u77e5\u65b9\u9762review\u7684\u6587\u7ae0\uff0c\u5475\u5475\u3002\u5199review\u7684\u6587\u7ae0\uff1f\u8fd9\u4e2a\u96be\u5ea6\u592a\u5927\uff0c\u592a\u5927\uff0c\u592a\u5927\u4e86\uff1b\u7cbe\u529b\u6709\u9650\uff0c\u80fd\u529b\u6709\u9650\uff0c\u6240\u4ee5\u8c22\u7edd\u4e86\u8fd9\u4e2a\u9080\u8bf7\u3002\u4f46\u90a3\u65f6\u4e5f\u51b3\u5b9a\u7528\u4e00\u4e9b\u8f7b\u677e\u7684\u6587\u5b57\u6765\u8c03\u4f83\u4e00\u4e0b\u8fd9\u4e2a\u8bdd\u9898\uff0c \u56e0\u4e3a\u8fd9\u7c7b\u578b\u7684\u6587\u5b57\u6240\u9700\u627f\u62c5\u7684\u8d23\u4efb\u662f\u6700\u5c0f\u7684\uff0c\u5475\u5475J\u3002\u7136\u800c\u4e00\u76f4\u4ee5\u6765\u90fd\u6bd4\u8f83\u5fd9\uff0c\u6240\u4ee5\uff0c\u2026..,, \u5929\u9042\u4eba\u613f\u963f\uff0c\u6070\u9022\u611f\u6069\u8282\u957f\u77ed\u9002\u4e2d\u7684\u5047\u671f\uff0c\u7ec8\u4e8e\u6709\u673a\u4f1a\u5199\u5199\u3002 \n \n \u8bf4\u8d77\u7a00\u758f\u91cd\u5efa\uff0c\u5c31\u4e0d\u5f97\u4e0d\u8bf4\u201c\u7a00\u758f\u201d\u7684\u5ea6\u91cf\u3002\u4e8b\u5b9e\u4e0a\uff0c\u5b83\u7684\u6839\u690d\u571f\u58e4\u6781\u5176\u7684\u80a5\u6c83\u3002\u76f4\u767d\u6765\u8bf4\uff0c\u7a00\u758f\u5c31\u662f\u5e7f\u88a4\u65e0\u57a0\u6c99\u6f20\u4e0a({x: Ax=b})\u7684\u82e5\u5e72\u5339\u9a86\u9a7c(min|x|_1,s.t. Ax=b)\uff0c\u5f53\u7136\uff0c\u5982\u679c\u5f00\u5fc3\uff0c\u4f60\u53ef\u4ee5\u7528\u5176\u5b83\u7684\u6bd4\u55bb\u6765\u63cf\u8ff0\u3002\u90a3\u4e48\uff0c\u201c\u7a00\u758f\u91cd\u5efa\u201d\u5c31\u662f\u6709\u52c7\u6c14\u8d70\u8fdb\u6c99\u6f20\uff0c\u628a\u8fd9\u4e9b\u9a86\u9a7c\u627e\u51fa\u6765\u3002\u4e8b\u5b9e\u4e0a\uff0c\u5de5\u7a0b\u4eba\u5458\u66f4\u559c\u6b22\u7528\u201c\u63a2\u6d4b(detection)\u201d\u8fd9\u4e2a\u591a\u5c11\u6709\u70b9\u548c\u853c\u53ef\u4eb2\u5473\u9053\u7684\u5b57\u773c\u3002\u6240\u8c13\u201c\u63a2\u6d4b\u201d\u53ef\u4ee5\u5927\u81f4\u5206\u4e3a\u4e09\u7c7b\uff1a\u7b2c\u4e00\u7c7b\u597d\u6bd4\u53bb\u63a2\u6d4b\u5916\u661f\u4eba\u662f\u5426\u5b58\u5728\uff0c\u662f\u5426\u80fd\u63a2\u6d4b\u5230\u5916\u661f\u4eba\u5e76\u4e0d\u5173\u952e\uff0c\u5173\u952e\u7684\u662f\u6211\u4eec\u66fe\u7ecf\u6709\u8fd9\u6837\u7684\u7ecf\u5386\uff0c\u8fd9\u6216\u8bb8\u591a\u5c11\u6709\u70b9\u70e7\u94b1\u7684\u611f\u89c9\u3002\u7b2c\u4e8c\u7c7b\u63a2\u6d4b\u76ee\u6807\u5f88\u660e\u786e\uff0c\u4f46\u662f\u80fd\u5426\u5982\u671f\u63a2\u6d4b\u5230\u76ee\u6807\u53ea\u6709\u5929\u77e5\u9053\u3002\u8fd9\u79cd\u63a2\u6d4b\u591a\u5c11\u6765\u7684\u5f88\u8f9b\u82e6\uff0c\u5c31\u597d\u6bd4\u8001\u7f8e\u7ffb\u6398\u963f\u5bcc\u6c57\u5bfb\u627e\u672c\u62c9\u767b\uff0c\u4f46\u5747\u65e0\u529f\u800c\u8fd4\u3002\u95ee\u9898\u5728\u4ec0\u4e48\u5730\u65b9\u5462\uff1f\u672c\u62c9\u767b\u90a3\u4e2a\u5bb6\u4f19\u4f1a\u52a8\u554a\uff0c\u800c\u4e14\u662f\u4e0d\u505c\u7684\u52a8, \u9b3c\u77e5\u9053\u4ed6\u4e0b\u4e00\u4e2a\u65f6\u523b\u8dd1\u4ec0\u4e48\u5730\u65b9\u53bb\u4e86\uff1f\u7b2c\u4e09\u7c7b\u597d\u6bd4\u9756\u54e5\u54e5\u82e6\u89c5\u84c9\u59b9\u59b9\uff08\u5176\u4e2d\u5047\u8bbe\u6211\u4eec\u628a\u84c9\u59b9\u59b9\u56fa\u5b9a\u5728\u6843\u82b1\u5c9b\u7684\u7b2ci\u68f5\u5927\u6811\u65c1\u8fb9\uff0c\u800c\u4e14\u5176\u5b83\u6811\u65c1\u4e5f\u56fa\u5b9a\u5f62\u5f62\u8272\u8272\u7684mm\uff09\uff0c\u832b\u832b\u4eba\u6d77\uff0c\u4f46\u76ee\u6807\u660e\u786e\uff0c\u6781\u5176\u70c2\u6f2b\u60ec\u610f (\u53ef\u80fd\u5f88\u591a\u4eba\u4e0d\u592a\u540c\u610f\u8fd9\u4e2a\u89c2\u70b9\uff0c\u5f53\u7136\uff0c\u8fd9\u533a\u522b\u4e8e\u84e6\u7136\u56de\u9996\uff0c\u90a3\u4eba\u5374\u5728\u706f\u706b\u9611\u73ca\u5904\u7684\u611f\u89c9)\uff0c\u8fd9\u624d\u662f\u6211\u4eec\u5173\u5fc3\u7684\u7a00\u758f\u91cd\u5efa\u3002 \n \u8981\u5728\u832b\u832b\u4eba\u6d77\u4e2d\u5bfb\u627e\u4f60\u7684\u84c9\u59b9\u59b9\uff0c\u90a3\u4e48\u4f60\uff0c\u6216\u8005\u4f60\u4f7f\u7528\u7684\u5de5\u5177\u4e00\u5b9a\u5f97\u5177\u6709\u5f3a\u6709\u529b\u7684\u201ddirectivity\u201d\u6216\u5206\u8fa8\u7387\uff0c\u5426\u5219\u5f88\u591a\u4eba\u90fd\u53ef\u80fd\u6210\u4e3a\u4f60\u7684\u201c\u84c9\u59b9\u59b9\u201d(uncertainty)\u800c\u4e0a\u9519\u82b1\u8f7f\u3002\u7528\u6570\u5b66\u6216\u7269\u7406\u7684\u8bed\u8a00\u6765\u63cf\u8ff0\uff0c\u5c31\u662f\u4f60\u7684\u5ea6\u91cf\u5de5\u5177\u4e00\u5b9a\u662f\u201c\u5404\u5411\u5f02\u6027\u201d\uff0c\u800c\u4e0d\u662f\u201c\u5404\u5411\u540c\u6027\u201d\u3002\u5173\u4e8e\u8fd9\u4e00\u70b9\uff0c\u6bd4\u8f83Lp(0<=p<=1)\u7403\u548cL2\u7403\u5c31\u4e0d\u96be\u7406\u89e3\u3002\u5728\u8fd9\u91cc\u7a0d\u5fae\u505c\u987f\u4e00\u4e0b\uff0c\u7f57\u55e6\u51e0\u53e5\u5173\u4e8e\u201dL1\u201d\u4f18\u5316\u7684\u4e00\u70b9\u4e8b\u60c5\u3002\u6211\u4eec\u77e5\u9053\uff0c\u4ece\u67d0\u4e2a\u5c42\u9762\u6765\u8bb2\uff0c\u6570\u5b66\u7279\u6027\u7684\u4e0d\u53cb\u597d\uff08nonsmooth\uff09\u4f7f\u5176\u8499\u4e0a\u51e0\u9053\u8d25\u7b14(\u4f46\u662f\u4ece\u53e6\u5916\u4e00\u4e2a\u5c42\u9762\uff0c\u5c31\u662f\u5728\u8fd9\u4e2a\u4e0d\u53cb\u597d\u7684\u7279\u6027\u4e0b\u8574\u6db5\u4e86\u6781\u5177\u751f\u547d\u529b\u7684soft-threshold\u7b97\u6cd5\uff0c \u8fd9\u662f\u540e\u8bdd\uff0c\u6682\u4e14\u7565\u8fc7)\uff0c\u5f88\u591a\u4eba\u8f9b\u8f9b\u82e6\u82e6\u53bbsmooth\u8fd9\u4e2a\u6ee1\u8eab\u662f\u523a\u7684bad boy\uff0c\u4f8b\u5982\uff0c\u5178\u578b\u7684NESTA\u7b97\u6cd5\u3002\u5475\u5475\uff0c\u5728\u8fd9\u91cc\u518d\u591a\u8bf4\u51e0\u53e5\u5e9f\u8bdd\u3002\u5982\u679c\u4f7f\u5176\u5ea6\u91cf\u5de5\u5177\u5177\u6709\u5404\u5411\u5f02\u6027\uff0c\u6216\u8005directivity\u7684\u7279\u6027\uff0c\u6211\u4eec\u4e0d\u59a8\u4ece\u9635\u5217\u5929\u7ebf\u7684\u89d2\u5ea6\u8bf4\u8bf4\u3002\u5177\u6709\u5929\u7ebf\u6216\u6ee4\u6ce2\u5668\u7406\u8bba\u80cc\u666f\u7684\u4eba\u5747\u77e5\u9053\uff0c\u653e\u7f6e\u4e00\u4e2a\u70b9\u6e90\u7684\u8f90\u5c04\u7279\u6027\u662fexp(jkr)/r, \u5176\u529f\u80fd\u662f\u5728\u6574\u4e2a\u7a7a\u95f4\u6781\u5176\u516c\u5e73\u7684\u8f90\u5c04\u5b83\u7684\u80fd\u91cf\uff0c\u5373\uff0cl2\u7403\u3002\u5982\u679c\u6211\u4eec\u6309\u7167\u67d0\u79cd\u89c4\u5219\u591a\u653e\u7f6e\u51e0\u4e2a\u8fd9\u6837\u7684\u70b9\u6e90\uff0c\u5219\u53ef\u4ee5\u5f62\u6210\u671f\u671b\u7684\u65b9\u5411\u56fe\uff0c\u5373\uff0clp\u7403(p<2)\u3002\u5f53\u7136\uff0c\u5982\u679c\u4f60\u613f\u610f\uff0c\u8fd9\u79cd\u201d\u7403\u201d\u8fd8\u5177\u6709\u4e86\u201dreweighted\u201d\u7684\u7279\u70b9\uff0c\u4e5f\u5c31\u662f\u8bf4\u53ef\u4ee5\u5728\u4e0d\u540c\u7684\u65b9\u5411\u8bbe\u7f6e\u5176\u4e0d\u540c\u7684\u8f90\u5c04\u5f3a\u5ea6\u3002\u5f53\u7136\uff0c\u8fd9\u79cd\u60c5\u51b5\u4e0b\u6240\u8bbe\u8ba1\u7684\u201c\u7a00\u758f\u5ea6\u91cf\u201d\u5177\u6709\u975e\u5e38\u53cb\u597d\u7684\u6570\u5b66\u7279\u6027\uff0c\u5149\u6ed1\uff0c\u975e\u5e38\u5149\u6ed1\u3002\u4e5f\u6216\u8bb8\uff0c\u4f60\u53ef\u4ee5\u7528\u8fd9\u79cd\u7b56\u7565\u8bbe\u8ba1\u4f60\u7684\u201c\u7a00\u758f\u6b63\u5219\u5316\u201d\u51fd\u6570(\u5982\u679c\u4f60\u7528\u8fd9\u4e2a\u601d\u60f3\u8bbe\u8ba1\u4e86\u4ee4\u4eba\u6ee1\u610f\u7684\u6b63\u5219\u5316\u51fd\u6570\uff0c\u4e0d\u8981\u5fd8\u4e86\u611f\u8c22\u6211\u54e6\uff0cJ)\u3002 \n \n \n \u8bf4\u5b8c\u7a00\u758f\u548c\u7a00\u758f\u5ea6\u91cf\uff0c\u63a5\u4e0b\u6765\u8bf4\u7a00\u758f\u91cd\u5efa\u3002\u54c7\uff0c\u8fd9\u662f\u4e00\u4e2a\u6781\u5176\u55a7\u95f9\u7684\u5e02\u573a\uff0c\u5404\u79cd\u53eb\u5356\u58f0\u6b64\u8d77\u5f7c\u4f0f\u3002\u628a\u6211\u4eec\u7684\u955c\u5934\u5bf9\u51c6\u57fa\u4e8el1\u7ea6\u675f\u7684\u7a00\u758f\u91cd\u5efa\uff0c\u5728\u6b64\u6846\u67b6\u4e0b\uff0c\u5176\u4e2d\u6709\u4e09\u7c7b\u95ee\u9898\u662f\u9887\u53d7\u6b22\u8fce\u7684\uff0c\u7b2c\u4e00\u7c7b\u5c31\u662f(BP)_sig\u95ee\u9898\uff0c\u5373\uff0cmin{norm(x,1)}, s.t., norm(Ax-b,2)<sig\uff1b\u7b2c\u4e8c\u7c7b\u95ee\u9898\u662fLASSO\u95ee\u9898\uff0c\u5373\uff0cmin{norm(Ax-b,2)}\uff0c s.t. norm(x,1)<=tao; \u7b2c\u4e09\u7c7b\u95ee\u9898\u662fQP_lambda\u95ee\u9898\uff0c\u5373\uff0cmin{lambda*norm(x,1)+norm(Ax-b,2)}\u3002\u8fd9\u4e09\u7c7b\u95ee\u9898\u5728\u4e09\u79cd\u4e0d\u540c\u7684\u5148\u9a8c\u4fe1\u606f\u6761\u4ef6\u4e0b\uff0c\u4ece\u4e09\u4e2a\u4e0d\u540c\u7684\u89d2\u5ea6\u63cf\u8ff0\u4e86\u7a00\u758f\u91cd\u5efa\u95ee\u9898\uff0c\u5e76\u4e14\u5728\u5404\u81ea\u7684\u5206\u652f\u5185\u8bde\u751f\u4e86\u5404\u81ea\u5177\u6709\u9c9c\u660e\u7279\u5f81\u7684\u7b97\u6cd5\u3002\u5c3d\u7ba1\u5982\u6b64\uff0c\u5982\u6b64\u540c\u6e90\u7684\u4e09\u4e2a\u95ee\u9898\u81ea\u7136\u6709\u5343\u4e1d\u4e07\u7f15\u7684\u5185\u5728\u5173\u7cfb\uff0c\u4f8b\u5982\uff0cPareto\u66f2\u7ebf\u5c31\u6dcb\u6f13\u5c3d\u81f4\u5730\u63cf\u8ff0\u4e86\u8fd9\u4e09\u7c7b\u95ee\u9898\u4e4b\u95f4\u7684\u76f8\u4e92\u4f9d\u5b58\u5173\u7cfb\u3002\u7efc\u89c2\u76ee\u524d\u7684\u4e00\u4e9b\u4f18\u79c0\u7b97\u6cd5\uff0c\u7b97\u6cd5\u53d1\u5c55\u4e0d\u5916\u4e4e\u4ee5\u4e0b\u4e09\u79cd\u7b56\u7565\uff1a\u7b2c\u4e00\u7c7b\u95ee\u9898\u7684\u96be\u70b9\u662f\u975e\u5149\u6ed1\u76ee\u6807\u51fd\u6570norm(x,1)\uff0c\u56e0\u6b64\u5176\u6838\u5fc3\u662fnorm(x,1)\u7684\u5149\u6ed1\u5316\u6280\u672f, \u4f8b\u5982\uff0cBarrier\u65b9\u6cd5\uff0cNESTA\uff0c PANS, \u7b49\u3002\u7b2c\u4e8c\u7c7b\u95ee\u9898\u63cf\u8ff0\u4e86{x: Ax=b}\u89e3\u5728norm(x,1)<=tao\u7684\u6295\u5f71\u95ee\u9898\uff0c\u56e0\u6b64\u8be5\u95ee\u9898\u7684\u6838\u5fc3\u662f\u5904\u7406L1-\u7403\u7684\u6295\u5f71\u95ee\u9898\uff0c\u4f8b\u5982\uff0cSPGL1\u3002\u7b2c\u4e09\u7c7b\u95ee\u9898\u7684\u96be\u70b9\u662f\u6570\u636e\u5931\u914d\u548c\u6b63\u5219\u5316\u9879\u7684\u5e73\u8861\uff0c\u56e0\u6b64\u5176\u96be\u70b9\u662flambda\u7684\u9009\u62e9, \u5982\u679c\u9009\u62e9\u4e86\u5408\u9002\u7684lambda\uff0c\u90a3\u4e48\u67f3\u6697\u82b1\u660e\u53c8\u4e00\u6751\uff0cnorm(x,1)\u5bfc\u6570\u7684\u7b26\u53f7\u5206\u5e03\u7279\u6027\u7ed9\u4f60\u655e\u5f00\u4e86\u5bbd\u9614\u7684\u5927\u95e8\uff0c\u4f8b\u5982\uff0csoft-threshold\u7b56\u7565\u3002\u5f53\u7136\uff0c\u4e0a\u8ff0\u65b9\u6cd5\u7684\u4e92\u76f8\u5ac1\u63a5\u4e5f\u8bde\u751f\u4e86\u5f62\u5f62\u8272\u8272\u7684\u4f18\u79c0\u513f\u5973. \n NOTE\uff1a \n \u7b2c\u4e00\u526f\u56fe\u6765\u81earice\u5927\u5b66\u5173\u4e8ecompressive sensing\u7684ppt\u6559\u7a0b\uff0c\u7b2c\u4e8c\u5e45\u6765\u81ea\u9b4f\u6587\u5143\u548c\u5bab\u5fb7\u660e\u7f16\u5199\u7684\u201c\u5929\u7ebf\u539f\u7406\u201d\u3002\u5728\u6b64\u4e00\u5e76\u611f\u8c22\u3002"], "link": "http://to-cs.blog.sohu.com/138250047.html", "bloglinks": {}, "links": {}, "blogtitle": "Compressive Sensing\uff1a\u4e00\u7f15\u6e05\u98ce"}, {"content": ["\u6700\u8fd1\u5fd9\u7740\u6574\u7406\u6587\u7ae0\uff0c\u6240\u4ee5\u6ca1\u65f6\u95f4\u6765\u8fd9\u91cc\u66f4\u65b0\u5e16\u5b50\uff1b\u660e\u5929\u5c31\u662fthanksgiving\uff0c\u6240\u4ee5\u4eca\u5929\u591a\u8d34\u51e0\u7bc7\u6587\u7ae0\u3002 \n \u8bb0\u5f97\u5728\u524d\u9762\u6211\u5df2\u7ecf\u8d34\u8fc7Donoho\u7b49\u4eba\u5173\u4e8e\"Message passing algorithm\"\u7684\u4e00\u4e2a\u5de5\u4f5c\uff0c\u4eca\u5929\u4eceIgor\u7684\u535a\u5ba2\u4e86\u89e3\u5230\u8fd9\u4e2a\u5de5\u4f5c\u6709\u8fdb\u4e00\u6b65\u7684\u53d1\u5c55(\u8fd9\u4e24\u4e2a\u5de5\u4f5c\u5747\u53ef\u4ee5\u5728arXiv.org\u4e0adownload)\uff0c\u5177\u4f53\u6765\u8bf4\uff0c \n [1]Message Passing Algorithms for Compressed Sensing: I. Motivation and Construction \n \u8bba\u6587\u6458\u8981\uff0c \n Abstract\u2014In a recent paper, the authors proposed a new class of low-complexity iterative thresholding algorithms for reconstructing sparse signals from a small set of linear measurements [1]. The new algorithms are broadly referred to as AMP, for approximate message passing. This is the first of two conference papers describing the derivation of these algorithms, connection with the related literature, extensions of the original framework, and new empirical evidence. In particular, the present paper outlines the derivation of AMP from standard sum-product belief propagation, and its extension in several directions. We also discuss relations with formal calculations based on statistical mechanics methods. \n [2]Message Passing Algorithms for Compressed Sensing: II. Analysis and Validation \n \u8bba\u6587\u6458\u8981\uff0c \n Abstract\u2014In a recent paper, the authors proposed a new class of low-complexity iterative thresholding algorithms for reconstructing sparse signals from a small set of linear measurements [1]. The new algorithms are broadly referred to as AMP, for approximate message passing. This is the second of two conference papers describing the derivation of these algorithms, connection with related literature, extensions of original framework, and new empirical evidence. This paper describes the state evolution formalism for analyzing these algorithms, and some of the conclusions that can be drawn from this formalism. We carried out extensive numerical simulations to confirm these predictions. We present here a few representative results. \n \n \u6bcb\u5eb8\u7f6e\u7591\uff0ccompressive sensing\u5728THZ,\u5149\u5b66,\u91cf\u5b50\u7b49\u6210\u50cf\u9886\u57df\u5c06\u53d1\u6325\u975e\u5e38\u91cd\u8981\u7684\u4f5c\u7528\uff0c\u4eca\u5929\u8d34\u7684\u7b2c\u4e8c\u4e2a\u4e8b\u60c5\u662f\u5173\u4e8eghost imaging\u548coptics imaging\u7684\u4e24\u4e2a\u5de5\u4f5c\u5de5\u4f5c\uff0c \n \n \u30101\u3011\u8bba\u6587\u9898\u76ee\uff0c \n Fourier-transfrom Ghost Imaging for pure phase object based on Compressive Sampling algorithm \n \u8bba\u6587\u6458\u8981\uff0c \n A special algorithm for the Fourier-transform Ghost Imaging (GI) scheme is discussed based on the Compressive Sampling (CS) theory. Though developed mostly in real space, CS algorithm could also be used for the Fourier spectrum reconstruction of pure phase object by setting a proper sensing matrix. This could find its application in diffraction imaging of X-ray, neutron and electron with higher efficiency and resolution. Simulation and experiment results are also presented to prove the feasibility. \n \n \n \n \n \u30102\u3011J.Ma\u7684single pixel imaging system,\u8be5\u8bba\u6587\u8bd5\u56fe\u8bbe\u8ba1satellite on-board\u7684single-pixel system\uff0c\u7528\u6570\u503c\u6a21\u62df\u4eff\u771f\u7684\u65b9\u6cd5\u8bba\u6587\u5176\u53ef\u884c\u6027\u3002 \n \u8bba\u6587\u9898\u76ee\uff0c \n A Single-Pixel Imaging System for Remote Sensing by Two-Step Iterative Curvelet Thresholding \n Download from \n IEEE GEOSCIENCE AND REMOTE SENSING LETTERS, VOL. 6, NO. 4, OCTOBER 2009 \n \u8bba\u6587\u6458\u8981\uff0c \n Abstract\u2014Recently, a new framework named compressed sensing (CS) for the simultaneous sampling and compression of signals has been applied for panoramic-view imaging in aerospace remote sensing. By CS, it is possible for us to take superresolution photographs using only one or a few pixels rather than a million pixels by conventional digital cameras. However, the most popular approach of satellite/airborne remote sensing is line-scan imaging instead of panoramic-view imaging. In this letter, we propose a single-pixel imaging system for line-scan onboard cameras by applying compressive-scanning matrices in a sensing step and a two-step iterative curvelet thresholding method in an offline decoding step, which converges faster than previous single-step iterative thresholding methods. Numerical experiments show good performance of the proposed method for remote sensing. Results indicate the need to design practical single-pixel remote sensing instruments involving less storage space, less power consumption, and smaller size than the currently used charged-coupled-device cameras."], "link": "http://to-cs.blog.sohu.com/137836071.html", "bloglinks": {}, "links": {}, "blogtitle": "Compressive Sensing\uff1a\u4e00\u7f15\u6e05\u98ce"}, {"content": ["\u6700\u8fd1\u505a\u4e86\u8bb8\u591a\u5173\u4e8efirst-order\u7684\u5de5\u4f5c\uff0c\u4eca\u5929\u5728\u8fd9\u91cc\u5520\u53e8\u4e24\u53e5\u3002\u8bb0\u5f97\u5728\u524d\u9762\u63d0\u53ca\u5230Bregman\uff0cNesterov\u7b49first-order\u6700\u4f18\u5316\u7b97\u6cd5\uff0c\u8fd9\u4e24\u4e2a\u7b97\u6cd5\u540c\u5c5e\u4e8eproximal gradient\u7c7b\u7b97\u6cd5\uff0c\u62e5\u6709\u8bf1\u4eba\u7684\u8ba1\u7b97\u901f\u5ea6\uff1b\u5e76\u4e14\u4ee4\u4eba\u9ad8\u5174\u7684\u662f\u8fd9\u4e9b\u7b97\u6cd5\u6709\u575a\u5b9e\u7684\u7406\u8bba\u57fa\u7840\u4f5c\u4e3a\u4fdd\u969c\uff0c\u5f53\u7136\u9700\u8981\u5728convex\u51fd\u6570\u7684\u6846\u67b6\u4e0b\u3002\u4eca\u5929\u518d\u8d34\u4e00\u4e2a\u76f8\u5173\u7684\u5de5\u4f5c\uff0c \n PARNES: A RAPIDLY CONVERGENT ALGORITHM FOR ACCURATE RECOVERY OF SPARSE AND APPROXIMATELY SPARSE SIGNALS \n (NOTE, can be downloaded from arXiv.org) \n BY, MING GU, LEK-HENG LIM, AND CINNA JULIE \n \u8bba\u6587\u6458\u8981\uff0c \n In this article we propose an algorithm, parnes, for the basis pursuit denoise problem bp(\\u001B) which approximately nds a minimum one-norm solution to an underdetermined least squares problem. parnes, (1) combines what we think are the best features of currently available methods spgl1 [35] and nesta [3], and (2) incorporates a new improvement that exhibits linear convergence under the assumption of the restricted isometry property (rip). As with spgl1, our approach `probes the Pareto frontier' and determines a solution to the bpdn problem bp(\\u001B) by exploiting the relation between the lasso problem ls(\\u001C) and bp(\\u001B) given by their Pareto curve. As with nesta we rely on the accelerated proximal gradient method proposed by Yu. Nesterov [27, 26] that takes a remarkable O(pL=\") iterations to come within \\u000F > 0 of the optimal value, where L is the Lipschitz constant of the gradient of the objective function. Furthermore we introduce an `outer loop' that regularly updates the prox center. Nesterov's accelerated proximal gradient method then becomes the `inner loop'. The restricted isometry property together with the Lipschitz di erentiability of our objective function permits us to derive a condition for switching between the inner and outer loop in a provably optimal manner. A by-product of our approach is a new algorithm for the lasso problem that also exhibits linear convergence under rip."], "link": "http://to-cs.blog.sohu.com/137629178.html", "bloglinks": {}, "links": {}, "blogtitle": "Compressive Sensing\uff1a\u4e00\u7f15\u6e05\u98ce"}, {"content": ["\u4eca\u5929\u8d34\u6211\u548cJafarpour\u5408\u4f5c\u7684\u4e24\u4e2a\u5de5\u4f5c\uff0c\u57fa\u4e8e\u6d41\u4f53\u6a21\u578b\u7684\u77f3\u6cb9\u52d8\u63a2\u7c7b\u7684\u4e24\u4e2a\u5de5\u4f5c\u3002\u5e76\u4e89\u53d6\u5728\u5723\u8bde\u8282\u653e\u5047\u524d\u5c06\u5269\u4f59\u7684\u4e09\u4e2a\u5de5\u4f5c\u6574\u7406\u51fa\u6765\u3002 \n \n \u30101\u3011 \n An Iteratively Reweighted Algorithm for Sparse Reconstruction of Subsurface Flow Properties from Nonlinear Dynamic Data \n BY, Lianlin Li and Behnam Jafarpour \n  \n \u8bba\u6587\u6458\u8981\uff0c \n  \n A challenging problem in predicting fluid flow displacement patterns in subsurface environment is the identification of spatially variable flow-related rock properties such as permeability and porosity. Characterization of subsurface properties usually involves solving a highly underdetermined nonlinear inverse problem where a limited number of measurements are used to reconstruct a large number of unknown parameters. To alleviate the non-uniqueness of the solution, prior information is integrated into the solution. Regularization of ill-posed inverse problems is commonly performed by imparting structural prior assumptions, such as smoothness, on the solution. Since many geologic formations exhibit natural continuity/correlation at various scales, decorrelating their spatial description can lead to a more compact or sparse representation in an appropriate compression transform domain such as wavelets or Fourier domain. The sparsity of flow-related subsurface properties in such incoherent bases has inspired the development of regularization techniques that attempt to solve a better-posed inverse problem in these domains. In this paper, we present a practical algorithm based on sparsity regularization to effectively solve nonlinear dynamic inverse problems that are encountered in subsurface model calibration. We use an iteratively reweighted algorithm that is widely used to solve linear inverse problems with sparsity constraint (known as compressed sensing) to estimate permeability fields from nonlinear dynamic flow data. To this end, we minimize a data misfit cost function that is augmented with an additive regularization term promoting sparse solutions in a Fourier-related discrete cosine transform domain. This regularization approach introduces a new weighting parameter that is in general unknown a priori, but controls the effectiveness of the resulting solutions. Determination of the regularization parameter can only be achieved through considerable numerical experimentation and/or a priori knowledge of the reconstruction solution. To circumvent this problem, we include the sparsity promoting constraint as a multiplicative regularization term which eliminates the need for a regularization parameter. We evaluate the performance of the iteratively reweighted approach with multiplicative sparsity regularization using a set of waterflooding experiments in an oil reservoir where we use nonlinear dynamic flow data to infer the spatial distribution of rock permeabilities, While, the examples of this paper are derived from the subsurface flow and transport application, the proposed methodology also can be used in solving nonlinear inverse problems with sparsity constraints in other imaging applications such as geophysical, medical imaging, electromagnetic and acoustic inverse problems. \n \n \n   \u30102\u3011 \n Reservoir History Matching Within the Framework of Sparse Bayesian Estimation \n BY, Lianlin Li and B. Jafaropur \n \u8bba\u6587\u6458\u8981\uff0c \n  \n The estimation of reservoir properties is inherently a highly underdetermined and nonlinear inverse problem because of two basic facts: (1) the complex physical interaction between the permeability/porosity and pressure/saturation, and (2) large number of unknowns to be reconstructed relative to the independent available data; consequently, some prior information should be efficiently exploited to obtain the reasonable reconstruction which can be used to make the successful reservoir forecast. The so-called compressibility of permeability and porosity field, which means that in some transformed domain such as DCT, wavelet, and so on only limited components are significant, has been empirically shown that it can be exploited to greatly improve the reconstruction of reservoir parameters. \n As we known, unlike most deterministic reconstruction methods, the Bayesian estimation based algorithm is fully-automated, i.e., the unknown signal coefficients and all necessary parameters are estimated solely from the observation and therefore no user-intervention is needed. Besides it, it also can provide the estimates of the uncertainty of the reconstruction. Inspired by this point, the sparse Bayesian algorithm recently developed to deal with the highly undetermined linear inverse problem with sparsity constraint has been introduced to attack the investigated problem in this paper, i.e. the highly underdetermined nonlinear inverse problem with sparsity constraint. \n Within the framework of Bayesian estimation, the history matching problem with sparsity constraint has been formulated and investigated in this paper. In order to model this sparsity promoting inverse problem, the required Laplace prior of Bayesian estimation has been modeled by two-hierarchical stage or Gaussian mixture strategy as done by standard sparse Bayesian estimation. Moreover, in order to model the measurements (i.e. pressure and saturation) in reservoir engineer which are the function of time and space and usually present different statistical properties, the different statistical parameters of noise variance has been assigned to different measurements instead of identical parameter for all measurements. Unfortunately, an artificial factor should be introduced to avoid the singularity in the resulting Bayesian estimation formulations. To deal with this issue, one efficient variant algorithm has been proposed afterwards. Several numerical synthetic experiments have been carried out to show high performance of proposed method, where the results using traditional Bayesian estimation also been provided and compared. In addition, the proposed methodology also can be used to deal with the nonlinear inverse problem in the other applied field, for example, the well-known electromagnetic inverse problem"], "link": "http://to-cs.blog.sohu.com/136987369.html", "bloglinks": {}, "links": {}, "blogtitle": "Compressive Sensing\uff1a\u4e00\u7f15\u6e05\u98ce"}]
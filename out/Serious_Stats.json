[{"blogurl": "http://seriousstats.wordpress.com\n", "blogroll": [], "title": "Serious Stats"}, {"content": ["One of the main attractions of R (for me) is the ability to produce high quality graphics that look just the way you want them to. The basic plot functions are generally excellent for exploratory work and for getting to know your data. Most packages have additional functions for appropriate exploratory work or for summarizing and communicating inferences. Generally the default plots are at least as good as other (e.g., commercial packages) but with the added advantage of being fairly easy to customize once you understand basic plotting functions and parameters. \n Even so, getting a plot looking just right for a presentation or publication often takes a lot of work using basic plotting functions. One reason for this is that constructing a good graphic is an inherently difficult enterprise, one that balances aesthetic factors and statistical factors and that requires a good understanding of who will look at the graphic, what they know, what they want to know and how they will interpret it. It can takes hours \u2013 maybe days \u2013 to get a graphic right. \n In Serious Stats I focused on exploratory plots and how to use basic plotting functions to customize them. I think this was important to include, but one of my regrets was not having enough space to cover a different approach to plotting in R. This is Hadley Wickham\u2019s ggplot2 package (inspired by Leland Wilkinson\u2019s grammar of graphics approach). \n In this blog post I\u2019ll quickly demonstrate a few ways that ggplot2 can be used to quickly produce amazing graphics for presentations or publication. I\u2019ll finish by mentioning some pros and cons of the approach. \n The main attraction of ggplot2 for newcomers to R is the qplot() quick plot function. Like the R plot() function it will recognize certain types and combinations of R objects and produce an appropriate plot (in most cases). Unlike the basic R plots the output tends to be both functional and pretty. Thus you may be able to generate the graph you need for your talk or paper almost instantly. \n A good place to start is the vanilla scatter plot. Here is the R default: \n \n Compare it with the ggplot2 default: \n \n Below is the R code for comparison. (The data here are from hov.csv file used in Chapter 10 Example 10.2 of Serious Stats ). \n \n \n # install and then load the package \n install.packages ( 'ggplot2' ) \n library ( ggplot2 ) \n\n # get the data \nhov.dat <- read.csv ( 'http://www2.ntupsychology.net/seriousstats/hov.csv' ) \n\n # using plot() \n with ( hov.dat , plot ( x , y ) ) \n\n # using qplot() \nqplot ( x , y , data =hov.dat ) \n \n \n R code formatted by Pretty R at inside-R.org \n Adding a line of best fit \n The ggplot2 version is (in my view) rather prettier, but a big advantage is being able to add a range of different model fits very easily. The common choice of model fit is that of a straight line (usually the least squares regression line). Doing this in ggplot2 is easier than with basic plot functions (and you also get 95% confidence bands by default). \n Here is the straight line fit from a linear model: \n POST \n qplot(x, y, data=hov.dat, geom=c(\u2018point\u2019, \u2018smooth\u2019), method=\u2019lm\u2019) \n The geom specifies the type of plot (one with points and a smoothed line in this case) while the method specifies the model for obtaining the smoothed line. A formula can also be added (but the formula defaults to y as a simple linear function of x ). \n Loess, polynomial fits or splines \n Mind you, the linear model fit has some disadvantages. Even if you are working with a related statistical model (e.g., a Pearson\u2019s r or least squares simple or multiple regression) you might want to have a more data driven plot. A good choice here is to use a local regression approach such as loess . This lets the data speak for themselves \u2013 effectively fitting a complex curve driven by the local properties of the data. If this is reasonably linear then your audience should be able to see the quality of the straight-line fit themselves. The local regression also gives approximate 95% confidence bands. These may support informal inference without having to make strong assumptions about the model. \n Here is the loess plot: \n \n \n Here is the code for the loess plot: \n qplot(x, y, data=hov.dat, geom=c(\u2018point\u2019, \u2018smooth\u2019), method=\u2019loess\u2019) \n I like the loess approach here because its fairly obvious that the linear fit does quite well. showing the straight line fit has the appearance of imposing the pattern on the data, whereas a local regression approach illustrates the pattern while allowing departures from the straight line fit to show through. \n In Serious Stats I mention loess only in passing (as an alternative to polynomial regression). Loess is generally superior as an exploratory tool \u2013 whereas polynomial regression (particularly quadratic and cubic fits) are more useful for inference. Here is an example of a cubic polynomial fit (followed by R code): \n \n qplot(x, y, data=hov.dat, geom=c(\u2018point\u2019, \u2018smooth\u2019), method=\u2019lm\u2019, formula= y ~ poly(x, 2)) \n Also available are fits using robust linear regression or splines. Robust linear regression (see section 10.5.2 of Serious Stats for a brief introduction) changes the loss function least squares in order to reduce impact of extreme points. Sample R code (graph not shown): \n library(MASS) \nqplot(x, y, data=hov.dat, geom=c(\u2018point\u2019, \u2018smooth\u2019), method=\u2019rlm\u2019) \n One slight problem here is that the approximate confidence bands assume normality and thus are probably too narrow. \n Splines are an alternative to loess that fits sections of simpler curves together. Here is a spline with three degrees of freedom: \n \n library(splines) \nqplot(x, y, data=hov.dat, geom=c(\u2018point\u2019, \u2018smooth\u2019), method=\u2019lm\u2019, formula=y ~ ns(x, 3)) \n A few final thoughts \n If you want to know more the best place to start is with Hadley Wickham\u2019s book . Chapter 2 covers qplot() and is available free online. \n The immediate pros of the ggplot2 approach are fairly obvious \u2013 quick, good-looking graphs. There is, however, much more to the package and there is almost no limit to what you can produce. The output of the ggplot2 functions is itself an R object that can be stored and edited to create new graphs. You can use qplot() to create many other graphs \u2013 notably kernel density plots, bar charts, box plots and histograms. You can get these by changing the geom (or by default with certain object types an input). \n The cons are less obvious. First, it takes some time investment to get to grips with the grammar of graphics approach (though this is very minimal if you stick with the quick plot function). Second, you may not like the default look of the ggplot2 output (though you can tweak it fairly easily). For instance, I prefer the default kernel density and histogram plots from the R base package to the default ggplot2 ones. I like to take a bare bones plot and build it up \u2026 trying to keep visual clutter to a minimum. I also tend to want black and white images for publication (whereas I would use grey and colour images more often in presentations). This is mostly to do with personal taste. \n \n Filed under: graphics , R code , serious stats Tagged: confidence intervals , exploratory data analysis , loess , multiple regression , polynomial regression , R , robust statistics , software , splines , statistics"], "link": "http://seriousstats.wordpress.com/2012/09/05/highqualitygraphs/", "bloglinks": {}, "links": {"http://amzn.to/": 2, "http://had.co.nz/": 2, "http://inside-r.org/": 7, "http://seriousstats.wordpress.com/": 14, "http://www.inside-r.org/": 1}, "blogtitle": "Serious Stats"}, {"content": ["Andy Field just tweeted this: \n https://twitter.com/ProfAndyField/status/219757478018166784/photo/1 \n Filed under: news , serious stats Tagged: text books"], "link": "http://seriousstats.wordpress.com/2012/07/02/geek-pride-and-confirmation-that-serious-stats-is-out/", "bloglinks": {}, "links": {"https://twitter.com/": 1, "http://seriousstats.wordpress.com/": 3}, "blogtitle": "Serious Stats"}, {"content": ["In a previous post I showed how to plot difference-adjusted CIs for between-subjects (independent measures) ANOVA designs (see here ). The rationale behind this kind of graphical display is introduced in Chapter 3 of Serious stats \u00a0(and summarized in my earlier blog post). \n In a between-subjects \u2013 or in indeed in a within-subjects (repeated measures) \u2013 design you or your audience will not always be interested only in the differences between the means. Rarely, the main focus may even be on the individual estimates themselves. A CI for each of the individual means might be informative for several reasons. \n First, it may be important to know that the interval excludes an important parameter value (e.g., zero). The example in Chapter 3 of \u00a0Serious Stats involved a task in which participants had to decide which of two diagrams matched a description they had just read. Chance performance is 50% matching accuracy, so a graphical display that showed that the 95% CI for each mean excludes 50% suggests that participants in each group were performing above chance. \n Second the CI for an individual mean gives you an idea of the relative precision with which that quantity is measured. This may be particularly important in an applied domain. For example, you may want to be fairly sure that performance on a task is high in some conditions as well as being sure that there are differences between conditions. \n Third, the CIs for the individual means are revealing about changes in the precision between conditions. If the sample sizes are equal (or nearly equal) they are also revealing about patterns in the variances. This is because the precision of the individual means is a function of the standard error and n . This may be obscured when difference-adjusted CIs are plotted \u2013 though mainly for within-subjects (repeated measures) designs which have to allow for the correlation between the samples. \n In any case, it may be desirable to display CIs for individual means and difference-adjusted means on the same plot. This could be accomplished in several ways but I have proposed using a two-tiered CI plot (see here for a brief summary of my BRM paper on this or see Chapter 16 of Serious stats). \n A common approach (for either individual means or difference-adjusted CIs) is to \u00a0adopt a pooled error term. This results in a more accurate CI if the homogeneity of variance assumption is met. For the purposes of a graphical display I would generally avoid pooled error terms (even if you use a pooled error term in your ANOVA). A graphical display of means is useful as an exploratory aid and supports informal inference. You want to be able to see any patterns in the precision (or variances) of the means. Sometimes these patterns are clear enough to be convincing without further (formal) inference or modeling. If they aren\u2019t completely convincing it usually better to show the noisy graphic and supplement it with formal inference if necessary. \n Experienced researchers understand that real data are noisy and may (indeed should!) get suspicious if data are too clean. (I\u2019m perhaps being optimistic here \u2013 but we really ought to have more tolerance for noisy data, as this should reduce the pressure on honest researchers to \u2018optimize\u2019 their analyses \u2013 e.g., see here ). \n My earlier post on this blog provided functions for the single tier difference-adjusted CIs. Here is the two-tiered function (for a oneway design): \n \n \n plot.bsci.tiered <- function ( data.frame , group.var= 1 , dv.var= 2 , var.equal= FALSE , conf.level = 0.95 , xlab = NULL , ylab = NULL , level.labels = NULL , main = NULL , pch = 19 , pch.cex = 1.3 , text.cex = 1.2 , ylim = c ( min.y , max.y ) , line.width= c ( 1.5 , 1.5 ) , tier.width= 0 , grid = TRUE ) { \n   data <- subset ( data.frame , select= c ( group.var , dv.var ) ) \n\tfact <- factor ( data [ [ 1 ] ] ) \n\tdv <- data [ [ 2 ] ] \n\tJ <- nlevels ( fact ) \n\tci.outer <- bsci ( data.frame = data.frame , group.var=group.var , dv.var=dv.var , difference= FALSE , var.equal=var.equal , conf.level =conf.level ) \n\tci.inner <- bsci ( data.frame = data.frame , group.var=group.var , dv.var=dv.var , difference= TRUE , var.equal=var.equal , conf.level =conf.level ) \n\tmoe.y <- max ( ci.outer ) - min ( ci.outer ) \n min.y <- min ( ci.outer ) - moe.y/ 3 \n max.y <- max ( ci.outer ) + moe.y/ 3 \n  if ( missing ( xlab ) ) \n  xlab <- \"Groups\" \n  if ( missing ( ylab ) ) \n  ylab <- \"Confidence interval for mean\" \n  plot ( 0 , 0 , ylim = ylim , xaxt = \"n\" , xlim = c ( 0.7 , J + 0.3 ) , xlab = xlab , \n  ylab = ylab , main = main , cex.lab = text.cex ) \n  if ( grid == TRUE ) grid ( ) \n  points ( ci.outer [ , 2 ] , pch = pch , bg = \"black\" , cex = pch.cex ) \n index <- 1 :J\n  segments ( index , ci.outer [ , 1 ] , index , ci.outer [ , 3 ] , lwd = line.width [ 1 ] ) \n  axis ( 1 , index , labels = level.labels ) \n  if ( tier.width== 0 ) { \n  segments ( index - 0.025 , ci.inner [ , 1 ] , index + 0.025 , ci.inner [ , 1 ] , lwd = line.width [ 2 ] ) \n  segments ( index - 0.025 , ci.inner [ , 3 ] , index + 0.025 , ci.inner [ , 3 ] , lwd = line.width [ 2 ] ) \n  } \n  else segments ( index , ci.inner [ , 1 ] , index , ci.inner [ , 3 ] , lwd = line.width [ 1 ] * ( 1 + abs ( tier.width ) ) ) \n\t } \n \n \n The following example uses the diagram data from the book: \n \n \n source ( 'http://www2.ntupsychology.net/seriousstats/SeriousStatsAllfunctions.txt' ) \n\ndiag.dat <- read.csv ( 'http://www2.ntupsychology.net/seriousstats/diagram.csv' ) \n\nplot.bsci.tiered ( diag.dat , group.var= 2 , dv.var= 4 , ylab= 'Mean description quality' , main = 'Two-tiered CIs for the Diagram data' , tier.width= 1 ) \n \n \n The result is a plot that looks something like this (though I should probably have reordered the groups and labeled them): \n  \n For these data the group sizes are equal and thus the width of the outer tier reflect differences in variances between the groups. The variances are not very unequal, but neither are they particularly homogenous. The inner tier suggests group three is different from groups 2 and 4 (but not from group 1). This is a pretty decent summary of what\u2019s going on and could be supplemented by formal inference (see Chapter 13 for a comparison of several formal approaches also using this data set). \n N.B. R code formatted via Pretty R at inside-R.org \n Footnote: The aesthetics of error bar plots \n A major difference between the plot shown here and that in my BRM paper or in the book is that I have changed the method of plotting the tiers. The change is mainly aesthetic, but also reflects the desire not to emphasize the extremes of the error bar. The most plausible values of the parameter (e.g., mean) are towards the center of the interval \u2013 not at the extremes. I have discussed the reasons for my change of heart in a bit more detail elsewhere . \n To this end I have also updated all my plotting functions. They still use the crossbar style from the book by default but this is controlled by a tier width argument. If tier.width=0 the crossbar style is used otherwise it used the tier.width to control the additional thickness of the difference-adjusted lines. In general, tier.width=1 seems to work well (but the crossbar style may be necessary for some unusual within-subject CIs where the difference-adjusted CI is wider than the CI for the individual means). \n Filed under: R code , serious stats Tagged: ANOVA , confidence intervals , exploratory data analysis , R , R functions , repeated measures ANOVA , statistics"], "link": "http://seriousstats.wordpress.com/2012/06/21/confidence-intervals-with-tiers/", "bloglinks": {}, "links": {"http://papers.ssrn.com/": 1, "http://inside-r.org/": 37, "http://www.co.uk/": 1, "http://psychologicalstatistics.co.uk/": 2, "http://seriousstats.wordpress.com/": 11, "http://www.inside-r.org/": 1}, "blogtitle": "Serious Stats"}, {"content": ["When starting out with R, getting data in and out can be a bit of a pain. It should take long to work out a convenient method \u2013 depending on what OS you use and what other packages you work with. \n In my case I prefer to work with Excel spreadsheets (which are versatile and \u2013 for the most part \u2013 convenient for sharing with collaborators or students). For this reason I mostly work with comma separated variable files created in Excel an imported using read.csv() . I even quite like the fact that this method requires me to save the .xls worksheet as a .csv file (as it makes it harder to over-write the original file when I edit it for R). In know that there are many other methods that I could use, but this works fine for me. \n I do however occasionally miss some of the functionality of software such as MLwiN \u00a0that allows me to paste Excel data directly into it. I\u2019ve seen instructions about how to do this on a Windows machine (e.g., see John Cook\u2019s notes ), but a while back I stumbled on a simple solution for the Mac. I\u2019ve forgotten where I saw it (but will add a link as soon as I find it or if someone reminds me). The solution uses read.table() but is a bit fiddly and therefore best set up as a function. \n \n \n paste.data <- function ( header= FALSE ) { read.table ( pipe ( \"pbpaste\" ) , header=header ) } \n \n \n I\u2019ve included this in my master function list so it can be loaded with other functions from the book and blog. \n To use it just copy tab-delimited data (the default for copying from an Excel file or Word table) and call the function in R. The data are then imported as a data frame in R. For an empty call it assumes there is no header and adds default variable names. Adding the argument header=TRUE or just TRUE will treat the first row as variable (column) names for the data frame. Copy some data and try the following: \n \n \n source ( 'http://www2.ntupsychology.net/seriousstats/SeriousStatsAllfunctions.txt' ) \n\npaste.data ( ) \n\npaste.data ( header = TRUE ) \npaste.data ( TRUE ) \npaste.data ( T ) \n \n \n N.B. R code formatted via Pretty R at inside-R.org \n UPDATE: Ken Knoblauch pointed out an older discussion of this issue in\u00a0 https://stat.ethz.ch/pipermail/r-help/2005-February/066257.html and also noted the read.clipboard() \u00a0function in William Revelle\u2019s excellent psych package (which works on both PC and Mac systems). \n Filed under: R code Tagged: Mac , R , R functions , software"], "link": "http://seriousstats.wordpress.com/2012/06/02/pasting-excel-data-into-r-on-a-mac/", "bloglinks": {}, "links": {"https://stat.ethz.ch/": 1, "http://inside-r.org/": 4, "http://www.ac.uk/": 1, "http://www.johndcook.com/": 1, "http://www.inside-r.org/": 1, "http://seriousstats.wordpress.com/": 5, "http://cran.r-project.org/": 1}, "blogtitle": "Serious Stats"}, {"content": ["For an hour or so earlier today Serious Stats was #1 in the amazon.co.uk sales rank for the category: \n Books\u00a0>\u00a0Health, Family & Lifestyle\u00a0>\u00a0Psychology & Psychiatry\u00a0>\u00a0Methodology\u00a0>\u00a0 Statistics \n As of writing the rank has dropped to #3 (but I\u2019m still quite excited \u2013 even though I know this may not imply large numbers of pre-orders). \n They have also increased the discount on pre-orders to 36%. The book should also be available for pre-order in other countries (though I\u2019ve only checked the US store), but for some reason the discount is not as generous there. \n If you can\u2019t get hold of the item in your country,\u00a0 bookdepository.com does free worldwide delivery (to most countries as far as I can tell). I\u2019ve used them to ship gifts to friends and family overseas and they seem pretty reliable (and also offer pretty good discounts). \n Filed under: news , serious stats Tagged: amazon , book depository , sales rank , text books"], "link": "http://seriousstats.wordpress.com/2012/05/29/serious-stats-1-on-amazon-co-uk/", "bloglinks": {}, "links": {"http://www.co.uk/": 2, "http://seriousstats.wordpress.com/": 6}, "blogtitle": "Serious Stats"}, {"content": ["Whilst writing\u00a0 the book \u00a0\u00a0the latest version of R changed several times. Although I started on an earlier version, the bulk of the book was written with 2.11 and it was finished under R 2.12. The final version of the R scripts were therefore run and checked using R 2.12 and, in the main, the most recent packages versions for R 2.12. \n When it came to proof read R 2.13 was already out and therefore most of the examples were also checked with version, but I stuck with R 2.12 on my home and work machines until last week. \n In general I don\u2019t see the point of updating to a new version number if everything is working fine. One advantage of this approach is that the version I install will usually have bugs from the initial release already ironed out. That said, new versions of R have (in my experience) been very stable. \n I tend to download the version only when I fall several versions behind or if it is a requirement for a new package or package version. On this occasion it turned out that the latest version of the\u00a0 ordinal \u00a0package (for fitting ordered logistic regression and multilevel\u00a0ordered logistic regression models). There are two main drawbacks with updating. The first is reinstalling all your favourite package libraries (and generally getting it set up how you like it). The second is dealing with changes in the way R behaves. \n For re-installing all my packages I use a very crude system. For any given platform (Mac OS, Windows or Linux) there are cleverer solutions (that you can find via google). My solution works across cross-platform and is fairly robust, if inelegant. I simply keep an R script with a number of install.packages() commands such as: \n install.packages(\u2018lme4\u2032, \u2018exactci\u2019, \u2018pwr\u2019, \u2018arm\u2019) \n I run these in batches after installing the new R version. I find this useful because I\u2019m forever installing R on different machines (so far Mac OS or Windows) at work (e.g., for teaching or if working away from the office or on a borrowed machine). I can also comment the file (e.g., to note if there are issues with any of the packages under a particular version of R). This usually suffices for me as I usually run a \u2018vanilla\u2019 set-up without customization. It would be more efficient for me to customize my set-up, but for teaching purposes I find it helps not to do that. Likewise, I tend to work with a clean workspace (and use a script file to save R code that creates my workspaces). I should stress that this isn\u2019t advice \u2013 and I would work differently myself if I didn\u2019t use R so much for teaching. \n One of the first things that happened after\u00a0installing R 2.15 was that some of my own functions started producing warnings. R warnings can be pretty scary for new users but are generally benign. Some of them are there to detect behaviour associated with common R errors or common statistical errors (and thus give you a chance to check your work). Others alert you to non-standard behaviour from a function in R (e.g., changing the procedure it uses when sample sizes are small). Yet others offer tips on writing better R code. Only very rarely are they an indication that something has gone badly wrong. \n Thus most R warnings are slightly annoying but potentially useful. In my case R 2.15 disliked a number of my functions of the form: \n mean(data.frame) \n The precise warning was: \n Warning message: \nmean() is deprecated. \nUse colMeans() or sapply(*, mean) instead. \u00a0 \n All the functions worked just fine, but (after my initial irritation had receded) I realize that colMeans() is a much better function. It is more efficient but, even better, it is obvious that it calculates the means of the columns of a data frame or matrix. With the more general \u00a0 mean() function it is not immediately obvious what will happen when called with a data frame as an argument. It is also trivial to infer that rowMeans() calculates the row means. \n I have now re-written \u00a0a number of functions to deal with this problem and to make a few other minor changes. The latest version of my functions can be loaded with the call: \n \n \n source ( 'http://www2.ntupsychology.net/seriousstats/SeriousStatsAllfunctions.txt' ) \n \n \n I will try and keep this file up-to-date with recent versions of R and correct any bugs as they are detected. \n The functions can be downloaded as a text file from: \n http://sites.google.com/site/seriousstats2012/home/ \n Filed under: news , R code , serious stats Tagged: R , software"], "link": "http://seriousstats.wordpress.com/2012/05/27/updating-to-r-2-15/", "bloglinks": {}, "links": {"http://wms.co.uk/": 1, "http://inside-r.org/": 1, "http://sites.google.com/": 1, "http://seriousstats.wordpress.com/": 5}, "blogtitle": "Serious Stats"}, {"content": ["UPDATE : Some problems arose with my previous host so I have now updated the links here and elsewhere on the blog. \n The companion web site for Serious Stats \u00a0has a zip file with R scripts for each chapter. This contains examples of R code and and all my functions from the book (and a few extras). This is a convenient form for working through the examples. However, if you just want to access the functions it is more convenient to load them all in at once. \n The functions can be downloaded as a text file from: \n http://www2.ntupsychology.net/seriousstats/SeriousStatsAllfunctions.txt \n More conveniently, you can load them directly into R with the following call: \n \n \n source ( 'http://www2.ntupsychology.net/seriousstats/SeriousStatsAllfunctions.txt' ) \n \n \n In addition to the Serious Stats functions, a number of other functions are contained in the text file. These include functions published on this blog for comparing correlations or confidence intervals for independent measures ANOVA and functions my paper on\u00a0confidence intervals for repeated measures ANOVA . \n N.B. R code formatted via Pretty R at inside-R.org \n Filed under: news , R code , serious stats Tagged: ANOVA , confidence intervals , correlation and covariance , R , R functions , repeated measures ANOVA , statistics , text books"], "link": "http://seriousstats.wordpress.com/2012/03/26/r-functions-for-serious-stats/", "bloglinks": {}, "links": {"http://inside-r.org/": 1, "http://www.palgrave.com/": 2, "http://www2.ntupsychology.net/": 1, "http://www.co.uk/": 1, "http://psychologicalstatistics.co.uk/": 1, "http://seriousstats.wordpress.com/": 13, "http://www.inside-r.org/": 1}, "blogtitle": "Serious Stats"}, {"content": ["The companion web site for Serious stats is now live: \n http://www.palgrave.com/psychology/Baguley/ \n It includes a sample chapter ( Chapter 15: Contrasts ), data sets, R scripts for all the examples and supplementary material . \n Filed under: news , R code , serious stats Tagged: behavioral sciences , contrasts , data , psychology , R , statistics , text books"], "link": "http://seriousstats.wordpress.com/2012/03/23/serious-stats-companion-web-site-now-live/", "bloglinks": {}, "links": {"http://www.palgrave.com/": 3, "http://seriousstats.wordpress.com/": 10}, "blogtitle": "Serious Stats"}, {"content": ["In Chapter 2 (Confidence Intervals) of Serious stats I consider the problem of displaying confidence intervals (CIs) of a set of means (which I illustrate with the simple case of two independent means). Later, in Chapter 16 (Repeated Measures ANOVA), I consider the trickier problem of displaying of two or more means from paired or repeated measures. The example in Chapter 16 uses R functions from my recent paper reviewing different methods for displaying means for repeated measures (within-subjects) ANOVA designs (Baguley, 2012b). For further details and links see a brief summary on my psychological statistics blog . The R functions included a version for independent measures (between-subject) designs, but this was a rather limited designed for comparison purposes (and not for actual use). \n The independent measures case is relatively straight-forward to implement and I hadn\u2019t originally planned to write functions for it. Since then, however, I have decided that it is worth doing. Setting up the plots can be quite fiddly and it may be useful to go over the key points for the independent case before you move on to the repeated measures case. This post therefore adapts my code for independent measures (between-subjects) designs. \n The approach I propose is inspired by Goldstein and Healy (1995) \u2013 though other authors have made similar suggestions over the years (see Baguley, 2012b). Their aim was to provide a simple method for displaying a large collection of independent means (or other independent statistics). At its simplest the method reduces to plotting each statistic with error bars equal to \u00b11.39 standard errors of the mean. This result is a normal approximation that can be refined in various ways (e.g., by using the t distribution or by extending it to take account of correlations between conditions). Using a Goldstein-Healy plot two means are considered different with 95% confidence if their two intervals do not overlap. In other words non-overlapping CIs are (in this form of plot) approximately equivalent to a statistically significant difference between the two means with \u03b1\u00a0= .05. For convenience I will refer to CIs that have this property as difference-adjusted CIs (to distinguish them from conventional CIs). \n It is important to realize that conventional 95% CIs constructed around each mean won\u2019t have this property. For independent means they are usually around 40% too wide and thus will often overlap even if the usual t test of their difference is statistically significant at\u00a0 p < .05. This happens because the variance of a difference is (in independent samples) equal to the sum of the variances of the individual samples. Thus the standard error of the difference is around times too large (assuming equal variances). For a more comprehensive explanation see Chapter 3 of Serious stats \u00a0or Baguley (2012b). \n What to plot \n If you have only two means there are at least three basic options: \n 1) plot the individual means with conventional 95% CIs around each mean \n 2) plot the difference between means and a 95% CI for the difference \n 3) plot some form of difference-adjusted CI \n Which option is \u00a0best? It depends on what you are trying to do. A good place to start is with your reasons for constructing a graphical display in the first place. Graphs are not particularly good for formal inference and other options (e.g., significance tests, reporting point estimates CIs in text, likelihood ratios, Bayes factors and so forth) exist for reporting the outcome of formal hypothesis tests. Graphs are appropriate for informal inference. This includes exploratory data analysis, to aid the interpretation of complex patterns or to summarize a number of simple patterns in a single display. If the patterns are very clear, informal inference might be sufficient. In other cases it can be supplemented with formal inference. \n What patterns do the three basic options above reveal?\u00a0Option 1) shows the precision around individual means. This readily supports inference about the individual means (but not their difference). For example, a true population outside the 95% CI is considered implausible (and the observed mean would be different from that hypothesized value with p < .05 using a one sample t test). \n Option 2) makes for a rather dull plot because it just involves a single point estimate for the difference in means and the 95% CI for the difference. If this is the only quantity of interest you\u2019d be better off just reporting the mean and 95% CI in the text. This has advantage of being more compact and more accurate than trying to read the numbers off a graph. [This is one reason that graphs aren't optimal for formal inference; it can be hard, for instance, to tell whether a line includes zero or excludes zero when the difference is just statistically significant or just statistically non-significant. With informal inference you shouldn't care where\u00a0 p = .049 or p = .051, but whether there are any clear patterns in the data] \n Option 3) shows you the individual means but calibrates the CIs so that you can tell if it is plausible that the sample means differ (using 95% confidence in the difference as a standard). Thus it seems like a good choice for graphical display if you are primarily interested in the differences between means. For formal inference it can be supplemented by reporting a hypothesis test in the text (or possibly a Figure caption). \n It is worth noting that option 3) becomes even more attractive if you have more than two means to plot. It allows you to see patterns that emerge over the set of means (e.g., linear or non-linear trends or \u2013 if n per sample is similar \u2013 changes in variances) and to compare pairs of means to see whether it is plausible that they are different. \n In contrast, option 2) is rather unattractive with more than two means. First, with J means there are J ( J -1)/2 differences and thus an unnecessarily cluttered graphical display (e.g., with J = 5 means there are 10 Cis to plot). Second, plotting only the differences can obscure important patterns in the data (e.g., an increasing or decreasing trend in the means or variances would be difficult to identify). \n Difference-adjusted CIs using the t distribution \n Where only a few means are to be plotted (as is common in ANOVA) it makes sense to take a slight more accurate approach than the approximation originally proposed by Goldstein and Healy for large collections of means. This approach uses the t distribution. A similar approach is advocated by Afshartous and Preston (2010) who also provide R code for calculating multipliers for the standard errors using the t distribution (and an extension for the repeated measures). My approach is similar, but involves calculating the margin of error (half width of the error bars) directly rather than computing a multiplier to apply to the standard error. \n Difference-adjusted CIs for the mean of each sample from an independent measures (between-subjects) ANOVA design is given by Equation 3.31 of Serious stats : \n  \n The\u00a0 term is the mean of the j th sample (where samples are labeled j = 1 to J ) and\u00a0 \u00a0is the standard error of that sample. The \u00a0 term is the quantile of the t distribution with degrees of freedom (where\u00a0 is the size of j th sample) that includes to 100(1 -\u00a0\u03b1) % of the distribution. \n Thus, apart from the\u00a0 term, this equation is identical to that for a 95% CI around the individual means, with the proviso that the standard error here is computed separately for each sample. This differs from the usual approach to plotting CIs for independent measures ANOVA design \u2013 where it is common to use a pooled standard error computed from a pooled standard deviation ( the root mean square error of the ANOVA) . While a pooled error term is sometimes appropriate, it is generally a bad idea for graphical display of the CIs because it will obscure any patterns in the variability of the samples. [Nevertheless, where\u00a0 is very small it make make sense to use a pooled error term on the grounds that each sample provides an exceptionally poor estimate of its population standard deviation] \n However, the most important change is the term. It creates a difference-adjusted CI by ensuring that the joint width of the margin of error around any two means is $latex\u00a0\\sqrt 2 $ times larger than for a single mean. The division by 2 arises merely as a consequence of dealing jointly with two error bars. Their total has to be\u00a0$latex\u00a0\\sqrt 2 $ times larger and therefore each one needs only to be\u00a0 times its conventional value (for an unadjusted CI). This is discussed in more detail by Baguley (2012a; 2012b). \n This equation should perform well (e.g., providing fairly accurate coverage) as long as variances are not very unequal and the samples are approximately normal. Even when these conditions are not met, remember the aim is not to support formal inference. In addition, the approach is likely to be slightly more robust than ANOVA (at least to homogeneity of variance and unequal sample sizes). So this method is likely to be a good choice whenever ANOVA is appropriate. \n R functions for independent measures (between-subjects) ANOVA designs \n Two R functions for difference-adjusted CIs in independent measures ANOVA designs are provided here. \u00a0The first function bsci() calculates conventional or difference-adjusted CIs for a one-way ANOVA design. \n \n \n bsci <- function ( data.frame , group.var= 1 , dv.var= 2 , difference= FALSE , pooled.error= FALSE , conf.level= 0.95 ) { \n\t data <- subset ( data.frame , select= c ( group.var , dv.var ) ) \n\tfact <- factor ( data [ [ 1 ] ] ) \n\tdv <- data [ [ 2 ] ] \n\tJ <- nlevels ( fact ) \n\tN <- length ( dv ) \n ci.mat <- matrix ( , J , 3 , dimnames = list ( levels ( fact ) , c ( 'lower' , 'mean' , 'upper' ) ) ) \n ci.mat [ , 2 ] <- tapply ( dv , fact , mean ) \n n.per.group <- tapply ( dv , fact , length ) \n  if ( difference== TRUE ) diff.factor= 2 ^ 0.5 / 2 else diff.factor= 1 \n  if ( pooled.error== TRUE ) { \n\t\t for ( i in 1 :J ) { \n\t\t\tmoe <- summary ( lm ( dv ~ 0 + fact ) ) $sigma/ ( n.per.group [ [ i ] ] ) ^ 0.5 * qt ( 1 - ( 1 -conf.level ) / 2 , N-J ) * diff.factor\n\t\t\tci.mat [ i , 1 ] <- ci.mat [ i , 2 ] - moe\n\t\t\tci.mat [ i , 3 ] <- ci.mat [ i , 2 ] + moe\n\t\t\t } \n\t\t } \n\t if ( pooled.error== FALSE ) { \n\t\t for ( i in 1 :J ) { \n\t\t \tgroup.dat <- subset ( data , data [ 1 ] == levels ( fact ) [ i ] ) [ [ 2 ] ] \n\t\t \tmoe <- sd ( group.dat ) /sqrt ( n.per.group [ [ i ] ] ) * qt ( 1 - ( 1 -conf.level ) / 2 , n.per.group [ [ i ] ] - 1 ) * diff.factor\n\t\t \tci.mat [ i , 1 ] <- ci.mat [ i , 2 ] - moe\n\t\t \tci.mat [ i , 3 ] <- ci.mat [ i , 2 ] + moe\n\t\t } \n\t } \n ci.mat\n } \n\nplot.bsci <- function ( data.frame , group.var= 1 , dv.var= 2 , difference= TRUE , pooled.error= FALSE , conf.level= 0.95 , xlab= NULL , ylab= NULL , level.labels= NULL , main= NULL , pch= 21 , ylim= c ( min.y , max.y ) , line.width= c ( 1.5 , 0 ) , grid = TRUE ) { \n  data <- subset ( data.frame , select= c ( group.var , dv.var ) ) \n  if ( missing ( level.labels ) ) level.labels <- levels ( data [ [ 1 ] ] ) \n\t if ( is.factor ( data [ [ 1 ] ] ) == FALSE ) data [ [ 1 ] ] <- factor ( data [ [ 1 ] ] ) \n\t if ( is.factor ( data [ [ 1 ] ] ) == TRUE ) data [ [ 1 ] ] <- factor ( data [ [ 1 ] ] ) \n\tdv <- data [ [ 2 ] ] \n\tJ <- nlevels ( data [ [ 1 ] ] ) \n\tci.mat <- bsci ( data.frame = data.frame , group.var=group.var , dv.var=dv.var , difference=difference , pooled.error=pooled.error , conf.level=conf.level ) \n\tmoe.y <- max ( ci.mat ) - min ( ci.mat ) \n min.y <- min ( ci.mat ) - moe.y/ 3 \n max.y <- max ( ci.mat ) + moe.y/ 3 \n  if ( missing ( xlab ) ) \n  xlab <- \"Groups\" \n  if ( missing ( ylab ) ) \n  ylab <- \"Confidence interval for mean\" \n  plot ( 0 , 0 , ylim = ylim , xaxt = \"n\" , xlim = c ( 0.7 , J + 0.3 ) , xlab = xlab , \n  ylab = ylab , main = main ) \n   grid ( ) \n  points ( ci.mat [ , 2 ] , pch = pch , bg = \"black\" ) \n index <- 1 :J\n  segments ( index , ci.mat [ , 1 ] , index , ci.mat [ , 3 ] , lwd = line.width [ 1 ] ) \n  segments ( index - 0.02 , ci.mat [ , 1 ] , index + 0.02 , ci.mat [ , 1 ] , lwd = line.width [ 2 ] ) \n  segments ( index - 0.02 , ci.mat [ , 3 ] , index + 0.02 , ci.mat [ , 3 ] , lwd = line.width [ 2 ] ) \n  axis ( 1 , index , labels =level.labels ) \n\t } \n \n \n The default is difference=FALSE (on the basis that these are the CIs most likely to be reported in text or tables). The second function plot.bsci() uses the former function to plot \u00a0the means and CIs the default here is\u00a0 difference=TRUE (on the basis that it the difference-adjusted CIs are likely to be more useful for graphical display). For both functions the default is a pooled error term ( pooled.error=FALSE ) and a 95% confidence level ( conf.level=0.95 ). Each function also takes input as a data frame and assumes that the grouping variable is the first column and the dependent variable the second column. If the appropriate variables are in different columns, the correct columns can be specified with the arguments group.var and dv.var . The plotting function also takes some standard graphical parameters (e.g., for labels and so forth). \n The following examples use the diagram data set from\u00a0 Serious stats . The first line loads the data set (if you have a live internet connection). The second line generated the difference-adjusted CIs. The third line plots the difference adjusted CIs. Note that the grouping variable (factor) is in the second column and the DV is in the fourth column. \n \n \n diag.dat <- read.csv ( 'http://www2.ntupsychology.net/seriousstats/diagram.csv' ) \n\nbsci ( diag.dat , group.var= 2 , dv.var= 4 , difference= TRUE ) \nplot.bsci ( diag.dat , group.var= 2 , dv.var= 4 , ylab= 'Mean description quality' , main = 'Difference-adjusted 95% CIs for the Diagram data' ) \n \n \n In this case the graph looks like this: \n  \n It should be immediately clear that while the segmented diagram condition (S) tends to have higher scores than the text (T) or picture (P) conditions, but the full diagram (F) condition is somewhere in between. This matches the uncorrected pairwise comparisons where S > P = T, S = F, and F = P = T. \n At some point I will also add a function to plot two-tiered error bars (combining option 1 and 3). For details of the extension to repeated measures designs see Baguley (2012b). The code and date sets are available here . \n References \n Afshartous D., & Preston R. A. (2010). Confidence intervals for dependent data: equating nonoverlap with statistical significance.\u00a0 Computational Statistics and Data Analysis. 54 , 2296-2305. \n Baguley, T. (2012a, in press).\u00a0 Serious stats: A guide to advanced statistics for the behavioral sciences . Basingstoke: Palgrave. \n Baguley, T. (2012b). Calculating and graphing within-subject confidence intervals for ANOVA. Behavior Research Methods, 44, 158-175. \n Goldstein, H., & Healy, M. J. R. (1995). Journal of the Royal Statistical Society. Series A (Statistics in Society), 158 , 175-177. \n Schenker, N., & Gentleman, J. F. (2001). On judging the significance of differences by examining the overlap between confidence intervals. The American Statistician, 55, 182-186. \n N.B. R code formatted via Pretty R at inside-R.org \n Filed under: R code , serious stats , stats advice Tagged: ANOVA , confidence intervals , exploratory data analysis , psychology , R , repeated measures ANOVA , significance tests , statistics"], "link": "http://seriousstats.wordpress.com/2012/03/18/cis-for-anova/", "bloglinks": {}, "links": {"http://psychologicalstatistics.blogspot.com/": 1, "http://inside-r.org/": 72, "http://www.co.uk/": 5, "http://psychologicalstatistics.co.uk/": 1, "http://seriousstats.wordpress.com/": 12, "http://www.inside-r.org/": 1}, "blogtitle": "Serious Stats"}, {"content": ["In section 10.4.4 of Serious\u00a0stats \u00a0(Baguley, 2012) I discuss the rank\u00a0transformation and suggest that it often makes sense to rank transform\u00a0data prior to application of conventional \u2018parametric\u2019 least squares\u00a0procedures such as t\u00a0 tests or one-way ANOVA. There are several advantages to this approach\u00a0over the usual approach (which involves learning and applying a new\u00a0test such as Mann-Whitney U, Wilcoxon T or Kruskal-Wallis for almost\u00a0every situation). One is pedagogic. It is much easier to teach or learn\u00a0the rank transformation approach (especially if you also cover other\u00a0transformations in your course). Another reason is that there are\u00a0situations where widely used rank-randomization tests perform very\u00a0badly, yet the rank transformation approach does rather well. In\u00a0contrast, Conover and Iman (1981) show that rank transformation\u00a0versions of parametric tests mimic the properties of the best known\u00a0rank randomization tests (e.g., Spearman\u2019s rho, Mann-Whitney U or\u00a0Wilcoxon T) rather closely with moderate to large sample sizes. The\u00a0better rank randomization tests tend to have the edge on rank\u00a0transformation approaches only when sample sizes are small (and that\u00a0advantage may not hold if there are many ties). \n The potential pitfalls of rank randomization tests is nicely\u00a0illustrated with the case of the Friedman test (and related tests such\u00a0as Page\u2019s L ).\u00a0I\u2019ll try and explain the problem here. \n Why\u00a0the Friedman test is an impostor \u2026 \n I\u2019ve always thought there was something odd about the way the Friedman\u00a0test worked. Like most psychology students I first learned the Wilcoxon\u00a0signed ranks ( T )\u00a0test. This is a rank randomization analog of the paired t\u00a0 test. It involves computing the absolute difference between paired\u00a0observations, ranking them and then adding the original sign back in.\u00a0Imagine that the raw data consist of the following paired measurements\u00a0(A and B) from four people (P1 to P4): \n \n \n \n \n A \n B \n \n \n P1 \n 13 \n 4 \n \n \n P2 \n 6 \n 9 \n \n \n P3 \n 11 \n 9 \n \n \n P4 \n 12 \n 6 \n \n \n \n This results in the following ranks being assigned: \n \n \n \n \n A \u2013 B \n Rank \n \n \n P1 \n +9 \n +4 \n \n \n P2 \n -3 \n -2 \n \n \n P3 \n +2 \n +1 \n \n \n P4 \n +6 \n +3 \n \n \n \n The signed ranks are then used as input to a randomization (i.e., permutation) test that, if there are no ties, gives the exact probability of the observed sum of the ranks (or a sum more extreme) being obtained if the paired observations had fallen into the categories A or B at random (in which case the expected sum is zero). The basic principle here is similar to the paired t test (which is a one sample t test on the raw differences). \n The Friedman test is (incorrectly) generally considered to be a rank randomization equivalent of one-way repeated measures (within-subjects) ANOVA in the same way that the Wilcoxon test is a\u00a0\u00a0a rank randomization equivalent of paired t . It isn\u2019t. To see why, consider three repeated measures ( A , B and C ) for two participants. \u00a0Here are the raw scores: \n \n \n \n \n A \n B \n C \n \n \n P1 \n 6 \n 7 \n 12 \n \n \n P2 \n 8 \n 5 \n 11 \n \n \n \n Here are the corresponding ranks: \n \n \n \n \n A \n B \n C \n \n \n P1 \n 1 \n 2 \n 3 \n \n \n P2 \n 2 \n 1 \n 3 \n \n \n \n The ranks for the Friedman test depend only on the order of scores within each participant \u2013 they completely ignore the differences between participants. This differs dramatically from the Wilcoxon test where information about the relative size of differences between participants is preserved. Zimmerman and Zumbo (1993) discuss this difference in procedures and explain that the Friedman test (devised by the noted economist and champion of the \u2018free market\u2019 Milton Friedman ) is not really a form of ANOVA but an extension of the sign test. It is an impostor. \n This is bad news because the sign test tends to have low power relative to the paired t test or Wilcoxon sign rank test. Indeed, the asymptotic relative efficiency relative to ANOVA of the Friedman test is .955\u00a0 J/ ( J +1) where J is the number of repeated measures (see Zimmerman & Zumbo, 1993). Thus it is about .72 for J = 3 and .76 for J = 4, implying quite a big hit in power relative to ANOVA when the assumptions are met. This is a large sample limit, but small samples should also have considerably less power because the sign test and the Friedman test, in effect, throw information away. The additional robustness of the sign test may sometimes justify its application (as it may outperform Wilcoxon for heavy-tailed distributions), but this does not appear to be the case for the Friedman test. Thus, where one-way repeated measures ANOVA is not appropriate, rank transformation followed by ANOVA will provide a more robust test with greater statistical power than the Friedman test. \n Running one-way repeated measures ANOVA with a rank transformation in R \n The rank transformation version of the ANOVA is relatively easy to set up. The main obstacle is that the ranks need to be derived by treating all nJ scores as a single sample (where n is the number of observations per J repeated measures conditions \u2013 usually the number of participants). If your software arranges repeated measures data in broad format (e.g., as in SPSS) this can involve some messing about cutting and pasting columns and then putting them back (for which I would use Excel). For this sort of analysis I would in case prefer R \u2013 in which case the data would tend to be in a single column of a data frame or in a single vector anyway. \n The following R code using demo data from the excellent UCLA R resources runs first a friedman test, then a one-way repeated measures ANOVA and then the rank transformation version ANOVA. For these data pulse is the DV, time is the repeated measures factor and id is the subjects identifier. \n \n \n demo3 <- read.csv ( \"http://www.ats.ucla.edu/stat/data/demo3.csv\" ) \n\n friedman.test ( pulse ~ time | id , demo3 ) \n\n library ( nlme ) \nlme.raw <- lme ( fixed = pulse ~ time , random = ~ 1 | id , data =demo3 ) \n anova ( lme.raw ) \n\nrpulse <- rank ( demo3 $ pulse ) \nlme.rank <- lme ( fixed = rpulse ~ time , random = ~ 1 | id , data =demo3 ) \n anova ( lme.rank ) \n \n \n It may be helpful to point out \u00a0a couple of features of the R code. The Friedman test is built into R and can take formula or matrix input. Here I used formula input and specified a data frame that contains the demo data. The vertical bar notation indicates that the time factor varies within participants. The repeated measures ANOVA can be run in many different ways (see Chapter 16 of Serious\u00a0stats \u00a0). Here I chose ran it as a multilevel model using the nlme package (which should still work even if the design is unbalanced). As you can see, the only difference between the code for the conventional ANOVA and the rank transformation version is that the DV is rank transformed prior to analysis. \n Although this example uses R, you could almost as easily use any other software for repeated measures ANOVA (though as noted it is simplest with software that take data structured in long form \u2013 with the DV in a single column or vector). \n Other advantages of the approach \n The rank transformation is, as a rule, more versatile than using rank randomization tests. For instance, ANOVA software often has options for testing contrasts or correcting for multiple comparisons. Although designed for analyses of raw data some procedures are very general and can be straightforwardly applied to the rank transformation approach \u2013 notably powerful modified Bonferroni procedures such as the Hochberg or Westfall procedures. A linear contrast can also be used to run the equivalent of a rank randomization trend test such as the Jonckheere test (independent measures) or Page\u2019s L (repeated measures). A rank transformation version of the Welch-Satterthwaite t test is also superior to the more commonly applied Mann-Whitney U test (being robust to homogeneity of variance when sample sizes are unequal which the\u00a0Mann-Whitney U test is not). \n References \n Baguley, T. (2012, in press).\u00a0 Serious stats: A guide to advanced statistics for the behavioral sciences . Basingstoke: Palgrave. \n Conover, W. J., & Iman, R. L. (1981). Rank transformations as a bridge between parametric and nonparametric statistics. American Statistician , 35, 124-129. \n Zimmerman, D. W., & Zumbo, Bruno, D. (1993). Relative power of the Wilcoxon test, the Friedman test, and repeated-measures ANOVA on ranks. Journal of Experimental Education , 62, 75-86. \n N.B. \u00a0R code formatted via \u00a0Pretty R at inside-R.org \n Filed under: R code , serious stats , stats advice Tagged: ANOVA , contrasts , friedman test , kruskal wallis , R , rank randomization tests , rank transformation , repeated measures ANOVA , robust statistics , significance tests"], "link": "http://seriousstats.wordpress.com/2012/02/14/friedman/", "bloglinks": {}, "links": {"http://inside-r.org/": 16, "http://en.wikipedia.org/": 1, "http://www.co.uk/": 3, "http://www.ucla.edu/": 1, "http://seriousstats.wordpress.com/": 13, "http://www.inside-r.org/": 1}, "blogtitle": "Serious Stats"}]
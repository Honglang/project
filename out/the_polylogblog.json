[{"blogurl": "http://polylogblog.wordpress.com\n", "blogroll": [], "title": "the polylogblog"}, {"content": ["After a very successful hiring season last year, the department is now focusing on hiring in theory, NLP, robotics, and vision (that\u2019s four separate searches rather than one extreme interdisciplinary position). \u00a0So please apply! The official ad is here \u00a0and note that, unlike previous years, we\u2019re able to hire in theory at either the assistant or associate level. We\u2019ll start reviewing applications December 3."], "link": "http://polylogblog.wordpress.com/2012/10/27/umass-hiring-in-theory/", "bloglinks": {}, "links": {"https://www.umass.edu/": 2, "http://feeds.wordpress.com/": 1, "http://people.umass.edu/": 1}, "blogtitle": "the polylogblog"}, {"content": ["Continuing the report from the Dortmund Workshop on Algorithms for Data Streams , here are the happenings from Day 3. Previous posts: Day 1 and Day 2 . \n \n Michael Kapralov started the day with new results on computing matching large matchings in the semi-streaming model, one of my favorite pet problems. You are presented with a stream of unweighted edges on n nodes and want to approximate the size of the maximum matching given the constraint that you only have O(n polylog n) bits of memory. It\u2019s trivial to get a 1/2 approximation by constructing a maximal matching greedily. Michael shows that it\u2019s impossible to beat a 1-1/e factor even if the graph is bipartite and the edges are grouped by their right endpoint. In this model, he also shows a matching (no pun intended) 1-1/e approximation and an extension to a approximation given p passes. \n Next up, Mert Seglam talked about sampling. Here the stream consists of a sequence of updates to an underlying vector and the goal is to randomly select an index where is chosen with probability proportional to . It\u2019s a really nice primitive that gives rise to simple algorithms for a range of problems including frequency moments and finding duplicates. I\u2019ve been including the result in recent tutorials . Mert\u2019s result simplifies and improves an earlier result by Andoni et al. \n The next two talks focused on communication complexity, the evil nemesis of the honest data stream algorithm. First, Xiaoming Sun talked about space-bounded communication complexity. The standard method to prove a data stream memory lower bound is to consider two players corresponding to the first and second halves of the data stream. A data stream algorithm gives rise to a communication protocol where the players emulate the algorithm and transmit the memory state when necessary. In particular, multi-pass stream algorithms give rise to multi-round communication protocols. Hence a communication lower bound gives rise to a memory lower bound. However, in the standard communication setting we suppose that the two players may maintain unlimited state between rounds. The fact that stream algorithms can\u2019t do this may lead to suboptimal data stream bounds. To address this, Xiaoming\u2019s work outlines a communication model where the players may maintain only a limited amount of state between the sending of each message and establishes bounds on classical problems including equality and inner-product. \n In the final talk of the day, Amit Chakrabarti extolled the virtues of Talagrand\u2019s inequality and explained why every data stream researcher should know it. In particular, Amit reviewed the history on proving lower bounds for the Gap-Hamming communication problem (Alice and Bob each have a length n string and wish to determine whether the Hamming distance is less than n/2-\u221an or greater than n/2+\u221an) and ventured that the history wouldn\u2019t have been so long if the community had had a deeper familiarity with Talagrand\u2019s inequality. It was a really gracious talk in which Amit actually spent most of the time discussing Sasha Sherstov\u2019s recent proof of the lower bound rather than his own work. \n BONUS! Spot the theorist\u2026 After the talks, we headed off to Revierpark Wischlingen to contemplate some tree-traversal problems. If you think your observation skills are up to it, click on the picture below to play \u201cspot the theorist.\u201d It may take some time, so keep looking until you find him or her."], "link": "http://polylogblog.wordpress.com/2012/07/29/data-streaming-in-dortmund-day-3/", "bloglinks": {}, "links": {"http://polylogblog.wordpress.com/": 1, "http://www.sfu.ca/": 1, "http://novel.ac.cn/": 1, "http://ls2-www.uni-dortmund.de/": 1, "http://www.dartmouth.edu/": 1, "http://geomblog.blogspot.com/": 1, "http://arxiv.org/": 3, "http://www.stanford.edu/": 1, "http://feeds.wordpress.com/": 1, "http://www.ucla.edu/": 1, "http://people.umass.edu/": 2}, "blogtitle": "the polylogblog"}, {"content": ["This week, I\u2019m at the Workshop on Algorithms for Data Streams in Dortmund, Germany. It\u2019s a continuation in spirit of the great Kanpur workshops from 2006 and 2009. \n \n The first day went very well despite the widespread jet lag (if only jet lag from those traveling from the east could cancel out with those traveling from the west.) Sudipto Guha kicked things off with a talk on combinatorial optimization problems in the (multiple-pass) data stream model. There was a nice parallel between Sudipto\u2019s talk and a later talk by David Woodruff and both were representative of a growing number of papers that have used ideas developed in the context of data streams to design more efficient algorithms in the usual RAM model. In the case of Sudipto\u2019s talk, this was a faster algorithm to approximate -matchings while David\u2019s result was a faster algorithm for least-squares regression . \n Other talks included Christiane Lammersen presenting a new result for facility location in data streams; Melanie Schmidt talking about constant-size coresets for -means and projective clustering; and Dan Feldman discussing the data stream challenges that arise when trying to transform real-time GPS data from your smart-phone into a human-readable diary of your life. I spoke about work on constructing a combinatorial sparsifier for an -dimensional graph via a single random linear projection into roughly dimensions. Rina Panigrahy wrapped things up with an exploration of different distance measures in social networks, i.e., how to quantify how closely-connected you are to your favorite celebrity. This included proposing a new measure based on the probability that two individuals remained connected if every edge was deleted with some probability. He then related this to electrical resistance and spectral sparsification. He refused to be drawn on which of his co-authors had the closest connection to the Kardashians. \n To be continued\u2026 Tomorrow, Suresh will post about day 2 across at the Geomblog ."], "link": "http://polylogblog.wordpress.com/2012/07/24/data-streaming-in-dortmund-day-1/", "bloglinks": {}, "links": {"http://arxiv.org/": 1, "http://feeds.wordpress.com/": 1, "http://ls2-www.uni-dortmund.de/": 1, "http://people.mit.edu/": 1, "http://geomblog.blogspot.com/": 1, "http://ls2-www.tu-dortmund.de/": 1, "http://www.sfu.ca/": 1, "http://www.ibm.com/": 1, "http://www.upenn.edu/": 1, "http://research.microsoft.com/": 1}, "blogtitle": "the polylogblog"}, {"content": ["As promised, here are the slides from the STOC Workshop on Algorithms for Distributed and Streaming Data. The workshop was standing-room only so here\u2019s your chance to review the slides while sitting down. More generally, all the workshops seemed to be a great success and I\u2019m happy to see that the experiment will be repeated at FOCS. Deadline for proposals is 20 June. \n \n Sergei Vassilvitskii , Google: Distributed and Parallel Models \n Andrew McGregor , UMass Amherst: Data Streams and Linear Sketches \n John Langford , Microsoft Research: Fun Machine Learning Problems on Big Data \n Piotr Indyk , MIT: CS on CS: Computer Science Insights into Compressive Sensing (and vice versa) \n Ashish Goel , Stanford and Twitter: Challenges in Industry and Education \n \n Thanks again to the speakers and everyone who came along. \n  \u00a9 Copyright Keith Edkins and licensed for reuse under this Creative Commons Licence"], "link": "http://polylogblog.wordpress.com/2012/06/12/slides-from-workshop-on-distributed-and-streaming-data/", "bloglinks": {}, "links": {"http://feeds.wordpress.com/": 1, "http://hunch.net/": 1, "http://people.mit.edu/": 1, "http://creativecommons.org/": 1, "http://www.org.uk/": 1, "http://www.stanford.edu/": 1, "http://theory.stanford.edu/": 2, "http://people.umass.edu/": 6}, "blogtitle": "the polylogblog"}, {"content": ["Atri Rudra asked me to post an announcement for this year\u2019s \n Coding, Complexity, and Sparsity Workshop. \n It\u2019ll take place at the University of Michigan from July 30th to August 2nd. I really enjoyed last year\u2019s workshop. \n The Blurb. Efficient and effective transmission, storage, and retrieval of information on a large-scale are among the core technical problems in the modern digital revolution. The massive volume of data necessitates the quest for mathematical and algorithmic methods for efficiently describing, summarizing, synthesizing, and, increasingly more critical, deciding when and how to discard data before storing or transmitting it. Such methods have been developed in two areas: coding theory, and sparse approximation (SA) (and its variants called compressive sensing (CS) and streaming algorithms). \n Coding theory and computational complexity are both well established fields that enjoy fruitful interactions with one another. On the other hand, while significant progress on the SA/CS problem has been made, much of that progress is concentrated on the feasibility of the problems, including a number of algorithmic innovations that leverage coding theory techniques, but a systematic computational complexity treatment of these problems is sorely lacking. The workshop organizers aim to develop a general computational theory of SA and CS (as well as related areas such as group testing) and its relationship to coding theory. This goal can be achieved only by bringing together researchers from a variety of areas. We will have several tutorial lectures that will be directed to graduate students and postdocs. \n These will be hour-long lectures designed to give students an introduction to coding theory, complexity theory/pseudo-randomness, and compressive sensing/streaming algorithms. \n We will have a poster session during the workshop and everyone is welcome to bring a poster but graduate students and postdocs are especially encouraged to give a poster presentation. \n Confirmed speakers: \n \n Eric Allender, Rutgers\n Mark Braverman, Princeton\n Mahdi Cheraghchi, Carnegie Mellon University\n Anna Gal, The University of Texas at Austin\n Piotr Indyk, MIT\n Swastik Kopparty, Rutgers\n Dick Lipton, Georgia Tech\n Andrew McGregor, University of Massachusetts, Amherst\n Raghu Meka, IAS\n Eric Price, MIT\n Ronitt Rubinfeld  MIT\n Shubhangi Saraf, IAS\n Chris Umans, Caltech\n David Woodruff, IBM\n \n We have some funding for graduate students and postdocs. For registration and other details, please look at the workshop webpage: \n \n https://sites.google.com/site/umccsworkshop2012/"], "link": "http://polylogblog.wordpress.com/2012/05/30/sparsity-workshop-2012/", "bloglinks": {}, "links": {"http://feeds.wordpress.com/": 1, "http://www.buffalo.edu/": 1, "https://sites.google.com/": 2}, "blogtitle": "the polylogblog"}, {"content": ["While on the topic of STOC, I also wanted to mention a STOC workshop on \u201c Algorithms for Distributed and Streaming Data \u201d that will hopefully be of interest. It will take place Saturday afternoon, 19th May in NYU. The schedule can be found here . \n So here\u2019s the pitch: At this point it\u2019s readily apparent that big data has become big news (e.g., see here and here ). But what does this mean for the STOC/FOCS/SODA community? What are the algorithmic problems we could be solving? What are the appropriate computational models? Are there opportunities for industrial impact? What should we be teaching our undergraduate and graduate students? To address the relevant topics, we\u2019ve lined-up a great set of speakers including Sergei Vassilvitskii , John Langford , Piotr Indyk , and Ashish Goel . Hope to see you there."], "link": "http://polylogblog.wordpress.com/2012/05/04/stoc-workshop-algorithms-for-distributed-and-streaming-data/", "bloglinks": {}, "links": {"http://feeds.wordpress.com/": 1, "http://hunch.net/": 1, "http://people.mit.edu/": 1, "http://theory.stanford.edu/": 1, "http://www.stanford.edu/": 1, "http://www.nytimes.com/": 2, "http://people.umass.edu/": 2}, "blogtitle": "the polylogblog"}, {"content": ["If yes, just a reminder that this year (for the first time) there\u2019ll be an award for the best student presentation. More details here . In addition to the cash, the reputation for giving great talks can be very helpful when applying for jobs. \n We\u2019ll be giving preference to talks that are \u201cclear, compelling, and appeal to a broad cross-section of the STOC audience.\u201d My suggestion of giving extra credit for incorporating fire juggling, 3D slides, and celebrity guests fell on deaf ears."], "link": "http://polylogblog.wordpress.com/2012/05/03/are-you-a-student-giving-a-stoc-presentation/", "bloglinks": {}, "links": {"http://feeds.wordpress.com/": 1, "http://www.nyu.edu/": 1}, "blogtitle": "the polylogblog"}, {"content": ["Next up in the mini-course on data streams (first two lectures here and here ) were lower bounds and communication complexity. The slides are here : \n  \n The outline was: \n \n Basic Framework: If you have a small-space algorithm for stream problem , you can turn this into a low-communication protocol for a related communication problem . Hence, a lower bound on the communication required to solve implies a lower bound on the space required to solve . Using this framework, we first proved lower bounds for classic stream problems such as selection, frequency moments, and distinct elements via the communication complexity of indexing, disjointness, and Hamming approximation. \n Information Statistics: So how do we prove communication lower bounds? One powerful method is to analyze the information that is revealed about a player\u2019s input by the messages they send. We first demonstrated this approach via the simple problem of indexing (a neat pedagogic idea courtesy of Amit Chakrabarti ) before outlining how the approach would extend to the disjointness problem.\n \n Hamming Distance: Lastly, we presented a lower bound on the Hamming approximation problem using the ingenious but simple proof [Jayram et al.] \n \n Tout le monde! Here\u2019s the group photo from this year\u2019s L\u2019Ecole de Printemps d\u2019Informatique Th\u00e9orique ."], "link": "http://polylogblog.wordpress.com/2012/04/12/epit-lectures-lower-bounds/", "bloglinks": {}, "links": {"http://polylogblog.wordpress.com/": 3, "http://feeds.wordpress.com/": 1, "http://www.dartmouth.edu/": 1, "http://www.univ-paris-diderot.fr/": 1, "http://www.theoryofcomputing.org/": 1, "http://people.umass.edu/": 2}, "blogtitle": "the polylogblog"}, {"content": ["Piotr Indyk asked if I could post the following announcement and I\u2019m happy to oblige. \n Piotr\u2019s Post-Doc Position: Applications are invited for a Postdoctoral Research Assistant position for the MIT-Shell-Draper Lab research project \n \u201cApplications of compressive sensing and sparse structure exploitation in hydrocarbon reservoir exploration and surveillance\u201d \n The goal of the project is to develop novel compressive sensing algorithms for geoscience problems in the area of hydrocarbon field exploration and surveillance. The appointment is initially for one-year, with the possibility of renewal for up to 3 years. The appointment should start either during the summer (the preferred option) or the fall of 2012. \n Duties and Responsibilities: \n \n Provide expertise on and contribute to the development of compressive sensing and sparse recovery algorithms for geoscience applications\n Help MIT faculty in coordination of research projects, including periodic reporting and documentation as required by the program timeline\n Frequent travel to Shell facilities in Houston\n \n Minimum Qualifications \n \n Ph.D. in Computer Science, Electrical Engineering, Mathematics or related disciplines\n \n Preferred Qualifications \n \n Expertise in sparse recovery, compressive sensing, streaming/sketching, machine learning and statistical inference algorithms\n Experience and/or interest in research projects of interdisciplinary nature\n Programming experience (MATLAB)\n \n Applications (including CV and three reference letters) should be submitted to \n \n https://postdoc.csail.mit.edu/searches/sparsityp-search/ \n \n ideally by April 15, 2012. However, applications will be considered until the position is filled."], "link": "http://polylogblog.wordpress.com/2012/04/08/compressed-sensing-post-doc/", "bloglinks": {}, "links": {"https://postdoc.mit.edu/": 1, "http://feeds.wordpress.com/": 1, "http://people.mit.edu/": 1}, "blogtitle": "the polylogblog"}, {"content": ["In the second lecture, we discussed algorithms for graph streams. Here we observe a sequence of edges and the goal is to estimate properties of the underlying graph without storing all the edges. The slides are here : \n  \n We covered: \n \n Spanners: If you judiciously store only a subset of the edges, you can ensure that the distance between any two nodes in the subgraph is only a constant factor larger than the distance in the entire graph. \n Sparsifiers: Here you also remember a subset of edges but also apply weights to these edges such that the capacity of every cut is preserved up to a small factor. We show how to do this incrementally. \n Sketching: All this talk of remembering a subset of the edges is all very well but what if we\u2019re dealing with a fully dynamic graph where edges are both added and deleted. Can we still compute interesting graph properties if we can\u2019t be sure the edges we remember wouldn\u2019t subsequently be deleted? You\u2019ll have to see the slides to find out. Or see this SODA paper . \n \n Lunch Break! If you want to fully recreate the experience of a French workshop, I suggest you now find yourself a plate of oysters and break for lunch. Lectures will resume shortly."], "link": "http://polylogblog.wordpress.com/2012/04/03/epit-lectures-graph-streams/", "bloglinks": {}, "links": {"http://feeds.wordpress.com/": 1, "http://people.umass.edu/": 4}, "blogtitle": "the polylogblog"}]
[{"blogurl": "http://hashimotolaboratory.blogspot.com\n", "blogroll": [], "title": "Hashimoto Laboratory's Blog"}, {"content": ["Improving the concept of self-balancing unicycle, Honda has introduced the brand new U3-X as their new personal mobility platform.  The regular large wheel, made up of several small wheels in a series makes the U3-X particularly interesting.  These small wheels can rotate independently, which make the device go forward, backward, side-to-side and diagonally. The user just has to lean to the direction where he wants to go.  Right now the \"experimental model\" of the U3-X gets a single hour of battery and weighs under 22 pounds, with a seat and foot rests that fold into the device for extra portability.   Remember you can follow our updates in our Twitter Account"], "link": "http://hashimotolaboratory.blogspot.com/feeds/6567627256339239826/comments/default", "bloglinks": {}, "links": {"http://twitter.com/": 1}, "blogtitle": "Hashimoto Laboratory's Blog"}, {"content": ["In the Natural History of our planet, humans and organisms have collaborated among themselves to create societies, farms, entities. We call this activity collective intelligence, and in some cases it is deliberate and in others is a consequence. MIT is actively pursuing research in this area with the Center for Collective intelligence , where they collect a number of works for everyone to take a peek on them. Some of the most impressive shows of collective intelligence in the world are the flying duck flocks which present beautiful forms, can you think in any other way organisms create forms that appear to be work of a higher intelligence.   Remember you can follow our updates in our Twitter Account"], "link": "http://hashimotolaboratory.blogspot.com/feeds/7566278980374069094/comments/default", "bloglinks": {}, "links": {"http://twitter.com/": 1, "http://cci.mit.edu/": 1}, "blogtitle": "Hashimoto Laboratory's Blog"}, {"content": ["As most of you should know, the mars rover, Spirit, was launched with the purpose to give us a better understanding of the mars soil and atmosphere characteristics. But now it is lost. The Spirit Rover , one of the most famous robots of late,\u00a0 was first deployed in 2004 with the simple, yet important, task of sampling Martian soil\u00a0 and get important information for further missions. Originally the rover was suppose to work for 90 days, yet the system was rather efficient and went on 20 times that time until it became stuck. Because of that, the solar panel system used to power up the robot wont be able to be filled on time resulting in the robot cease of functions. NASA is still suing the robot for some basic sensing functions, and they will till it becomes inoperable. This is just an example on how robots, through expensive are also made to be recyclable, maybe in some 50 years we will be able to retrieve it, who knows, maybe sooner.    Remember you can follow our updates in our Twitter Account"], "link": "http://hashimotolaboratory.blogspot.com/feeds/4610194261643759520/comments/default", "bloglinks": {}, "links": {"http://twitter.com/": 1, "http://en.wikipedia.org/": 1}, "blogtitle": "Hashimoto Laboratory's Blog"}, {"content": ["Last year at iREX 2009 Mitsubishi debuted a robot arm capable of building a lego piece in a rather fast way. With this kind of advancements and precision, teleoperation and robotic surgery are surely deemed to become more reliable to the eyes of people. As well more mundane tasks may be done by robots in a more efficient way and even faster than by humans.  What do you think, do robots are being built in the right direction??   Remember you can follow our updates in our Twitter Account"], "link": "http://hashimotolaboratory.blogspot.com/feeds/8593922600107465859/comments/default", "bloglinks": {}, "links": {"http://singularityhub.com/": 1, "http://twitter.com/": 1}, "blogtitle": "Hashimoto Laboratory's Blog"}, {"content": ["We all have seen movies like Matrix, Star Trek and Star Wars where ships somehow land pretty much by themselves, the pilot has nothing but press a couple of buttons and the ship will land. People at MIT in joint research with the NASA are working together to be a step closer to this reality.  SPHERES project aims to have autonomous mobile objects capable of autonomous flight and interaction, and are currently being tested in zero gravity environments in the International Space Station. What are your thoughts on this, would you ride a vehicle knowing that most of the control is being performed by a computer.   Remember you can follow our updates in our Twitter Account"], "link": "http://hashimotolaboratory.blogspot.com/feeds/34932109234571477/comments/default", "bloglinks": {}, "links": {"http://twitter.com/": 1, "http://hashimotolaboratory.blogspot.com/": 2}, "blogtitle": "Hashimoto Laboratory's Blog"}, {"content": ["This blog is now located at http://hashimotolaboratory.blogspot.com/.  You will be automatically redirected in 30 seconds, or you may click here .   For feed subscribers, please update your feed subscriptions to  http://hashimotolaboratory.blogspot.com/atom.xml."], "link": "http://hashimotolaboratory.blogspot.com/", "bloglinks": {}, "links": {"http://hashimotolaboratory.blogspot.com/": 1}, "blogtitle": "Hashimoto Laboratory's Blog"}, {"content": ["Hello everyone and we hope you have a good Monday. This time at CeBIT in Hannover there was a special display that catch everyone\u2019s attention. The Intendix from Guger Technologies ( g*tec ) is a device that uses a swimming like cap to detect EEG from the brain, and it uses specialized software to translate those signals into directed information. For example, we have some applications using Second Life and the device where the avatar is being controlled by thoughts rather than conventional input.  As well the shown application was oriented towards spelling with the brain, where you do nothing but think about the word and it will appear in the screen. Do you think these are good technologies, we hope to hear from you, meanwhile here are some videos of the applications.  \u00a0  \u00a0   Remember you can follow our updates in our Twitter Account"], "link": "http://hashimotolaboratory.blogspot.com/feeds/1825415851429805885/comments/default", "bloglinks": {}, "links": {"http://twitter.com/": 1, "http://www.intendix.com/": 1, "http://www.cebit.de/": 1, "http://www.gtec.at/": 1}, "blogtitle": "Hashimoto Laboratory's Blog"}, {"content": ["Willow Garage is a startup devoted to develop a fully and integral OS for robots. Their current work is called ROS, but this specific entry is to talk about the Texas Robot.  This robot is made to be able to help people working far from the company to have a more interactive dynamic with the people working at the headquarters, what started as an experiment now is a fully developed platform and probably with huge commercializing possibilities. We leave you with a video explaining the concept behind the Texas Robot.   Remember you can follow our updates in our Twitter Account"], "link": "http://hashimotolaboratory.blogspot.com/feeds/854977775093690998/comments/default", "bloglinks": {}, "links": {"http://twitter.com/": 1, "http://www.willowgarage.com/": 1}, "blogtitle": "Hashimoto Laboratory's Blog"}, {"content": ["Since we were kids, robots showing feelings have been in the grey area of the amazing and the creepy.\u00a0 Being able to interpret how a robot is feeling have being an exiting and daunting idea.  Engineered arts a British company bring us a step closer to that realization. With their RoboThespian (Thespian is a word for actor) and a solid implementation of open source implementation like Blender they have been able to recreate theatrical scenes, as well as to imprint a degree of emotion to the robot movements and expressions. The robots are for sale and fully available to research purposes, be sure to check them out, meanwhile we leave you with a couple of videos that show how the system is implemented and the degree of realism the robot can achieve.    Remember you can follow our updates in our Twitter Account"], "link": "http://hashimotolaboratory.blogspot.com/feeds/5584007862433642066/comments/default", "bloglinks": {}, "links": {"http://twitter.com/": 1, "http://www.robothespian.com/": 1}, "blogtitle": "Hashimoto Laboratory's Blog"}, {"content": ["This blog post is about some of the work that\u2019s being done at the Cognitive Informatics Research Group at MTA SZTAKI, in Budapest, Hungary. Hashimoto Lab is in loose but constant collaboration with this lab. If we were asked to summarize what were are trying to do at the Cognitive Informatics Research Group, we would probably say that we are working on enhancing the flexibility of telemanipulation. Telemanipulation is the act of remotely controlling an actuator (which is located in a distant or possibly hazardous environment that cannot easily be accessed by the operator at any rate). A conceptual diagram of traditional teleoperation can be seen on Figure 1. As we can see, the operator handles a local master device, which is usually a replica of the actuator and is connected with the real actuator (the slave device) through telecommunication channels. Traditional teleoperation introduces many control and stability issues, to which many solutions have been proposed and these solutions have contributed to a huge body of literature on the subject.    Figure 1  Our goal is to enhance the teleoperation experience by introducing new channels of communication between the operator and the master device. In more traditional environments, generally we use exact replicas of the slave devices, and the modes of interaction between the operator and the master devices are analogous to the modes of operation that the slave device would require. In order to enhance these modes of interaction, we create an environment that aims to put the brain in the loop , as we like to say. The conceptual diagram of the master side of the telemanipulation setup can be seen in figure 2. In the figure, non-conventional communication channels are modes of communication that use sensory modalities to convey information that are different from the sensory modalities normally used for the task. For example, we could imagine force feedback to be provided through the visual cues or through audio. Provided that the channels are designed well, and the coding techniques used to code the transferred information are light enough not to overburden the operator\u2019s cognitive capacities, the operator can quickly learn how to use the channel efficiently.    Figure 2  This example highlights an important aspect of our telemanipulation setup. By decoupling the feedforward (control) path from the feedback channels, we alleviate stability problems that could be caused by using the same device for actuation and feedback. In addition, by introducing a virtual reality between the master and slave side, we provide a means for software-based actuation. The software can be distributed in nature, so that several parties can contribute to the telemanipulation tasks simultaneously. Problems caused by feedback delays can also be alleviated by such a system, if blocking mechanisms are incorporated within the virtual reality in order to keep the operator from manipulating the system when it is still in a transient state. Within the framework presented here, our research can be broken into the following 3 main branches:    Cognitive actuation    Cognitive communication channels for feedback    Eto-robotics   These research directions, while somewhat disparate, all contribute to the same goals of providing more flexible means for (remote) human-robot interaction.    Cognitive actuation   We are developing a 3D virtual environment like the one shown in figure 2. It is highly modular and has well-defined interfaces for actuation devices. Any device can be incorporated into the virtual reality environment, provided that it is programmed to implement these interfaces. Currently we can control remote transportation robots by using more expensive devices such as position tracking data suits, or cheaper ones such as Nintendo Wii controllers and iPhones. The virtual environment has a distributed architecture, people can log on from different locations, connect their actuation and/or feedback devices (provided these devices implement a generic interface), and control devices that have been connected from different locations. Other forms of actuation include path control based on automated matching of human hand movements to CAD models. In order to facilitate the control of various devices connected in various locations through our virtual environment, we have developed appropriate access mechanisms and distributed computational processing mechanisms.    Cognitive communication channels for feedback   Currently we have three projects within the area running in parallel: force feedback through peripheral vision, tactile feedback using applied models of tactile nerve endings, and tactile feedback through sound. Force feedback through peripheral vision provides a vision-based feedback method that is minimally invasive. After a short learning period, the user can learn to interpret the visual cues without paying much explicit attention to them. The models of tactile nerve endings used in our tactile feedback project involve descriptions of time-variant characteristic functions of different kinds of tactile receptors, and also their relative distributions. Finally, our study of sound-based tactile feedback deals with two aspects: the kinds of sound parameters that can be used to convey physical parameters of surfaces (we find that optimal sound parameters depend on the dimension of tactile perception we would like to convey), and the ways these sounds can be combined so that the end result is meaningful and at the same time does not overload the user\u2019s cognitive capacities.    Eto-robotics   Eto-robotics comes from the words ethology (the science dealing with animal behavior) and robotics. The goal of this research is to use models of animal behavior to create synthetic forms of robot behavior that users can sympathize with and relate to. The idea for this research comes from the realization that while humanoid robotics is a very impressive and dynamically evolving field, more often than not it produces robots that the user quickly becomes frustrated with. This is due to the contradiction between the user\u2019s expectations and what the robots can do. The user\u2019s expectations are unreasonably high because the robot looks like a human and is therefore expected to act like a human. According to some, the more human-like a robot becomes, the greater the tension will be between the user\u2019s expectations and reality, because the robot will almost be human, but not a human (see uncanny valley effect). The main idea of our research in eto-robotics is to create behavioral forms for robots that will help them to be perceived as a different species altogether. This way, the user will approach the robot with reduced expections, and a more realistic view of what kinds of tasks the robot can accomplish and how the user should interact with it in order to perform these tasks with greater efficiency. In a way similar to how we have learned to deal with cats, dogs and other pets (as a result of millennia of interactive experience), perhaps we can learn to interact with robots more efficiently by perceiving them as an eccentric, but somewhat loveable species.  Remember you can follow our updates in our Twitter Account"], "link": "http://hashimotolaboratory.blogspot.com/feeds/5312032024426416716/comments/default", "bloglinks": {}, "links": {"http://twitter.com/": 1, "http://lh4.ggpht.com/": 1, "http://lh6.ggpht.com/": 1}, "blogtitle": "Hashimoto Laboratory's Blog"}, {"content": ["Hello readers, this time we have an entry wrote by Peshala, member of our lab and member of the team that participated in the competition. This time we would like to share our experience at \"Real World Robot Challenge 2009\", which is also referred to as the \"Tsukuba Challenge\". The New Technology Foundation holds Tsukuba Challenge in Tsukuba City (Ibaraki prefecture, Japan) every year, which is a mobile robot contest to spur innovation and encourage research on outdoor autonomous navigation. The challenge is to cover a distance of 1 km along a predefined course by an autonomous mobile robot in the presence of pedestrians and cyclists. The track is one used by people in their everyday life and is not being modified in anyway for robot navigation. To qualify for the final, the mobile robots should pass a trial qualifying event with a distance of 140m.  Among 72 teams from various universities, research institutes and individuals, 34 teams made it to the final including our team. An unexpected problem came in the way in the final challenge and our robot only navigated 192m in 12 minutes. Our robot got stuck in amidst of an area full of fallen leaves and we had to announce retirement. Five teams managed to clear the goal in the final. Here are some of the photos of our robot from the real event. \u00a0  \u00a0 In the right column of the blog you can find the link to the official site as well as the official route.   Remember you can follow our updates in our Twitter Account"], "link": "http://hashimotolaboratory.blogspot.com/feeds/8675424386409833446/comments/default", "bloglinks": {}, "links": {"http://twitter.com/": 1, "http://lh5.ggpht.com/": 1}, "blogtitle": "Hashimoto Laboratory's Blog"}, {"content": ["A new development of Kyoto University, a Jumping robot that has been developed by Tomotaka Takahashi. The creator stated he would rather have a robot that entertains people than a robot that performs an specific task. Lets hope to see more of this in the future."], "link": "http://hashimotolaboratory.blogspot.com/feeds/478802477732780843/comments/default", "bloglinks": {}, "links": {}, "blogtitle": "Hashimoto Laboratory's Blog"}, {"content": ["Boston Dynamics, the creators of the Big Dog robot have developed a new biped model which looks fairly stable.  It can react positively to pushes and velocity changes. This research will allow for faster humanoid robots in the future, which will allow for easier implementation for routine tasks.   \u00a0 Remember you can follow our updates in our Twitter Account"], "link": "http://hashimotolaboratory.blogspot.com/feeds/8819519748107044432/comments/default", "bloglinks": {}, "links": {"http://twitter.com/": 1}, "blogtitle": "Hashimoto Laboratory's Blog"}, {"content": ["We are implementing now a new way to share the blog posts here in Hashimoto Laboratory, via Facebook share counter.  Share"], "link": "http://hashimotolaboratory.blogspot.com/feeds/6049232288130546811/comments/default", "bloglinks": {}, "links": {"http://www.facebook.com/": 1}, "blogtitle": "Hashimoto Laboratory's Blog"}, {"content": ["Since its first inception, Robots have always been hard to standardize, Japan has its own RT Middleware to try and fight this issue, and other platforms such as ICE and Microsoft Robotics Developer Studio also exists. Yet, efforts have not been oriented in the fact that a Robot may need a native OS to run and generate any function it is capable of.  For this reason some people are proposing to standardize an unique system, so development can be easily transferred from some platform to another, a good candidate for this is Willow Garage own OS system, which has proven to be most effective for their current research. We leave you with a video and remember to send any comments and questions.   Remember you can follow our updates in our Twitter Account"], "link": "http://hashimotolaboratory.blogspot.com/feeds/101819633622431806/comments/default", "bloglinks": {}, "links": {"http://twitter.com/": 1}, "blogtitle": "Hashimoto Laboratory's Blog"}, {"content": ["Hello readers. We hope you have had a nice time during our absence.  Now we are going to report on a new technology that was recently shown here in Tokyo University at Shinoda Laboratory . Basically they are able to five physical feedback to a hand grasping an hologram, this technology is feasible thanks to a couple of Wii Motes that are in charge of tracking the hand position. And an air tracking display, which basically lets the user pin point where point of pressure will be delivered and giving the sensation of touching something. The amount of applications this work could have range among other, videogames and disabled people help when going through the street. We let you with the video and hope you enjoy.   Remember you can follow our updates in our Twitter Account"], "link": "http://hashimotolaboratory.blogspot.com/feeds/5129109507466514894/comments/default", "bloglinks": {}, "links": {"http://twitter.com/": 1, "http://www.ac.jp/": 1}, "blogtitle": "Hashimoto Laboratory's Blog"}, {"content": ["Hello, we hope you have had a great week, we know we have. Here in Japan the national sport is the baseball, they have a very strong league and in fact they won the last Baseball World Classic, which is the major award a nation can obtain in this sport. So, what happens with a nation leading the world in robotics and baseball lover, yes, Masatoshi Ishikawa has developed a robotic arm that is able to pitch and catch baseball balls as fast as 150 kph, which is itself an impressive feat for a robotic architecture. Enjoy the video, and remember to comment and send ideas and suggestions.   Remember you can follow our updates in our Twitter Account"], "link": "http://hashimotolaboratory.blogspot.com/feeds/2498649983761299778/comments/default", "bloglinks": {}, "links": {"http://twitter.com/": 1}, "blogtitle": "Hashimoto Laboratory's Blog"}, {"content": ["Computers now a days have been granted with a very high number of communication abilities, like text recognition, or some early form of speech recognition. Oxford University researchers have created a program that allows a computer to recognize sign language when watching TV, now, itself is already a big task, furthermore they ere able to allow the computer learn the language without external help, then after watching a TV program featuring sign language commentator, the computer will be capable of recognizing as many words as they showed in the program. This presents a great hop in recognition field, as it may allow deaf and mute people to interact with robots and computer maybe in a more seamless way than we already do. You can watch a demo in the following video.   Remember you can follow our updates in our Twitter Account"], "link": "http://hashimotolaboratory.blogspot.com/feeds/7125376578282308236/comments/default", "bloglinks": {}, "links": {"http://twitter.com/": 1}, "blogtitle": "Hashimoto Laboratory's Blog"}, {"content": ["Last week we had the pleasure of receiving a visitor researcher in the area of mobile robotics from India, his Name is Prabin Padhy, and we wish him a fruitful experience during his 8 months of stay."], "link": "http://hashimotolaboratory.blogspot.com/feeds/1197617588866560445/comments/default", "bloglinks": {}, "links": {}, "blogtitle": "Hashimoto Laboratory's Blog"}, {"content": ["By now, probably all of you are aware of the existence of Honda amazing humanoid robot ASIMO, well Toyota is having its share in these kind of robotics and from time to time have presented us a wide variety of models, being one of the most popular its trumpet and violin playing robot. Now, we have a video of their latest development, the running robot, the feat itself does not sound impressive at all, yet, wait to see how well the robot behaves, even with external forces pushing it, it has yet to be perfected, but the path is right on tracks. We leave you with a video of the robot in action.  Remember you can follow our updates in our Twitter Account"], "link": "http://hashimotolaboratory.blogspot.com/feeds/4427934294948401738/comments/default", "bloglinks": {}, "links": {"http://twitter.com/": 1}, "blogtitle": "Hashimoto Laboratory's Blog"}, {"content": ["Do you know what happens when a giant claw of 15 tones a Wiimote and a good programming ability are mixed. Well\u00a0 Transmin company at Australia just had the answer to that question in they latest development, where they implemented a solution for controlling a giant crane using a Wiimote and some python programming. Do you have some more applications using the Wiimote, please be sure to share them by sending a mail to this blog. See you next time \u00a0   Remember you can follow our updates in our Twitter Account"], "link": "http://hashimotolaboratory.blogspot.com/feeds/7077294631787183399/comments/default", "bloglinks": {}, "links": {"http://twitter.com/": 1, "http://transmin.com.au/": 1}, "blogtitle": "Hashimoto Laboratory's Blog"}, {"content": ["As we all know global Warming is becoming a major trend in all kind of researches in the world. Lately the NASA associated with Northrop Grumman into releasing a version of the Global Hawk, which is an unmanned flying vehicle into sensing the status in the northern pole so information in current climate changes is delivered efficiently online. \u00a0    \u201cUsing these data, scientists would also be able to measure the speed, direction and topographic height of ice caps whose sub-glacial bedrock topography is already mapped \u2013 thereby providing critical information that can be used to improve models of glacier mechanics.\u201d  \u00a0  So Robotics are in our everyday lives and hopefully some day soon we will be able to interact more than ever with robots.   Remember you can follow our updates in our Twitter Account"], "link": "http://hashimotolaboratory.blogspot.com/feeds/4338082009916500291/comments/default", "bloglinks": {}, "links": {"http://lh3.ggpht.com/": 1, "http://twitter.com/": 1}, "blogtitle": "Hashimoto Laboratory's Blog"}, {"content": ["It is no secret in Japan there has always been a particular fascination with robots. This highly resonates in the country research output in the robotic matter, which is the number one in the world.  This said, this fascination extrapolates to the animation, which is by many probably the most recognized way of Japanese culture known in the world.      In the artificial island of Odaiba located in Tokyo bay there is a 1:1 Robot of the Gundam anime to commemorate the 50 anniversary of this series start. If you happen to be in Japan within the next 2 months be sure to check it, as it is going to Korea in August.   Remember you can follow our updates in our Twitter Account"], "link": "http://hashimotolaboratory.blogspot.com/feeds/2230507438654170507/comments/default", "bloglinks": {}, "links": {"http://twitter.com/": 1, "http://www.youtube.com/": 1}, "blogtitle": "Hashimoto Laboratory's Blog"}, {"content": ["Hello readers, here we are again bringing you some good stories from the scientific world. Now, we are going to introduce you to a rush that recently finished called the Netflix Prize . It consisted basically in a prize open to the public to see who get to design the most effective prediction algorithm. The objective of having a competition to get the most efficient prediction algorithm was to apply it to the recommendation engine they have running in their site, and in doing so being able to recommend movies that the user might like in a more precise and effective way. The winner team has been  BellKor's Pragmatic Chaos which was a joint team leader by AT&T research.    Is good to see this good initiative in promoting the commercial development of algorithms.    \u00a0    Remember you can follow our updates in our Twitter Account"], "link": "http://hashimotolaboratory.blogspot.com/feeds/6051599228879172352/comments/default", "bloglinks": {}, "links": {"http://twitter.com/": 1, "http://www.netflixprize.com/": 1}, "blogtitle": "Hashimoto Laboratory's Blog"}, {"content": ["Hello readers, we hope you have a wonderful day, night or afternoon. In a very uncommon report, Forbes Magazine has released what they call the AI report , this has as its objective to inform people the current state of the art in Artificial Intelligence. It presents a good insight on some of the most important ideas and theories on AI that have been developed in the recent years, like the creation of the AGI, which we will cover in an upcoming post. We hope you have fun reading it and commenting on it.   Remember you can follow our updates in our Twitter Account"], "link": "http://hashimotolaboratory.blogspot.com/feeds/4273200564529845851/comments/default", "bloglinks": {}, "links": {"http://twitter.com/": 1, "http://www.forbes.com/": 1}, "blogtitle": "Hashimoto Laboratory's Blog"}]
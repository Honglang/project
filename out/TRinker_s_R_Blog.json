[{"blogurl": "http://trinkerrstuff.wordpress.com\n", "blogroll": [], "title": "TRinker's R Blog"}, {"content": ["I have been playing with the beta version of qdap utilizing the presidential debates as a data set. qdap is in a beta phase lacking documentation though I\u2019m getting there. In previous blog posts ( presidential debate 1 LINK and VP debate LINK ) I demonstrated some of the capabilities of qdap . I wanted to further show some of qdap\u2019s capabilities while seeking to provide information about the debates. \n In previous posts readers made comments or emailed regarding functionality of qdap . This was extremely helpful in working out bugs that arise on various operating systems. If you have praise or methods you used to run the qdap scripts please leave a comment saying so. However, if you are having difficulty please file an issue at qdap\u2019s home, GitHub ( LINK ). \n In this post we\u2019ll be looking at: \n 1. A faceted gantt plot for each of the speeches via gantt_plot \n2. Various word statistics via word_stats \n3. A venn diagram showing the overlap in word usage via trans.venn \n4. A dissimilarity matrix indicating closeness in speech via dissimilarity \n5. iGraph Visualization of dissimilarity \n Installing qdap (note: qdap was updated 10/23/12) \nHere\u2019s the github link for qdap ( LINK ) and install instructions \n # install.packages(\"devtools\")\nlibrary(devtools)\ninstall_github(\"qdap\", \"trinker\") \n Reading in the data sets and Cleaning \n library(qdap) #load qdap\n# download transcript of the debate to working directory\nurl_dl(pres.deb1.docx, pres.deb2.docx, pres.deb3.docx) \n\n# load multiple files with read transcript and assign to working directory\ndat1 <- read.transcript(\"pres.deb1.docx\", c(\"person\", \"dialogue\"))\ndat2 <- read.transcript(\"pres.deb2.docx\", c(\"person\", \"dialogue\"))\ndat3 <- read.transcript(\"pres.deb3.docx\", c(\"person\", \"dialogue\"))\n\n# qprep for quick cleaning\ndat1$dialogue <- qprep(dat1$dialogue)\ndat2$dialogue <- qprep(dat2$dialogue)\ndat3$dialogue <- qprep(dat3$dialogue)\n\n# Split each sentece into it's own line\ndat1b <- sentSplit(dat1, \"dialogue\", stem.col=FALSE) \ndat1$person <- factor(dat1$person , levels = qcv(ROMNEY, OBAMA, LEHRER))\ndat2b <- sentSplit(dat2, \"dialogue\", stem.col=FALSE) \ndat3b <- sentSplit(dat3, \"dialogue\", stem.col=FALSE) \n\n# Create a large data frame by the three debates times\nL1 <- list(dat1b, dat2b, dat3b)\nL1 <- lapply(seq_along(L1), function(i) data.frame(L1[[i]], time = paste(\"time\", i)))\ndat4 <- do.call(rbind, L1)\n\n#view a truncated version of the data (see also htruncdf)\ntruncdf(dat4)  \n Faceted Gantt Plot \n #reorder factor levels\ndat4$person <- factor(dat4$person, \n levels=qcv(terms=\"OBAMA ROMNEY CROWLEY LEHRER QUESTION SCHIEFFER\"))\n\nwith(dat4, gantt_plot(dialogue, person, time, xlab = \"duration(words)\", scale = \"free\")) \n \n Basic Word Statistics \nThis section utilizes the word_stats function in conjunction with ggplot2 to create a heat map for various descriptive word statistics. Below is a list of column names for the function\u2019s default print method. \n column.title description       \n1 n.tot  number of turns of talk    \n2 n.sent  number of sentences     \n3 n.words  number of words      \n4 n.char  number of characters     \n5 n.syl  number of syllables     \n6 n.poly  number of polysyllables    \n7 sptot  syllables per turn of talk   \n8 wps   words per sentence     \n9 cps   characters per sentemce    \n10 sps   syllables per sentence    \n11 psps   polly syllables per sentence   \n12 cpw   characters per word     \n13 spw   syllables per word     \n14 n.state  number of statements     \n15 n.quest  number of questions     \n16 n.incom  number of incomplete satetments  \n17 n.hapax  number of hapax legomenon    \n18 n.dis  number of dis legomenon    \n19 grow.rate proportion of hapax legomenon to words\n20 prop.dis  proportion of dis legomenon to words \n z <- with(dat4, word_stats(dialogue, list(person, time), tot))\nz$ts\nz$gts\n(z2 <- colsplit2df(z$gts)) #split a qdap merged column apart\nz2$person <- factor(z2$person, levels=   #relevel factor\n qcv(terms=\"OBAMA ROMNEY CROWLEY LEHRER SCHIEFFER QUESTION\"))\nx <- with(z2, z2[order(person, time), ])\n\nlibrary(reshape2); library(plyr)\nx2 <- melt(x)\nx2 <- ddply(x2, .(variable), transform,\n rescale = rescale(value))\nx2$var <- as.factor(paste2(x2[, 1:2]))\nx3 <- x2[x2$person %in% qcv(ROMNEY, OBAMA), ]\nx3$var <- factor(x3$var, levels = rev(levels(x3$var)))\n\nggplot(x3, aes(variable, var)) + geom_tile(aes(fill = rescale),\n colour = \"white\") + scale_fill_gradient(low = \"white\",\n high = \"black\") + theme_grey() + labs(x = \"\",\n y = \"\") + scale_x_discrete(expand = c(0, 0)) +\n scale_y_discrete(expand = c(0, 0)) + theme(legend.position = \"none\",\n axis.ticks = element_blank(), axis.text.x = element_text(angle = -90, \n  hjust = 0, colour = \"grey50\")) \n \n Venn Diagram \nWith proper stop word use and small, variable data sets a Venn diagram can be informative. In this case the overlap is fairly strong and less informative though labels are centered. Thus labels closer in proximity are closer in words used. \n with(subset(dat4, person == qcv(ROMNEY, OBAMA)), \n trans.venn(dialogue, list(person, time), \n title.name = \"Presidential Debates Word Overlap 2012\")\n) \n \n Dissimilarity Matrix \n dat5 <- subset(dat4, person == qcv(ROMNEY, OBAMA))\ndat5$person <- factor(dat5$person, levels = qcv(OBAMA, ROMNEY))\n#a word frequency matrix inspired by the tm package's DocumentTermMatrix\nwith(dat5, wfm(dialogue, list(person, time)))\n#with row and column sums\nwith(dat5, word.freq.df(dialogue, list(person, time), margins = TRUE))\n#dissimilarity (similar to a correlation \n#The default emasure is 1 - binary or proportion overlap between grouping variable\n(sim <- with(dat5, dissimilarity(dialogue, list(person, time)))) \n    OBAMA.time.1 OBAMA.time.2 OBAMA.time.3 ROMNEY.time.1 ROMNEY.time.2\nOBAMA.time.2   0.293              \nOBAMA.time.3   0.257  0.303           \nROMNEY.time.1  0.317  0.261  0.245       \nROMNEY.time.2  0.273  0.316  0.285   0.317    \nROMNEY.time.3  0.240  0.276  0.311   0.265   0.312 \n Network Graph \nThe use of igraph may not always be the best way to view the data but this exercise shows one way this package can be utilized. In this plot the wlabels are sized based on number of words used. The distance measures that label the edges are taken from the dissimilarity function (1 \u2013 binary). Colors are based on political party. \n library(igraph)\nZ <- with(dat5, adjacency_matrix(wfm(dialogue, list(person, time))))\ng <- graph.adjacency(Z$adjacency, weighted=TRUE, mode ='undirected')\ng <- simplify(g)\n# set labels and degrees of vertices\nV(g)$label <- V(g)$name\nV(g)$degree <- degree(g)\n\nset.seed(3952)\nlayout1 <- layout.auto(g)\nopar <- par()$mar; par(mar=rep(.5, 4)) #Give the graph lots of room\nplot(g, layout=layout1)\n\nedge.weight <- 9 #a maximizing thickness constant\nz1 <- edge.weight * sim/max(sim)*sim\nE(g)$width <- c(z1)[c(z1) != 0] #remove 0s: these won't have an edge\nnumformat <- function(val, digits = 2) { sub(\"^(-?)0.\", \"\\\\1.\", sprintf(paste0(\"%.\", digits, \"f\"), val)) }\nz2 <- numformat(round(sim, 3), 3)\nE(g)$label <- c(z2)[c(z2) != 0]\nplot(g, layout=layout1) #check it out! \n\nlabel.size <- 15 #a maximizing label size constant\nWC <- aggregate(dialogue~person +time, data=dat5, function(x) sum(word.count(x), na.rm = TRUE))\nWC <- WC[order(WC$person, WC$time), 3]\nresize <- (log(WC)/max(log(WC)))\nV(g)$label.cex <- 5 *(resize - .8)\nplot(g, layout=layout1) #check it out!\n\nV(g)$color <- ifelse(substring(V(g)$label, 1, 2)==\"OB\", \"pink\", \"lightblue\")\n\nplot(g, layout=layout1)\ntkplot(g)\n \n \n This blog post is a rough initial analysis of the three presidential debates. It was meant as a means of demonstrating the capabilities of qdap rather than providing in depth analysis of the candidates. Please share your experiences with using qdap in a comment below and suggestions for improvement via the issues page of qdap\u2019s github site( LINK ). \n For a pdf version of all the graphics created in the blog post -click here-"], "link": "http://trinkerrstuff.wordpress.com/2012/10/23/presidential-debates-2012/", "bloglinks": {}, "links": {"https://dl.dropbox.com/": 1, "http://feeds.wordpress.com/": 1, "https://github.com/": 4, "http://trinkerrstuff.wordpress.com/": 2}, "blogtitle": "TRinker's R Blog"}, {"content": ["One of the most widely seen FAQ coming across list serves and R help sites is the question: \n \u201cHow do I re-arrange/re-order (plotting geom/aesthetic such as bar/labels) in a (insert plot type here) using(insert graphics system here) in R?\u201d \n . \n Don\u2019t believe me? google \u201creorder factor r plot\u201d and see how many hits you get. I\u2019d venture to say that in almost all cases when you use the words \u201cplot\u201d and \u201cre-arrange\u201d/\u201dre-order\u201d in a question the answer is\u2026 \n Reorder your factor levels!! \n . \n Here\u2019s a quick and dirty R theater demo of how to do this: \n library(ggplot2)\nggplot(data=mtcars, aes(y=as.factor(carb), x=mpg, colour=hp)) +\n geom_point()\n\n# Rearrange_Guy: But I want 2 to come first and 8 last\n# Helpful_Gal: OK use rev with levels \n\nmtcars$carb2 <- factor(mtcars$carb, levels=rev(levels(factor(mtcars$carb))))\n\nggplot(data=mtcars, aes(y=carb2, x=mpg, colour=hp)) +\n geom_point()\n\n# Rearrange_Guy: Well I just want to specify the order\n# Helpful_Gal: OK type it in by hand then\n\nmtcars$carb2 <- factor(mtcars$carb, levels=c(\"1\", \"2\", \"3\", \"6\", \"8\", \"4\"))\nggplot(data=mtcars, aes(y=carb2, x=mpg, colour=hp)) +\n geom_point()\n\n# Rearrange_Guy: What about faceting? I bet it doesn't work for that.\n# Helpful_Gal: Um yes it does.\n\nggplot(data=mtcars, aes(y=carb2, x=mpg, colour=hp)) +\n geom_point() + facet_grid(cyl~.)\n\n# Rearrange_Guy: OK Helpful_Gal I want it to go 6, 4, and then 8\n# Helpful_Gal: OK\n\nmtcars$cyl2 <- factor(mtcars$cyl, levels=c(\"6\", \"4\", \"8\"))\nggplot(data=mtcars, aes(y=carb2, x=mpg, colour=hp)) +\n geom_point() + facet_grid(cyl2~.)\n\n# Rearrange_Guy: Why do you keep making new variables?\n# Helpful_Gal: It's probably not the best idea to overwrite variables just for the sake of plotting\n# Rearrange_Guy: Thank you for showing me the way of re-ordering and re-arranging.\n# Helpful_Gal: You welcome. \n So if you catch yourself using \u201cre-arrange\u201d/\u201dre-order\u201d and \u201cplot\u201d in a question think\u2026 \n factor & levels"], "link": "http://trinkerrstuff.wordpress.com/2012/10/15/how-do-i-re-arrange-ordering-a-plot/", "bloglinks": {}, "links": {"http://feeds.wordpress.com/": 1}, "blogtitle": "TRinker's R Blog"}, {"content": ["After the presidential debates I used the beta version of qdap to provide some initial surface level analysis ( LINK to Presidential Debates with qdap-beta ). In the comments of that post, annon (a commenter) provided a link to an analysis/visualization that utilizes bubbles to demonstrate proportion of words and colors and labels to show each candidate\u2019s usage ( LINK ). While I initially liked the graphic it was the shape and colors that appealed to me. Closer inspection reveals that smaller words are hard to get information for and the bubbles make comparing across words difficult. I decided to attempt a visualization for the vice presidential debates using qdap and ggplot2 . \n I decided to use themes rather than words and categorize similar words together. This approach utilizes a function in qdap called termco.a . Here\u2019s the function\u2019s arguments: \n termco.a(text.var, grouping.var=NULL, match.list, short.term = FALSE, \n ignore.case = TRUE, lazy.term = TRUE, elim.old = TRUE, \n zero.replace = 0, output = \"percent\", digits = 2) \n Basically you can supply a list of named character vectors (our themes) to this function as well as dialogue (the debate text) and grouping variable (person) and it will output a list with several data frames. You can get raw counts, percent/proportions or a combination of raw and percent/proportions by grouping variable (person) for each theme. \n The important part is the themes we supply to match list. This function relies on gregexpr meaning it will do partial matching, so there\u2019re some things you\u2019ll want to think about when supplying the themes: \n \n \n If you want to find \u201cread\u201d but not \u201cbread\u201d or \u201creading\u201d use a trailing and leading white space as in \u201d read \u201c \n If you want to find and root word with \u201cread\u201d leading white space as in \u201d read\u201d \n This will also find \u201cready\u201d so if you want any form of the word \u201cread\u201d you\u2019ll have to be explicit and put all these forms in the vector for read with trailing and leading white spaces; ie \u201d read \u201c , \u201d reads \u201c , \u201d reader\u201d (reader and readers), \u201d reading \u201c \n If you use \u201d obama\u201d and \u201d obamacare\u201d termco.a will count obamacare two times; instead use \u201d obama \u201c and \u201d obamacare \u201c or just \u201d obama\u201d \n \n The basic form for the list of vectors supplied to match.list is: \n target.words <- list(\n theme_1 = c(),\n theme_2 = c(),\n theme_n = c(),\n) \n Installing qdap (note: qdap was updated 10/14/12) \nHere\u2019s the github link for qdap ( LINK ) and install instructions \n # install.packages(\"devtools\")\nlibrary(devtools)\ninstall_github(\"qdap\", \"trinker\") \n Let\u2019s look at the results with some themes I examined for VP debates \n library(qdap)\n\nurl_dl(\"vpres.deb1.docx\") #downloads a docx file of the debate to wd\n\ndat <- read.transcript(\"vpres.deb1.docx\", col.names=c(\"person\", \"dialogue\"))\ntruncdf(dat)\nleft.just(dat)\ndat <- read.transcript(\"vpres.deb1.docx\", col.names=c(\"person\", \"dialogue\"))\ntruncdf(dat)\nleft.just(dat)\ndat$dialogue <- qprep(dat$dialogue) \ndat2 <- sentSplit(dat, \"dialogue\", stem.col=FALSE) \nhtruncdf(dat2) #view a truncated version of the data (see also truncdf)\ndat2$person <- factor(Trim(dat2$person))\n\n#the themes we're looking at (termco.a is only as good as the researcher who supplied these themes)\ntw2 <- list(health=c(\" health\", \" insurance\", \" medic\", \"obamacare\", \" hospital\", \" doctor\"), \n  economic = c(\" econom\", \" jobs\", \" unemploy\", \" business\", \" banks\", \" mortgage\",\n   \" budget\", \" market\", \" paycheck\", \" wall street\"),\n  foreign = c(\" war \", \" terror\", \" foreign\", \"iran\", \"iraq\", \"sanctions\", \"nuclear\", \n   \"al qaida\", \"libya\", \"netanyahu\", \"israel\", \"africa\", \"afgha\", \" embassy\", \"russia\"),\n  democratic_people = c(\"the president\", \" obama \", \" obamas\", \" obama's\", \"biden\", \n   \"the vice president\", \"mister vice president\"),\n  rebublican_people = c(\"my friend\", \" ryan\", \"romney\"),\n  obama_any_name = c(\"obama \", \"obamas\", \"obama's\", \"the president\"),\n  \"romney\", #you don't have to name a vector of length 1\n  obama_by_name = c(\"obama \", \"obamas\", \"obama's\"))\n\n\n(a <- with(dat2, termco.a(dialogue, person, tw2, short.term = TRUE)))\n\nnames(a) #see what else is in the termco object\na$raw #raw numbers of use\na$prop #proportions or percentages of use\na$rnp #default print for termc.a \n For a txt version of the data frame that termco.a produces click here \n Creating the graphic of the themes via ggplot2 \n library(ggplot2)\nlibrary(reshape2)\ndat3 <- melt(a$raw[-2,], id=qcv(grouping.var, word.count)) #drop the moderator\ndat3$labs <- melt(a$rnp[-2,], id=qcv(grouping.var, word.count))[, 4]\ndat3$variable <- factor(dat3$variable, levels=names(sort(apply(a$prop[-2, -c(1:2)], 2, max))))\ndat3$loc <- dat3$value - 6.5; dat3$loc[15] <- 7; dat3$loc[6] <- 65.75\ndat3$cols <- rep(\"white\", 16); dat3$cols[1] <- \"black\"\n\nggplot(dat3, aes(x=variable, y=value, fill=grouping.var)) + \n geom_bar(position=\"dodge\", stat=\"identity\") +\n coord_flip() + theme_bw() + \n theme(legend.position=c(.91, 0.07), legend.background = element_rect(color=\"grey60\"),\n  panel.grid.major=element_blank(),panel.grid.minor=element_blank()) +\n ylab(\"Occurances\") +\n xlab(\"Theme\") +\n scale_fill_manual(values=c(\"#0000FF\", \"#FF0000\"),\n  name=\"Candidate\", guide = guide_legend(reverse=TRUE)) +\n geom_text(aes(label = labs, y = loc, x = variable),\n    size = 5, position = position_dodge(width=0.9), color=dat3$cols) + \n scale_y_discrete(expand = c(0, 0), breaks=seq(0,80,20)) \n The graphic \n \n For a pdf version of the output click here \n Discussion of the results \nAt first I ran a search to see who used the name Obama the most and I saw Vice President Biden only used the name once. At first I concluded (wrongly) he was focused on himself; after all the point of the vice presidential debates is to sell your boss as the winner. I did more inspection of the terminology (via word clouds) and I found Biden refers to President Obama as \u201cThe President\u201d. This must be an inner circle respect thing that\u2019s so ingrained in The Vice President that using the term \u201cMr. Obama\u201d or \u201cPresident Obama\u201d just doesn\u2019t happen for him. \n I also noticed Ryan pushed the economic theme hard. Vice President Biden discussed the opposition quite a bit as well. \n This was a quick and dirty demo. I didn\u2019t actually put a tremendous amount of thought into the themes but was more demonstrating the ability of qdap for aiding the researcher in representing themes numerically and visually"], "link": "http://trinkerrstuff.wordpress.com/2012/10/13/vice-presidential-debates-with-qdap-beta/", "bloglinks": {}, "links": {"https://dl.dropbox.com/": 2, "http://feeds.wordpress.com/": 1, "http://predictive-models.blogspot.com/": 1, "https://github.com/": 2, "http://trinkerrstuff.wordpress.com/": 1}, "blogtitle": "TRinker's R Blog"}, {"content": ["A question that often comes across various help lists is how to combine or split an output from an R graphics device. Maybe you have looped/combined multiple visuals into a single pdf to avoid cluttering your working directory and now you want to pull various pages out. Or maybe you have several different pdfs of various sizes you\u2019d like to combine into a single multi page file ( example-click here- ). This post utilizes 2 short videos to demonstrate combining and splitting R produced pdfs. \n \n This post serves two purposes: \n \n \n To show Windows users how to combine and split pdf\u2019s (sorry this works only for Windows users) \n To challenge R bloggers who use other operating systems to perform the same combine and split tasks \n \n \n \n First you\u2019ll need to download PDF24 Editor (a free program) \n \n \n Click Here \n \n Combining Multiple R pdf Graphics in a Single File \n  \n \n Splitting R pdf Pages into Separate Files \n  \n \n Pretty easy. Now I challenge R bloggers who use Mac and Linux to provide the same \u201cFREE\u201d functionality for their platforms. Ideally, someone has an approach that spans multiple platforms. \n If you have an alternate method for any operating system please provide a link to your blog in the comments below."], "link": "http://trinkerrstuff.wordpress.com/2012/10/08/splitting-and-combining-r-pdf-visuals/", "bloglinks": {}, "links": {"https://dl.dropbox.com/": 1, "http://feeds.wordpress.com/": 1, "http://trinkerrstuff.wordpress.com/": 2, "http://en.pdf24.org/": 2}, "blogtitle": "TRinker's R Blog"}, {"content": ["qdap brief intro \nFor the past year I\u2019ve been working on a package ( qdap ) to assist my field in quantitative discourse analysis; basically looking at patterns in language. It\u2019s still a ways from being finished and lacks documentation ( roxygen2 is my friend), but after seeing the presidential debates yesterday I decided to try using some of the package\u2019s functions on a transcript of the dialogue. \n Getting qdap to work may take some finagling because the package relies on the openNLP package. You have to make sure you have the correct version of java installed. I know the package is able to be installed on all three major OS. You\u2019ll also notice quickly that the tm, ggplot2 , and wordcloud packages are relied upon as well. \n Installing qdap \nHere\u2019s the github link for qdap ( LINK ) and install instructions: \n # install.packages(\"devtools\")\nlibrary(devtools)\ninstall_github(\"qdap\", \"trinker\") \n Note: I display the graphics here with .png files but recommend .pdf or .svg as the image is much clearer. For a combined pdf version of the graphics in this post click here . \n Getting and cleaning transcripts of the debate \n library(qdap)\nurl_dl(\"pres.deb1.docx\") #downloads a docx file of the debate to wd\n# the read.transcript function allows reading in of docx file \n# special thanks to Bryan Goodrich for his work on this\ndat <- read.transcript(\"pres.deb1.docx\", col.names=c(\"person\", \"dialogue\"))\ntruncdf(dat)\nleft.just(dat)\n# qprep wrapper for several lower level qdap functions\n# removes brackets & dashes; replaces numbers, symbols & abbreviations\ndat$dialogue <- qprep(dat$dialogue) \n# sentSplit splits turns of talk into sentences\n# special thanks to Dason Kurkiewicz for his work on this\ndat2 <- sentSplit(dat, \"dialogue\", stem.col=FALSE) \nhtruncdf(dat2) #view a truncated version of the data(see also truncdf) \n Wordclouds (relies on Ian Fellows\u2019 wordcloud package) \n #first put a unique character between words we want to keep together\ndat2$dia2 <- mgsub(c(\"Governor Romney\", \"President Obama\", \"middle class\", \n  \"The President\", \"Mister President\"), \n c(\"Governor~Romney\", \"President~Obama\", \"middle~class\", \"The~President\", \n  \"Mister~President\"), dat2$dialogue)\n\n#Generate target words to color by\ntw <- list(health=c(\"health\", \"insurance\", \"medic\", \"obamacare\", \"hospital\"), \n  economic = c(\"econom\", \"jobs\", \"unemploy\", \"business\", \"banks\", \n   \"budget\", \"market\", \"paycheck\"),\n  foreign = c(\"war \", \"terror\", \"foreign\"),\n  class = c(\"middle~class\", \"poor\", \"rich\"),\n  opponent = c(\"romney \", \"obama\", \"the~president\", \"mister~president\"))\n\n#create stop word list from qdap data set Top25Words but exclude he and I\nsw <- exclude(Top25Words, \"he\", \"I\")\n\n#the word cloud by grouping variable function\nwith(dat2, trans.cloud(dia2, person, \n proportional = TRUE,\n target.words = tw,\n cloud.colors = c(\"red\", \"blue\", \"black\", \"orange\", \"purple\", \"gray45\"),\n legend = names(tw),\n stopwords=sw, \n max.word.size = 4,\n char2space = \"~\")) \n Visuals of the trans.cloud function \n \n \n \n Gantt Plot of the dialogue over time \nObviously (when you see the output), this uses Hadley Wickham\u2019s ggplot2 . \n # special thanks to Andrie de Vries for his work on this function\nwith(dat2, gantt_plot(dialogue, person, xlab = \"duration(words)\", x.tick=TRUE,\n minor.line.freq = NULL, major.line.freq = NULL, rm.horiz.lines = FALSE)) \n Visualization of the Gantt Plot \n \n Formality scores (how formal a person\u2019s language is) \nThis concept comes from: \n Heylighen, F., & Dewaele, J.-M. (2002). Variation in the \n contextuality of language: An empirical measure. Foundations \n of Science, 7(3), 293\u2013340. doi:10.1023/A:1019661126744 \n The code can be run in parallel because this is a slower function. It uses openNLP to first map parts of speech for every word. \n #parallel about 1:20 on 8 GB ram 8 core i7 machine\nv <- with(dat2, formality(dialogue, person, plot=TRUE, parallel=TRUE))\n#about 4 minutes on 8GB ram i7 machine\nv <- with(dat2, formality(dialogue, person, plot=TRUE)) \n\n# note you can resupply the output from formality back\n# to formality and change arguments. This avoids the need for\n# openNLP, saving time.\nwith(dat2, formality(v, person, plot=TRUE, bar.colors=c(\"Dark2\"))) \n Output and plot from the formality function \n person word.count formality\n1 ROMNEY  4068  61.82\n2 LEHRER  765  61.31\n3 OBAMA  3595  58.30 \n \n Afterthought: I was remiss to mention that the word clouds are proportional (argument proportional = TRUE) for all words spoken rather than frequency per person. This enables comparison across clouds."], "link": "http://trinkerrstuff.wordpress.com/2012/10/04/presidential-debates-with-qdap-beta/", "bloglinks": {}, "links": {"https://dl.dropbox.com/": 1, "http://feeds.wordpress.com/": 1, "https://github.com/": 2}, "blogtitle": "TRinker's R Blog"}, {"content": ["I recently posted a blog about adding text to a ggplot2 faceted plot ( LINK ). \n I was unhappy with the amount of time it takes to create the text data frame to then label the plot. And then yesterday when the new version of ggplot2 0.9.2 was announced I got to reading about how ggplot2 objects are stored and I decided that I could extract a great deal of the information for plotting the text directly from the ggplot2 object. \n After I did it I decided to wrap the function up into a package that I can add more ggplot2 extension functions to in the future. \n Optionally Download the Package: \n \ninstall_github(\"acc.ggplot2\", \"trinker\")\nlibrary(acc.ggplot2) \n Here\u2019s the Function Code and a Few Examples: \n \nlibrary(ggplot2)\n\nqfacet_text <- function(ggplot2.object, x.coord = NULL, y.coord = NULL, \n labels = NULL, ...) {\n require(ggplot2)\n dat <- ggplot2.object$data\n rows <- ggplot2.object$facet[[1]][[1]]\n cols <- ggplot2.object$facet[[2]][[1]]\n fcol <- dat[, as.character(cols)]\n frow <- dat[, as.character(rows)]\n len <- length(levels(factor(fcol))) * length(levels(factor(frow)))\n vars <- data.frame(expand.grid(levels(factor(frow)), levels(factor(fcol))))\n colnames(vars) <- c(as.character(rows), as.character(cols))\n if (any(class(ggplot2.object) %in% c(\"ggplot\", \"gg\"))) {\n  if (is.null(labels)) {\n   labels <- LETTERS[1:len]\n  }\n  if (length(x.coord) == 1) {\n   x.coord <- rep(x.coord, len)\n  }\n  if (length(y.coord) == 1) {\n   y.coord <- rep(y.coord, len)\n  }\n  text.df <- data.frame(x = x.coord, y = y.coord, vars, labs=labels)\n } else {\n  if (class(ggplot2.object) == \"qfacet\") {\n   text.df <- ggplot2.object$dat\n   if (!is.null(x.coord)) {\n    text.df$x.coord <- x.coord\n   }\n   if (!is.null(y.coord)) {\n    text.df$y.coord <- y.coord\n   }\n   if (!is.null(labels)) {\n    text.df$labs <- labels\n   }\n   ggplot2.object <- ggplot2.object$original\n  }\n }\n p <- ggplot2.object + geom_text(aes(x, y, label=labs, group=NULL), \n  data=text.df, ...)\n print(p)\n v <- list(original = ggplot2.object, new = p, dat = text.df)\n class(v) <- \"qfacet\"\n invisible(v)\n} \n Examples (using the same basic examples as my previous blog post): \n \n#alter mtcars to make some variables factors\nmtcars[, c(\"cyl\", \"am\", \"gear\")] <- lapply(mtcars[, \n c(\"cyl\", \"am\", \"gear\")], as.factor)\n\np <- ggplot(mtcars, aes(mpg, wt, group = cyl)) + \n geom_line(aes(color=cyl)) +\n geom_point(aes(shape=cyl)) + \n facet_grid(gear ~ am) +\n theme_bw() \n\nz <- qfacet_text(ggplot2.object = p, x.coor = 33, y.coor = 2.2, labels = 1:6, color=\"red\")\nstr(z); names(z) #look at what's returned\n\n#approach 1 (alter the text data frame and pass the qfacet object)\nz$dat[5, 1:2] <- c(15, 5)\nqfacet_text(z, color=\"red\")\n\n#approach 2 (alter the original ggplot object)\nqfacet_text(p, x = c(33, 33, 33, 33, 15, 33), \n y = c(2.2, 2.2, 2.2, 2.2, 5, 2.2), 1:6, color=\"red\")\n\n#all the same things you can pass to geom_text qfacet_text takes\nqfacet_text(z, labels = paste(\"beta ==\", 1:6), \n size = 3, color = \"grey50\", parse = TRUE) \n Notice at the end you can pass qfacet_text a ggplot object or an object from qfacet_text . The qfacet_text function invisibly returns a list with the original ggplot2 object, the new ggplot2 object and the text data frame. This enables the user to alter the coordinates of the data frame and return the the qfacet_text object back to qfacet_text , thus altering the text position. There\u2019s actual documentation for this package and function so ?qfacet_text should get you a help file with the same example. \n PS this gave me a chance to actually run roxygen2 for the first time to create documentation. Also a pretty slick Hadley Wickham package. \n The Plot:"], "link": "http://trinkerrstuff.wordpress.com/2012/09/07/add-text-annotations-to-ggplot2-faceted-plot-an-easier-approach/", "bloglinks": {}, "links": {"http://feeds.wordpress.com/": 1, "http://trinkerrstuff.wordpress.com/": 1}, "blogtitle": "TRinker's R Blog"}, {"content": ["In my experience with R learners there are two basic types. The \u201cshow me the code and what it does and let me play\u201d type and the \u201cplease give me step by step directions\u201d type. I\u2019ve broken the following tutorial on plotting text on faceted ggplot2 plots into 2 sections: \n \n The Complete Code and Final Outcome \n A Bit of Explanation \n \n Hopefully, whatever learner you are you\u2019ll be plotting text on faceted graphics in no time. \n Section 1: The Complete Code and Final Outcome mtcars[, c(\"cyl\", \"am\", \"gear\")] <- lapply(mtcars[, c(\"cyl\", \"am\", \"gear\")], as.factor)\n\np <- ggplot(mtcars, aes(mpg, wt, group = cyl)) + \n geom_line(aes(color=cyl)) +\n geom_point(aes(shape=cyl)) + \n facet_grid(gear ~ am) +\n theme_bw()                  \np                  \n \n\nlen <- length(levels(mtcars$gear)) * length(levels(mtcars$am))\n\nvars <- data.frame(expand.grid(levels(mtcars$gear), levels(mtcars$am)))\ncolnames(vars) <- c(\"gear\", \"am\")\ndat <- data.frame(x = rep(15, len), y = rep(5, len), vars, labs=LETTERS[1:len])\n\np + geom_text(aes(x, y, label=labs, group=NULL),data=dat) \n\n\ndat[1, 1:2] <- c(30, 2) #to change specific locations\np + geom_text(aes(x, y, label=labs, group=NULL), data=dat) \n\n\np + geom_text(aes(x, y, label=paste(\"beta ==\", labs), group=NULL), size = 4, \n color = \"grey50\", data=dat, parse = T) \n \n Section 2: A Bit of Explanation The following portion of the tutorial provides a bit more of a step by step procedure for plotting text to faceted plots as well as a visual to go with the code. \n The initial non annotated plot \nFirst, let\u2019s make a faceted line plot with the mtcars data set. I reclassed a few variables to make factors. \n mtcars[, c(\"cyl\", \"am\", \"gear\")] <- lapply(mtcars[, c(\"cyl\", \"am\", \"gear\")], as.factor)\n\np <- ggplot(mtcars, aes(mpg, wt, group = cyl)) + \n geom_line(aes(color=cyl)) +\n geom_point(aes(shape=cyl)) + \n facet_grid(gear ~ am) +\n theme_bw()                  \np                  \n \n \n Add text to each facet \nThe key here is a new data frame with three pieces of information (ggplot2 seems to like information given in a data frame). \n \n Coordinates to plot the text \n The faceted variable levels \n The labels to be supplied \n \n The first information piece is the coordinates (two columns x and y) to plot the text in each facet. Generally I find that one set of coordinates will work in most of the facet boxes and I just use rep to make these coordinates (I suppose the recycling rule could be used if you added it to an already existing data frame). \n The second information piece is the faceted variable labels (in our case gear ~ am ). There\u2019re many ways to achieve this but I like a combination of levels and expand.grid . I renamed these columns to be exactly the same as the variable names (gear & am) I used in the original data frame (mtcars in this case). \n Lastly, you must make the labels. I chose letters so you can track what piece of the data frame is plotted in which facet. \n Your data should look something like this: \n x y gear am labs\n1 30 2 3 0 A\n2 15 5 4 0 B\n3 15 5 5 0 C\n4 15 5 3 1 D\n5 15 5 4 1 E\n6 15 5 5 1 F \n Note that the group=NULL is essential to let ggplot2 know you\u2019re dealing with a new data set and the mapping from before can be forgotten (or at least this is how I understand it). \n \n#long cut way to find number of facets\nlen <- length(levels(mtcars$gear)) * length(levels(mtcars$am))\n\nvars <- data.frame(expand.grid(levels(mtcars$gear), levels(mtcars$am)))\ncolnames(vars) <- c(\"gear\", \"am\")\ndat <- data.frame(x = rep(15, len), y = rep(5, len), vars, labs=LETTERS[1:len])\n\np + geom_text(aes(x, y, label=labs, group=NULL),data=dat) \n \n Moving just one text location \nGenerally I can usually find one spot that most every text plot will work except that one dog gone facet that just won\u2019t match up with the other coordinates. In this case label A is that pesky label. The key here is to figure out what text labels you want to move and alter those coordinates appropriately. \n dat[1, 1:2] <- c(30, 2) #to change specific locations\np + geom_text(aes(x, y, label=labs, group=NULL), data=dat) \n \n \n Adding equation (Greek letters/math) and alter size/color \nTo annotate with math code use the parse = T argument in geom_text . For more on plotting math code see this ggplot wiki and this SO question . To alter the size just throw a size argument in geom_text. I also toned down the color of the text a bit to allow the line to pop the most visually. \n \np + geom_text(aes(x, y, label=paste(\"beta ==\", labs), group=NULL), size = 4, \n color = \"grey50\", data=dat, parse = T) \n \n If you have suggestions for improvement, links, or other thoughts please leave a comment."], "link": "http://trinkerrstuff.wordpress.com/2012/09/01/add-text-annotations-to-ggplot2-faceted-plot/", "bloglinks": {}, "links": {"http://had.co.nz/": 1, "https://github.com/": 1, "http://feeds.wordpress.com/": 1, "http://stackoverflow.com/": 1}, "blogtitle": "TRinker's R Blog"}, {"content": ["Well I bought a new computer a month back (i7 8GB memory). Finally more than one core and a chance to try parallelization . I saw this blog post a while back and was intrigued and was further intriqued when I saw that plyr/reshape2 has some paralellization capabilities( LINK ). Let me say up front this is my first experience so there may be better ways but it sped up my code by over four times. \n \n Let me warn you now, when I first read the A No BS Guide to the Basics of Parallelization in R I tried to see how many cores I had on my computer (this shows my ignorance; which may be of comfort to some of you, others will stop reading this blog post immediately). 1 is the loneliest number especially if you\u2019re attempting to run on multiple cores. \n Suggestion if you type detectCores() and see 1 you can\u2019t run code in parallel, at least not by running it on different cores of your machine. \n Background (skip this if you are short on time) \nI\u2019m working on a package ( qdap ) and have a function ( pos ) that takes a long time to run. It is basically finding parts of speech by sentence (each sentence is a cell and there are thousands of them). I rely on openNLP for the pos tagging but the whole process is time consuming. I figured perfect time to try this parallelization out. \n I skimmed the Task View for parallel computing and knew I was out of my league and decided to just focus on my problem not the whole parallelization concept. Back to wrathematics bog post and I discovered my silly Windows machine was not compatible with mcapply but saw hope with the clusterApply() . Using ?clusterApply \nI saw parLapply said it was a parallel version of lapply . I like lapply and dicided that was what I\u2019d go with. \n Working with parallel coding in functions (skip to here) \nThese are the three major problems/differences I encountered with parLapply over lapply inside a function: \n \n \n You need to pass/export the functions and variables you\u2019ll be needing in the parLapply using\u00a0 makeCluster & clusterExport . See Andy Garcia\u2019s helpful response to my question about this ( LINK ) \n You have to specify the envir argument of clusterExport as envir=environment() . See GSee\u2019s helpful response to my question about this ( LINK ) \n You have to explicitly stop the cluster when you\u2019re finished using it, much like closing a connection you opened. You stop the cluster using the stopCluster function (see line 37 in the code below). \n  \n EDIT: Martin Morgan of stackoverflow.com gives a solution that addresses both the first and second problems. He suggests passing all objects directly to parLapply ( LINK ). \n \nBelow is an example of taking a non parallel function and making it run in parallel: \n library(parallel)\ndetectCores() #make sure you have > 1 core\n\nnonpar.test <- function(text.var, gc.rate=10){ \n ntv <- length(text.var)\n require(parallel)\n pos <- function(i) {\n  paste(sapply(strsplit(tolower(i), \" \"), nchar), collapse=\" | \")\n }\n x <- lapply(seq_len(ntv), function(i) {\n   x <- pos(text.var[i])\n   if (i%%gc.rate==0) gc()\n   return(x)\n  }\n )\n return(x)\n}\n\nnonpar.test(rep(\"I wish I ran in parallel.\", 20))\n\npar.test <- function(text.var, gc.rate=10){ \n ntv <- length(text.var)\n require(parallel)\n pos <- function(i) {\n  paste(sapply(strsplit(tolower(i), \" \"), nchar), collapse=\" | \")\n }\n#======================================\n cl <- makeCluster(mc <- getOption(\"cl.cores\", 4))\n clusterExport(cl=cl, varlist=c(\"text.var\", \"ntv\", \"gc.rate\", \"pos\"), \n  envir=environment())\n x <- parLapply(cl, seq_len(ntv), function(i) {\n#======================================\n   x <- pos(text.var[i])\n   if (i%%gc.rate==0) gc()\n   return(x)\n  }\n )\n stopCluster(cl) #stop the cluster\n return(x)\n}\n\npar.test(rep(\"I wish I ran in parallel.\", 20)) \n Notice that lines 27-30; 37 (between the #==== lines and stopping the cluster) is all that changes. Once you get it down working with parLapply is pretty easy. \n Note: \nIt doesn\u2019t always make sense to run in parallel as it takes time to make the cluster. In the pos I added parallel as an argument because for smaller text vectors running in parallel doesn\u2019t make sense (it\u2019s slower). \n Wonderings and future direction: \nThe pos function I have in qdap uses a progress bar. Currently I couldn\u2019t make a progress bar work with parLapply but it\u2019s less of a need because it was so much faster. \n Benchmarking (1 run) \n > system.time(pos(rajSPLIT$dialogue, parallel=T))\n user system elapsed \n 2.35 0.08 199.53 \n\n> system.time(pos(rajSPLIT$dialogue, progress.bar =F))\n user system elapsed \n 816.61 16.74 833.47 \n This is benchmarked using the rajSPLIT$dialogue which is the text from Romeo and Juliet, a data set in qdap . This consists of 2151 rows or 23,943 words. \n Hopefully this blog post is useful to those learning some parallelization. Check out Task View , the Documentation for the Parallel package and the Vignette for the parallel package. \n If you have suggestions for improvement, links, or help on getting a progress bar with parLapply please leave a comment."], "link": "http://trinkerrstuff.wordpress.com/2012/08/19/parallelization-speed-up-functions-in-a-package/", "bloglinks": {}, "links": {"https://github.com/": 5, "http://stackoverflow.com/": 3, "http://trinkerrstuff.wordpress.com/": 1, "http://librestats.com/": 2, "http://www.r-statistics.com/": 1, "http://www.compunity.org/": 1, "http://www.r-bloggers.com/": 1, "http://feeds.wordpress.com/": 1, "http://stat.ethz.ch/": 2, "http://cran.r-project.org/": 2}, "blogtitle": "TRinker's R Blog"}, {"content": ["I love when people take a sophisticated tool and use it to play video games. Take R for example. I first saw someone create a game for R at talk.stats.com . My friend Dason inspired me to more efficiently waste time in R with his version of minesweeper . The other day I had an immense amount of work to do and decided it was the perfect time to make a hangman game. \n Now some of the skills to create hangman were outside my typical uses and skills for R. It caused me to stretch and grow a bit. The purpose of this post is two fold: \n \n To share the hangman game with people who have nothing better to do than waste time on a childhood game \n To share the learning experiences I had in creating the game \n \n First the hangman game \n I have the code for the function posted here but I have saved the code and data set (word list) for the function at github . \u00a0You can download the package that contains the hangman game and data set by either downloading the zip ball or tar ball , decompress and run\u00a0 R CMD INSTALL\u00a0 on it, or use the devtools package to install the development version: \n \n# install.packages(\"devtools\")\nlibrary(devtools)\ninstall_github(\"hangman\", \"trinker\")\n \n To play type hangman() into the console and hit enter. \n Here\u2019s a screenshot of the game \n \n Now for the learning \n Here\u2019s the code for the hangman function: \n \nhangman <- function(reset.score = FALSE) {\n opar <- par()$mar\n on.exit(par(mar = opar))\n par(mar = rep(0, 4))\n x1 <- DICTIONARY[sample(1:nrow(DICTIONARY), 1), 1]\n x <- unlist(strsplit(x1, NULL))\n len <- length(x)\n x2 <- rep(\"_\", len)\n chance <- 0\n if(!exists(\"wins\", mode=\"numeric\", envir = .GlobalEnv) | reset.score){\n  assign(\"wins\", 0, envir = .GlobalEnv)\n }\n if(!exists(\"losses\", mode=\"numeric\", envir = .GlobalEnv) | reset.score){\n  assign(\"losses\", 0, envir = .GlobalEnv)\n }\n win1 <- 0\n win <- win1/len\n wrong <- character()\n right <- character()\n print(x2, quote = FALSE)\n circle <- function(x, y, radius, units=c(\"cm\", \"in\"), segments=100, \n  lwd = NULL){ \n  units <- match.arg(units) \n  if (units == \"cm\") radius <- radius/2.54 \n  plot.size <- par(\"pin\") \n  plot.units <- par(\"usr\") \n  units.x <- plot.units[2] - plot.units[1] \n  units.y <- plot.units[4] - plot.units[3] \n  ratio <- (units.x/plot.size[1])/(units.y/plot.size[2]) \n  size <- radius*units.x/plot.size[1] \n  angles <- (0:segments)*2*pi/segments \n  unit.circle <- cbind(cos(angles), sin(angles)) \n  shape <- matrix(c(1, 0, 0, 1/(ratio^2)), 2, 2) \n  ellipse <- t(c(x, y) + size*t(unit.circle %*% chol(shape))) \n  lines(ellipse, lwd = lwd) \n } #taken from John Fox: http://tolstoy.newcastle.edu.au/R/help/06/04/25821.html\n hang.plot <- function(){ #plotting function\n  plot.new()\n  parts <- seq_len(length(wrong))\n  if (identical(wrong, character(0))) {\n   parts <- 0\n  }\n  text(.5, .9, \"HANGMAN\", col = \"blue\", cex=2) \n  if (!6 %in% parts) { \n   text(.5, .1, paste(x2, collapse = \" \"), cex=1.5) \n  }\n  text(.05, .86, \"wrong\", cex=1.5, col = \"red\") \n  text(.94, .86,\"correct\", cex=1.5, col = \"red\")\n  text(.05, .83, paste(wrong, collapse = \"\\n\"), offset=.3, cex=1.5, \n   adj=c(0,1))\n  text(.94, .83, paste(right, collapse = \"\\n\"), offset=.3, cex=1.5, \n   adj=c(0,1))\n  segments(.365, .77, .365, .83, lwd=2)\n  segments(.365, .83, .625, .83, lwd=2)\n  segments(.625, .83, .625, .25, lwd=2)\n  segments(.58, .25, .675, .25, lwd=2)\n  if (1 %in% parts) {\n   circle(.365, .73, .7, lwd=4)\n   if (!6 %in% parts) { \n    text(.365, .745, \"o o\", cex=1)\n   }\n   if (!5 %in% parts) { \n    text(.365, .71, \"__\", cex = 1)\n   }\n  text(.36, .73, \"<\", cex=1)\n  }\n  if (2 %in% parts) {\n   segments(.365, .685, .365, .4245, lwd=7)\n  }\n  if (3 %in% parts) {\n   segments(.365, .57, .45, .63, lwd=7)\n  }\n  if (4 %in% parts) {\n   segments(.365, .57, .29, .63, lwd=7)\n  }\n  if (5 %in% parts) {\n   segments(.365, .426, .43, .3, lwd=7)\n   text(.365, .71, \"O\", cex = 1.25, col = \"red\")\n  }\n  if (6 %in% parts) {\n   segments(.365, .426, .31, .3, lwd = 7)\n   text(.365, .745, \"x x\", cex=1)\n   text(.5, .5, \"You Lose\", cex=8, col = \"darkgreen\") \n   text(.5, .1, paste(x, collapse = \" \"), cex=1.5) \n  }\n  if (win1 == len) {\n   text(.5, .5, \"WINNER!\", cex=8, col = \"green\")\n   text(.505, .505, \"WINNER!\", cex=8, col = \"darkgreen\")\n  }\n } #end of hang.plot\n guess <- function(){#start of guess function\n  cat(\"\\n\",\"Choose a letter:\",\"\\n\") \n  y <- scan(n=1,what = character(0),quiet=T)\n  if (y %in% c(right, wrong)) {\n   stop(paste0(\"You've already guessed \", y))\n  }\n  if (!y %in% letters) {\n   stop(paste0(y, \" is not a letter\"))\n  }\n  if (y %in% x) {\n   right <<- c(right, y)\n   win1 <<- sum(win1, sum(x %in% y)) \n   win <<- win1/len \n   message(paste0(\"Correct!\",\"\\n\"))\n  } else {\n   wrong <<- c(wrong, y)\n   chance <<- length(wrong)\n   message(paste0(\"The word does not contain \", y, \"\\n\"))\n  }\n  x2[x %in% right] <<- x[x %in% right]\n  print(x2, quote = FALSE)\n  hang.plot()\n }#end of guess function\n hang.plot()\n while(all(win1 != len & chance < 6)){ \n  try(guess())\n } \n if (win == 1) {\n  outcome <- \"\\nCongratulations! You Win!\\n\"\n  assign(\"wins\", wins + 1, envir = .GlobalEnv)\n } else {\n  outcome <- paste(\"\\nSorry. You lose. The word is:\", x1, \"\\n\")\n  assign(\"losses\", losses + 1, envir = .GlobalEnv)\n }\n cat(outcome)\n cat(paste0(\"\\nwins: \", wins, \" | losses: \", losses, \"\\n\"))\n text(.5, .2, paste0(\"wins: \", wins, \" | losses: \", \n  losses), cex = 3, col = \"violetred\")\n}\n \n Things I tried and learned: \n \n Translating simple game rules into systematic logic \n try \n plotting dynamically ( text vs. mtext ) \n while loop \n assign \n \n I used try one other time in a web scraping function. If you don\u2019t know anything about this function it allows you to try to do something and if an error occurs move onto the next step. This allows the game user to input wrong information yet the function doesn\u2019t stop but instead recovers and prints a message. \n I first tried plotting the symbols and text with mtext . Thanks to some help at stack.overflow I found out the text function is a more controllable choice. I also grabbed a circle plotting function from John Fox to avoid calling a package that plots circles. \n This was my first need for a while loop (generally I use the apply functions but in this case the game logic demanded I repeat something until one of two circumstances were met (win or loss of the game) \n assign is a nice function and I generally don\u2019t use it as I can get away with <<- (cringe if you want but if you think it through the <<- operator can be handy. \n So I encourage you to write your own R game as you\u2019ll likely learn a bit, while effectively wasting time and will provide enjoyment to others. \u00a0 \n Warning: not tested on a Linux or Mac machine"], "link": "http://trinkerrstuff.wordpress.com/2012/07/29/hangman-in-r-a-learning-experience/", "bloglinks": {}, "links": {"http://feeds.wordpress.com/": 1, "http://stackoverflow.com/": 1, "http://tolstoy.edu.au/": 1, "https://github.com/": 3, "http://botthoughts.wordpress.com/": 1, "http://www.talkstats.com/": 2}, "blogtitle": "TRinker's R Blog"}, {"content": ["I\u2019ve been playing with the igraph package a bit lately ( see previous post HERE ) and wanted to approach a problem I once visited in the past. The basic gist of the problem is this: \n Students in a class are asked their top three favorite students to work with (rank order). \u00a0After a social intervention this same question is posed again to students. \u00a0The intended outcome of the intervention is that the\u00a0distribution\u00a0of students\u00a0receiving\u00a0many or very few choices will\u00a0diminish. \u00a0In other words the dorks will become less dorky and the popular students will become less popular. \u00a0The idea is to visual this relationship. \n Here is a script of one such\u00a0visualization. \u00a0It\u2019s a bit light on annotations but merely experimenting with the code should give a good sense of what is\u00a0occurring. \n \nlibrary(igraph)\nset.seed(101)\n#create a data set\nX <-lapply(1:10, function(i) sample(LETTERS[c(1:10)[-i]], 3))\nY <- data.frame(person = LETTERS[1:10], sex = rbinom(10, 1, .5), do.call(rbind, X))\nnames(Y)[3:5] <- paste0(\"choice.\", 1:3)\n\n#reshape the data to long format\nZ <- reshape(Y, direction=\"long\", varying=3:5)\ncolnames(Z)[3:4] <- c(\"choice.no\", \"choice\")\nrownames(Z) <- NULL\nZ <- Z[, c(1, 4, 3, 2)]\n\n#turn the data into a graph structure\nedges <- as.matrix(Z[, 1:2])\ng <- graph.data.frame(edges, directed=TRUE)\nV(g)$label <- V(g)$name\n\n#change label size based on number of votes\nSUMS <- data.frame(table(Z$choice))\nSUMS$Var1 <- as.character(SUMS$Var1)\nSUMS <- SUMS[order(as.character(SUMS$Var1)), ]\nSUMS$Freq <- as.integer(SUMS$Freq)\nlabel.size <- 2\nV(g)$label.cex <- log(scale(SUMS$Freq) + max(abs(scale(SUMS$Freq)))+ label.size)\n\n#Color edges that are reciprocal red\nx <- t(apply(edges, 1, sort))\nx <- paste0(x[, 1], x[, 2])\ny <- x[duplicated(x)]\nCOLS <- ifelse(x %in% y, \"red\", \"gray40\")\nE(g)$color <- COLS\n\n#reverse score the choices.no and weight\nE(g)$width <- (4 - Z$choice.no)*2\n\n#color vertex based on sex\nV(g)$gender <- Y$sex\nV(g)$color <- ifelse(V(g)$gender==0, \"pink\", \"lightblue\")\n\n#plot it\nopar <- par()$mar; par(mar=rep(0, 4)) #Give the graph lots of room\nplot.igraph(g, layout=layout.auto(g))\npar(mar=opar)\n \n \n For an additional script of this analysis with 20 students click here . \n For helpful igraph documentation click here"], "link": "http://trinkerrstuff.wordpress.com/2012/06/30/igraph-and-sna-an-amateurs-dabbling/", "bloglinks": {}, "links": {"http://igraph.sourceforge.net/": 1, "http://trinkerrstuff.wordpress.com/": 1, "http://feeds.wordpress.com/": 1, "http://dl.dropbox.com/": 1}, "blogtitle": "TRinker's R Blog"}]
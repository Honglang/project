[{"blogurl": "http://www.thejuliagroup.com/blog\n", "blogroll": [], "title": "AnnMaria's Blog"}, {"content": ["I\u2019m never going to understand the idea that start-ups are for young people. It is like the ads you see where people want a 25-year-old with 15 years of experience, you know, \n \u201cExpert in C++, systems administration, Linux, Windows, SAS, R, Hadoop, Ruby, Python and Java. Must have 5-plus years experience in development for mobile platforms.\u201d \n That\u2019s where you get all this nonsense with people claiming to be programming since they were nine. That\u2019s funny because I have seen plenty of nine-year-old boys, usually on skateboards, and none of them were programming. \n If you really do have experience programming in multiple languages, at least within your group, if not you personally, it\u2019s a big advantage because some languages are better at certain tasks than others. \u00a0It\u2019s not that you can\u2019t do pretty much anything in any language. Hell, I\u2019m sure I could do structural equation models using Excel if I wanted to badly enough. It\u2019s just more effort. \n For example, our game is going great in terms of collecting data, but there is one slight problem. The problem is that we want to track the time students in each class spend playing it, the correct and incorrect answers, and a lot more. \u00a0When students take pop-up quizzes their username is captured, but there were some parts in the game where that was not happening. This is a beta-test after all. We give the school the update in a week or so that will have this fix in it. What to do with the first three weeks of data that we have collected? \n Simple \u2013 there is a PHP script that writes the data to MySQL database. One of the options is to download the data as an OpenOffice spreadsheet. I could import that into SAS and it has a field with the timestamp. Since we know what hours each class is scheduled to use the game, I assigned the records based on time of day to class and am now whipping out a nice little pdf report for the teachers and administration. I\u2019m also merging that with other data that includes the username, grade, class and scores on the quizzes so we can give each teacher and the administration a complete picture of how the students are doing. \n Even easier, though, was to download it as a csv file, do some of the simple data things- \u00a0typing, variable names, breaking the long-ass string into columns \u2013 in SPSS. That was especially easier since my main computer is a Mac (I do have bootcamp on it and a Windows \u00a0machine on the other desk behind me). I then output the file as a SAS dataset and away \u00a0I went. \n (Side note: Although the SAS Web Editor for academics is a great stride in the right direction, I still think they need to get moving with a Mac native version.) \n Then there are all the little things, like adding the narrative in Dakota, \u00a0editing movies, the 3-D programming, the 2-D animation, Javascript for the logic and some of the auxiliary games, etc. etc. \n Our game is not an \u201capp\u201d. \u00a0It is not something we did in a week with an SDK. While there is no question that a lot of start-ups are done by people who are very young, there is also the fact that a huge percentage of them fail. Something that only uses one language or one area of expertise (and how many things CAN you be an expert in at 25 years old?) may be far more easily replicated or replaced than something more complex. \n That is right-hecetu"], "link": "http://www.thejuliagroup.com/blog/?p=2706", "bloglinks": {}, "links": {"http://www.thejuliagroup.com/blog": 2}, "blogtitle": "AnnMaria's Blog"}, {"content": ["Hey, kids, wanna come over after school and study math? The two students we gave this tempting offer stayed until the office closed and we had to leave. It\u2019s been like that all week. \n This is what kids playing our new math game look like. I would insert a video but it is not so interesting to watch in some ways. They all wear headphones, because there are usually 14 or 15 kids playing at a time and they quickly get to very different levels. What you see is kids at a computer clicking a mouse, typing numbers, staring at a screen \u2013 engrossed. Our scheduled 30-minute sessions today both morphed into hour sessions. \n Don\u2019t get the wrong idea \u2013 we are coming home with a HUNDRED fixes, small and large. Some are actual problems \u2013 the main one being that children naturally want to explore the virtual world and they wander off into the woods and get lost. We need to add more barriers in more places. Most are ideas to make it better \u2013 add more hints, add more places to click and get stories on Dakota culture, more supplemental materials for teachers, new levels, more complete compatibility across browsers and operating systems. \n Unlike a lot of companies creating educational software, we spend days in classrooms with students using the game. We ask teachers their opinions and then we go back and make those changes. We ask kids what they would like to see. We also look at the Common Core Standards and the state standards. Let me say something about state standards that is probably not a revelation to anyone very familiar with them \u2013 the percentage of kids who meet state standards varies WILDLY by socioeconomic status. The proportion of kids who can divide a three-digit number by a one-digit number is vastly different depending on the average income of your zip code. \n We intend to change that."], "link": "http://www.thejuliagroup.com/blog/?p=2702", "bloglinks": {}, "links": {"http://www.thejuliagroup.com/blog": 1}, "blogtitle": "AnnMaria's Blog"}, {"content": ["Yesterday, I mentioned this problem \n For 17 girls diagnosed with anorexia, weight change after family therapy was as follows: \n 11,11, 6, 9, 14, -3, 0, 7, 22, -5 , -4, 13, 13, 9, 4 , 6, 11 \n Partial results are shown below. Fill in the missing results: \n And we had gotten the table completed as far as this. We also along the way found out that the mean was 7.29 \n \n \n \n Lower C.L. \n Upper C.L. \n t-value \n df \n 2-tail Sig \n \n \n 3.60 \n \u00a010.98 \n \n \u00a016 \n .0007 \n \n \n \n #1 CHILL ! \n I mean this most seriously. This really is the first step. \n #2 UNDERSTAND! \n What is it you are asked to do in the problem? All that is left is to find the t-value. Here is where several of the students went wrong. So many of them went wrong I would have thought they had cheated, but they were sitting all around the room. Barring some secret hand signals, that was not possible. \n Many of the students obtained a value of around 2.12, which is very much NOT correct. \u00a0I was confused and then I realized that while *I* knew that the problem was asking for the obtained t-value, what the students had computed was the critical t-value with 16 degrees of freedom. The problem did not specify and the textbook author, like me, just assumed that you would know that the value shown on a print-out was the obtained t-value, not the critical t-value. \n Well, sure you would know that if like me, and no doubt like the author of the textbook, you had been looking at printouts from statistical programs for the past 30 years. These students could not be expected to know that, so, I ended up giving them full credit if that is what the answered. \n What you should know now \n \n The t-value referenced in the print-out is the OBTAINED t, not the critical t-value for that number of degrees of freedom. \n The formula for obtaining t \u00a0is (obtained mean \u2013 hypothesized mean)/ standard error \n Your hypothesized mean is 0 \n Your obtained mean is 7.29 \n The standard error is the standard deviation divide by the square root of N \n The critical value for t for 16 degrees of freedom when p < .05 is 2.12 \n The lower confidence limit is the mean MINUS the CRITICAL t times the standard error \n The lower confidence limit is 3.6 \n The difference between the mean and the lower confidence limit is 3.69 \n The standard deviation is the square root of the sum of squared deviations from the mean divided by n -1 \n \n #3 SELECT A STRATEGY \n There are a number of ways to find the t-value. All involve subtracting the hypothesized mean from the obtained mean and dividing by the standard error. Some ways are harder than others. You could compute the standard deviation and divide by the square root of N but that is a lot of work. Here is what I think is the easiest way \n \n Divide 3.69 by 2.12 \u00a0\u2014 that will give us the standard error \n Subtract 0 from 7.29 \n Divide 7.29 by \u00a0the standard error \n \n In this case, it was this step and the previous one where people ran into trouble. What is interesting is that they did not realize what they DIDN\u2019T understand. That is, they didn\u2019t understand that the t-value they were expected to produce was the obtained t-value, not the critical t-value. \n You could (and many people did) compute the standard deviation, then divide it by the square root of N to get the standard error and it would give the correct answer, but it just seems more work than dividing 3.69 by 2.12. \n #4 DO IT \n Carry out your strategy. \n \n 3.69/ 2.12 \u00a0 \u2014- The standard error is 1.74 \n 7.29 -0 \u00a0= 7.29 \n Divide 7.29 by 1.74 = 4.19 \n \n That\u2019s your answer. As in the previous example, the actual doing it part is pretty easy. \n #5 TEST IT \n Do a reality check.\u00a0No one in the class asked which t-value it should be and it never occurred to me that people would not automatically know that it was the obtained t-value that is of interest. I mean, seriously, what\u2019s the purpose of doing a study to find a critical value of t that was established a hundred years ago? I\u2019m not surprised though, that people who are not experienced statisticians don\u2019t immediately think of that. Probably a lot of what statisticians do doesn\u2019t seem very obvious so maybe it\u2019s just another of those weird things. \n So, I guess it is up to me on Thursday to explain to the class that you have a critical value for a test statistic and an obtained value. \n A lot of #5 comes from experience. For example, immediately, when I saw t-values of around 2 that the students had obtained, I thought that can\u2019t be right, because even with 17 people, 7 pounds is pretty far from 0, it seemed like it ought to be significant. \n So \u2026. this brings me to number 6 \n  \n #6 PRACTICE \n The more problems you do, the better you get at solving them. People often get the impression that people who are good at math have some kind of special math brain. It\u2019s not true. If you are telling yourself that you are just not good at math, cut it out right now before I come over there and smack you. \n I married a rocket scientist \u2013 literally \u2013 someone whose idea of the way to a woman\u2019s heart was to write a program to generate fractals and email her a pink fractal for Valentine\u2019s Day. It worked, too. \u00a0And yet \u2014 I can guarantee you that he, and I, both ran into the same obstacles in learning mathematics that anyone else does. The only difference between us and our friends who quit school and ended up working at Wal-Mart is that we spent hours and hours and hours learning programming, statistics(well, I learned the statistics), Calculus, Physics (well, he learned the physics). \n Last week, more than one student said to me, with some frustration. \n \u201cDr. De Mars, I studied for HOURS for this class.\u201d \n Yes!"], "link": "http://www.thejuliagroup.com/blog/?p=2692", "bloglinks": {}, "links": {"http://www.thejuliagroup.com/blog": 3, "http://www.fractaldomains.com/": 1}, "blogtitle": "AnnMaria's Blog"}, {"content": ["I was grading the quizzes from my Advanced Quantitative Data Analysis class. This is a class of really smart people in a doctoral program at a selective university. And yet, some of them still had problems with the quiz. Therefore, in however many parts I feel like doing, I am going to discuss how to solve any statistics problem. \n #1 CHILL ! \n I mean this most seriously. Often, I see people make mistakes because they panic, think they can\u2019t do it, underestimate themselves and think, \u201cThe problem cannot be that easy\u201d. \n Here is an example: \n For 17 girls diagnosed with anorexia, weight change after family therapy was as follows: \n 11,11, 6, 9, 14, -3, 0, 7, 22, -5 , -4, 13, 13, 9, 4 , 6, 11 \n Partial results are shown below. Fill in the missing results: \n \n \n \n \n Lower C.L. \n Upper C.L. \n t-value \n df \n 2-tail Sig \n \n \n 3.60 \n \n \n \n .0007 \n \n \n \n #2 UNDERSTAND! \n What is it you are asked to do in the problem? You need to find the upper confidence limit for the mean, the t-value and the degrees of freedom. \n What are the degrees of freedom for a t-test? \n \u201c A single sample: There are n observations. There\u2019s one parameter (the mean) that needs to be estimated. That leaves n-1 degrees of freedom for estimating variability. \u201c \n The degrees of freedom when you are estimating the mean with one sample is N-1, or\u00a0 17-1, which is 16. \n To understand a problem, look at the numbers you DO have. \n \n You have the lower confidence limit. \n You have all of the individual scores \n You know the number of scores (17) \n \n Think about what you DO know (or can look up in a textbook) \n \n The mean is the sum of the scores divided by the number of scores \n The lower confidence limit is the obtained mean MINUS (t * standard error). \n The UPPER confidence limit is the obtained mean PLUS (t * standard error). \n \n \n #3 SELECT A STRATEGY \n There are a number of ways to find the upper confidence limit but all involve adding the value of (t*standard error)\u00a0 to the mean. With what you have from #2, I\u2019d think the easiest strategy is \n \n Find what the mean is \n Find the difference between the lower confidence limit and the mean \n Add that number to the mean \n \n This is often the step where people have trouble. I think it comes from three missteps. One is that they are too stressed out. The second is they don\u2019t relax a minute and think about what they DO know first. The third is that they don\u2019t relax a minute and think about what is the right strategy. In short, I think most people (and I am as guilty of this as anyone) don\u2019t spend enough time on the first three steps before jumping right to number four. \n #4 DO IT \n Carry out your strategy. \n \n The mean is 7.29 \n 7.29 -3.6 = 3.69 \n Add 3.69 to 7.29\u00a0 to get 10.98 \n \n That\u2019s your answer. \n #5 TEST IT \n Do a reality check. The mean is 7.29 . If it doesn\u2019t fall between your upper and lower confidence limits, you did something wrong. \n Check back tomorrow for further proof that these steps can be applied to any statistics problem (and any math problem \u2013 maybe any problem in life. )"], "link": "http://www.thejuliagroup.com/blog/?p=2688", "bloglinks": {}, "links": {"http://www.tufts.edu/": 1, "http://www.thejuliagroup.com/blog": 1}, "blogtitle": "AnnMaria's Blog"}, {"content": ["Twenty-eight years ago, I won the world judo championships. Unlike almost everyone else who accomplishes that feat, I did NOT go into running a judo school, selling martial arts supplies, or, more recently, mixed martial arts. \n  Photo courtesy of Hans Gutknecht of the Los Angeles Daily News \n On the contrary, I immediately went into a doctoral program at the University of California, where I specialized in Applied Statistics and Psychometrics. After several years as a professor, I went into the consulting business full-time. \n So, was that 14 years of competing and training a waste, as far as my career is concerned? I would say no. Thinking about it lately, I see some important lessons I learned from martial arts. \n 1. To succeed, you don\u2019t need to be like the other successful people. No one is a less unlikely world judo champion than me. I wasn\u2019t Japanese, I had no money, and oh, yes, I wasn\u2019t male. The first women\u2019s world championships were still eight years in the future when I started judo. Japan has the largest number of international medalists, followed by France and the former Soviet Union, I never even had an instructor from any of those countries. \n Of course, this has been an extraordinarily useful lesson since being female, over 50 and Hispanic and not only not dropped out of Ivy League schools but having actually graduated with a Ph.D., no one looks less like Silicon Valley than me. \n 2. To succeed you don\u2019t need to be in \u201cthe right place\u201d or with \u201cthe right people\u201d. It is NOT all who you know.\u00a0 I started at Alton YMCA in middle of nowhere Illinois, and trained there my first few years. While many people travel to Japan or Europe to train 20 or 30 times, I went to Japan once, for my junior year abroad, because it was all I could afford. While I was there, Margot Sathay taught me. She was, at the time, the highest ranking non-Asian woman in the world. No one else wanted to bother with me. \n This is, of course, a good thing, because I am not in Silicon Valley, Boston or New York City. I\u2019m in Los Angeles and don\u2019t intend to move because I like my life. \n 3. Success requires effort. Amazing success requires amazing effort. I work 7 days a week. My \u201coff-days\u201d I only work six hours or so. Other days, I usually work from 11 a.m. to 2 a.m. with an hour or so break for lunch or dinner. \n 4. Working hard doesn\u2019t mean not enjoying life. Just like when I was competing in judo, I am enjoying what I am doing very much, so it is not all that difficult. One side benefit from all of those years of training \u2013 I never got into the habit of watching TV. I watch maybe 4 hours of TV a week \u2013 frees up a whole lot of time compared to the typical American\u2019s schedule. Half the time I\u2019m watching TV I\u2019m probably riding the exercise bike in the living room at the same time. \n 5. Focus on what you can do, not what you can\u2019t. I tore my ligaments and cartilage in my right knee in an accident when I was 17 years old. Knee replacements and even orthoscopic surgery were years in the future. Any reasonable person would have quit competing. Instead, I focused on being best in the world at matwork and won international tournaments on four continents. I couldn\u2019t train with top athletes twice a day because I had a job as an industrial engineer. I couldn\u2019t quit my job because I was a divorced mom with a baby that needed stuff. So, I got up every morning, ran or lifted weights, went out on my lunch hour and ran or lifted weights and then did judo after work every night. \n I have a lot of advantages right now. We have every possible piece of hardware and software for development and testing. After years in business, we have a stable customer base and a sizable 401k. I can afford to invest a lot of my unpaid time and company funds in design and development. Yes, some of those customers mean I can\u2019t always spend as much time on development as I want. On the flip side, that gives us money and stuff. We\u2019re not part of any incubator, accelerator or co-working arrangement, but The Rocket Scientist, the person who, when we were dating, my research assistants referred to as \u201cComputer God\u201d, is right upstairs. \n 6. Persistence is probably the biggest lesson I learned from martial arts . When I was 12 years old, there were thousands of kids in this country as good at judo as me, if not much better. When I was 16 years old, there were probably hundreds of kids in this country as good as me, if not better. When I was 21 years old, there were certainly less than 100 people in this country as good at judo as me. When I was 26 years old, I was the best in the world. The biggest difference between me and the thousands of other kids is that I just kept at it. \n The first draft of the game was pretty ragged \u2013 just like my technique when I started judo. BUT \u2013 it gave our team something to work with. For the last few weeks, we have all been working on fixing every part of it,changing the intro, making all the graphics the same size, creating a theme for the web pages,\u00a0 adding levels to the 3-D portion, adding a sound track \u2013 adding, changing, fixing. \n It did not look very good at all when we began, but I have learned that how you look at the beginning, or even in the middle, is not the important part. It\u2019s how you end up."], "link": "http://www.thejuliagroup.com/blog/?p=2684", "bloglinks": {}, "links": {"http://www.thejuliagroup.com/blog": 1, "http://www.blogher.com": 1}, "blogtitle": "AnnMaria's Blog"}, {"content": ["Several times on this blog, I have mentioned that the most common errors I make , and most programmers*, are the simple things like typing or forgetting to close a bracket or tag. Many of those errors are now automatically fixed by the intellisense of various IDEs (Integrated Development Environment), like Webstorm, but they still pop up. \n Well, as I have said before (after nearly five years, almost everything on this blog I have said before), I started writing this blog because I wanted to remember solutions to problems for when I had the same problem six months later and was in a different state using a different computer at some random hotel. This is one of those problems. \n We are developing a game that uses mostly javascript but since it runs on the web there is also html involved and some PHP (not written by me) that is used for writing the data from the game to our database. \n Everything was working until Friday when all of a sudden the input forms quit inputting. I was able to look at the files on the server and see that a few of them had been changed on Friday. Obvious suspect, no? \n Unfortunately, I had updated my local machine using the other person\u2019s code from the server, so I had the non-working files on my machine also. \n Of course, I had back-ups on my local machine. So, I copied those files over the newer ones on my local machine. This should bring me back to the pre-update state, where everything was working, yes? No. \n How could this be? Files on local machine worked. Copied over by files on server. Copied original files that worked back on local machine (yes, they really were the correct files) and they did not work. How can that be? \n Well, I gave it away in the title of this post. One of the javascript files had the ABSOLUTE path to the PHP file, not the relative path. So, when I ran it on my local machine, it accessed the non-working, newer, file on the server. \n A billion thank-yous to the wonderful tech support staff at pair.com , our web host, who helped me figure this out on a Saturday night. They could see that there was an attempt to connect to the database, and so we knew that the javascript was working and it must be something in the PHP file. At which point I said, \n \u201cI can see the error in the PHP file on the remote server but that would only be a problem if the javascript had that file name coded in to call instead of a relative path \u2026\u201d \n and then a lightbulb went off and it was all fixed in a minute. \n Take away message \u2013 if things aren\u2019t working in any way that makes sense, perhaps you are looking at the wrong files. \n * The Rocket Scientist says that I should not call myself a programmer because programmers are lower-level and it is only a slightly more impressive title than code monkey. I am ignoring him for now, but if anyone has suggestions for new titles, I am listening. My business cards say \u201cPresident\u201d, \u00a0which last week led a child just old enough to read, but not old enough to follow politics obviously, to ask me if I was the president of the country. He was very disappointed when I said no."], "link": "http://www.thejuliagroup.com/blog/?p=2681", "bloglinks": {}, "links": {"http://www.thejuliagroup.com/blog": 1, "http://www.pair.com/": 1}, "blogtitle": "AnnMaria's Blog"}, {"content": ["I\u2019ve been somewhat of a fan of SAS On-Demand for Academics, but there are two problems. One is that it runs slow and the other is that it doesn\u2019t run native on a Mac at all. Enter the SAS Web Editor. \n I just started using it yesterday and so far, I love it. It is in beta, so if you are interested, I suggest you contact the people in the academic division of SAS and get right on it. \n One glitch so far to be aware of - \n If you re-load the page, it reloads everything. I wanted to clear the results, and when I reloaded the page, everything was cleared, including the code. Since I was just messing around it was no big deal, but if it was your assignment, you might be unhappy. \n Solution: Save your code often \n This is something you just ought to be doing anyway, anywhere, as a good habit. \n Here is my sample code \n /* Enter your code here */ \ndata test ; \ninput group $ wt ; \ncards ; \naa 207 \nca 55 \n; \nproc freq ; \ntables group / binomial (p=.422 ac) ; \nweight wt ; \nrun; \n and here is a link to my output which I just downloaded by clicking on the download button. The code above tests whether the proportion of African-Americans stopped in 262 routing traffic stops is different than the population proportion of 42.2% . Through in confidence intervals for good measure. \n As I said, I\u2019ve only been using this for less than 24 hours and I started with solving statistics homework problems. So far, it is awesome. Whether it will be equally awesome once I upload some data sets and try to run more complex statistics, who knows. So far, though \n \n Runs on a Mac \u2013 check \n Can save programs on-line and access them later \u2013 check \n Fast response time \u00a0- check \n Does basic statistics \u2013 check \n Produces presentation-quality output that can be easily downloaded \u2013 check"], "link": "http://www.thejuliagroup.com/blog/?p=2678", "bloglinks": {}, "links": {"http://www.thejuliagroup.com/": 1}, "blogtitle": "AnnMaria's Blog"}, {"content": ["For reasons I may explain later \u2013 or maybe not \u2013 I decided to analyze the TIMSS data, which is Trends in International \u00a0Mathematics and Science Study . \n Use a colon: Nifty tip #1 \n** Ran this first *** \n libname LIB \u2018C:\\TIMSS2007\\Data\u2019; \n proc contents data =\u00a0lib.G4_ACHIEVE07; \n *** Modified to only keep math items ; \ndata lib.G4_ACHIEVE07; \nset lib.G4_ACHIEVE07; \ndrop s: ; \n I was only interested in the mathematics items, not the science ones, and since I did not want 170+ items cluttering up my data set, I used the statement below \n DROP S: ; \n This statement drops all of the variables beginning with S. You should be cautious of this, because \u00a0if there is a variable with a name like STUDENT_ID that will be dropped also. \u00a0This is why I ran the PROC CONTENTS first and verified that all of the science items and only t hose items began with an S. \n Nifty tip #2 \u00a0- use a %INCLUDE statement \n It only appears that the point of today\u2019s blog is to include all possible special characters. That is merely a fringe benefit. \n The %INCLUDE statement essentially copies and pastes code from another file into your program in the spot where you inserted it. I like it for things like 400 lines of formats because just like I don\u2019t like extra variables cluttering up my data set, I don\u2019t like extraneous lines cluttering up my code. I do need to use the PROC FORMAT but I don\u2019t need to see it every time I run the program and I do not want to store it permanently. \n %include \u201cc:\\timss2007\\programs\\achievefmts.sas\u201d ; \n Problem solved. \n Nifty tip #3 \u00a0Use the LINESIZE option to see all of your results on one line \n I am easily annoyed. If you read my blog often, you know that this has been established. If I have 200 variables and the minimum and maximum does not fit on the same line as the mean because the label is \n \u201cThis is that question where we asked the student about long division which involves dividing a two- digit number into a three-digit number and has a remainder\u201d \n and then you have the mean and need to scroll down 200 lines to see the minimum and another 200 lines to see the maximum, well it\u2019s annoying. \n Do this: \n OPTIONS LINESIZE = 255 ; \n or whatever large number you like. No, I don\u2019t have paper that is that wide, but I\u2019m not planning on printing this out, I just want to scroll through and see that the minimum, maximum, mean and standard deviation are reasonable. \n Nifty tip #4 Use a temporary data step to find the number of variables \n No, smart ass, PROC CONTENTS would NOT do this. I want to know how many math items there are, not how many total. The math items (now that I deleted the science ones above) are in order. I run this statement, look in my log and it tells me there are 178 variables in the data set. \n data test ; \nset lib.G4_ACHIEVE07; \nkeep M031106 \u2013M041191 ; \n Nifty tips #5 \u00a0and #6 \u2013 Create an array and use the VVALUE function to score data \n TIMSS has formats (remember the %INCLUDE ) that are things like 98 = \u201cNOT ADMIN.\u201d , 10 = \u201cCORRECT RESPONSE\u201d. \n data lib.G4_scored ; \nset lib.G4_ACHIEVE07; \narray ans{*} M031106 \u2013M041191 ; \narray sc{*} $18 tmp1 \u2013 tmp178 ; \n I created an array of the mathematics items and the ans{*} says to create an array of dimension however many variables there are between\u00a0M031106 and M041191 . The double dashes signify between as in \u201cbetween locations in the data set\u201d with M031106 coming first. If you use one dash SAS assumes the variables are numbered\u00a0M031106 \u00a0M031107 all the way toM041190\u00a0M041191. Which they are not. Do double dashes count as two special characters or only one? \n I could have used 178 instead of * since I actually knew there were 178 variables, but I wanted to throw in another special character. Yes, I am immature. That was established long ago. The $18 denotes this as an array of character variables and assigns them all a length of 18 which is the length of the maximum formatted response. Also, a $ is another special character. \n do i = 1 to 178 ; \nsc{i} = trim(vvalue(ans{i})) ; \nif sc{i} in (\u201cINCORRECT RESPONSE\u201d,\u201dNOT REACHED\u201d, \u201cOMITTED\u201d) then ans{i} = 0 ; \nelse if sc{i} = \u201cCORRECT RESPONSE\u201d then ans{i} = 1 ; \nelse if sc{i} = \u201d PARTIAL RESPONSE\u201d then ans{i} = .5 ; \nelse if sc{i} = \u201cNOT ADMIN.\u201d then ans{i} = . ; \nend ; \ndrop tmp1 \u2013 tmp178 M031002 M031223; \n Here I have my handy do-loop and a VVALUE function. You can use VVALUE when you don\u2019t know the variable format, or, as in my case, are too lazy to look it up and type it in. The formatted value of ans{i} , whatever that format might be, is put into sc{i}. I also used the TRIM function to trim trailing blanks while I was at it. \n Now that I have scored all of the items to suit my nefarious purposes, I drop the temporary variables as well as two variables that it turned out are questions not administered to anyone. \n And that, is my nifty SAS tips of the night."], "link": "http://www.thejuliagroup.com/blog/?p=2674", "bloglinks": {}, "links": {"http://nces.ed.gov/": 1}, "blogtitle": "AnnMaria's Blog"}, {"content": ["Testing in the schools starts in a few weeks. We\u2019ve been writing a computer game to teach math. Here is a look at some of the scenes. \n  \n The poster is thanks to one of the awesome members of our graphics team, Justin Flores. You can find him at Jflo Productions . \n Of course, we will be using statistics on the back end to see what parts of it students play the most and correlating that to student outcomes."], "link": "http://www.thejuliagroup.com/blog/?p=2669", "bloglinks": {}, "links": {"http://www.thejuliagroup.com/blog": 1, "http://jfloproductions.com": 1}, "blogtitle": "AnnMaria's Blog"}, {"content": ["Let\u2019s say that all you knew about probability were some basic rules. Would it be enough to convince you that gambling is a bad bet? I think so.\u00a0 Let\u2019s begin with these four: \n Probability of something not happening = 1 \u2013 the probability of that something happening \n P(Not X) = 1 \u2013 P(X) \n Since the total of all probabilities = 100%\u00a0 , that is, there will be SOME result, and the probabilities of something not happening and the same something not happening are mutually exclusive, the probability of something NOT happening must be 100% minus the probability of it happening. (This relates to the next rule). \n The probability of either of two mutually exclusive events is the sum of their individual probabilities \n P(A or B) = P(A) + P(B) \n Notice that the key phrase there is mutually exclusive. Here is where people often go astray. \n There was the famous case of the gambler who bet that a six would come up at least once in four throws of a die. A person misapplying this rule would say the probability is \n 2/3 or 4/6 that this would happen. \n That is, your odds are 1 out of 6 possibilities on the first throw, the second throw, the third throw and the fourth throw. \n These are not mutually exclusive probabilities. A person can throw a six the first time and the third time. So, no, this rule won\u2019t work. \n For independent events, the probability of any combination of them is the product of the individual probabilities. \n That is, \n P( A and B) = P(A) * P(B) \n Let\u2019s take our gambler again, written about in a free and highly recommended book on probability by Grinstead and Snell . \n So, the probability of NOT getting a six is 5/6 \u2013 since there are 5 sides on a die that are NOT a 6. \n The probability of not getting a 6 four times in a row is \n 5/6 * 5/6 * 5/6 * 5/6 \u00a0= .482 \n Since \u00a048.2% of the time you won\u2019t get a 6, that means 51.8% of the time you will. The odds are in your favor to bet on getting a 6. \n So \u2026 why did the gambler lose money? This, my friends, brings into consideration, \n The Law of Large Numbers \n The best \u00a0description of the Law of Large Numbers I have read comes from wikipedia \n \u201cIt follows from the law of large numbers that the\u00a0 empirical probability \u00a0of success in a series of\u00a0 Bernoulli trials \u00a0will converge to the theoretical probability.\u201d \n A Bernoulli trial is an event that can have one of two possible outcomes, and which outcome is obtained is determined at random. Sounds like throwing a die and getting either a 6 or not a 6. \n So, over the long run, the larger and larger number of trials you have, the closer you will get to the theoretical distribution, in this case, getting a six 48.2% of the time. \n Incidentally, for all the trashing academics do of wikipedia, I have found their sections on statistics to be extremely accurate and well-written. Whoever the people are who write it, kudos to them. \n So, if we had an infinite number of trials, we would always end up with 51.8% of the time a 6 coming up on four throws of a die. \n Here are the results from someone who bet 100 times on a binary outcome, with a distribution of 10,000 trials. That is, assume you went to Las Vegas for 10,000 days in a row and every day you made 100 bets. \n  \n Two take-away points: \n \n The house always wins because the casino makes a LARGE number of bets. If you count every time someone pulls a slot machine or bets on 21, it is hundreds of thousands of bets a day. If they are taking the equivalent of that 51.2% bet, over a large number of trials, they will always win. If the odds are 50%, as above, they are going to be centered around 50. If, as on most bets people make, the odds are more around 52% , in the house\u2019s favor, the distribution is going to be centered around 52%. More than half of the time, the house wins. \n People will say things like, \u201cYes, but what if you are the one on the end before the house starts to win? What if you are that one person out of the 10,000 where the die comes up with a 6 only 30 times out of 100? You\u2019d win big, wouldn\u2019t you? That\u2019s possible, isn\u2019t it? Yes, it is possible, but it\u2019s not the way to bet. The odds are not zero, but they ARE against you. \n \n So, you now you know why statisticians are no fun in Vegas. In fact, I was at a conference not long ago where someone at the casino told me, \n \u201cWe hate you people (statisticians). Everyone always makes less money on the statistics conferences than any other event because they understand the odds, so they very seldom gamble.\u201d"], "link": "http://www.thejuliagroup.com/blog/?p=2659", "bloglinks": {}, "links": {"http://www.dartmouth.edu/": 1, "http://www.thejuliagroup.com/blog": 2, "http://en.wikipedia.org/": 3}, "blogtitle": "AnnMaria's Blog"}]
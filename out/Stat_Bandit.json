[{"blogurl": "http://statbandit.wordpress.com\n", "blogroll": [], "title": "Stat Bandit"}, {"content": ["Two blog posts in the last 24 hours caught my attention. First was this post \u00a0by Jeff Leek noting that there are many fields which are applied statistics by another name (and I\u2019d add operations research to his list). The second is an excellent post \u00a0on Cloudera\u2019s blog on constructing case-control studies. It is generally excellent, but has this rather unfortunate (in my view) statement: \n Analyzing a case-control study is a problem for a statistician.\u00a0 Constructing \u00a0a case-control study is a problem for a data scientist. \n First of all, this ignores what biostatisticians have been doing in collaboration with epidemiologists for decades. The design of a study, as any statistician understands, is just as, if not more, important than the analysis, and statisticians have been at the forefront of pushing good study design. Second, it shows a fundamental lack of understanding of the breadth of what statistics as a discipline encompasses. Third, this almost reiterates Jeff\u2019s point about the different fields, considered different but essentially \u201capplied statistics\u201d. There seems to be a strong push to claim a new field as different and sexier than what has come before (an issue of branding and worth, perhaps?) without understanding what is already out there. \n Statistics as a field has been guilty of this as well. The most obvious and wasteful consequence of this is \u201cre-inventing the wheel\u201d, rather than leveraging the power of other discoveries. Ownership of an idea is a powerful concept, but there must be the recognition that while\u00a0 translating a concept for a new audience is useful and extremely necessary, merely claiming ownership while willfully ignoring the developments by colleagues in another field is wasteful and disingenuous. \n A recent discussion with a colleague further reiterated this point even within statistics. Some of the newer developments in a relatively new methodologic space are along the same lines of theoretical development in an older methodologic space. The new guys are coming up against the same brick walls as the earlier researchers, and there seems to be a lack of understanding among the new researchers of the path already travelled (since the keywords are different and not necessarily directly related, Google Scholar fails). \n The bottom line here is the strong need for more cross-talk between disciplines, more collaboration among researchers, having greater understanding for the knowledge already out there, and more breadth in our own training and knowledge."], "link": "http://statbandit.wordpress.com/2012/04/12/the-many-faces-of-statisticsdata-science-cant-we-all-just-get-along-and-learn-from-each-other/", "bloglinks": {}, "links": {"http://www.cloudera.com/blog": 1, "http://feeds.wordpress.com/": 7, "http://simplystatistics.tumblr.com/": 1}, "blogtitle": "Stat Bandit"}, {"content": ["I have always been provided SAS as part of my job, so I never really realized how much it cost. I\u2019ve bought Stata before, and of course R . I recently found out how much a reasonable bundle of SAS modules along with base SAS costs per year per seat, at least under the GSA. I tried finding out how much IBM SPSS is for a comparable bundle, but their web page was \u201cnot available\u201d. Stata costs in the ballpark of $1700 (for a permanent license of Stata/SE) or $845 for an annual license. SAS costs over 5 times that per seat for similar functionality (Ouch!!). R, with its quirks but with similar if not enhanced functionality in a lot of areas, is of course, freely downloadable.\u00a0 \n Matlab is another software I\u2019ve bought as part of my job. For a reasonable bundle, in an academic setting, it is close to $3000. Of course, here it\u2019s a bit easier to pick and choose, since I don\u2019t need most of the modules which are of more interest to engineers."], "link": "http://statbandit.wordpress.com/2012/02/23/pocketbook-costs-of-software/", "bloglinks": {}, "links": {"http://feeds.wordpress.com/": 7}, "blogtitle": "Stat Bandit"}, {"content": ["I had a recent request to convert an entire folder of JPEG images into EPS or similar vector graphics formats. The client was on a Mac, and didn\u2019t have ImageMagick. I discovered the Python Image Library\u00a0 \u00a0to be enormously useful in this, and allowed me to implement the conversion in around 10 lines of Python code!!! \n \nimport Image\nfrom glob import glob\n\njpgfiles = glob('*.jpg')\nfor u in jpgfiles:\n out = u.replace('jpg','eps')\n print \"Converting %s to %s\" % (u, out)\n img=Image.read(u)\n img.thumbnails((800,800)) # Changing the size\n img.save(out)\n\n \n What an elegant solution from Python \u2014- \u201cbatteries included\u201d \n To be sure, using ImageMagick is more powerful, and Python wrappers ( PyMagick ), albeit old, do exist."], "link": "http://statbandit.wordpress.com/2011/09/29/converting-images-in-python/", "bloglinks": {}, "links": {"http://feeds.wordpress.com/": 7, "http://pymagick.sourceforge.net/": 1, "http://www.pythonware.com/": 1}, "blogtitle": "Stat Bandit"}, {"content": ["I\u2019ve updated the R code for the enhanced K-M plot to include additions and improvements by Gil Thomas and Mark Cowley. Thanks fellows for the feedback and updates. \n http://statbandit.wordpress.com/2011/03/08/an-enhanced-kaplan-meier-plot/"], "link": "http://statbandit.wordpress.com/2011/09/01/an-enhanced-kaplan-meier-plot-updated/", "bloglinks": {}, "links": {"http://feeds.wordpress.com/": 7}, "blogtitle": "Stat Bandit"}, {"content": ["Prof. Atul Butte of Stanford University and colleagues just published two articles in Science Translational Research \u00a0which got a fair amount of press. \u00a0In fact I heard about the work on the radio on my commute to work. The research involves developing a computational method which can look at drug-disease interactions based on the NCBI GEO repository to discover potentially new uses for approved drugs. On reading the paper, I realized that their main computational tool is R, in particular the Bioconductor tools as well as pvclust \u00a0 and qvalue . You can read the article here ."], "link": "http://statbandit.wordpress.com/2011/08/18/another-application-of-r-getting-press/", "bloglinks": {}, "links": {"http://stm.sciencemag.org/": 1, "http://feeds.wordpress.com/": 7}, "blogtitle": "Stat Bandit"}, {"content": ["I just updated my RStudio version to the latest, v.0.94.92 (will this asymptotically approach 1, or actually get to 1?). It was nice to see the number of improvements the development team has implemented, based I\u2019m sure on community feedback. The team has, in my experience, been extraordinarily responsive to user feedback, and I\u2019m sure this played a large part in the development path taken by the team. \n First and foremost, I was happy to see most of my wants met in this version: \n \n There now is a keyboard shortcut for <- that is easy and intuitive (Alt+_/Option+_) \n The File window now allows sorting by modification date in addition to name, which was becoming an issue for one of my projects \n Plots can be saved as BMP, TIFF, JPEG and Postscript in addition to PNG and PDF \n Bracket completion and matching, very much similar to the R Mac GUI, and actually better than Emacs/ESS, specially when deleting. \n An easy shortcut to repeat blocks of text or transpose two lines of text (though this appears mistakenly overloaded with another shortcut on Windows/Linux)  \n Keyboard shortcuts are reasonably consistent with OS-specific shortcuts, though the Ctrl key is used in Mac more than generally seen in the OS. It is however convenient for those of us migrating from Emacs/ESS, who use the Ctrl key often. \n \n My wishlist for RStudio is pretty much fulfilled with respect to R development. However, a few improvements need to be made in the TeX/Sweave interface to allow for autocompletion, templates, and fuller functionality in line with Emacs/Auctex and Texmate. Currently writing LaTeX and Sweave feels like writing in Wordpad, albeit with R-specific word completion and R functionality. This can be a bit more polished. Of course TeX and Sweave are still used by a minority of R users, so the fact that this functionality hasn\u2019t developed is no surprise. \n All in all, the current version of RStudio feels like a very usable IDE for R, and certain features and similarities make migrating from Emacs pretty easy (provided you don\u2019t miss Emacs\u2019 overall power and flexibility too much)"], "link": "http://statbandit.wordpress.com/2011/07/30/rstudio-0-94-92-visited/", "bloglinks": {}, "links": {"http://feeds.wordpress.com/": 7}, "blogtitle": "Stat Bandit"}, {"content": ["At the DC useR meetup last week, Marck Vaisman (@wahalulu) showed me a neat trick he\u2019d learned to allow different facets in a faceted ggplot graph to have different plot types. The basis for this trick is this blog post in the Learn-R blog . Marck was trying to plot different statistics on our Meetup group\u2019s membership on a faceted plot. Some of the variables were amenable to a step plot while others were more amenable to plotting using vertical lines. \n The interesting trick in this example is to use the subset command within each geom to only layer one facet at a time. The source code is given below: \n \n \nmeetup <- read.csv('MeetupDates.csv', as.is=T)\nnames(meetup) <- 'Dates'\nmeetup$Dates <- as.Date(meetup$Dates,format='%m/%d/%y')\nfiles <- dir(pattern='DC_useR')\nbl <- list()\nfor(f in files){\n bl[[f]] <- read.csv(f, as.is=T)\n bl[[f]]$Date <- as.Date(bl[[f]]$Date,format='%m/%d/%y')\n}\ndat <- Reduce(function(x,y) merge(x,y), bl) # Merge the data frames by Date\ndat2 <- melt(dat,id=1)\n\n# Here comes the trick !!\nf1 <- ggplot(dat2, aes(x=Date,y=value,ymin=0,ymax=value))+facet_grid(variable~., scales='free')\nf2 <- f1+geom_step(subset=.(variable=='Total.Members'))\nf3 <- f2+geom_step(subset=.(variable=='Active.Members'))\nf4 <- f3+geom_linerange(subset=.(variable=='Member.Joins'))\nf5 <- f4+geom_linerange(subset=.(variable=='RSVPs'))\nf5+geom_vline(xintercept=meetup$Dates, color='red',alpha=.3)+ylab('')\n\n \n This produces the following plot: \n  A faceted ggplot object with different plot types"], "link": "http://statbandit.wordpress.com/2011/07/29/a-ggplot-trick-to-plot-different-plot-types-in-facets/", "bloglinks": {}, "links": {"http://learnr.wordpress.com/": 1, "http://feeds.wordpress.com/": 7, "http://learnr.wordpress.com": 1, "http://statbandit.wordpress.com/": 1}, "blogtitle": "Stat Bandit"}, {"content": ["I\u2019ve often selected columns or rows of a data frame using grep or which , based on some property. That is inherently sound, but the trouble comes when you wish to remove rows or columns based on that grep or which call, e.g., \n \ndat <- dat[,-grep('\\\\.1', names(dat))]\n \nwhich would remove columns with a .1 in the name. This is fine the first time around, but if you forget and re-run the code, grep('\\\\.1',names(dat)) gives a vector of length 0, and hence dat becomes a data.frame with 0 columns. The function which also has similar pitfalls, as demonstrated in a recent R-help posting by David Winsemius. I find a more reliable method is to do \n \ndat <- dat[,setdiff(1:ncol(dat),grep('\\\\.1',names(dat)))]\n \nwhich will always give the right number of columns. Other suggestions for getting around this issue are welcomed in the comments."], "link": "http://statbandit.wordpress.com/2011/07/13/a-word-of-warning-about-grep-which-and-the-like/", "bloglinks": {}, "links": {"http://feeds.wordpress.com/": 7}, "blogtitle": "Stat Bandit"}, {"content": ["One of the disappointing problems in SAS (as I need PROC MIXED for some analysis) is to recode categorical variables to have a particular reference category. In R, my usual tool, this is rather easy both to set and to modify using the \u00a0 relevel command available in base R (in the stats package). My understanding is that this is actually easy in SAS for GLM, PHREG and some others, but not in PROC MIXED. (Once again I face my pet peeve about the inconsistencies within a leading commercial product and market \u201cleader\u201d like SAS). The easiest way to deal with this, I believe, is to actually create the dummy variables by hand using ifelse statements and use them in the model rather than the categorical variables themselves. If most of the covariates are not categorical, this isn\u2019t too burdensome. \n I\u2019m sure some SAS guru will comment on the elegant or \u201cright\u201d solution to this problem."], "link": "http://statbandit.wordpress.com/2011/07/13/sas-r-and-categorical-variables/", "bloglinks": {}, "links": {"http://feeds.wordpress.com/": 7}, "blogtitle": "Stat Bandit"}, {"content": ["We often see, in publications, a Kaplan-Meier survival plot, with a table of the number of subjects at risk at different time points aligned below the figure. I needed this type of plot (or really, matrices of such plots) for an upcoming publication. Of course, my preferred toolbox was R and the ggplot2 package. \n There were other attempts to do this type of plot in ggplot2, mainly by\u00a0 Gary Collins and an anonymous author as seen on the ggplot2 mailing list. There was also an invaluable blog on Learn-R on plotting a table using geom_text . \n I decided to use Gary\u2019s code as my starting point. I wanted to add a log-rank test p-value for stratified KM curves on the plot, and I wanted to code it so that the text in the table remained aligned to the x-axis even when my strata names changed with different data sets. The former was relatively easy, but the latter was challenging (and seemed to be unsolved by Gary, who had posed it as a question). Both were instructive, and took me back a layer to the grid graphics engine (on which both ggplot2 and lattice are based) and the gridExtra package. \n The placement of the p-value in the plot is a case of a single character string being placed at a certain point on the graph, which I had done with the text command in base R. However, the geom_text layer seems to be intended for plotting text at all points in the data and not for inserting a single text string. However, I learned of the grid.text function from the grid package, which would enable me to do this for grid -based graphics. \n The second part is to plot a table aligned to the x-axis of the plot. The plotting was achieved using Gary\u2019s code using the method outlined on the Learn-R website. The problem was alignment. A few experiments showed that alignment depended on the size of the strata labels used in the plot. I started playing with the plot.margin option in ggplot2 and then figured out that I could maintain the alignment (more or less) if the left margin was computed based on the length of the labels. Some experimentation got me to a reasonable formula for this computation. \n Now I had to put the 3 parts together. Both the plot and the table were ggplot objects, so I knew I could stitch them together with grid.arrange from the gridExtra package. However, the p-value was being written using a separate grid.text command. I had to learn more about grid . I decided to use basic grid commands to convert the KM plot to a grid object using ggplotGrob and add the p-value text string to it using addGrob and textGrob . I could now stitch this together with the plotted table using grid.arrange, using the same layout specs. \n However, this still wasn\u2019t ideal since the plots were overlapping a bit. I decided to put a buffer blank image in between. In base graphics, I could achieve this with plot(..., type=\"n\") . In ggplot, I learned about geom_blank() and theme_blank() to create a blank image. This I then put in a thin row between the plot and the table. \n I incorporated this process into the function ggkm which is given below. An example plot generated by this code: \n data(colon)\nfit <- survfit(Surv(time,status)~rx, data=colon)\nggkm(fit, timeby=500) \n is shown here: \n rstudio-V79384 \n The ggkm function is given below: \n Update: The following code is modified thanks to Baptiste Auguie\u2019s comments, which were very helpful. I also make the p-value text optional for the plot, with the default settings omitting the p-values. \n Update (3/26/2011) I\u2019ve further updated the code based on comments which allow it to work on a naive install (albeit with the required packages), as well as replacing \u201cdf\u201d with \u201cdframe\u201d to get around the fact that \u201cdf\u201d is a R function. \n Update (9/1/2011) \u00a0Both Gil Thomas and Mark Cowley have made improvements to the code that have made it more stable and universally run-able (is that a word?). The following reflects Mark\u2019s last edits to the code. \n \n#\u2019 Create a Kaplan-Meier plot using ggplot2\n#\u2019\n#\u2019 @param sfit a \\code{\\link[survival]{survfit}} object\n#\u2019 @param table logical: Create a table graphic below the K-M plot, indicating at-risk numbers?\n#\u2019 @param returns logical: if \\code{TRUE}, return an arrangeGrob object\n#\u2019 @param xlabs x-axis label\n#\u2019 @param ylabs y-axis label\n#\u2019 @param ystratalabs The strata labels. \\code{Default = levels(summary(sfit)$strata)}\n#\u2019 @param ystrataname The legend name. Default = \u201cStrata\u201d\n#\u2019 @param timeby numeric: control the granularity along the time-axis\n#\u2019 @param main plot title\n#\u2019 @param pval logical: add the pvalue to the plot?\n#\u2019 @return a ggplot is made. if return=TRUE, then an arrangeGlob object\n#\u2019 is returned\n#\u2019 @author Abhijit Dasgupta with contributions by Gil Tomas\n#\u2019 \\url{http://statbandit.wordpress.com/2011/03/08/an-enhanced-kaplan-meier-plot/}\n#\u2019 @export\n#\u2019 @examples\n#\u2019 \\dontrun{\n#\u2019 data(colon)\n#\u2019\tfit <- survfit(Surv(time,status)~rx, data=colon)\n#'\tggkm(fit, timeby=500)\n#' }\nggkm <- function(sfit, table = TRUE, returns = FALSE,\nxlabs = \"Time\", ylabs = \"survival probability\",\nystratalabs = NULL, ystrataname = NULL,\ntimeby = 100, main = \"Kaplan-Meier Plot\",\npval = TRUE, ...) {\nrequire(ggplot2)\nrequire(survival)\nrequire(gridExtra)\nif(is.null(ystratalabs)) {\n ystratalabs <- as.character(levels(summary(sfit)$strata))\n}\nm <- max(nchar(ystratalabs))\nif(is.null(ystrataname)) ystrataname <- \"Strata\"\ntimes <- seq(0, max(sfit$time), by = timeby)\n.df <- data.frame(time = sfit$time, n.risk = sfit$n.risk,\n n.event = sfit$n.event, surv = sfit$surv, strata = summary(sfit, censored = T)$strata,\n upper = sfit$upper, lower = sfit$lower)\nlevels(.df$strata) <- ystratalabs\nzeros <- data.frame(time = 0, surv = 1, strata = factor(ystratalabs, levels=levels(.df$strata)),\n upper = 1, lower = 1)\n.df <- rbind.fill(zeros, .df)\nd <- length(levels(.df$strata))\np <- ggplot(.df, aes(time, surv, groups = strata)) +\n geom_step(aes(linetype = strata), size = 0.7) +\n theme_bw() +\n opts(axis.title.x = theme_text(vjust = 0.5)) +\n scale_x_continuous(xlabs, breaks = times, limits = c(0, max(sfit$time))) +\n scale_y_continuous(ylabs, limits = c(0, 1)) +\n opts(panel.grid.minor = theme_blank()) +\n opts(legend.position = c(ifelse(m < 10, .28, .35), ifelse(d < 4, .25, .35))) +\n opts(legend.key = theme_rect(colour = NA)) +\n labs(linetype = ystrataname) +\n opts(plot.margin = unit(c(0, 1, .5, ifelse(m < 10, 1.5, 2.5)), \"lines\")) +\n opts(title = main)\n\n## Create a blank plot for place-holding\n## .df <- data.frame()\nblank.pic <- ggplot(.df, aes(time, surv)) +\n geom_blank() +\n theme_bw() +\n opts(axis.text.x = theme_blank(), axis.text.y = theme_blank(),\n  axis.title.x = theme_blank(), axis.title.y = theme_blank(),\n  axis.ticks = theme_blank(), panel.grid.major = theme_blank(),\n  panel.border = theme_blank())\nif(pval) {\n sdiff <- survdiff(eval(sfit$call$formula), data = eval(sfit$call$data))\n pval <- pchisq(sdiff$chisq, length(sdiff$n) \u2013 1, lower.tail = FALSE)\n pvaltxt <- ifelse(pval < 0.0001, \"p < 0.0001\", paste(\"p =\", signif(pval, 3)))\n p <- p + annotate(\"text\", x = 0.6 * max(sfit$time), y = 0.1, label = pvaltxt)\n}\nif(table) {\n ## Create table graphic to include at-risk numbers\n risk.data <- data.frame(strata = summary(sfit, times = times, extend = TRUE)$strata,\n  time = summary(sfit, times = times, extend = TRUE)$time,\n  n.risk = summary(sfit, times = times, extend = TRUE)$n.risk)\n data.table <- ggplot(risk.data, aes(x = time, y = strata, label = format(n.risk, nsmall = 0))) +\n  #, color = strata)) +\n  geom_text(size = 3.5) +\n  theme_bw() +\n  scale_y_discrete(breaks = as.character(levels(risk.data$strata)), labels = ystratalabs) +\n  # scale_y_discrete(#format1ter = abbreviate,\n  # breaks = 1:3,\n  # labels = ystratalabs) +\n  scale_x_continuous(\"Numbers at risk\", limits = c(0, max(sfit$time))) +\n  opts(axis.title.x = theme_text(size = 10, vjust = 1), panel.grid.major = theme_blank(),\n  panel.grid.minor = theme_blank(), panel.border = theme_blank(),\n  axis.text.x = theme_blank(), axis.ticks = theme_blank(),\n  axis.text.y = theme_text(face = \"bold\", hjust = 1))\n data.table <- data.table + opts(legend.position = \"none\") +\n  xlab(NULL) + ylab(NULL)\n data.table <- data.table +\n  opts(plot.margin = unit(c(-1.5, 1, 0.1, ifelse(m < 10, 2.5, 3.5) \u2013 0.28 * m), \"lines\"))\n## Plotting the graphs\n## p <- ggplotGrob(p)\n## p <- addGrob(p, textGrob(x = unit(.8, \"npc\"), y = unit(.25, \"npc\"), label = pvaltxt,\n ## gp = gpar(fontsize = 12)))\n grid.arrange(p, blank.pic, data.table,\n  clip = FALSE, nrow = 3, ncol = 1,\n  heights = unit(c(2, .1, .25),c(\"null\", \"null\", \"null\")))\n if(returns) {\n  a <- arrangeGrob(p, blank.pic, data.table, clip = FALSE,\n   nrow = 3, ncol = 1, heights = unit(c(2, .1, .25),c(\"null\", \"null\", \"null\")))\n  return(a)\n }\n}\nelse {\n ## p <- ggplotGrob(p)\n ## p <- addGrob(p, textGrob(x = unit(0.5, \"npc\"), y = unit(0.23, \"npc\"),\n ## label = pvaltxt, gp = gpar(fontsize = 12)))\n print(p)\n if(returns) return(p)\n }\n}"], "link": "http://statbandit.wordpress.com/2011/03/08/an-enhanced-kaplan-meier-plot/", "bloglinks": {}, "links": {"http://feeds.wordpress.com/": 7, "http://groups.google.com/": 2, "http://learnr.wordpress.com": 1, "http://statbandit.wordpress.com/": 1}, "blogtitle": "Stat Bandit"}]
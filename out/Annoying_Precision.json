[{"blogurl": "http://qchu.wordpress.com\n", "blogroll": [], "title": "Annoying Precision"}, {"content": ["Three years ago I thought it would be fun to write a blog post every day of November . I\u2019m not sure why I didn\u2019t do this in November 2010 or 2011 because I\u2019m pretty sure I learned a lot from doing it in 2009, so I\u2019d like to do it again. The posts will probably be shorter this time."], "link": "http://qchu.wordpress.com/2012/10/28/mablowrimo-is-upon-us/", "bloglinks": {}, "links": {"http://feeds.wordpress.com/": 1, "http://qchu.wordpress.com/": 1, "http://rigtriv.wordpress.com/": 1}, "blogtitle": "Annoying Precision"}, {"content": ["There are various natural questions one can ask about monomorphisms and epimorphisms all of which lead to the same answer: \n \n What is the \u201ceasiest way\u201d a morphism can be a monomorphism (resp. epimorphism)?\n What are the absolute monomorphisms (resp. epimorphisms) \u2013 that is, the ones which are preserved by every functor?\n A morphism which is both a monomorphism and an epimorphism is not necessarily an isomorphism. Can we replace either \u201cmonomorphism\u201d or \u201cepimorphism\u201d by some other notion to repair this?\n If we wanted to generalize surjective functions, why didn\u2019t we define an epimorphism to be a map which is surjective on generalized points?\n \n The answer to all of these questions is the notion of a split monomorphism (resp. split epimorphism ), which is the subject of today\u2019s post. \n \n Equivalent characterizations and examples \n The first question is the easiest one to get out of the way: a morphism is an epimorphism if and only if it is right-cancellative, and the \u201ceasiest\u201d way to cancel something on the right is to give it an inverse on the right. (We discuss epimorphisms first because we saw earlier that they behave less like surjective maps than monomorphisms behave like injective maps, so we are more interested in looking for stronger notions of epimorphism than for stronger notions of monomorphism.) \n Definition-Proposition: The following conditions on a morphism in a category are equivalent, and a morphism satisfying the first condition (hence any of the following conditions) is a split epimorphism : \n \n \n has a right inverse ; that is, a map such that .\n is an absolute epimorphism in the sense that for every functor , the morphism is an epimorphism.\n is surjective on generalized points in the sense that, for any , the induced map is surjective.\n \n \n Proof. : let be a parallel pair of morphisms in . If , then , and since , it follows that . Hence is an epimorphism. \n : surjective on generalized points is equivalent to the condition that is an epimorphism for the functor . \n : let . Then the induced map is surjective, so there exists some with image . But this is precisely the statement that . \n Dually, a morphism is a monomorphism if and only if it is left-cancellative, and the \u201ceasiest\u201d way to cancel something on the left is to give it an inverse on the left. Dualizing the above proposition, we obtain the following: \n Definition-Proposition: The following conditions on a morphism in a category are equivalent, and a morphism satisfying the first condition (hence any of the following conditions) is a split monomorphism : \n \n \n has a left inverse ; that is, a map such that .\n is an absolute monomorphism in the sense that for every functor , the morphism is a monomorphism.\n is surjective on generalized copoints in the sense that, for any , the induced map is surjective.\n \n \n Note that the right inverse to a split epimorphism is a split monomorphism and conversely, so every example of one also gives an example of the other. \n If is a morphism with a right inverse , then we say that \n \n is a section of ,\n is a retraction of , and\n is a retract of .\n \n Example. Let be a split epimorphism in . Then in particular is surjective. A right inverse to is a choice, for every , of an element of ; in other words, it is equivalent to a choice function for the family of sets , and consequently the statement that every epimorphism in is split is equivalent to the axiom of choice . \n Motivated by this example, we might say that the axiom of choice holds in a category if every epimorphism is split. \n On the other hand, every monomorphism in (edit: with non-empty domain!) is split with no set-theoretic assumptions: if is injective, then we can define a left inverse by defining it to be equal to whenever and equal to some fixed element otherwise. \n Example. Let be a split epimorphism in with right inverse . Then in particular is surjective and is injective. Furthermore, the statement that is the identity implies that is an embedding and that is a quotient map; in other words, is simultaneously a quotient space and a subspace of . \n Note that a split epimorphism in must in particular be a quotient map, so a generic epimorphism in cannot be split. In other words, the axiom of choice is false in ! This provides a great reason for caring about when the axiom of choice gets used in an argument; see, for example, this MO question for further discussion. Similarly, a split monomorphism must in particular be an embedding, so a generic monomorphism in cannot be split. \n A large class of examples of split epimorphisms come from deformation retracts . This is the origin of the term \u201cretraction\u201d for and \u201cretract\u201d for . \n Another large class of examples is the vector bundles , thought of via their projection maps . If is, for example, the tangent bundle of a smooth manifold , then a section of the projection map is precisely a vector field on . This is the origin of the term \u201csection\u201d for . Any vector bundle has a distinguished section, the zero section, given by sending each point to the zero vector in the vector space . \n A closely related class of examples are principal bundles , which admit a section if and only if they are trivializable. The existence of nontrivial principal bundles is an important topological fact; for example, isomorphism classes of principal -bundles on a topological space are in natural correspondence with classes in upon taking Chern classes , with trivial bundles corresponding to , so if the axiom of choice were true in then second cohomology would always be trivial. \n The fact that split epimorphisms are absolute can be used to show the nonexistence of certain maps in . For example, proving the Brouwer fixed point theorem amounts to proving the nonexistence of a retraction of the ball onto its boundary, the sphere , and this can be shown using the fact that such a retraction induces a retraction of the homology onto the homology . But the former is trivial and the latter is not, so the induced map on homology cannot be surjective (hence cannot be an epimorphism, hence cannot be a retraction). \n Example. Let be a split epimorphism in with right inverse . Then in particular is surjective and is injective, so this data determines a short exact sequence \n \n where is the kernel of . Because has a section , we know furthermore that is both a quotient group and a subgroup of , and in fact the existence of is equivalent to being a semidirect product . \n Many epimorphisms of groups, even abelian groups, are not split; the simplest example is the quotient map . Thus the axiom of choice is also false in . \n Similarly, many monomorphisms of groups, even abelian groups, are not split; the simplext example is the inclusion . (This example can be thought of as obtained from the above example by Pontrjagin duality .) \n Isomorphisms \n In familiar algebraic categories like and , a morphism which is both injective and surjective on underlying sets is already an isomorphism. Unfortunately, the more general statement that a morphism which is both a monomorphism and an epimorphism is an isomorphism is usually false. \n Example. Any morphism in a poset is a monomorphism and an epimorphism in which is not an isomorphism if . \n Example. Any localization of an integral domain is a monomorphism and an epimorphism in which is not an isomorphism if is nontrivial. \n Example. Any inclusion of a dense subspace into a space is a monomorphism and an epimorphism in the category of Hausdorff topological spaces which is not an isomorphism if the dense subspace is nontrivial. \n A salvage of this statement is the following. \n Proposition: The following conditions on a morphism are equivalent. \n \n \n is an isomorphism.\n is bijective on generalized points.\n is a monomorphism and a split epimorphism.\n \n \n Proof. : clear. \n : clear. \n : let be a monomorphism with a right inverse . Then , hence , hence (by left cancellability) . \n Dually, we have the following. \n Proposition: The following conditions on a morphism are equivalent. \n \n \n is an isomorphism.\n is bijective on generalized copoints.\n is a split monomorphism and an epimorphism.\n \n \n This is not an ideal salvage, however; it is not a strong enough statement to recover the fact that a morphism in which is both a monomorphism and an epimorphism is an isomorphism in the sense that we can\u2019t assume that a monomorphism or an epimorphism in is split."], "link": "http://qchu.wordpress.com/2012/10/01/split-epimorphisms-and-split-monomorphisms/", "bloglinks": {}, "links": {"http://mathoverflow.net/": 1, "http://feeds.wordpress.com/": 1, "http://ncatlab.org/": 8, "http://en.wikipedia.org/": 10}, "blogtitle": "Annoying Precision"}, {"content": ["Previously we discussed categories with finite biproducts, or semiadditive categories. Today, partially as a further warmup for the axioms defining an abelian category, we\u2019ll discuss monomorphisms and epimorphisms . \n Monomorphisms and epimorphisms are supposed to be a categorical generalization of the familiar notion of an injective resp. surjective structure-preserving map (such as an injective resp. surjective group homomorphism or an injective resp. surjective continuous function). This idea more or less works out for monomorphisms, but epimorphisms are somewhat infamous for behaving in unexpected ways, and even monomorphisms can behave unexpectedly sometimes. \n \n Monomorphisms \n Let be a category. A morphism is a monomorphism or monic if it is left-cancellative in the sense that, if is a parallel pair of morphisms with , then . \n (Note that, strictly speaking, it is not necessary to specify the source or target of any of these morphisms. The statement already only makes sense if have appropriately compatible sources and targets.) \n Monomorphisms are supposed to abstract the notion of an injective function to an arbitrary category. In the category of sets, a function is injective precisely if it is left-cancellative with respect to morphisms from a one-element set, so monomorphisms are injective, and conversely injective functions are monomorphisms by inspection. \n Left-cancellation is also a natural condition to study in a monoid, so thinking of categories as \u201cmonoids with many objects\u201d, monomorphisms can also be thought of as generalizing left-cancellable elements of monoids. In that spirit, some basic algebraic properties of monomorphisms, without proof: \n \n Identity morphisms are always monomorphisms.\n If are monomorphisms, so is .\n If is a monomorphism, so is .\n \n In a more categorical spirit driven by the Yoneda lemma, an equivalent way to restate left-cancellation is that a monomorphism is injective on generalized points in the sense that, for any object , the induced map \n \n is injective. This point of view is particularly attractive, for example, in the category of schemes. \n A functor is said to reflect a property of something in if, whenever has that property, also has that property. \n Proposition: Let be a faithful functor. Then reflects monomorphisms. \n Corollary: Let be a concrete category (a category equipped with a faithful \u201cunderlying set\u201d functor ). Then any morphism in which is injective on underlying sets is a monomorphism. \n Proof. Let be a monomorphism. If in , then because is a monomorphism, and then because is faithful. \n (Non)example. Consider the category of affine schemes equipped with the underlying set functor sending an affine scheme to its prime spectrum. This functor is not faithful, and so we should not expect a morphism which is injective on spectra to be a monomorphism in general. For example, any field extension is a bijection on spectra, but the corresponding map is not a monomorphism if, for example, has any nontrivial automorphisms that fix (so in particular if the extension is Galois). \n In most familiar concrete categories, it is true conversely that a monomorphism is injective on underlying sets. To prove this, first recall that a pullback or fiber product of two morphisms with common target is the limit of the diagram . More explicitly, it is the universal object together with projection maps such that . \n Example. The simplest way to explain the term \u201cfiber product\u201d is to examine what the fiber product looks like in . If are two functions, we should think of them as describing sets \u201cfibered over \u201c: that is, for every element we have fibers . Alternatively, can be thought of as assigning colors to the elements of , which then become colored sets. \n In any case, the fiber product is then \n \n together with projection maps to inherited from the Cartesian product. Either of these projection maps in turn gives rise to a map to , so one should think of the fiber product as also being a set fibered over , and the corresponding fiber over is precisely the Cartesian product of fibers . So the fiber product is literally the fiberwise product. \n Example. The origin of the term pullback, if I understand the history correctly, is in the theory of vector bundles . Here the pullback of describes the result of pulling back a vector bundle on some space along a map to obtain a bundle . Somewhat confusingly, the term \u201cpullback\u201d is also used to describe precomposition , and again if I understand the history correctly, this is because specifying the data of a vector bundle over is equivalent to specifying a homotopy class of maps from into a certain classifying space, and then pulling back vector bundles corresponds to precomposing such classifying maps. \n Some general comments. If a fiber product and an ordinary product both exist, then the former admits a natural map into the latter by the universal property of the product. This map is always a monomorphism, so the fiber product can naturally be thought of as a subobject of the ordinary product. The fiber product can also be thought of as the ordinary product in the slice category of objects over . \n If the fiber product exists, we say that the corresponding commutative square \n  \n is a pullback square or cartesian square. \n Proposition: A morphism is a monomorphism if and only if the pullback of and exists and is (together with the identity maps ). In other words, is a monomorphism if and only if the commutative square \n  \n is a pullback square. \n Remark. This condition says precisely that the kernel pair of is trivial. This result is therefore a natural generalization of both the familiar fact that a morphism of abelian groups is injective if and only if it has trivial kernel and of our previous discussion of internal equivalence relations . \n Corollary: Being a monomorphism is a \u201climit property\u201d: more precisely, any functor which preserves pullbacks (in particular any functor which preserves finite limits, in particular any functor which preserves all limits) preserves monomorphisms. \n Corollary: Let be a concrete category whose underlying set functor has a left adjoint. Then a morphism in is a monomorphism if and only if it is injective on underlying sets. \n Proof. The above diagram is a pullback square if and only if , together with projections to and given by the identity, satisfies the universal property of the pullback, which is the following: if is an object with two morphisms such that , then uniquely factor through a map to . But this occurs precisely when . Hence the universal property is satisfied if and only if is a monomorphism as desired. \n Example. , and many other familiar categories all have underlying set functors with left adjoints, so monomorphisms are precisely injective maps on underlying sets in all these categories. So on the one hand monomorphisms reproduce a familiar notion in these settings and on the other hand the definition of a monomorphism does not depend on a choice of embedding into . \n The following two (non)examples are from Borceux\u2019s Handbook of Categorical Algebra . \n Example. The category of divisible abelian groups has a forgetful functor to which does not have a left adjoint, which we can show by writing down a monomorphism which is not an injection on underlying sets. The claim is that the quotient map is a monomorphism: to see this, if are a parallel pair of morphisms such that , then for every we have \n \n for every positive integer by divisibility. Taking sufficiently large gives , hence , hence . \n Example. The category of pointed connected topological spaces has a forgetful functor to which does not have a left adjoint, which we can show by writing down a monomorphism which is not an injection on underlying sets. The claim is that any pointed covering map is a monomorphism. That is, if is a pair of maps such that , then . But this is precisely the statement of the unique lifting property of covering maps, since are precisely two lifts of the same map . (Sketch: the set of points at which is non-empty because it contains , open by taking a neighborhood of such a point in whose image in is evenly covered, and closed because the set of points at which is open by the same argument.) \n Epimorphisms \n Epimorphisms are the categorical dual to monomorphisms: an epimorphism is a monomorphism in the opposite category. Equivalently, a morphism is an epimorphism or epic if it is right-cancellable in the sense that if is a parallel pair of morphisms such that , then . \n I promise that this section is not just the categorical dual of the previous section. \n Epimorphisms are supposed to abstract the notion of a surjective function to an arbitrary category. In the category of sets, a function is surjective precisely if it is right-cancellative with respect to morphisms into a two-element set; more precisely, if is a map of sets, we can define two functions where identically and where on the image of and otherwise, and then . On the other hand, if and only if is surjective. Conversely, surjective functions are epimorphisms by inspection. \n It\u2019s very nice that in the notions of injective and surjective function turn out to be categorically dual. However, for other concrete categories this example is misleading; the argument above makes essential use of the fact that is a subobject classifier in , and many algebraic categories such as groups and rings don\u2019t have subobject classifiers. \n Before we discuss examples, let\u2019s dualize everything stated above about monomorphisms to obtain the corresponding statements for epimorphisms. The basic algebraic properties: \n \n Identity morphisms are always epimorphisms.\n If are epimorphisms, so is .\n If is an epimorphism, so is .\n \n The Yoneda interpretation: an epimorphism is a map which is injective on generalized copoints in the sense that, for any object , the induced map \n \n is injective. \n Proposition: Let be a faithful functor. Then reflects epimorphisms. \n Corollary: Let be a concrete category. Then any morphism in which is surjective on underlying sets is an epimorphism. \n (Non)example. We return to the category of affine schemes. If is a field of characteristic not equal to , the quotient map induces a bijection on spectra, but the corresponding map is not an epimorphism since, for example, it is not cancellable with respect to the identity map and the map sending to . \n The dual notion to pullback or fiber product is the pushout or amalgamated coproduct of two morphisms with common source. This is the colimit of the diagram . More explicitly, it is the universal object together with inclusion maps such that . \n Example. If are two continuous maps between topological spaces, think of them as describing inclusions of a subspace of both and . Then the amalgamated coproduct is the quotient space of the disjoint union obtained by identifying both copies of ; in other words, by identifying any pair of points of the form for . This process should be thought of as \u201cgluing together along .\u201d \n This is an important example for understanding nice topological spaces, which can often be thought of as obtained by gluing together simpler spaces. From this perspective, the Seifert-van Kampen theorem can be thought of as the statement that the fundamental group functor preserves certain pushouts (it sends them to the corresponding amalgamated free products of groups). \n Example. In , the pushout of two morphisms is precisely the tensor product over . From a geometric point of view, we should think of as the fiber product of the two schemes , which are fibered over . Even in the innocuous case , which corresponds to taking the tensor product of rings, this suggests that we should really think of commutative rings geometrically as spaces fibered over (roughly speaking, the primes) and their tensor product as the fiber product over . \n Dual to the corresponding statements for monomorphisms, if an amalgamated coproduct and an ordinary coproduct both exist, there is a natural map from the latter to the former. This map is always an epimorphism, but we should be careful not to be tempted into thinking of epimorphisms as quotient maps in general. The amalgamated coproduct can also be thought of as the ordinary coproduct in the coslice category of objects under . \n If the pushout exists, we say that the corresponding commutative square \n  \n is a pushout square or cocartesian square . \n Proposition: A morphism is an epimorphism if and only if the pushout of and exists and is (together with the identity maps ). In other words, is an epimorphism if and only if the commutative square \n  \n is a pushout square. \n Remark. This condition says dually that the cokernel pair of is trivial, which should be regarded as a natural generalization of the familiar fact that a morphism of abelian groups is surjective if and only if it has trivial cokernel. \n Corollary: Being an epimorphism is a \u201ccolimit property\u201d: more precisely, any functor which preserves pushouts (in particular any functor which preserves finite colimits, in particular any functor which preserves all colimits) preserves epimorphisms. \n Corollary: Let be a concrete category whose underlying set functor has a right adjoint. Then a morphism in is an epimorphism if and only if it is surjective on underlying sets. \n Now that we\u2019ve dualized everything, we can see what goes wrong with epimorphisms in familiar categories that doesn\u2019t go wrong with monomorphisms: in categories like , etc. the underlying set functor usually does not have a right adjoint because it usually does not preserve colimits, hence there is no reason to expect that all epimorphisms are surjective. \n Example. If is a commutative ring, then any localization is an epimorphism. More generally, by the above proposition, a morphism of commutative rings is an epimorphism if and only if the tensor product is naturally isomorphic to . For a thorough discussion about when this occurs, see this MO question . \n Example. The forgetful functor has a right adjoint sending a set to the indiscrete topology on that set, so epimorphisms in are precisely the surjective continuous maps. This can also be shown using the space with the indiscrete topology, mimicking the argument in . However, the category of Hausdorff topological spaces does not have this property. An epimorphism in this category is instead precisely a continuous map with dense image. \n To see this, in one direction, if a map has dense image, then any two maps such that agree on the image of , hence agree on its closure by Hausdorffness, hence . Conversely, if a map is an epimorphism, consider the quotient of by the closure of the image of , which is Hausdorff. admits two maps to this quotient, namely the quotient map and the constant map with value the point to which has been identified, and is right-cancellable with respect to these maps if and only if is all of . \n Edit (10/15/12): The above argument fails; see this math.SE question for the correct argument, which proceeds by computing the pushout. \n Example. The forgetful functor does not have a right adjoint because it does not preserve coproducts. Nevertheless, it is still true that the epimorphisms in are precisely the maps which are surjective on underlying sets. This is not obvious. For abelian groups this is clear because we can imitate the argument above and quotient by the image, but for groups the image of a group homomorphism may not be normal. \n The proof instead proceeds as follows. By the proposition, a morphism of groups is an epimorphism if and only if the amalgamated free product is naturally isomorphic to . This requires in particular that for all (where the first lies in the first copy of and the second lies in the second copy of ) and it is a nontrivial fact about amalgamated free products that this can only occur if lies in the image of (roughly speaking because the only relations imposed on the free product come from elements in the image of )."], "link": "http://qchu.wordpress.com/2012/09/29/monomorphisms-and-epimorphisms/", "bloglinks": {}, "links": {"http://feeds.wordpress.com/": 1, "http://ncatlab.org/": 2, "http://qchu.wordpress.com/": 6, "http://mathoverflow.net/": 1, "http://en.wikipedia.org/": 16, "http://books.google.com/": 1, "http://math.stackexchange.com/": 1}, "blogtitle": "Annoying Precision"}, {"content": ["There are, roughly speaking, two kinds of algebras that can be functorially constructed from a group . The kind which is covariantly functorial is some variation on the group algebra , which is the free -module on with multiplication inherited from the multiplication on . The kind which is contravariantly functorial is some variation on the algebra of functions with pointwise multiplication. \n When and when is respectively either a discrete group or a compact (Hausdorff) group, both of these algebras can naturally be endowed with the structure of a random algebra. In the case of , the corresponding state is a noncommutative refinement of Plancherel measure on the irreducible representations of , while in the case of , the corresponding state is by definition integration with respect to normalized Haar measure on . \n In general, some nontrivial analysis is necessary to show that the normalized Haar measure exists, but for compact groups equipped with a faithful finite-dimensional unitary representation it is possible to at least describe integration against Haar measure for a dense subalgebra of the algebra of class functions on using representation theory. This construction will in some sense explain why the category of (finite-dimensional continuous unitary) representations of behaves like an inner product space (with being analogous to the inner product); what it actually behaves like is a random algebra, namely the random algebra of class functions on . \n \n Discrete groups and Plancherel measure \n Let be a group and consider the -algebra with involution given by extending . When is finite, is finite-dimensional, so states on it are completely described by the results in the previous post. In general, we may construct states on from unitary representations of on inner product spaces by choosing unit vectors in them and considering pure states. If is a finite-dimensional unitary representation of , then the normalized character \n \n extends to a state on . The distribution of a random variable with respect to this state is given by the uniform distribution on its eigenvalues as an operator on , as can be seen by comparing moments. \n There is also a distinguished state given by setting \n \n for all which generalizes the normalized trace on when is finite. With respect to the corresponding inner product, the elements are orthonormal. The moments of a random variable with respect to this distinguished state are related to random walks on : for example, if , then counts the number of closed walks of length from the identity to itself on the Cayley graph of with generating set . \n When is given the normalized trace, how should we interpret the corresponding noncommutative probability space ? When is finite, we know that is canonically a finite product \n \n where runs through the irreducible representations of . The corresponding noncommutative probability space is therefore a disjoint union of the spaces associated to each of the matrix -algebras ; moreover, the system is in with probability given by the normalized trace of the idempotent corresponding to above. The trace of an idempotent is the dimension of its image, so we conclude that the system is in with probability \n . \n This defines Plancherel measure on the irreducible representations of . The corresponding commutative probability space can be constructed as follows. has a distinguished commutative subalgebra given by its center . When is finite, is canonically a finite product \n \n where is the number of irreducible representations of . Consequently, can be canonically identified with the set of irreducible representations of , and the normalized trace on descends to the state on describing Plancherel measure on the irreducible representations. \n It is plausible that similar results hold when is infinite, although to actually obtain them it would be sensible to complete to get more analytic structure. \n Compact groups and Haar measure \n Let be a compact Hausdorff group and consider the C*-algebra of continuous functions with pointwise conjugation and pointwise multiplication. By the Riesz representation theorem, a state on is precisely a Radon probability measure on . A distinguished such state is given by integration against normalized Haar measure : \n . \n By the uniqueness of Haar measure, this is the unique state which is invariant under translation by elements of . The corresponding probability space is of course just equipped with normalized Haar measure. \n has a natural closed subalgebra consisting of class functions (functions invariant under conjugation), which is therefore also a C*-algebra; its Gelfand spectrum can be identified with the space of conjugacy classes of , and the restriction of the state above to describes the pushforward of Haar measure to the space of conjugacy classes of . \n Integration against Haar measure on the conjugacy classes of is completely determined by the representation theory of in the following sense. Inside is a natural subspace spanned by the characters of finite-dimensional continuous unitary representations of . This subspace is closed under multiplication by taking tensor products and closed under conjugation by taking duals, so it is a -subalgebra. By the Peter-Weyl theorem , is in fact a dense -subalgebra, so is completely determined by its values on characters, but by Schur\u2019s lemma we know that the integral \n \n is the dimension of the invariant subspace of . In other words, is completely determined by its values on irreducible characters, and these are given by for the trivial representation and otherwise. In particular, the joint moments of a collection of are given by the dimension of the invariant subspace of their tensor product, so understanding these dimensions is essentially equivalent to knowing . \n Example. Let and let be the defining representation. The character is just the trace of regarded as a matrix, which completely determines its conjugacy class; consequently, already separates points, and to understand Haar measure on the conjugacy classes of it suffices to understand the moments of . But these are just the dimensions of the invariant subspaces of the tensor powers of . The explicit description \n \n of the tensor product of with the other irreducible representations of can be used to compute by a combinatorial argument that \n \n where are the Catalan numbers. Consequently, the moments of are the same as those of the Wigner semicircular distribution with , and this completely describes Haar measure on the conjugacy classes of . \n Example. Let and let be the defining representation. The character is again just the trace of regarded as a matrix, which completely determines its conjugacy class. This is less obvious than for and it is false for higher : it comes from the fact that the conjugacy class of an element of is determined by its eigenvalues, which are in turn determined by symmetric functions of the eigenvalues. But these are determined by the characters of the exterior powers of , and when the representation is trivial and is dual to , hence the character of one determines the other. \n As a consequence, to understand Haar measure on the conjugacy classes of it suffices to understand the joint moments of the real and imaginary part of . Computations of some of these moments using highest weight theory can be found at this MO question . \n A strategy for extending this algebraic description of Haar measure on the conjugacy classes to Haar measure on the group itself can be found in David Speyer\u2019s answer to this MO question . \n Haar measure and representation theory \n The category of finite-dimensional continuous unitary representations of a compact (Hausdorff) group bears a striking resemblance to an inner product space, mainly due to the properties of the Hom functor . The Hom functor is is bilinear in the sense that it respects finite direct sums in both arguments. We always have because of the identity morphism. The Hom functor is also contravariantly functorial in the first argument and covariantly functorial in the second, analogous to how the inner product (in the physicist\u2019s convention) is conjugate-linear in the first argument and linear in the second. Schur\u2019s lemma can be restated as saying that the irreducible representations of are an orthonormal basis with respect to . Finally, there is the formula \n \n showing that naturally extends to an inner product on the space of class functions on . \n Baez\u2019s Higher-Dimensional Algebra II: 2-Hilbert Spaces uses this observation as motivation to categorify the notion of a Hilbert space. In this post I would prefer instead to hint at a categorification of the notion of a random algebra. The first step is to observe that \n \n and to replace thinking directly about with thinking about tensor product, dual, and invariant subspace. These structures make seem less like an inner product space and more like a random algebra. The tensor product is multiplication, taking duals is the -operation, and taking invariant subspaces is the state. \n In fact, all of this structure descends to the Grothendieck group of , which is the universal way to assign every object in an element of an abelian group in such a way that direct sum is taken to multiplication. More explicitly, the Grothendieck group is the free abelian group on symbols standing for the irreducible (finite-dimensional continuous unitary) representations of . Tensor product naturally descends to a multiplication on the Grothendieck group, so in this context it is sometimes called the Grothendieck ring or representation ring of . Explicitly, if \n \n then \n . \n Dual naturally descends to a -involution given by extending , and taking invariant subspaces naturally descends to a map from the Grothendieck ring of to the Grothendieck ring of , which is just ; explicitly, is sent to if it is trivial and otherwise. \n Tensoring with (and extending the -operation appropriately), we get precisely the random algebra above. In other words, can be thought of as a categorified random algebra whose decategorification is precisely . This is a more precise version of the statement that understanding the representation theory of is equivalent to understanding Haar measure on the conjugacy classes of and suggests a general strategy for finding interesting random algebras, which is to decategorify interesting monoidal categories with duals , such as the category of representations of a Hopf algebra ."], "link": "http://qchu.wordpress.com/2012/09/24/noncommutative-probability-and-group-theory/", "bloglinks": {}, "links": {"http://arxiv.org/": 1, "http://mathoverflow.net/": 2, "http://feeds.wordpress.com/": 1, "http://qchu.wordpress.com/": 1, "http://en.wikipedia.org/": 7}, "blogtitle": "Annoying Precision"}, {"content": ["Previously we described all finite-dimensional random algebras with faithful states. In this post we will describe states on the infinite-dimensional -algebra . Along the way we will run into and connect some beautiful and classical mathematical objects. \n A special case of part of the following discussion can be found in an old post on the Catalan numbers . \n \n Positivity and Hankel determinants \n Consider the -algebra with involution given by extending ; in other words, the free complex -algebra on a self-adjoint element. A state is uniquely determined by the moments which are real since the are all self-adjoint and which satisfy . Positivity is equivalent to the condition that for any we have \n \n and this condition characterizes states on . That this condition actually characterizes Borel measures on the real line is the content of the solution to the Hamburger moment problem , although we will not use this fact. In discussing examples, we will make implicit use of the fact that various kinds of Borel measures on are uniquely determined by their moments thanks to results like Carleman\u2019s condition , but only in order to identify these measures from their moments. \n Note that by the universal property, if is any random algebra and any self-adjoint element, then there is a unique morphism of -algebras sending to , and pulling back the state on gives a state on . Consequently, everything we are about to say about states on places restrictions on states on any random algebra (more precisely, on moment sequences of self-adjoint elements of any random algebra). \n The states which are not faithful are straightforward to describe. \n Proposition: Let be a state on which is not faithful. If is a nonzero self-adjoint element of minimal degree such that , then is a finite sum of Dirac measures supported at the roots of , all of which are real. \n Proof. Note that \u201cself-adjoint\u201d here is equivalent to having real coefficients. We first show that the roots of are all real. Suppose by contradiction that has a complex root with . Then it is divisible by . Writing where is self-adjoint, we have \n . \n By positivity of , it follows that , and since , it follows that , which contradicts the assumption that has minimal degree. Hence all of the roots of are real. \n By the division algorithm, we can write any in the form where . By Cauchy-Schwarz we have , hence \n . \n Let be the real roots of . Since , by Lagrange interpolation we know that can be written \n \n where \n \n are the Lagrange interpolation polynomials, which do not depend on . Consequently, \n \n which is a finite sum of Dirac measures supported at the points as desired. \n The corresponding universal statement is the following: if is a self-adjoint element of any random algebra which has a minimal polynomial, then the state on restricted to is a finite sum of Dirac measures supported on the spectrum of (which is finite). \n As for the faithful states, we can say the following. Faithfulness is equivalent to the condition that for every the Hankel matrix \n \n with entries is positive-definite. This is because is the symmetric matrix describing the restriction of the inner product to the subspace of polynomials of degree less than . In particular, if is faithful, the Hankel determinants are positive. For example, is the variance . \n Proposition ( Sylvester\u2019s criterion ): is positive-definite if and only if for all . \n Corollary: A moment sequence determines a faithful state if and only if for all . \n Proof. We observed one direction above. In the other direction, we prove the contrapositive. Note that is always positive-definite. We proceed by induction. Assume that is positive-definite. By the spectral theorem, has an orthonormal basis of eigenvectors, which we may take to be self-adjoint elements of . Since , it follows that has an even number of eigenvectors with negative eigenvalues. Suppose by contradiction that it has at least one, hence at least two, such eigenvectors with negative eigenvalues . Then \n \n with strict inequality if either or is nonzero. On the other hand, there exists some choice of such that , from which it follows that is not positive-definite; contradiction. \n Hence has only positive eigenvalues, so is positive-definite. \n So we have reduced the problem of determining whether a moment sequence describes a state on to the problem of determining whether its Hankel determinants are non-negative. Unfortunately, it is not at all obvious how to compute Hankel determinants. We give without proof several evaluations of Hankel determinants below; the proofs will be subsumed in a more general result later in the post. \n Example. Consider the moment sequence . The corresponding Hankel matrices are the Hilbert matrices \n \n and the corresponding Hankel determinants are \n . \n The corresponding state on describes the uniform distribution on . \n Example. Consider the moment sequence , the Bell numbers . The corresponding Hankel determinants are \n . \n The corresponding state on describes the Poisson distribution with parameter . \n Example. Consider the moment sequence with odd terms and even terms \n . \n The corresponding Hankel determinants are again \n . \n The corresponding state on describes the Gaussian distribution with mean and variance . As a corollary, the Hankel determinants of a moment sequence do not uniquely determine it. \n Example. Consider the moment sequence . The corresponding Hankel determinants are \n . \n The corresponding state on describes the exponential distribution with mean . \n Example. Consider the moment sequence with odd terms and even terms , the Catalan numbers . The corresponding Hankel determinants are \n . \n The corresponding state on describes the Wigner semicircle distribution with radius . The semicircle distribution is important in free probability, where it takes on a role analogous to the Gaussian distribution in a noncommutative version of the central limit theorem. It also appears in number theory as the Sato-Tate distribution , where it comes from the distribution of traces of a random element of . \n Example. Consider the moment sequence . The corresponding Hankel determinants are again \n . \n The corresponding state on describes a random variable which is the square of a Wigner semicircularly distributed random variable. \n Non-example. This example occurred a few years ago at the Secret Blogging Seminar . Consider the moment sequence with odd terms and even terms \n . \n The third Hankel determinant is \n . \n Hence this moment sequence does not define a state (and consequently cannot describe a random variable). \n Orthogonal polynomials and Motzkin paths \n Faithful states on are closely related to the classical theory of orthogonal polynomials . The starting point is that is a faithful state on if and only if defines an inner product on . Applying the Gram-Schmidt process with a slightly different normalization to the basis , we obtain a sequence of monic self-adjoint polynomials of degree , uniquely determined by the moment sequence , such that \n \n whenever . (In addition, by faithfulness.) These are the orthogonal polynomials associated to (equivalently, to the moment sequence ). \n Example. For a state describing a Wigner semicircular distribution with radius , the corresponding polynomials are the Chebyshev polynomials of the second kind . \n Example. For a state describing a Gaussian distribution with mean and variance , the corresponding polynomials are the probabilist\u2019s Hermite polynomials . \n Example. For a state describing the uniform distribution on , the corresponding polynomials are the Legendre polynomials . \n The moments can be evaluated in terms of the orthogonal polynomials as follows. First, by construction is orthogonal to all polynomials of degree at most . Since is self-adjoint with respect to the inner product above, is orthogonal to all polynomials of degree at most . It follows that the polynomials are orthogonal to all polynomials of degree at most but have degree at most , hence lie in a -dimensional subspace of . Moreover, by orthogonality are linearly independent. Hence there exists a nontrivial linear dependence of the form \n \n where the coefficient of is determined by comparing leading coefficients. Thus the matrix of the linear operator given by multiplication by with respect to the basis is tridiagonal: it begins \n . \n Corollary: is the characteristic polynomial of the matrix \n . \n Proof. Multplication by has characteristic polynomial on , which has basis , and the above is the matrix by which acts in this basis. Alternately, this can be proven by induction on using the recurrence relation above. \n It will be convenient to think of the above matrix as the weighted adjacency matrix of a weighted graph with vertex set the non-negative integers and, for every , three edges: an edge to with weight , an edge to with weight , and an edge to with weight . \n  \n The power of this matrix describes the sums of weights of paths of length in this graph, and these weights describe the action of multiplication by with respect to the basis . The corresponding paths (disregarding weights) are Motzkin paths , and they are counted by the Motzkin numbers . \n In particular, is equal to the sum of the weights of all closed walks in from to itself of length ; this sum contains terms, one for each Motzkin path, and may be thought of as a weighted Motzkin number. The first few such sums are as follows: \n \n \n \n \n . \n Example. For the Wigner semicircular distribution with , we have for all . The above expression for moments then reduces to a sum over Motzkin paths which never stay at a given vertex, hence over Dyck paths, which are counted by the Catalan numbers. There are no paths of odd length, and a path of length has weight . This gives and as expected. \n The combinatorial description of moments in terms of Motzkin paths leads to the following beautiful continued fraction expansion. \n Theorem: We have an equality of formal power series \n . \n Proof. This is more difficult to formalize than to understand. Consider the weighted graph described above. Let be the graph obtained from by deleting the vertices (and all corresponding edges), and let be the set of all paths from to in . The combinatorial content of the above theorem is that a path in has a unique decomposition into a sequence of paths of the following two forms: \n \n A loop (weight , length ), or\n A step (weight , length ), a path in , and a step (weight , length ).\n \n Let denote the sum of all weights of all paths in , weighted in addition by . Then , and the above argument shows that \n . \n Applying this identity times verifies the desired equality , and taking gives the result by the universal property of formal power series. \n A converse result \n We saw above that we can associate to a faithful state on a sequence of monic polynomials of degree such that and \n \n for some pair of sequences of real numbers uniquely determined by . This pair of sequences in turn uniquely determines the sequence of polynomials , hence uniquely determines the state via the conditions and . \n Given an arbitrary such pair of real sequences, it is natural to ask when the corresponding linear functional determines a faithful state. \n Proposition: If , then , and . \n Proof. If , assume WLOG that . Write and apply the recurrence above to \n \n to write it in the basis . Then does not appear as a term. One way to see this is to use the combinatorial interpretation; the coefficients in count paths on the weighted graph starting at of length , and such a path cannot return to the origin. Hence by construction . \n If , then applying the recurrence to we see that the only contribution to the coefficient of comes from the unique path from to of length , which has weight as desired. \n Corollary ( Favard\u2019s theorem ): The linear functional on associated to a pair of real sequences as above is a faithful state if and only if for all . \n Proof. Since the are orthogonal, is faithful if and only if for all . \n This gives us a method to construct faithful states on without computing Hankel determinants: we can instead write down a sequence of real numbers and another sequence of positive real numbers, then compute the corresponding orthogonal polynomials. The corresponding moment sequence can be computed using Motzkin paths or using the continued fraction. Alternatively, given a moment sequence which we suspect determines a faithful state, we can write down what we suspect the corresponding orthogonal polynomials are and compute the sequences and to verify that for all . \n Example. Taking for all gives the Wigner semicircular distribution with . \n Computing Hankel determinants \n We now give the promised result which explains the Hankel determinants given without proof above. \n Theorem: With notation as above, we have \n \n Proof 1. First, observe that the change of basis matrix from the basis to the basis is by construction triangular with s on the diagonal. Such a change of basis changes the Hankel matrices by a congruence where has determinant , and consequently does not affect the value of the Hankel determinants. We can therefore compute the Hankel determinants with respect to the basis of orthogonal polynomials. By construction, the Hankel matrices with respect to are diagonal: \n . \n It follows that \n \n as desired. \n Proof 2. We will give a combinatorial proof using the Lindstr\u00f6m-Gessel-Viennot lemma . Consider the following locally finite directed acyclic graph : the vertices are the set of pairs with . The edges take the following forms: \n \n edges with weights ,\n edges with weight , and\n edges with weights .\n \n For a fixed positive integer , take the sources in the statement of the LGV lemma to be the vertices and take the sinks to be the vertices . Then the paths from to may be identified with closed walks of length on the weighted Motzkin graph (in the sense that there is a weight-preserving bijection between them), so the matrix appearing in the statement of the LGV lemma is precisely the Hankel matrix (with respect to the basis ). \n  \n On the other hand, there is a unique non-intersecting -path in : the source is taken to the sink by diagonal steps up and to the right, then diagonal steps down and to the right, and this is the unique possibility by induction on . This path has weight , from which the conclusion follows by the LGV lemma. \n Example. For the Wigner semicircular distribution with , we know that for all , which gives for all as desired."], "link": "http://qchu.wordpress.com/2012/09/18/moments-hankel-determinants-orthogonal-polynomials-motzkin-paths-and-continued-fractions/", "bloglinks": {}, "links": {"http://sbseminar.wordpress.com/": 1, "http://feeds.wordpress.com/": 1, "http://qchu.wordpress.com/": 5, "http://en.wikipedia.org/": 20}, "blogtitle": "Annoying Precision"}, {"content": ["The goal of today\u2019s post is to introduce and discuss semiadditive categories . Roughly speaking, these are categories in which one can add both objects and morphisms. Prominent examples include the abelian categories appearing in homological algebra , such as categories of sheaves and modules and categories of chain complexes. \n Semiadditive categories display some interesting categorical features, such as the prominence of pairs of universal properties and the surprising ways in which commutative monoid structures arise, which seem to be underemphasized in textbook treatments and which I would like to emphasize here. I would also like to emphasize that their most important properties are unrelated to the ability to subtract morphisms which is provided in an additive category . \n In this post, for convenience all categories will be locally small (that is, -enriched). \n \n This post can be thought of as motivated by the following question: what basic categorical properties 1) distinguish the category of abelian groups from categories like and 2) are inherited by related categories like categories of modules? \n Zero morphisms and zero objects \n A simple way to distinguish from categories like is the behavior of initial and terminal objects: they are different in , but in both are given by the trivial group. \n An object which is both initial and terminal in a category is a zero object , usually denoted . Equivalently, a category has zero objects if it has an initial object and a terminal object and moreover the unique map from the former to the latter is an isomorphism. A category with a zero object is sometimes said to be pointed . \n Zero objects are perhaps the simplest examples of objects satisfying two dual universal properties: one making them a limit and one making them a colimit. They also give perhaps the simplest example of a functor having a left and a right adjoint which agree (namely the unique functor from a category to the terminal category). \n Example. The category of monoids has a zero object given by the trivial monoid. \n Example. If is a category with a zero object , then remains a zero object in any full subcategory containing it (such as ). \n Example. Let be a dagger category . Then any initial object (resp. terminal object) is automatically a zero object by applying . \n Sub-example. In particular, the dagger category of sets and relations has an initial object given by the empty set, which therefore is also a zero object. \n Example. The definition of a zero object is self-dual, so the opposite category of a category with a zero object has the same zero object. \n Example. Let be a small category and be a category with a zero object . Then the functor category has a zero object given by the functor which is identically equal to . \n Example. Let be a category with a terminal object . Consider the coslice category , whose objects are morphisms in and whose morphisms are commutative triangles. Thinking of as a point, is the category of \u201cpointed -objects\u201d (hence the name pointed categories) and could also be denoted . The identity morphism is always an initial object in a coslice category regardless of the properties of ; because is also terminal, it is also a terminal object, so has a zero object. Dually, taking the slice category  where has an initial object produces a category with a zero object. \n Sub-examples. Taking we obtain the category of pointed sets . Note that forgetting the the distinguished point of a pointed set gives an equivalence between the category of pointed sets and the category of sets and partial functions, and note also that the category of monoids has a natural forgetful functor to the category of pointed sets. Taking we obtain the category of pointed topological spaces . This is an important category since, for example, the fundamental group is naturally defined as a functor on it. \n If is a category with a zero object , then between any two objects there is a canonical morphism obtained as the composition \n \n where the first arrow is the unique map and the second arrow is the unique map . The two universal properties of show that for any morphism and similarly for any morphism . We say that a category has zero morphisms if there exists a collection of morphisms having the above properties. \n Proposition: Zero morphisms are unique if they exist. \n Proof. Let be two collections of zero morphisms. Then for every triple of objects . \n This is analogous to the uniqueness of identities in a monoid. In the same way that we often refer to the zero element in different monoids with the same symbol , we will often refer to the zero morphism in different Hom-sets with the same symbol . \n Having zero morphisms is a special kind of enrichment: it is equivalent to being equipped with an enrichment over the category of pointed sets if the latter is equipped with the monoidal product given by its categorical product \n . \n Here denotes a set and a distinguished element . Enrichment over is special because it is unique if it exists, something which is quite false in general. In particular, is canonically enriched over itself; it is the primordial category with zero morphisms in the same way that is the primordial category. \n Example. Let be a monoid regarded as a one-object category. Then a zero morphism in this category is precisely an absorbing element in . The most familiar examples occur when is a ring under multiplication. Note that this example shows that a category can have zero morphisms without having a zero object. \n Example. Any -enriched category has zero morphisms; each Hom-set is an abelian group and the identity element of that group is a zero morphism. More abstractly, there is a natural product-preserving forgetful functor . \n The above discussion shows that a category with a zero object is canonically equipped with zero morphisms, which are precisely the morphisms factoring through ; equivalently, it is canonically enriched over . The converse claim, that categories with zero morphisms also have zero objects, is false as we saw above. However, we can say the following. \n It is possible to think of pointed sets as a particularly simple kind of algebraic structure described by a single unary operation sending every element of to the distinguished point of ; morphisms of pointed sets are then precisely functions preserving this operation. A category with a zero object is automatically -enriched, and then in a -enriched category a zero object is a zero object for \u201cpurely algebraic reasons\u201d in the following sense. In particular, unlike the definition of an initial object or terminal object in an arbitrary category, the following definition requires no quantifiers. \n Theorem (algebraic definition of zero objects): Let be a -enriched category. Then an object is a zero object if and only if (in other words, if and only if is a zero morphism). \n Proof. Follows from the definition of zero morphisms. \n Corollary: Let be a -enriched category. Any initial object in is a zero object. \n Proof. If is an initial object, then there is a unique morphism , so it must satisfy . \n This is perhaps the simplest example of a result of the following form: if an object in a certain kind of enriched category satisfies a universal property in one direction, it also satisfies a universal property in the other direction. \n Corollary: Let be categories with zero objects (in particular, -enriched). Then a functor is -enriched if and only if it preserves zero objects. \n Proof. : if is -enriched, then it preserves the algebraic definition of zero objects. \n : by hypothesis, is a zero object in . Consequently, the zero morphisms in are precisely the morphisms factoring through the zero object, and this condition is preserved by . \n Remark 1. Relative to an enriching category , an absolute colimit is a colimit preserved by any -enriched functor whatsoever. The first half of the second corollary then states that for -enriched categories, initial objects are absolute colimits. \n Remark 2. The hypothesis of the second half of the second corollary holds in particular if is either a left or a right adjoint, since in the first case it preserves colimits (hence preserves initial objects, hence preserves zero objects by the first corollary) and in the second case it preserves limits. \n We mention in closing that it is particularly easy to adjoin a zero object to a -enriched category which does not have one, since all of the additional morphisms one has to specify are unique (they are all zero morphisms) and so are their compositions with all other morphisms (they are all also zero morphisms). By contrast, if we want to adjoin an initial object to an ordinary category, the morphisms out of it and their compositions are uniquely determined, but the morphisms into it and their compositions are not. \n Interlude: diagonal and codiagonal \n Recently I learned the following from Mike Shulman on MO , and it\u2019s relevant to the next section but more general than it so should be discussed first. \n Let be a category with finite coproducts regarded as a monoidal category. Recall that a monoid object in is an object together with a multiplication map and an identity map satisfying associativity and identity. \n Theorem: Every object of has a unique monoid structure given by a canonical map , the codiagonal ; this monoid structure is commutative; and any morphism in is automatically a morphism of monoids. \n In other words, the forgetful functor is an equivalence of categories! \n Proof. Since is the initial object, the identity map is unique. By the universal property of the coproduct, to give a map is precisely to give a pair of maps , and compatibility with the identity implies that both of these maps must be . This defines the codiagonal map . Composing the codiagonal in all possible ways with itself gives maps which are all uniquely determined by the requirement that all of the corresponding maps are , so is commutative and associative, and we already know that it is compatible with the identity, so it defines a unique commutative monoid structure on . \n If is any morphism in , it clearly preserves identities; moreover, is the morphism whose components are both given by , and this is equal to , so preserves the codiagonal as desired. \n Dualizing, we obtain the following. \n Cotheorem: Let be a category with finite products regarded as a monoidal category. Every object of has a unique comonoid structure given by a canonical map , the diagonal ; this comonoid structure is cocommutative; and any morphism in is automatically a morphism of comonoids. \n In particular, in a category with finite products and coproducts, every object is canonically both a commutative monoid and a cocommutative comonoid (with respect to two different monoidal category structures). \n Example. Let , which has both finite coproducts and finite products. The diagonal in this case is just the map , which explains the name. The codiagonal is the map which sends to . \n The diagonal and codiagonal are maps which are in some sense waiting to become interesting after suitable functors are applied. For example, the free vector space functor is monoidal with respect to the product and tensor product, and consequently every free vector space is canonically a coalgebra . \n Example. Let , which has both finite coproducts and finite products. Moreover, the forgetful functor has both a left adjoint (taking a set to the discrete topology on that set) and a right adjoint (taking a set to the indiscrete topology on that set), so preserves both limits and colimits, hence we expect that the diagonal and codiagonal maps are the same as above, and indeed they are. \n Again, these maps are waiting to become more interesting after suitable functors are applied. For example, the functor sending a topological space to its singular homology groups over a field is monoidal with respect to the product and tensor product (of graded vector spaces) by the K\u00fcnneth theorem , and consequently the singular homology of is canonically a coalgebra. (The hypothesis that is a field is crucial; see this MO question for a discussion.) Similar considerations define the cup product on cohomology, which is induced from the diagonal. \n Example. Let , which has both finite coproducts and finite products. The diagonal in this case is just the set-theoretic diagonal (since the forgetful functor has a left adjoint and consequently preserves limits), and the codiagonal is multiplication of elements of regarded as a map , where is the free product. (Note that this is not multiplication regarded as a map ; in particular, we have not just proven that every monoid is commutative!) \n Example. Let be the category of commutative monoids. Everything is as above except that there is a natural identification between the coproduct and the product of commutative monoids, so that the codiagonal really is the multiplication map in the ordinary sense. This is relevant for the next section. \n Adding objects and adding morphisms \n A more general way in which categories like differ from categories like is in the behavior of products and coproducts. (The above section describes the special case of empty products and coproducts.) In , finite products and coproducts are nonisomorphic in general, but in both are given by the direct sum. \n The sense in which the direct sum of abelian groups is both a product and a coproduct should be made precise. In the case of zero objects there is always a unique morphism from an initial object to a terminal object and the only question is whether it is an isomorphism. In general, however, there does not exist a distinguished morphism from a coproduct to a product. In fact, in general there does not exist any such morphism. \n Example. Let be a poset regarded as a category. Then the coproduct of two objects is their sup and the product of two objects is their inf, so if these are distinct then the former is strictly greater than the latter. \n Since a product is equipped with projections and a coproduct is equipped with inclusions , we can write down two morphisms \n \n from the product to the coproduct, but even in neither of these is the isomorphism we want. \n One definition to try is the following. Say that a naive biproduct of two objects in a category is an object together with four morphisms such that is a product with respect to the first two morphisms and a coproduct with respect to the second two morphisms. Specifying a naive biproduct is equivalent to specifying a coproduct , a product , and an isomorphism between them. \n This definition has the enormous drawback that a naive biproduct does not have the characteristic property we expect of our universal objects: it is not unique, not even up to isomorphism (let alone unique isomorphism)! If there are at least two different isomorphisms between a coproduct and a product of , then using a different isomorphism will give a genuinely different naive biproduct (in the sense that the natural diagram one would want to write down involving both biproducts will not commute). Specifying objects with two universal properties is not as easy as it sounds, but we really want uniqueness up to unique isomorphism if there\u2019s any chance of, say, upgrading the biproduct to a bifunctor. \n If there is any hope to get a notion of object-which-is-both-a-coproduct-and-a-product which is actually unique up to unique isomorphism, then at a minimum we need to fix the four compositions \n . \n Ideally we should fix them functorially in both and . The first two are easy: based both on our experience with abelian groups and on functorial considerations, we want them to be and . Specifying the second two compositions canonically requires a functorial choice of a morphism and of a morphism . In the case of abelian groups both of these morphisms are just the zero morphism, which is certainly functorial. This has the intuitive meaning that are behaving \u201cindependently\u201d in the biproduct. \n Accordingly, we now formulate a better definition. A biproduct of two objects in a -enriched category is an object together with four morphisms as above which is a product and a coproduct and which also satisfies \n . \n The definition of a biproduct of a finite number of objects is similar, but if binary biproducts exist then finite biproducts can be obtained from them (provided that the empty biproduct, e.g. the zero object, exists). A -enriched category with all finite biproducts is a semiadditive category . \n Note that, by the remarks in the interlude, every object in a semiadditive category is canonically both a commutative monoid and a cocommutative comonoid with respect to biproduct. In fact, these two structures canonically make every object a bimonoid ; see the discussion at this nCafe post . \n Note also that the condition of having biproducts is a property of an ordinary unenriched category and not an extra kind of structure placed on : the question of whether has a zero object and hence zero morphisms is a property of as a category, and this then defines what a biproduct is and whether has them. \n Example. The category of commutative monoids is semiadditive. \n Example. The dagger category of sets and relations is semiadditive with biproduct given by disjoint union. \n Example. The definition of a biproduct is self-dual, so the opposite category of a semiadditive category is semiadditive. \n Example. Let be a ring. Then the category of left -modules is semiadditive. (This is inherited from in a sense we will make precise below.) \n Non-example. A category may have zero objects but also have two objects such that and are not isomorphic at all. Such a category cannot be semiadditive (indeed it does not even have naive biproducts). is a familiar example; less familiar examples include , etc. \n Theorem: The biproduct of two objects in a -enriched category is unique up to unique isomorphism. It defines a bifunctor which is naturally equivalent to both the product and coproduct bifunctors. \n Proof. A biproduct is in particular a naive biproduct, so it is obtained by specifying an isomorphism , and showing that biproducts are unique up to unique isomorphism is equivalent to showing that is unique on the nose. By the universal property of the product, specifying a map into the product is equivalent to specifying a pair of maps into , and by the universal property of the coproduct, specifying a map out of the coproduct is equivalent to specifying a pair of maps out of . Hence specifying a map is equivalent to specifying four maps \n . \n These four maps are in fact precisely , and , which have been fixed to equal respectively, and consequently is unique on the nose as desired. \n To prove that the biproduct defines a bifunctor (note that \u201cbi\u201d is being used in two different senses here) it suffices to show that as defined above actually extends to a natural isomorphism of functors. So let be a pair of morphisms in . Then finite product and finite coproduct define morphisms \n \n and we want to show that (we are referring to two different morphisms by the same name here). Both of these morphisms are defined by their components , and by the definition of these components are necessarily , so they are the same morphism and the conclusion follows. \n Essentially the same proof also shows that the biproduct of a finite number of objects is unique up to unique isomorphism. \n Theorem: Let be a small category and let be a semiadditive category. Then the functor category is semiadditive. \n Proof. We already know that has a zero object, hence zero morphisms. Since limits and colimits can be computed pointwise in functor categories, has finite coproducts and finite products because does, and the isomorphism between them necessary to obtain biproducts can also be defined pointwise. \n All of the examples of semiadditive categories we have given so far happen to be enriched over the category of commutative monoids (equipped with the tensor product); that is, their Hom-sets are all commutative monoids, and composition of morphisms is bilinear. This is not completely obvious for , but the union of two relations (as a subset of ) is another relation, and composition of relations respects union. \n In fact this is inevitable. \n Theorem: A semiadditive category is canonically enriched over . The identity in each commutative monoid is the zero morphism . \n Proof. Let be a pair of parallel morphisms. Consider the composition \n . \n If then the middle map factors through , and we have natural identifications which show that, tracing through all of the morphisms above, . Commutativity and associativity follow from the commutativity and associativity of and the cocommutativity and coassociativity of . So defines a commutative monoid operation on with identity . \n It remains to show that composition \n \n is bilinear. By dualizing, it suffices to show that for any . Writing down the composition \n \n we see that the composition is just the morphism whose components are , and writing down we get the same composition, so the conclusion follows. \n The converse is, as in the case of the relationship between zero objects and zero morphisms, false. For example, most one-object -enriched categories (that is, semirings , or rigs ) fail to have biproducts. However, just as zero objects in -enriched categories are zero objects for \u201cpurely algebraic reasons,\u201d the same is true for biproducts in -enriched categories; in particular, the following gives a remarkable definition of biproducts in -enriched categories which requires no quantifiers. \n Theorem (algebraic definition of biproducts): Let be a -enriched category and let be two objects in it. Suppose an object is equipped with two morphisms and two morphisms such that \n \n and such that \n . \n Then (together with these four morphisms) is a biproduct of . \n (That the converse is true can be seen by inspecting the components of to verify that it has the same components as .) \n Proof. We first show that the morphisms equip with the structure of a coproduct. Given a pair of maps , we want to show that they uniquely factor through a map such that . This map is necessarily unique since \n \n so it remains to show that actually works. But by assumption \n \n and similarly for . So (together with ) is a coproduct. The hypotheses are self-dual, so dualizing, we conclude that (together with ) is a product, hence a biproduct. \n Remark. We required five algebraic identities to hold among morphisms above; in fact either the two identities or the two identities are redundant in that the remaining two together with the fifth can prove them. \n Corollary: Let be semiadditive categories (in particular, -enriched). Then a functor is -enriched if and only if it preserves biproducts. \n A -enriched functor is also said to be additive . \n Proof. : the addition on morphisms is defined only in terms of identity morphisms and the biproduct, both of which are by assumption preserved by . \n : if preserves addition of morphisms, then it preserves the algebraic conditions characterizing a biproduct. \n Corollary: Let be a -enriched category. Any coproduct in is a biproduct. More precisely, we can canonically write down projections making a biproduct. \n Proof. Let be a coproduct with structure maps . Let be the morphism with components and let be the morphism with components . This is equivalent to requiring the first four identities in the algebraic definition of biproducts, so it suffices to verify the fifth identity \n . \n A morphism is determined by its components , and we compute that the components of the LHS are , which are the same as the components of the RHS. The conclusion follows. \n We conclude that in a -enriched category there is an algebraic characterization of finite coproducts and products, both of which must be biproducts, which implies that finite coproducts are absolute colimits for -enriched categories. \n Corollary: Let be a small -enriched category and let be a semiadditive category. Then the category of -enriched functors is also semiadditive. \n Proof. We know that has zero objects. To verify that it has biproducts, it suffices by the algebraic definition of biproducts to verify that the pointwise biproduct of two -enriched functors in the ordinary functor category is still -enriched. In other words, if are a parallel pair of morphisms in and are a pair of -enriched functors, then we want to verify that \n \n as morphisms . But this follows from the fact that are -enriched and from an examination of the components , etc. of the two morphisms above. \n Example. This subsumes our earlier result that if is a small category and is a semiadditive category, then is additive. Indeed, from any category we may construct a free -enriched category on whose Hom-monoids are given by the free commutative monoids on the Hom-sets of , and then -enriched functors from this category to are naturally identified with ordinary functors from to . \n Example. Let be a rig regarded as a one-object -enriched category and let . Then is the category of left - semimodules , so semimodule categories over rigs are semiadditive. Similarly, module categories over rings are semiadditive. \n A slight variant of the above proof gives the following. \n Corollary: Let be a small -enriched category and let be a semiadditive category. Then the category of -enriched functors is also semiadditive. \n Example. Let be the free category on a chain complex , which explicitly is the category whose objects are the integers and where , all other Homs consist only of zero morphisms, and . Then a -enriched functor , where is a -enriched functor, is precisely a chain complex in . The category of such functors is denoted by , and by the above is semiadditive if is. \n We mention in closing that, as for zero objects, it is particularly easy to adjoin biproducts to a -enriched category which does not have them, since all of the additional morphisms one has to specify are uniquely determined (by the two universal properties) as well as their compositions with all other morphisms (by bilinearity). \n Matrix multiplication \n Let be a finite collection of objects in a semiadditive category . A particularly nice feature of having finite biproducts is that \n \n can be explicitly described in terms of using matrices of morphisms in a way that directly generalizes the usual description of linear transformations using matrices (which corresponds to taking and the to all be the base field) as well as the use of block matrices, etc. Explicitly, the above commutative monoid can be described as a direct sum , or more suggestively as the matrix of commutative monoids \n \n and moreover the matrix description sends composition of morphisms to matrix multiplication (this follows by writing a morphism as the sum of its components and using the bilinearity of composition). This is particularly useful if is semisimple . \n Example. Let be the category of finite sets and relations. Every finite set is a biproduct of copies of the one-element set, and consequently a relation between two finite sets can be described by a matrix whose entries lie in the rig . This is precisely the rig of truth values with addition given by logical OR and multiplication given by logical AND. See also the nLab article on matrix mechanics . \n Example. The free category with biproducts on one object is the category whose morphisms are matrices with values in the non-negative integers . Morphisms in this category can be given an explicit combinatorial and visual description as collections of arrows between collections of dots, and working in this category appears to be a feasible combinatorial version of linear algebra. \n Example. Let be a -enriched category with exactly two objects such that there are no nonzero morphisms . Then is a rig , is a rig , and is an arbitrary -semibimodule . If we adjoin the biproduct to , then is the triangular matrix ring of matrices of the form \n \n where . Rings of this form are sometimes used as counterexamples in noncommutative ring theory as they often have different properties from their opposites; for example, a ring of this form is right Noetherian but not left Noetherian ."], "link": "http://qchu.wordpress.com/2012/09/14/a-meditation-on-semiadditive-categories/", "bloglinks": {}, "links": {"http://feeds.wordpress.com/": 1, "http://ncatlab.org/": 11, "http://mathoverflow.net/": 2, "http://en.wikipedia.org/": 17, "http://golem.utexas.edu/": 1, "http://planetmath.org/": 1}, "blogtitle": "Annoying Precision"}, {"content": ["The previous post on noncommutative probability was too long to leave much room for examples of random algebras. In this post we will describe all finite-dimensional random algebras with faithful states and all states on them. This will lead, in particular, to a derivation of the Born rule from statistical mechanics. We will then give a mathematical description of wave function collapse as taking a conditional expectation. \n \n Some preliminary remarks \n Previously we described how the tensor product of two random algebras could be endowed with the structure of a random algebra in a natural way. The direct product can also be endowed with such a structure, but to construct a state on it given states on it is necessary to fix a parameter and then define \n . \n Conversely, every state on is of this form for some , which is precisely the expected value of the idempotent . The corresponding noncommutative probability space is a disjoint union of the spaces , with the system finding itself in with probability and in with probability . \n More generally, the set of states on any complex -algebra are closed under convex linear combinations: that is, if are states, then so is \n \n where the are non-negative reals such that . This is what one might refer to as a classical superposition of states. Thus states form a convex cone . Suitably defined, we can also take infinite sums or integrals of families of states to get more states, but this won\u2019t be necessary in the finite-dimensional case. \n States and density operators \n Recall that we showed that a finite-dimensional random algebra with a faithful state is semisimple. Actually the proof shows slightly more than this: it shows that is a finite direct product, as a -algebra, of -algebras of the form where is a finite-dimensional Hilbert space, or more concretely of the form (equipped with the familiar conjugate transpose). In the commutative case, we get a finite direct product of copies of , which is familiar as the algebra of random variables on a finite set. In both the commutative and noncommutative cases states have a uniform description as follows. \n Any finite-dimensional algebra over a field comes equipped with a canonical linear functional , namely the trace \n \n where is the linear operator described by left multiplication by . This defines a canonical bilinear form , the trace form \n . \n Since , the trace form is symmetric. The radical consists of all such that is identically zero. Since , this condition is invariant under right multiplication, so is a right ideal of , and since , this condition is invariant under left multiplication, so is a two-sided ideal of . In fact it is a familiar such ideal. \n Theorem: , the Jacobson radical of . \n Proof. Recall that for a left Artinian ring, the Jacobson radical is the largest nilpotent (left or right) ideal, so it suffices to show that is the largest nilpotent right ideal. By passing to the algebraic closure and upper-triangularizing, it follows that if is nilpotent then . Consequently, if is a nilpotent right ideal then is nilpotent for all by assumption, hence for all , so . \n Corollary: is semisimple if and only if the trace form is nondegenerate. \n Specializing to the case that is a finite-dimensional complex -algebra, we can say more. \n Theorem: Let be a finite-dimensional complex -algebra. The following are equivalent: \n \n \n has a faithful state.\n is a finite direct product of matrix -algebras (those of the form with involution the conjugate transpose).\n has a faithful -representation on a Hilbert space.\n is a C*-algebra.\n is semisimple.\n The trace form on is nondegenerate.\n The normalized trace is a faithful state.\n \n \n (In particular, a finite-dimensional C*-algebra has a faithful state and a faithful -representation on a Hilbert space. This is a special case of the noncommutative Gelfand-Naimark theorem .) \n Proof. : proved previously; follows from the GNS construction. \n : any matrix -algebra comes by definition with a faithful -representation, and we can take finite direct sums of these. \n : any closed -subalgebra of a C*-algebra is a C*-algebra. \n : follows from the fact that C*-algebras are semiprimitive. \n : proven above. \n : faithfulness is equivalent to a modified version of the trace form being an inner product, the Hilbert-Schmidt inner product . The axioms are straightforward to verify with the possible exception of positive-definiteness, which we verify as follows. Since is invertible, the form is nondegenerate, and consequently for every there exists such that . But by Cauchy-Schwarz, it follows that \n \n so as desired. \n : by assumption the normalized trace is such a state. \n For satisfying any of the equivalent conditions above, by the nondegeneracy of the trace form a state can be uniquely expressed in the form \n \n for some , the density operator associated to the state. The axioms describing a state translate into properties satisfied by the density operator: \n \n -linearity is equivalent to the condition that , and by the uniqueness of this is equivalent to the condition that ( is self-adjoint).\n is equivalent to the condition that .\n is equivalent to the condition that .\n \n The last condition can be interpreted as follows. acts by left multiplication on , which is a Hilbert space equipped with the inner product , as a self-adjoint operator. Consequently, by the spectral theorem it admits an orthonormal basis with real eigenvalues, and the last condition is equivalent to the condition that all of the eigenvalues are non-negative, hence that is a positive element of . Furthermore, if denotes an orthonormal basis of eigenvectors of with eigenvalues , then we can write \n . \n The condition that is equivalent to the condition that . The corresponding state is \n \n (where the inner product above is the Hilbert-Schmidt inner product). This describes a mixed state , which is a classical superposition of the pure states . \n It is worth pointing out the special status of the density operator , whose corresponding state is the normalized trace itself. With respect to an arbitrary orthonormal basis , it may be written \n \n which gives the uniform distribution, and it is the unique density operator with this property. \n If desired, writing as a finite direct product of matrix -algebras gives a corresponding decomposition of a density operator as a finite direct product of density operators associated to each factor , so understanding density operators in general reduces to understanding density operators in matrix -algebras. \n A warning about pure states \n Strictly speaking, from the perspective of noncommutative probability the term \u201cpure state\u201d as we have been using it is a misnomer because being pure is not a property of a state on a complex -algebra . Rather, it is a property of a state together with a -representation of . If is a -representation, then a state is pure with respect to if \n \n for some , and this notion depends very strongly on the inner product space . Above we used with the Hilbert-Schmidt inner product; in the special case that it is more typical to use . \n Note that by the GNS construction, every state is pure with respect to some -representation. Apparently the use of this perspective has a name: it is referred to as the Church of the Larger Hilbert Space . \n Examples in finite probability \n Let be a finite-dimensional commutative semisimple complex -algebra. Then for some finite set , the sample space in the usual sense. A density operator on isin this case is precisely a function assigning to an element of the sample space its probability, and so we recover the familiar setting of probability on a finite sample space from the above. \n For a less familiar example, let be the complex -algebra describing a qubit . The space of states on can be explicitly described as follows. Any density operator must in particular be self-adjoint with trace , hence must have the form \n \n where is self-adjoint with trace . If the eigenvalues of are for some real , then the eigenvalues of are , hence is positive if and only if . \n If , then is the normalized trace. Otherwise, for fixed , has distinct eigenvalues, hence the -eigenspace uniquely determines the -eigenspace by orthogonality, so is uniquely specified by specifying a -dimensional subspace of , which may be identified with a point on a sphere (the Bloch sphere ) of radius . \n This interpretation continues to makes sense when , giving a parameterization of the states on by the points in a solid ball , which may be thought of as the Bloch sphere together with its interior. Note that the boundary of this ball consists of precisely the states such that , which is equivalent to having rank and hence equivalent to describing a pure state. \n Gibbs states and the Born rule \n Although mixed states are natural from the perspective of noncommutative probability, traditional introductions to quantum mechanics generally begin by talking about pure states. The probability distributions on measurements are then given by the Born rule , which may appear somewhat mysterious at first glance. In noncommutative probability, the Born rule is equivalent to the description of a state as \n \n where is an element of a complex -algebra , is a -representation of , and is a unit vector. When is finite-dimensional and admits a faithful state, we saw above that any state on may be described in terms of a density operator. Moreover, the density operators in, say, giving rise to states of the above form (with ) are precisely the density operators of rank . So the only mystery in the Born rule is why one should expect density operators to have rank , at least in some situations. \n One answer is the following. Let , and let be a self-adjoint element, to be thought of as a Hamiltonian. Using the Heisenberg picture , we can describe time evolution of states on with respect to the Hamiltonian as follows: after time , a state is sent to the state \n . \n Writing in terms of a density operator, we may equivalently describe by describing its density operator, which is given by \n \n using the cyclic symmetry of the trace. \n Suppose now that the state is a Gibbs state , meaning that it is invariant under time evolution. This is equivalent to the condition that commutes with for all . Differentiating with respect to , it follows that commutes with , and exponentiating it follows that this necessary condition is also sufficient. In other words, an equilibrium state is a state whose density operator lies in the centralizer \n \n of . \n Assume now that has distinct eigenvalues (that is, that there are no degenerate energy levels ). \n Proposition: Let be a linear operator on a finite-dimensional vector space over an algebraically closed field with distinct eigenvalues. Then . \n Proof. Since has distinct eigenvalues, breaks up into a direct sum of eigenspaces, and any operator commuting with necessarily preserves each eigenspace. Writing as a diagonal matrix, it follows that consists precisely of diagonal matrices, which are spanned by the powers of by standard arguments (for example the invertibility of Vandermonde determinants). \n (By passing to the algebraic closure we can remove the hypothesis that is algebraically closed, but this is not needed in what follows.) \n It follows that a Gibbs state has a density operator which is a polynomial in . That is, writing \n \n where the are energy eigenstates with energy eigenvalues , it follows that \n \n for some ; in other words, describes a state in which the probability that the system is measured to be in a particular energy eigenstate depends only on the value of the energy. However, in order for to be determined in a physically meaningful way from , it must be the case that adding an arbitrary scalar to does not affect ; equivalently, only differences between energies are physically meaningful, and consequently the ratios can only depend on the value of . Writing \n \n we observe that \n \n and so, under very mild continuity assumptions on (enough to rule out pathological solutions to the Cauchy functional equation , none of which are physically meaningful anyway), together with the constraint that is positive, it follows that must have the form \n \n for some real constant . Under the additional physical assumption that the system is more likely to be in a state with low energy than in a state with high energy, it follows that is non-negative. An equivalent way of stating the above identity is to write the density operator as \n \n where \n \n is the partition function (a normalization necessary for to have trace ). The corresponding Gibbs state is then \n . \n Explicitly, the probability that the system is in energy eigenstate is given by . \n In statistical mechanics, is interpreted as thermodynamic beta  where is temperature and is the Boltzmann constant . When is very large, is very small, and the system resembles a distribution which is uniform in energy eigenstates. \n When is very small, is very large, and the system is overwhelmingly likely to be in its lowest energy eigenstate; that is, if the energy eigenvalues are ordered , then the lowest energy eigenstate is times more likely to occur than the second-lowest energy eigenstate, and the other energy eigenstates are even less likely. In terms of the density operator, we can write \n \n for large ; in other words, as , approaches an operator of rank , and the corresponding Gibbs state approaches the pure (with respect to ) state described by the lowest energy eigenstate. \n Wave function collapse as conditioning \n The Born rule describes the probability distribution associated to a measurement of a quantum system, but another postulate of quantum mechanics, the collapse postulate , describes what happens to a measured quantum system afterwards. It asserts the following (simplified to the case of discrete spectrum): suppose a quantum system is in a pure state described by a unit vector in a Hilbert space . Suppose we measure an observable , given by a suitable self-adjoint operator . Then this observable takes value , some eigenvalue of , with probability , where is the projection onto the -eigenspace of . After this measurement, the state is replaced by its projection , normalized to have unit length. \n The physical meaning of the collapse postulate is contentious. Here I only want to record a mathematical observation, which is that it is mathematically equivalent to conditioning with respect to the observation that was measured to have value . \n Recall that if is a random algebra and a projection in with (an event that occurs with positive probability), then the conditional expectation (the expected value of conditional on the fact that the event happened) is given by \n . \n If has a -representation on a Hilbert space relative to which the state is the pure state for some , then \n \n (using the fact that and that is self-adjoint). In other words, the conditional expectation is precisely the pure state associated to the projection , normalized to have unit length."], "link": "http://qchu.wordpress.com/2012/09/09/finite-noncommutative-probability-the-born-rule-and-wave-function-collapse/", "bloglinks": {}, "links": {"http://feeds.wordpress.com/": 1, "http://qchu.wordpress.com/": 4, "http://en.wikipedia.org/": 20}, "blogtitle": "Annoying Precision"}, {"content": ["I\u2019ve uploaded current notes for the classes I\u2019m taking. I make no claim that these notes are complete or correct, but they may be useful to somebody. The notes for Dylan Thurston\u2019s class are particularly fun to take; I\u2019ve been drawing the pictures in Paper and I\u2019m generally very happy with the way they\u2019re turning out. \n Edit: It would probably be a good idea for me to briefly describe these classes. \n \n Homological Algebra (Wodzicki): An introduction to homological algebra aimed towards triangulated categories. Taking these notes is a good exercise in live-TeXing commutative diagrams.\n Curves on Surfaces (Thurston): An introduction to various interesting structures related to curves on surfaces. There are cluster algebra structures involved related to Teichm\u00fcller space , the Jones polynomial , and 3- and 4-manifold invariants, but the actual curves on the actual surfaces remain very visualizable. Taking these notes is a good exercise in drawing pictures like this (a curve on a thrice-punctured disc being acted on by an element of the mapping class group , which in this case is the braid group ):\n  \n Quantum Field Theory (Reshetikhin): An introduction to the mathematics of quantum field theory. The course website has more details. Taking this class is a strong incentive for me to learn differential, Riemannian, and symplectic geometry."], "link": "http://qchu.wordpress.com/2012/09/07/notes/", "bloglinks": {}, "links": {"http://qchu.wordpress.com/": 1, "http://feeds.wordpress.com/": 1, "http://itunes.apple.com/": 1, "http://math.berkeley.edu/": 5, "http://en.wikipedia.org/": 5}, "blogtitle": "Annoying Precision"}, {"content": ["The traditional mathematical axiomatization of probability, due to Kolmogorov, begins with a probability space and constructs random variables as certain functions . But start doing any probability and it becomes clear that the space is de-emphasized as much as possible; the real focus of probability theory is on the algebra of random variables. It would be nice to have an approach to probability theory that reflects this. \n Moreover, in the traditional approach, random variables necessarily commute. However, in quantum mechanics, the random variables are self-adjoint operators on a Hilbert space , and these do not commute in general. For the purposes of doing quantum probability , it is therefore also natural to look for an approach to probability theory that begins with an algebra, not necessarily commutative, which encompasses both the classical and quantum cases. \n Happily, noncommutative probability provides such an approach. Terence Tao\u2019s notes on free probability develop a version of noncommutative probability approach geared towards applications to random matrices, but today I would like to take a more leisurely and somewhat scattered route geared towards getting a general feel for what this formalism is capable of talking about. \n \n Classical and quantum probability \n (Below, if the reader chooses, she can restrict herself to finite sets and finite-dimensional Hilbert spaces so as to ignore measure-theoretic and analytic difficulties.) \n A classical probability space consists of the following data: \n \n A set , the sample space . Elements of this set describe possible states of some system.\n A -algebra  of subsets of , the events . Events describe properties of states. The pair is a measurable space \n A probability measure  on . This measures the probability that the system has some property.\n \n Example. Let be the set of possible outcomes of coin flips. Letting be the set of all subsets of , we can describe various events like \u201cno heads are flipped\u201d or \u201cat most three tails are flipped,\u201d and we can compute their probabilities using the fact that every point in has probability . \n Example. Let be a -dimensional symplectic manifold with symplectic form (e.g. the cotangent bundle of some other manifold). The exterior power of the symplectic form defines a volume form on which defines a Borel measure on called Liouville measure (locally just Lebesgue measure). Since Liouville measure is built from the symplectic form, it is preserved under all symplectomorphisms, and in particular under time evolution with respect to any Hamiltonian. \n A random variable is a measurable function (where is given the Borel -algebra generated by the Euclidean topology). In our coin-flipping example, \u201cnumber of heads flipped\u201d is a random variable. A random variable which only takes the values or encodes the same data as an event (more precisely, it is the indicator function of a unique event, which takes the value on and on its complement). More generally, we can construct events from random variables: for any Borel subset the preimage is an event (the event that lies in ), often written , and so we can consider its probability . (This is the pushforward measure .) \n Random variables should be thought of as real-valued observables of our system (and events, as random variables which take the value or , are the observables given by answers to yes-no questions). By repeatedly measuring an observable and averaging, we can obtain its expected value \n . \n (if this integral converges). If only takes the values , then reduces to the probability of the corresponding event. In general, if is a random variable and is a Borel subset of , then is the indicator function of , and . \n If we wanted to define a quantum probability space by analogous data, it would consist of the following (not standard): \n \n A Hilbert space , the space of states .\n An abstract -algebra of closed subspaces of , the events . The intersection of two subspaces is their set-theoretic intersection, the union is the closure of their span, and the complement is the orthogonal complement.\n A unit vector , the state vector .\n \n Example. Every classical probability space defines a quantum probability space as follows: is the Hilbert space of (equivalence classes of) square-integrable functions under the inner product \n , \n consists of the closed subspaces of functions which are (a.e.) equal to zero except on a given event , and is the function which is identically equal to . \n Example. The quantum probability space describing a qubit comes from applying the above construction to a bit; thus is a -dimensional Hilbert space with orthonormal basis , consists of four subspaces , and is the state of the qubit. \n A quantum probability space does not have points in the classical sense, but we can still talk about the probability of an event : if denotes the projection onto , then it is given by \n \n and writing as the sum of its components parallel and orthogonal to we see that this is the square of the absolute value of the component of parallel to . This is a simple form of the Born rule , and it describes the probability that , when measured to determine whether or not it lies in , will in fact lie in . Applied to a qubit, we conclude that a qubit described by , when measured, takes the value with probability and the value with probability . \n Note that if is the entire Hilbert space then the condition that the corresponding probability is is precisely the condition that is a unit vector. Note also that the probability assigned by to an event does not change if is multiplied by a unit complex number; for this reason, state vectors are really points in the projective space over . Thus the possible states of a qubit are parameterized by the Riemann sphere (called in this context the Bloch sphere ). \n A (real-valued) quantum random variable (probably not standard) is a self-adjoint operator on (possibly unbounded and/or densely defined in general). The values taken by are precisely its spectral values (the points in its spectrum ). This specializes even to the classical case: the values for which a random variable has the property that fails to be invertible are precisely its values (up to the subtlety that we can ignore the behavior of on a set of measure zero, but in practice we cannot meaningfully evaluate random variables at points anyway). In particular, for bounded, takes only the values if and only if it is idempotent by Gelfand-Naimark, hence if and only if it is a projection; thus as in the classical case, random variables generalize events. \n The expected value of a quantum random variable is \n \n (when lies in the domain of ). If happens to have a countable orthonormal basis of eigenvectors with eigenvalues , then writing we compute that \n \n so this really is the expected value of if we think of it classically as a random variable taking the value with probability . \n As in the classical case, we can make sense of probabilities such as where is a Borel subset of , but this requires more work. If has a countable orthonormal basis this is straightforward; in general, we need the Borel functional calculus in order to define as an operator so that we can compute (note that we do not need to be a projection whose image lies in to compute this expectation, although this would be the appropriate analogue of the random variable being measurable). Roughly speaking we ought to be able to start from the continuous functional calculus and approximate the indicator function of by continuous functions, then show that the corresponding limit exists as a self-adjoint operator. \n Unlike the classical case, the expected value can be computed independently of any measurability hypotheses on ; in particular, the probability of a particular event occurring (that is, the expected value of an arbitrary projection) is automatically well-defined. \n Noncommutative probability \n The classical and quantum cases above have several features in common. In both cases we saw that, although we started with a description of events and their probabilities and moved on to a description of random variables and their expected values, we could recover events through their indicator functions as the idempotent random variables and recover probabilities of events as expected values of indicator functions. This suggests that we might fruitfully approach probability in general using algebras of random variables and the expectation. \n If the algebra is commutative, we might hope to recover an underlying probability space, but a random-variables-first approach will allow us to work independently of a particular representation of a family of random variables as an algebra of functions on a probability space. If the algebra is noncommutative, we might hope to recover a Hilbert space on which it acts, but again, a random-variables-first approach will allow us to work independently of a particular representation as operators on a Hilbert space. We can also think of the algebra as the algebra of functions on a noncommutative space in the spirit of noncommutative geometry . Although noncommutative spaces don\u2019t have a good notion of point, quantum probability spaces suggest that they have a good notion of measure (which we can think of as a \u201csmeared-out\u201d point, the Dirac measures corresponding to ordinary points). \n The following definition is morally due to von Neumann and Segal. A random algebra (not standard) is a complex -algebra together with a -linear functional such that \n . \n Such a functional is called a state on (as it describes the state of some probabilistic system by describing the expected value of observables). The (real-valued) random variables in are its self-adjoint elements (and an event is a projection; that is, a self-adjoint idempotent). \n A morphism of random algebras is a morphism of complex -algebras such that . This defines the category of random algebras, and the category of noncommutative probability spaces is . (This is probably the wrong choice of morphisms, but we\u2019ll ignore that for now.) \n Example. From a classical probability space we obtain a random algebra by letting be the von Neumann algebra of essentially bounded measurable functions under conjugation and letting be the integral. \n Example. From a quantum probability space we obtain a random algebra by letting be the span of the space of self-adjoint operators such that for all Borel subsets and letting be the functional . \n (Because we have not developed the Borel functional calculus, it will be cleaner just to work with an arbitrary -algebra of bounded operators from which can but need not be derived. We can do the same thing in the classical case by starting with a collection of functions and taking the preimages under all of them of the Borel subsets of to define a -algebra on .) \n The above examples require some analysis to define in full generality. However, the reason we do not require any analytic hypotheses on is to have a formalism flexible enough to discuss more algebraic examples such as the following. \n Example. Let be a group. The group algebra is a -algebra in the usual way (with involution extending , so that every element of is unitary). There is a distinguished state given by and for every non-identity . \n The axioms we have chosen require some explanation. Working in a complex -algebra is both convenient and has clear ties to quantum mechanics, but I do not have a good explanation of this axiom from first principles. The condition that is -linear reflects linearity of expectation, which holds both in the classical and quantum cases, and the fact that we want the expected value of a self-adjoint element to be real. The condition that ( positivity ) reflects the fact that we want probabilities to be non-negative in the following sense. \n In any complex -algebra , we may define a positive (really non-negative) element to be an element of the form . A positive element is in particular self-adjoint. In the case of measurable functions on a probability space, the positive elements are precisely the elements which are (a.e.) non-negative, and in the case of operators on a Hilbert space, the positive elements are precisely the self-adjoint elements which have non-negative spectrum ( by Gelfand representation this is subtle; see the comments below). Hence positivity is a natural analogue in the algebraic setting of the condition that probabilities are non-negative. \n Finally, the condition that reflects the fact that we want the total probability to be . \n The semi-inner product \n The state allows us to define a bilinear map on any random algebra which satisfies all of the axioms of an inner product except that it is not necessarily positive-definite, but only satisfies the weaker axiom that . We call such a gadget a semi-inner product (since it is positive-semidefinite ). \n As for classical random variables we can define the covariance \n \n of two elements, and positive-semidefiniteness implies that the variance is non-negative, hence that . More generally, the proof of the Cauchy-Schwarz inequality goes through without modification, and we conclude that \n . \n This is already enough for us to prove the following general version of Heisenberg\u2019s uncertainty principle. \n Theorem ( Robertson uncertainty ) : Let be self-adjoint elements of a random algebra . Then \n . \n Proof. Since both sides are invariant under translation of either or by a nonzero constant, we may assume without loss of generality that have mean zero (that is, that ). This gives \n \n by Cauchy-Schwarz. We can write as the sum of its real and imaginary parts \n \n and computing using the above decomposition gives \n . \n where and . The conclusion follows. \n Interpreting Robertson uncertainty will be easier once we do a little more work. By Cauchy-Schwarz, if an element satisfies then in fact it satisfies for all (and the converse is clear). In the classical picture, a function satisfying either of these conditions is equal to zero almost everywhere, which motivates the following definition. An element of a random algebra is null or zero almost surely (abbreviated a.s.) if for all , which as we have seen is equivalent to . The null elements form a subspace of . Two elements are equal almost surely if , hence equality a.s. is equivalent to equality in the quotient . \n An element has variance zero if and only if it is constant almost surely. Robertson uncertainty then says that if two self-adjoint elements have the property that their commutator has nonzero expectation, then neither of them can be constant almost surely in a strong sense: the product of their variances is bounded below by a positive constant, so as one increases, the other must decrease. In other words, not only are they uncertain, but a state in which is less uncertain is a state in which is more uncertain. \n The standard application of Robertson uncertainty is to the case that are the position and momentum operators respectively acting on a quantum particle on . This application has the following purely mathematical interpretation: a function in and its Fourier transform cannot simultaneously be too localized. \n Independence \n A fundamental notion in classical probability theory is the notion of independence . It can be generalized to random algebras as follows: two -subalgebras of a random algebra are independent if \n \n for all . \n Example. Let be the random algebra associated to a classical probability space and let be the subalgebras of functions which are measurable with respect to two -subalgebras of . Then are independent in the above sense if and only if are independent in the sense that \n \n where (by the monotone class theorem). Note that this condition is equivalent to . \n Example. Let be two random algebras with expectations . Their tensor product acquires a natural -algebra structure given by on pure tensors (it is the universal -algebra admitting morphisms from whose images commute), and moreover we can define on it a state given by \n \n on pure tensors. Conversely, any state on such that and are independent is of this form. This is a noncommutative generalization of product measure; when come from classical probability spaces , a suitable completion of is the corresponding algebra of functions on the product , and the state above comes from integration against the corresponding product measure. \n Example. is independent of itself (in ) if and only if the state is actually a homomorphism of -algebras. Thinking of the case that is a C*-algebra in particular, the corresponding states can be thought of as Dirac measures supported at points of . In the noncommutative case, may admit no homomorphisms to (for example if contains the Weyl algebra), hence no Dirac measures, an expression of the general intuition that noncommutative spaces are \u201csmeared out\u201d and not easily expressible in terms of points. \n Independence is a formalization of the intuitive idea that knowing the values of the random variables in doesn\u2019t allow you to deduce anything about the values of the random variables in and vice versa. One indication of how this works in the setting of random algebras is as follows: if is a projection with (that is, an event that occurs with positive probability) we can define a conditional expectation \n . \n (The first factor of is necessary in the noncommutative case to ensure that the result is still a state.) This represents the expected value of given that the event occurred. If are independent, it follows that ; in other words, knowing that occurred has no effect on the expected value of any of the elements of . \n Independence is a very strong condition to impose if the subalgebras do not commute. For example, it implies that for all , which is the only condition under which Robertson uncertainty cannot relate the variances of . In the particular case of the position and momentum operators, is a nonzero scalar, hence always has nonzero expectation; it follows that position and momentum cannot be made independent! (By contrast, in the classical setting any pair of random variables is independent with respect to a Dirac measure.) \n In the noncommutative setting, a different notion of independence, free independence (replacing the tensor product with the free product), becomes more natural and useful. We will not discuss this issue further, but see Terence Tao\u2019s notes linked above. \n The Gelfand-Naimark-Segal construction \n If is any inner product space, any -algebra of linear operators on , and is any unit vector, then is a concrete random algebra with expectation . This subsumes the examples coming from both classical and quantum probability spaces. The goal of this section is to determine to what extent we can prove a Cayley\u2019s theorem for random algebras to the effect that random algebras are concrete. \n The above suggests the following definition. If is a complex -algebra, then a -representation of is a homomorphism from to the endomorphisms of an inner product space such that \n \n for all . (Note that if is not a Hilbert space then is not necessarily a -algebra because adjoints may not exist in general.) A Hilbert -representation is a -representation on a Hilbert space. \n The semi-inner product on a random algebra descends to the quotient space , where it is becomes an inner product because we have quotiented by the elements of norm zero. Moreover, since \n \n it follows that is a left ideal, so the quotient map is a quotient of left -modules; consequently, acts on by linear operators. Since \n \n it follows that defines a -representation of . The procedure we have outlined is essentially the Gelfand-Naimark-Segal (GNS) construction : we associate to any state on a -algebra a corresponding -representation such that the state can be recovered from the representation as \n \n where . This may be regarded as a weak Cayley\u2019s theorem: unfortunately, this -representation is not faithful in general. To get a stronger statement about random algebras, we will now assume another condition, namely that the if , then (the state is faithful ). \n The faithfulness axiom is equivalent to requiring and also equivalent to requiring that is an inner product space (rather than a semi-inner product space). It implies, but is stronger than, the assumption that the action of on is faithful. The remarks about the state above then prove the following. \n \u201cCayley\u2019s theorem for random algebras\u201d: A random algebra with a faithful state is concrete. \n This is still not a true analog of Cayley\u2019s theorem because the converse is false: the state of a concrete random algebra need not be faithful. It is faithful if and only if for all . \n From here we will assume, in addition to faithfulness, another condition, namely that for every there exists a constant such that ( boundedness ). Boundedness is equivalent to requiring that acts on itself by bounded linear operators. This action therefore uniquely extends to the completion of with respect to its inner product, which we\u2019ll denote by , and consequently it follows that in this case admits a Hilbert -representation . The closure of the image of in is a C*-algebra of bounded linear operators on , and moreover since where , the expectation uniquely extends to . \n This motivates the following definition: a random C*-algebra is a random algebra which is also a C*-algebra. The above discussion proves the following. \n Theorem: Let be a random algebra with a faithful state satisfying boundedness. Then canonically embeds as a dense -subalgebra of a random C*-algebra equipped with a Hilbert -representation via the GNS construction; moreover, there is a canonical vector such that for all . \n This is a much stronger conclusion than the conclusion that is concrete, since it allows us to use facts from the theory of C*-algebras. \n Corollary: Let be a commutative random algebra with a faithful state satisfying boundedness. Then canonically embeds as a dense -subalgebra of the algebra of continuous functions on a compact Hausdorff space . \n Proof. The closure of a commutative -subalgebra of is also commutative, since commutativity is a continuous condition. The conclusion then follows from Gelfand-Naimark. \n Corollary (\u201cMaschke\u2019s theorem\u201d): Let be a finite-dimensional random algebra with a faithful state. Then is semisimple. \n Proof. A finite-dimensional random algebra automatically satisfies boundedness. The GNS construction equips with a faithful -representation, namely itself. Let be a submodule of . Then for every , \n \n so is also a submodule of . So every submodule of is a direct summand; consequently, is semisimple. \n Note that we really do recover Maschke\u2019s theorem for complex representations of finite groups as a corollary, since is a finite-dimensional random algebra with a faithful state. \n Moments \n The axioms for a random algebra may not seem strong enough to capture random variables. For example, it does not seem possible to directly access probabilities like . However, our axioms are enough to define the moments \n \n of a random variable, and under suitable hypotheses (discussed under the general heading of the moment problem ) it is possible to recover a random variable in the classical sense from its moments. We prove a result of this type for random C*-algebras. \n Proposition: Any state on a C*-algebra has norm (and in particular is continuous). \n Proof. By examining real and imaginary parts, it suffices to show that a self-adjoint element of norm maps to an element of norm at most . Since has non-negative spectrum, by the continuous functional calculus it has a square root, hence is positive, so \n . \n Similarly, has non-negative spectrum, so by the continuous functional calculus it has a square root, hence is positive, so \n . \n We conclude that , with equality if . \n In fact a much stronger statement is true due to the following corollary of the Riesz-Markov theorem , which we will not prove; see Terence Tao\u2019s notes . \n Theorem: Let be a compact Hausdorff space and be a positive linear functional. Then there is a unique Radon measure on such that \n \n for all (and conversely any Radon measure defines a positive linear functional on ). \n It follows by Gelfand-Naimark that specifying a commutative random C*-algebra is equivalent to specifying a compact Hausdorff space and a Radon measure on it of total measure . \n Corollary: Let be a random C*-algebra. If is normal, then there is a unique Radon measure on such that \n \n for all continuous functions (where is defined using the continuous functional calculus). \n Proof. Since is dense in by construction, a morphism is uniquely determined by what it does to , hence , regarded as a function , is injective. Since it is a continuous map between compact Hausdorff spaces, it is also an embedding, so we may regard as canonically embedded into . (This embedding is actually a homeomorphism but we do not need this.) By Tietze extension , any continuous function extends to a continuous function , so the continuous functions given by applying the continuous functional calculus to include all continuous functions , and we reduce to the previous result. \n Corollary: With the same hypotheses as above, the Radon measure above is uniquely determined by the values \n \n where is a polynomial in and . Consequently, is uniquely determined by the -moments . If is self-adjoint, is uniquely determined by the values \n \n where is a polynomial in one variable. Equivalently, is uniquely determined by the moments . \n Proof. is a compact subset of , so by Stone-Weierstrass the polynomial functions in and are uniformly dense in the space of continuous functions . Now recall that the continuous functional calculus and both preserve uniform limits. If is self-adjoint, is real, so we only need to take polynomial functions in . \n The proofs above generalize essentially unchanged to the following. \n Corollary: Let be commuting normal elements of a random C*-algebra . Then there exists a unique Radon measure on such that \n \n for all continuous functions . Furthermore, is uniquely determined by the joint -moments \n \n of the . If the are self-adjoint, is uniquely determined by the joint moments of the . \n The hypothesis that the commute is crucial in the following sense. We restrict to the self-adjoint case for simplicity. \n Proposition: Let be self-adjoint elements of a random C*-algebra with faithful state such that there exists a measure on a measure space and two measurable functions satisfying \n \n for all . Then . \n Proof. If are self-adjoint then so is . The hypothesis above implies that , but since is self-adjoint is positive, hence by faithfulness . \n This result may be interpreted as saying that two noncommuting random variables do not in general have a reasonable notion of joint distribution. \n Some closing remarks about quantumness \n Classical mechanics is in principle deterministic: if the initial state of a system is known deterministically, then classical mechanics can in principle determine all future states. The predictions of quantum mechanics are, however, probabilistic: all that can be determined is a probability distribution on possible outcomes of a given experiment. \n The two can be made to seem more similar if classical mechanics is generalized by allowing the state of the system to be probabilistic in the classical sense. Then classical and quantum mechanics can both be subsumed under the heading of random algebras, where in the classical case we do not keep track of the position and momentum of a particle but a probability distribution over all possible positions and momenta. What distinguishes the classical from the quantum cases is the noncommutativity of the random algebras in the latter case, and in particular the fact that the random algebras occurring in quantum mechanics generally do not admit any homomorphisms , hence admit no Dirac measures, so we are forced to always work probabilistically. \n The formal similarity between classical and quantum mechanics described here only applies to states and observables; to get time evolution back into the picture we should endow our random algebras with Poisson brackets, giving us random Poisson algebras , and Hamiltonians\u2026"], "link": "http://qchu.wordpress.com/2012/08/18/noncommutative-probability/", "bloglinks": {}, "links": {"http://feeds.wordpress.com/": 1, "http://en.wikipedia.org/": 30, "http://terrytao.wordpress.com/": 2}, "blogtitle": "Annoying Precision"}, {"content": ["For the last few weeks I\u2019ve been working as a counselor at the PROMYS program. The program runs, among other things, a course in abstract algebra, which was a good opportunity for me to get annoyed at the way people normally introduce normal subgroups, which is via the following unmotivated \n Definition: A subgroup of a group is normal if for all . \n It is then proven that normal subgroups are precisely the kernels of surjective group homomorphisms . In other words, they are precisely the subgroups you can quotient by and get another group. This strikes me as backwards. The motivation to construct quotient groups should come first. \n Today I\u2019d like to present an alternate conceptual route to this definition starting from equivalence relations and quotients. This route also leads to ideals in rings and, among other things, highlights the special role of the existence of inverses in the theory of groups and rings (in the latter I mean additive inverses). The categorical setting for this discussion is the notion of a kernel pair and of an internal equivalence relation in a category, but for the sake of accessibility we will not use this language explicitly. \n \n Equivalence relations and quotients of sets \n Let be a set and let be a function. We can think of as capturing some property of the objects of with values in . If is not injective, then doesn\u2019t completely capture all properties of elements of , but it does capture something. What exactly does it capture? \n Consider the relation . This relation inherits the following properties from the properties of ordinary equality: \n \n reflexivity: ,\n transitivity: ,\n symmetry: .\n \n A relation on a set with these properties is an equivalence relation , and the above axioms are in fact enough to describe precisely the relations we can get in this way. To see this, note that an equivalence relation on a set partitions it into disjoint subsets, the equivalence classes , which consist of maximal collections of elements which are equivalent to each other. We may write the set of equivalence classes as , and then there is a canonical surjective function \n \n assigning an element of its equivalence class. Moreover, the procedure above which constructs an equivalence relation from a function outputs here. Thus talking about surjective functions out of (or quotient sets of ), up to a suitable notion of isomorphism, is equivalent to talking about equivalence relations on . \n Equivalence relations and quotients of groups \n Let be a group and let be a group homomorphism. As before, the relation is an equivalence relation on . However, because is also a group homomorphism, if and then . This gives an additional axiom: \n \n compatibility with multiplication: if and then .\n \n This defines, in the terminology of universal algebra, a congruence relation on groups. Note that compatibility with multiplication, in the presence of the other axioms defining an equivalence relation, is equivalent to the condition that the equivalence relation, as a subset \n \n of , is a subgroup. \n Compatibility with multiplication is precisely the condition needed for multiplication in to be well-defined on the equivalence classes , so given a congruence relation on a group we can recover a quotient map which is a group homomorphism. However, due to inverses we can say more. Compatibility with multiplication shows that \n . \n In other words, a congruence relation is completely determined by which elements are congruent to the identity; call these elements . (The corresponding relation might be called congruence by analogy with the case of .) Then: \n \n having an identity is equivalent to being reflexive,\n being closed under multiplication is equivalent to being transitive, and\n being closed under inverses is equivalent to being symmetric.\n \n In other words, is an equivalence relation if and only if is a subgroup. This is fairly special to groups; it highlights a close relation between groups, group actions, and equivalence relations which motivates the definition of a groupoid . \n But we also want compatibility under multiplication, and since \n \n it follows that has another property: it is closed under conjugation, so it is a normal subgroup. Conversely, if we define an equivalence relation by where is a normal subgroup, then \n \n hence \n \n so normality of is equivalent to being compatible with multiplication. Thus talking about surjective group homomorphisms out of (or quotient groups of ), up to a suitable notion of isomorphism, is equivalent to talking about congruence relations on , which is in turn equivalent to talking about normal subgroups of . \n Equivalence relations and quotients of rings \n Let be a ring and let be a ring homomorphism. As before, the relation is an equivalence relation on . But since it must also respect addition and multiplication, satisfies \n \n compatibility with addition: if and then ,\n compatibility with multiplication: if and then .\n \n This defines a congruence relation on rings. Since addition has inverses, we conclude that is equivalence modulo for some normal subgroup of (under addition), namely the kernel of as a homomorphism of additive groups. Since addition is commutative, we can drop the adjective \u201cnormal.\u201d Note that compatibility with addition and multiplication, in the presence of the other axioms, is equivalent to the condition that the equivalence relation, as a subset \n \n of , is a subring. \n As before, we get a quotient map of rings. In addition, compatibility with multiplication implies that \n . \n Thus is closed under left and right multiplication by elements of : it is a two-sided ideal. Conversely, if is a two-sided ideal, then the corresponding equivalence relation has the following property: if , then \n \n and similarly \n \n from which it follows that \n \n hence . So being a two-sided ideal is equivalent to being compatible with multiplication. Thus talking about surjective ring homomorphisms out of (or quotient rings of ) is equivalent to talking about congruence relations on , which is in turn equivalent to talking about two-sided ideals of . \n Equivalence relations and quotients for monoids \n When we try to repeat the above discussion in the setting of monoids we run into the problem that a congruence on a monoid is not completely determined by what is equivalent to the identity since we can no longer rely on inverses. \n Example. Consider the monoids . The monoid admits a surjective homomorphism to sending a generator to a generator. It is not injective, but the kernel is trivial. \n Thus monoids resemble more closely the situation for sets and topological spaces: we have to talk about congruence relations (namely submonoids of which are also equivalence relations) and talking about these isn\u2019t equivalent to talking about special kinds of submonoids of . \n Equivalence relations and quotients for topological spaces \n We close with a less algebraic example. Let be a topological space and let be a continuous function to another topological space . As before, the relation is an equivalence relation on . In the setting of general topological spaces, we cannot say any more about since it can in fact be arbitrary: the set of equivalence classes with respect to any equivalence relation may be given the quotient topology , which is by definition the universal topology such that the quotient map is continuous. \n However, if is Hausdorff (in particular if we are working in a subcategory of the category of Hausdorff spaces), then the equivalence relation, as a subset \n \n of , is the preimage of the diagonal under the map \n . \n Since is Hausdorff, the diagonal is closed (this is equivalent to being Hausdorff!), so its preimage is also closed. Thus the equivalence relation itself must be a closed subspace of . If we restrict ourselves to the category of compact Hausdorff spaces, then it follows that the equivalence relation is a compact Hausdorff subspace of ."], "link": "http://qchu.wordpress.com/2012/08/03/internal-equivalence-relations/", "bloglinks": {}, "links": {"http://feeds.wordpress.com/": 1, "http://www.promys.org/": 1, "http://ncatlab.org/": 2, "http://en.wikipedia.org/": 3}, "blogtitle": "Annoying Precision"}]